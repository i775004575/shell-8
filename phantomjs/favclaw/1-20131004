========== http://blog.sina.com.cn/qingxue ==========
 加载中…
青雪故事
http://blog.sina.com.cn/qingxue [订阅][手机订阅]
首页博文目录图片关于我
个人资料

青雪故事
Qing  微博
加好友发纸条
写留言加关注
博客等级：
博客积分：2332
博客访问：17,349,515
关注人气：7,706
搜博主文章
搜索
添加到我的博客
新浪微博
加载中…
添加到我的博客
公告
《青雪故事》时间
22:00-23:00   FM101.9
19:00-19:30  FM101.9
 
邮箱： 
qinger1038@sina.com
  
青雪简介：现任职于吉林省人民广播电台。
 
曾获全国电视海选知识竞赛节目《智者为王》冠军；新浪“百万博客写车展”大赛冠军及轿车大奖；“新浪年度十大汽车博客”；中国广播文艺奖；中国广电协会“民生影响力广播节目十强”；国家广电总局金鹿奖；中国交通广播奖；东三省汽车越野联赛亚军；吉林省广电系统新闻知识大赛冠军；吉林省广播电视电影局人才优胜工程奖、首届吉林省广播电视电影局最具人气女主持至尊大赏；吉林省卫视《超级发烧友》电影知识大赛冠军；全国中学生地理知识大赛亚军等等50余项国家及省级大奖。
 
连续四年应国家体育总局中汽联指名邀请为全国汽车大赛决赛担任现场解说及评论员。
 
担任数千期文物收藏、汽车评论、音乐欣赏及新闻评论广播电视专栏主播。
分类
全部博文(923)
我是女生(24)
青雪故事(412)
青雪评书(53)
主持“日”记(115)
碟海赶海(33)
流光碎影(85)
食用主义(43)
辣妹爱车(52)
婀娜雅集(25)
集外集(56)
访客
加载中…
我的链接
柴静
坚持的贞德
马未都
博物致知
南派三叔
头文字N
南风窗
喜欢的新闻财经杂志
博文
盗墓笔记续集《藏海花》26-31     (2013-07-24 15:33) 转载▼
标签： 藏海花 盗墓笔记续集 配乐惊悚 青雪故事 有声书	分类： 青雪故事


五年的平静生活，被一块刻有蝎子图案的宝石打断，，，吴邪只身前往西藏，竟然在闷油瓶的笔记当中发现了另外一扇青铜巨门！

“世界的终极”到底是什么？
为何吴邪成了唯一能拯救闷油瓶家族的人？
欢迎收听南派三叔《盗墓笔记》续集——《藏海花》。
 
阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
盗墓笔记续集《藏海花》09-25     (2013-04-19 12:58) 转载▼
标签： 盗墓笔记续集 有声书 青雪故事 配乐惊悚 藏海花	分类： 青雪故事


五年的平静生活，被一块刻有蝎子图案的宝石打断，，，吴邪只身前往西藏，竟然在闷油瓶的笔记当中发现了另外一扇青铜巨门！

“世界的终极”到底是什么？
 
为何吴邪成了唯一能拯救闷油瓶家族的人？
 
欢迎收听南派三叔《盗墓笔记》续集——《藏海花》。
 
青雪故事，好书好听
阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
动漫节青雪场照及COS舞台剧《盗墓镇魂歌》视频首发~     (2013-04-16 11:45) 转载▼
标签： 盗墓笔记 cosplay舞台剧 live现场视频 青雪照片	分类： 流光碎影
    4月14日（周日）下午，中国国际动漫大赛（吉林分赛区）决赛在长春万达广场举行。COS舞台剧《盗墓镇魂歌》（预告篇 GDC出品）于长春现场首发。此为10分钟的“预告篇”完整视频。“参赛版”预计30分钟，“剧场版”90分钟。
    闷油瓶COSER：烈
    吴邪COSER：大强
    摄录：青雪


《盗墓笔记》播讲者青雪应邀LIVE展演，与听友现场
阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
盗墓笔记续集《藏海花》07-08     (2013-04-08 18:37) 转载▼
标签： 文化	分类： 青雪故事


五年的平静生活，被一块刻有蝎子图案的宝石打断，，，吴邪只身前往西藏，竟然在闷油瓶的笔记当中发现了另外一扇青铜巨门！

“世界的终极”到底是什么？
 
为何吴邪成了唯一能拯救闷油瓶家族的人？
 
欢迎收听南派三叔《盗墓笔记》续集——《藏海花》!
 
青雪故事，好书好听。

阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
《盗墓笔记》新版全集第一季49-51     (2013-03-24 16:18) 转载▼
标签： 青雪故事 新版盗墓笔记 第一季 有声书 配乐惊悚	分类： 青雪故事


《盗墓笔记》第一季（新版全集）49——

 
《盗墓笔记》第一季（新版全集）50——

 
阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
盗墓笔记续集《藏海花》04-06     (2013-03-08 20:44) 转载▼
标签： 盗墓笔记续集 藏海花 青雪故事 有声书 配乐惊悚	分类： 青雪故事


    五年的平静生活，被一块刻有蝎子图案的宝石打断，，，吴邪只身前往西藏，竟然在闷油瓶的笔记当中发现了另外一扇青铜巨门！

   “世界的终极”到底是什么？
 
    为何吴邪成了唯一能拯救闷油瓶家族的人？
 
    欢迎收听南派三叔《盗墓笔记》续集——《藏海花》!
 
    青雪故事，好书好听。

阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
《盗墓笔记》新版全集第一季46-48     (2013-02-16 15:38) 转载▼
标签： 盗墓笔记新版 第一季 青雪故事 有声书 配乐惊悚	分类： 青雪故事


《盗墓笔记》第一季（新版全集）46——

 
《盗墓笔记》第一季（新版全集）47——

阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
《盗墓笔记》二（新版）01   (2013-02-06 17:12) 转载▼
标签： 新版 青雪故事 有声书 盗墓笔记第二季 悬疑经典	分类： 青雪故事

再版说明：
    作为国内最先制播《盗墓笔记》的《青雪故事》，因是追着尚未出书的网络版同步播出，实体书上市之后，对于作者三叔重写的文字部分便也进行了重新制播，从而导致“青雪有声版”的《盗墓笔记》前几季之间的内容衔接与实体书不完全一致。

   经过一年多的重新修饬，再版的“新编精华版”《盗墓笔记》全集，应网络听友反映过的“音量差别过大”、“背景配乐声过大”（因青雪是吉林省广播电台的一名主播，当时播出节目的各项指标是专为广播播出而定制的，绝大多数音频符合相关的技术要求，但其中确有数期因设备故障而效果不佳，在此深表遗憾）、“内容衔
阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
盗墓笔记续集《藏海花》01-03     (2013-01-18 13:34) 转载▼
标签： 盗墓笔记 续集 藏海花 青雪故事 试听	分类： 青雪故事

    五年的平静生活，被一块刻有蝎子图案的宝石打断，，，吴邪只身前往西藏，竟然在闷油瓶的笔记当中发现了另外一扇青铜巨门！
 
    “世界的终极”到底是什么？
 
    为何吴邪成了唯一能拯救闷油瓶家族的人？
 
    欢迎收听南派三叔《盗墓笔记》续集——《藏海花》!
 
    青雪故事，好书好听。

《藏海花》第一季01——

阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
《盗墓笔记》新版全集第一季41-45     (2012-12-27 16:31) 转载▼
标签： 盗墓笔记 新版 青雪故事 有声 配乐惊悚	分类： 青雪故事


《盗墓笔记》第一季（新版全集）41——

 
《盗墓笔记》第一季（新版全集）42——

 
阅读  ┆ 评论 	 ┆ 转载 ┆ 收藏  查看全文>>
新浪BLOG意见反馈留言板　不良信息反馈　电话：4006900000 提示音后按1键（按当地市话标准计费）　欢迎批评指正
新浪简介 | About Sina | 广告服务 | 联系我们 | 招聘信息 | 网站律师 | SINA English | 会员注册 | 产品答疑
Copyright © 1996 - 2013 SINA Corporation, All Rights Reserved
新浪公司 版权所有

========== http://cctv.cntv.cn/lm/zuqiuzhiye/index.shtml ==========
登录　注册加入收藏
>> 进入央视网



首播时间：	每周四 18:35
独播频道：	CCTV-5
>> 博客 >> 微博>> 栏目大全
足球之夜首页 往期回顾 CCTV-5官网 足球之夜十五周年专题

2013年9月26日完整版：恒大客场大捷 跨向巅峰
足球之夜完整
[足球之夜]完整版 20130926
[足球之夜]张稀哲领衔中超第21-25轮最佳前卫
[足球之夜]中超第21-25轮最佳前锋：瓦伦西亚
[足球之夜]杜威领衔中超第21-25轮最佳后卫
[足球之夜]中超第21-25轮最佳门将：刘殿座
[足球之夜]留学日记：梅斯塔利亚的欢呼
[足球之夜]中超第21-25轮最佳教练：沈祥福
[足球之夜]中超第21-25轮最佳球员：瓦伦西亚
[足球之夜]联赛榜样第25轮最佳进球：埃尼奥
[足球之夜]联赛榜样第25轮最佳球员：徐亮
[足球之夜]联赛榜样：中超第21-25轮最佳阵容
[足球之夜]夜·聚焦：恒大客场大捷跨向巅峰
第1/1页1 
9月26日节目内容

      本期足球之夜为您带来：亚冠赛后恒大球员第一时间专访回顾比赛；中超第21-25轮各项最佳；新学期聚焦留学西班牙的万达小球员，他们当中有未来的孔卡、穆里奇吗？




往期回顾更多往期视频

2013年9月19日

2013年8月22日

2013年8月15日

2013年8月1日

2013年7月25日

2013年7月18日

2013年7月11日

2013年7月4日
第1/5页1 2 3 4 5 >> 
主持人：刘建宏

国籍：中国
性别：男
民族：汉族
毕业院校：中国人民大学
生日：9月17日
出生地：河北石家庄
星座：处女座
职业：主持人，足球评论员
>>主持人博客>>主持人微博
您可能还喜欢


关于CCTV  |  联系CCTV  |  人才招聘  |  CCTV广告
中国爱乐乐团  |  中国国际电视总公司  |  中国电视网  |  CCTV发展研究中心视听新媒体网  |  中广协会信息资料委员会  |  中广协会电视文艺工作委员会  |  中国新闻记录电影制片厂
中国中央电视台  版权所有
京ICP证060535号  网络文化经营许可证文网文[2010]024号
网上传播视听节目许可证号 0102004  中国互联网视听节目服务自律公约 
========== http://u.youku.com/user_show/id_UMzI4MTU2ODQ=.html ==========

========== http://www.tudou.com/home/wangshirumeng ==========

点播单
 
土豆网
原创电视剧电影综艺更多
注册登录观看历史上传视频
網事如梦的个人主页
http://www.tudou.com/home/wangshirumeng复制链接 | 加入收藏
主页
推过的
上传的视频
编辑的豆单
日志
小组
網事如梦推的
：4月3日-星期三《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:33:28
6个月前转推 私藏 评论
：4月2日-星期二《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:38:24
6个月前转推 私藏 评论
：4月1日-星期一《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:32:41
6个月前转推(2) 私藏 评论(1)
：3月28日-星期四《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:31:17
6个月前转推 私藏 评论
：3月30日-星期六《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:30:33
6个月前转推 私藏 评论
：3月29日-星期五《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:30:16
6个月前转推 私藏 评论
：3月27日-星期三《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:30:33
6个月前转推 私藏 评论
：3月26日-星期二《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:29:56
6个月前转推 私藏 评论
：3月25日-星期一《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:27:53
6个月前转推 私藏 评论
：3月23日-星期六《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:33:10
6个月前转推 私藏 评论
：3月22日-星期五《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:34:05
6个月前转推 私藏 评论
：3月21日-星期四《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:29:18
6个月前转推 私藏 评论
：3月20日-星期三《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:31:29
6个月前转推 私藏 评论
：3月19日-星期二《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:34:02
6个月前转推 私藏 评论
：3月18日-星期一《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:31:22
6个月前转推 私藏 评论
：3月16日-星期六《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:35:12
6个月前转推 私藏 评论
：3月15日-星期五《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:34:53
6个月前转推 私藏 评论
：3月14日-星期四《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:37:05
6个月前转推 私藏 评论
：3月13日-星期三《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:36:01
6个月前转推 私藏 评论
：3月12日-星期二《信不信由你》-2013年 - 本录音由 天上寅间荣誉出品。 天上寅间 与你共享精彩寅生。
 1:33:26
6个月前转推 私藏 评论
查看更多
網事如梦的豆单
查看全部

tsyj
更新: 2011-11-22
视频数: 0

信不信由你 王寅 节目录音 2011年
更新: 2012-01-01
视频数: 285

信不信由你 王寅 节目录音 2010年
更新: 2011-01-01
视频数: 134

信不信由你 王寅 节目录音
更新: 2012-10-19
视频数: 480
網事如梦的视频日历
2013年10月<>
周日周一周二周三周四周五周六29
30
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
1
2
網事如梦 (离线)

0
关注
293
粉丝
421
推
豆花9级
加为关注

发私信     小组邀请
个人信息
最近登录: 2009-12-22
主页浏览: 11234
收视数: 866047
QQ：242555
喜欢的电影/演员/导演:
喜欢的音乐/歌曲/音乐人:
喜欢的书籍/作者:
喜欢的体育:
个人兴趣:
網事如梦的视频日历
2013年10月<>
up
29周日
30周一
1周二
2周三
3周四
4周五
5周六
6周日
7周一
8周二
9周三
10周四
11周五
12周六
13周日
14周一
15周二
16周三
17周四
18周五
19周六
20周日
21周一
22周二
23周三
24周四
25周五
26周六
27周日
28周一
29周二
30周三
31周四
1周五
2周六
down
举报该用户
土豆网
排行榜
频道创新产品软件帮助公司
Copyright © 2005-2013 土豆网 (www.tudou.com)
沪ICP证：沪B2-20120009  网络视听许可证：0908301
广播电视节目制作经营许可证：(沪)字第678号
沪公网安备：3101040256
药品服务许可证：(沪)-非经营性-2008-0051
网络文化经营许可证：沪网文[2012]0101-015
互联网医疗卫生许可证：沪卫(中医)网审[2012]第10015号
请使用者仔细阅读土豆使用协议和版权政策
中国互联网违法和不良信息举报中心
上海市举报中心 网络违法犯罪举报网站
“扫黄打非”办公室举报中心：12390

========== http://www.yoyo2008.com/ ==========
========== http://www.tudou.com/programs/view/lfVPoK8nD3s/ ==========
========== http://www.tudou.com/programs/view/5cycwJxJntw/ ==========
土豆网
电视剧
 
登录注册
观看历史
上传
倚天屠龙记[马景涛版]01
倚天屠龙记[马景涛版]01
加载中...
土豆网
 
频道创新产品软件帮助公司
Copyright © 2005-2013 土豆网 (www.tudou.com)
沪ICP证：沪B2-20120009  网络视听许可证：0908301
广播电视节目制作经营许可证：(沪)字第678号
沪公网安备：3101040256
药品服务许可证：(沪)-非经营性-2008-0051
网络文化经营许可证：沪网文[2012]0101-015
互联网医疗卫生许可证：沪卫(中医)网审[2012]第10015号
请使用者仔细阅读土豆使用协议和版权政策
中国互联网违法和不良信息举报中心
上海市举报中心 网络违法犯罪举报网站
“扫黄打非”办公室举报中心：12390

========== http://www.soku.com/search_video/q_%E5%B7%A6%E8%BD%AE%E5%90%89%E4%BB%96 ==========
电影票 排行榜 影视大全 优酷 土豆



视频专辑用户
全网优酷土豆
综合排序
最新发布
最多播放
最多评论
最多收藏
筛选条件

07:23
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 469,411
发布: 2年前

09:17
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 369,163
发布: 2年前

04:34
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 319,694
发布: 2年前

06:07
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 299,433
发布: 2年前

10:59
ramones rd-36民谣吉他评测
用户: 左轮儿@taobao
播放: 1
发布: 7小时前

08:03
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 288,676
发布: 2年前

09:49
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 252,353
发布: 2年前

07:40
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 276,017
发布: 2年前

08:02
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 273,386
发布: 2年前

12:18
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 250,315
发布: 2年前

06:10
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 299,514
发布: 2年前

07:45
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 256,065
发布: 2年前

08:39
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 241,388
发布: 2年前

06:13
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 223,292
发布: 2年前

08:25
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 210,982
发布: 2年前

07:10
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 154,341
发布: 2年前

05:41
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 148,543
发布: 2年前

11:31
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 136,760
发布: 2年前

06:28
左轮吉他初级入门教程《人人可以弹吉他》..
用户: 左轮吉他网
播放: 153,022
发布: 2年前

03:15
左轮吉他店 JOYO OD30 前级电子管吉他音箱
用户: 左轮儿@taobao
播放: 335
发布: 1月前
1 2 3 4 5 6 7 8 9 10 下一页
相关搜索: 左轮吉他初级入门教程 左轮吉他初级入门教程合集 左轮吉他初级入门教程9 左轮吉他教学 左轮电吉他自学入门教学 :左轮电吉他自学入门教学全集 : 左轮电吉他自学入门教学-7 [电吉他教学入门教程左轮 : 左轮电吉他教学 :+左轮民谣吉他教学有没有人告诉你 : 左轮民谣吉他教学入门1教程 吉他左轮扫弦

Copyright©2013 搜库soku.com版权所有 京ICP证060288号 免责声明 开放协议

========== http://v.youku.com/v_show/id_XMTY4MjcyMjA0.html ==========


上传
观看记录
登录|注册
首页
频道

综艺频道 > 综艺列表 > 小品
视频: 小品【算命】笑抽了

您还没有安装flash播放器,请点击这里安装
 15:17
2012赵本山最新小品<不差钱后传>
2644912441
158,007 5
25:09
赵本山春晚被毙掉的小品
兰亭墨客
1,090,276 61
04:21
小沈阳谢娜主持新闻联播，笑死银了。。。
吴小超。
240,392 121
16:53
2013春晚小品【大考当前】
蔡群根
415,942 49
03:09
能笑掉大牙 赵四打吊瓶 赵四
ximi180
99,131 4
03:19
赵本山最新小品《出名》
阍阍
198,653 10
12:49
不看会后悔的！！！央视被毙掉 《送礼》...
最新原娱乐
186,425 50
08:32
2013春晚小品【山里的娘们山里汉】
蔡群根
219,246 12
07:18
太搞笑了啊，赵四不红，天理不容啊，赵...
xiaoweizi828
43,206 4
06:04
赵四（刘小光）二人转小品（借酒消愁）
香山幽谷
124,509 13
18:23
刘小光（赵四） 网络春晚 逗笑全场
励志创业28
19,929 0
16:50
赵四 爆笑二人转，笑尿你！
丘丘a140
44,281 2
27:04
赵本山小品大全《屌丝女士搞笑》
中国好声音2
40,333 3
08:33
搞笑东北二人转【卖土豆的故事】.flv
单身战神
1,065,920 175
04:25
赵四（刘小光）爆笑二人转小品找媳妇
haorennanzuoa
247,348 29
03:43
赵四街舞逆袭(江南style) 太逗了！ 高清
抬头看弯月
127,410 27

00:42
刘小光《江南style》
beyond帝国网络家园
60,774 2
14:18
超级搞笑小品--《算命》
上帝阿拉
18,723 11
01:34
美女擦鞋工
半醉坊、123
39,957 0
677147

收藏
下载
一点即发 将视频下载到手机
用手机看
播放

心情驿站king
订  阅
请等待我稍后补充视频描述
评论 转发     
3年前 上传自 优酷PC客户端
登录|注册
0/300

表情
发表评论
全部评论

发表评论
资源
首页 电视剧 电影 综艺 视频
社区
空间 看吧
 
分类
资讯 拍客 体育 汽车 科技 财经
广告 娱乐 原创 音乐 游戏 公益
生活 时尚 教育 旅游 搞笑
 
软件
PC客户端
手机客户端
实验室开放平台
 
支持
繁体版
在线反馈
帮助中心
 
优酷土豆集团
Youku Tudou Inc.
关于优酷
友情链接
 
优酷
Youku.com
优酷指数
工作机会
 
土豆网
Tudou.com
媒体合作
广告服务
 经营性网站备案信息

 中国互联网诚信联盟

 不良信息举报中心

北京互联网举报中心

 
京ICP证060288号

网络视听许可证0108283号

网络110报警服务

北京12318文化市场举报热线

 
网络文化经营许可证 文网文[2011]0088-037号

新出网证(京)字160号 节目制作经营许可证京字670号

京卫审字[2009]6号 京公网安备110000000017号

药品服务许可证(京)-经营-2010-0048

 优酷App
扫描或点击下载
请使用者仔细阅读优酷使用协议和版权声明 Copyright©2013 优酷 youku.com 版权所有
========== http://v.youku.com/v_show/id_XMTMzMDM3NDg=.html ==========


上传
观看记录
登录|注册
首页
频道

报卡
关灯
弹窗
综艺频道 > 综艺列表 > 小品
视频: 大工小品《审小偷》

您还没有安装flash播放器,请点击这里安装
 
12:33
虚惊一场 大工电信爆笑小品
tianyi407
7,979 3

28:50
大工爆笑小品 甲流风云 12届峰岚杯 特约...
暮狐秋
80,633 67
15:39
非常经典的大学生搞笑小品(太有才了,太...
liubo536455
614,794 855
21:44
大学生搞笑小品 我差点笑破肚皮
没有email
313,894 79
18:28
峰岚杯物理经济板块05
zhaohuicong
7,873 42

21:44
东北大学全场笑声78次、爆笑42次小品《...
scientist1
1,066,831 203

20:33
爆笑大学生小品，有史以来看到最搞笑得...
攀藤网版权
49,599 61
19:34
超级有才的大学生
玉门不恨春风
9,205,336 10,806
09:01
大连理工DV－爱情上甘岭
weng640
2,297 3
21:42
21分钟让观众爆笑143次的小品（完整带字...
yanrui19830511
3,142,885 2,178

22:37
【2011史上最牛B毕业生晚会小品《与青春...
jiakeqing
75,772 236
05:20
大连理工大学，献给2007届毕业生
deoman
2,038 11
23:48
咱理工土木院的小品
janjay123
565,357 622
15:12
【爆笑】中传毕业晚会小品，基情四射啊...
泡芙来了
596,895 2,380

13:38
大学生搞笑小品《巅峰对决》
西门小凯
14,310 6
03:22
爆笑：班上只有一个男生的后果！太搞笑了！
爱人坊
3,754,472 1,185
09:30
四川大学高分子学院08届迎新晚会，超搞...
guangguang8724
503,009 688
01:33
超级搞笑的大学生小品之行骗经典造型
麻辣重庆
110,316 26

22:22
09年最搞笑的大学小品《比武招亲》
移不动连不通
89,543 35

12214

收藏
下载
一点即发 将视频下载到手机
用手机看
播放:15,754

zzyround
订  阅
大连理工峰岚杯上的小品，非常搞。
评论 转发     
5年前 上传

登录|注册
0/300

表情
发表评论
全部评论(19)
第1-19/19条
上一页
下一页
1

国贸后勤部长
这海蛎子味
回复 转发     
9个月前 来自优酷

runrunrun321
哇塞~~爱死了
回复 转发     
9个月前 来自优酷

流动的色彩Co
出门让飞机撞死
回复 转发     
3年前 来自优酷

流动的色彩Co
他俩就是 大工另一个小品 心理医生的扮演者吧.
回复 转发     
3年前 来自优酷

xiajibatutu
你个2B //@hahahaha5：大连人就是这么正义 你们沈阳人看着办吧
回复 转发     
3年前 来自优酷

hahahaha5
大连人就是这么正义 你们沈阳人看着办吧
回复 转发     
3年前 来自优酷

ysc8589
说的是---你沈阳人看着办吧！ //@夏雨凌阳：是你们沈阳人不行 
回复 转发     
3年前 来自优酷

889king

回复 转发     
3年前 来自优酷

xpanuo
我看了两遍才听明白 //@edogawakyo：为什么根本都听不懂！！！！！
回复 转发     
3年前 来自优酷

xpanuo
今年的一部大片 //@亡灵使者影客：神话前一句啥玩意来的
回复 转发     
3年前 来自优酷

edogawakyo
为什么根本都听不懂！！！！！
回复 转发     
3年前 来自优酷

亡灵使者影客
神话前一句啥玩意来的
回复 转发     
3年前 来自优酷

与中国同在
非常棒！！
回复 转发     
4年前 来自优酷

夏雨凌阳
是你们沈阳人不行 //@超级小宝宝宝：大连人就是这么正义，后面那句是什么啊
回复 转发     
4年前 来自优酷

跳跳龙
有才 服了
回复 转发     
4年前 来自优酷

超级小宝宝宝
大连人就是这么正义，后面那句是什么啊
回复 转发     
4年前 来自优酷

夜神月vsl
现场看氛围更好哈，赞一个，太逗了
回复 转发     
5年前 来自优酷

陈铁西
[
回复 转发     
5年前 来自优酷

Snakewolf

回复 转发     
5年前 来自优酷
第1-19/19条
上一页
下一页
1
发表评论
资源
首页 电视剧 电影 综艺 视频
社区
空间 看吧
 
分类
资讯 拍客 体育 汽车 科技 财经
广告 娱乐 原创 音乐 游戏 公益
生活 时尚 教育 旅游 搞笑
 
软件
PC客户端
手机客户端
实验室开放平台
 
支持
繁体版
在线反馈
帮助中心
 
优酷土豆集团
Youku Tudou Inc.
关于优酷
友情链接
 
优酷
Youku.com
优酷指数
工作机会
 
土豆网
Tudou.com
媒体合作
广告服务
 经营性网站备案信息

 中国互联网诚信联盟

 不良信息举报中心

北京互联网举报中心

 
京ICP证060288号

网络视听许可证0108283号

网络110报警服务

北京12318文化市场举报热线

 
网络文化经营许可证 文网文[2011]0088-037号

新出网证(京)字160号 节目制作经营许可证京字670号

京卫审字[2009]6号 京公网安备110000000017号

药品服务许可证(京)-经营-2010-0048

 优酷App
扫描或点击下载
请使用者仔细阅读优酷使用协议和版权声明 Copyright©2013 优酷 youku.com 版权所有
========== http://www.youku.com/playlist_show/id_5964257.html ==========

排行榜电视剧电影综艺音乐动漫App下载
全部
上传
观看记录
通知
登录 注册
视频: 38 | 总时长: 02:50:31 | 总播放: 11,558 | 创建: 2年前 | 更新: 2年前
专辑: 摇滚 电吉他 入门 （赵卫）
音乐频道 >>	 专辑列表 >> 音乐 >>
收藏本专辑
视频列表
图片详情
播放排序:   与创建顺序相同   与创建顺序相反

00:44
CD1 03 片头3
 wangben79
173

02:01
CD1 04 弹奏电吉他 需要的设备
 wangben79
593

18:05
CD1 05 电吉他 及其构造
 wangben79
641

04:05
CD1 06 持琴的姿势 坐姿 站姿
 wangben79
196

07:12
CD1 07 左手 弹奏方法
 wangben79
379

04:07
CD1 08 右手拨片 拿法
 wangben79
980

06:15
CD1 09 右手拨片 弹奏方法
 wangben79
708

05:58
CD1 10 左右手 配合练习
 wangben79
325

04:32
CD1 11 定音的方法
 wangben79
193

08:52
CD1 12 C大调的把位
 wangben79
187

09:27
CD2 01 C大调 音阶模进
 wangben79
195

05:22
CD2 02 左右手 弹奏练习
 wangben79
162

06:25
CD2 03 八分音符 节奏练习
 wangben79
411

01:36
CD2 04 八分音符 Hard Rock 练...
 wangben79
147

01:40
CD2 05 八分音符 重金属节奏 练...
 wangben79
431

03:09
CD2 06 八分拖拍 节奏练习
 wangben79
178

01:58
CD2 07 八分拖拍 练习曲
 wangben79
116

02:41
CD2 08 三连音节奏 练习
 wangben79
275

02:23
CD2 09 Shuffle 节奏练习
 wangben79
168

03:57
CD2 10 十六分音符 （Funk） 练习
 wangben79
175
首页 | << | 1 2 | >> | 末页 38条的第1-20条
专辑信息
wangben792年前
全部专辑信息
标签:摇滚 电吉他 入门 （赵卫） >>
相关话题进入看吧
排行榜爱在春天两个爸爸好心作怪快男
资源
首页电视剧电影综艺视频
社区
空间看吧
分类
资讯拍客体育汽车科技财经 广告娱乐原创音乐游戏公益生活时尚教育旅游搞笑
软件
PC客户端
手机客户端
实验室
支持
繁體版
在线反馈
帮助中心
集团优酷土豆网About UsYouku.comTudou.com关于优酷优酷指数媒体合作友情链接工作机会广告服务
 经营性网站备案信息 京ICP证060288号网络文化经营许可证 文网文[2011]0088-037号 中国互联网诚信联盟 网络视听许可证0108283号新出网证(京)字160号 节目制作经营许可证京字670号 不良信息举报中心网络110报警服务京卫审字[2009]6号 京公网安备110000000017号北京互联网举报中心北京12318文化市场举报热线药品服务许可证(京)-经营-2010-0048
请使用者仔细阅读优酷使用协议和版权声明
Copyright©2013 优酷 youku.com 版权所有

========== http://www.anysql.net/ ==========
AnySQL.net
数据复制，数据迁移，数据库优化，系统监控，备份恢复，报表展现，原创工具等
 
Weblog
Question
产品介绍
技术服务
工具下载
博客聚合
文章归档
关于我们
Tips: ASM Recovery, AUL License, DBA Tools, MyDUL.net, weibo.com/dbatools

 
orastats & mysqlstats通用监控工具
Posted by anysql on 2013-03-19
    以前曾写过Oracle与MySQL的监控工具，但随着数据库版本的变化，性能指标也在发生变化，常常需要改进代码，然后再进行编译，比较麻烦。这个时间和OceanBase开发人员在一起久了，受了他们一点灵气的影响，想出了通用的监控工具的方法。
    将所有性能指标理解成一个Key及一个Value的组合，Key为字符串类型，Value为浮点数类型，可以自定义SQL在数据库中查询出来。比如下面的SQL语句：
select name, bytes from v$sgastat
union all
select name, value from v$sysstat
    将上面查询的结果，再加一个当前的时间点(Key=orastats.timestamp)存放到一个Hash表中，然后根据一定的格式规则显示出其中的数据，就是一个非常好的通用监控工具了，我们以如下SQL为例。
select name, value from v$sga
    输出格式使用如下格式进行控制，对任何一个Key需要指定数值的类型（显示当前值还是差量值？），然后指定一个简写的指标名字。
Key|{CURR|DELTA}|Label|...
    编写如下的文本文件(orastats.txt)。
user=sys
query=select name, value from v$sga
format=Fixed Size|curr|Fixed|
        Variable Size|curr|VarS|
        Database Buffers|curr|Data|
loop=10
wait=5
    使用orastats工具来运行，就可以得到如下有效的监控输出。
D:\MyTools\x64>orastats parfile=orastats.txt
2013-03-19 22:57:08 Fixed VarS Data
2013-03-19 22:57:08 2174k 134m 134m
2013-03-19 22:57:13 2174k 134m 134m
2013-03-19 22:57:18 2174k 134m 134m
2013-03-19 22:57:23 2174k 134m 134m
2013-03-19 22:57:28 2174k 134m 134m
2013-03-19 22:57:37 2174k 134m 134m
    不指定Format选项的话，会以Key/Value的方式显示数据。
D:\MyTools\x64>orastats parfile=orastats.txt wait=5 loop=1 format=
orastats.timestamp=2013-03-19 22:58:46
Database Buffers=134217728.000000
Fixed Size=2174888.000000
Redo Buffers=5005312.000000
Variable Size=134217816.000000
    为MySQL也准备了类拟的工具(mysqlstats)，这样的话数据库的版本变了，只需要改一下配置文件即可以跟上时代了，明天会加入Linux下的一些基本负载信息，就可以完全用于收集Oracle或MySQL的性能数据了。
ToolsNo Comments »
从MySQL迁移数据到Oracle库的工具
Posted by anysql on 2013-02-01
    MySQL用于处理简单事务，还是不错的，但用于保存较大的数据则还不行，一般公司的历史库之类的还是可以用Oracle进行保存，那么从MySQL如何迁移数据到Oracle呢？MySQL的文本导出工具（MYSQLULDR2）固然是一个不错的选择，将数据导成文本，然后用SQL*Loader进行导入，不过不落地的工具使用起来会更方便。在以前写的程序的基础上，很容易就写出了一个MYSQL2ORA工具，并且性能也不错。
    使用Direct Load方式，将MySQL的表对拷到Oracle数据库中，要以用如下语法，因为MySQL中建议用自增主键，所以相对于Oracle中多了一个ID列，在导入过程中使用FILLER选项直接跳过。
mysql2ora.exe user1=/@::test user2=test/test table1=emp_his table2=emp_his direct=yes filler=id
          0 rows processed at 2013-02-01 21:01:39.
    1000000 rows processed at 2013-02-01 21:01:41.
    2000000 rows processed at 2013-02-01 21:01:44.
    3000000 rows processed at 2013-02-01 21:01:46.
    3830800 rows processed at 2013-02-01 21:01:48.
    使用普通方式，只要不加DIRECT选项就行了，拷贝数据的话，本质是源端一个SQL语句（query1）以及目标端一个DML语句（query2），大家可以更灵活地指定。
mysql2ora.exe user1=/@::test user2=test/test table1=emp_his table2=emp_his filler=id
          0 rows processed at 2013-02-01 21:11:24.
    1000000 rows processed at 2013-02-01 21:11:28.
    2000000 rows processed at 2013-02-01 21:11:32.
    3000000 rows processed at 2013-02-01 21:11:37.
    3830800 rows processed at 2013-02-01 21:11:40.
    可以下载Windows版本或Linux版本进行测试，商业环境使用请支持100RMB给开发者，以创造良好的技术生存环境。
ToolsNo Comments »
按事务一致性导出的数据
Posted by anysql on 2013-01-31
    昨天收到一邮件，内容如下：
Hi Fangxin,
I’ve just discovered your tool and am excited about the prospect of using it for some of our extract needs. The problem is, I often have sets of tables which must be extracted with a consistent view across those tables at a specific point in time. As such, we normally, set a read only transaction, extract the data from table 1 to file 1, then table 2 to file 2, then table 3 to file 3, then commit. This gives us data integrity and consistency across those tables even if updates/deletes are going on while we are extracting. Is there any way to accomplish this using your sqluldr2 tool?
Please note that our customer does not enable Oracle flashback in production so using the “as of” notation across separate runs is not an option. Thanks in advance for your assistance.
-Eric
    想一想这个要求还是合理的，于是给工具增加了query2-query9的选项，以实现按事务导出功能，加上"presql"选项就可以实现按读事务导出了, 使用方法如下：
user=stats_user/stats_user@tooldb
presql=set transaction read only
query=select * from all_objects
file=nul
query2=select * from all_tables
file2=nul
    执行的日志如下所示，在一个命令里导出多个表。
E:\>.\sqluldr2 parfile=test.txt
          0 rows exported at 2013-01-31 13:07:43, size 0 MB.
      12916 rows exported at 2013-01-31 13:07:44, size 1 MB.
        output file nul closed at 12916 rows, size 1 MB.
          0 rows exported at 2013-01-31 13:07:44, size 0 MB.
        1435 rows exported at 2013-01-31 13:07:44, size 0 MB.
        output file nul closed at 1435 rows, size 0 MB.
    不过这个改动还是没有能够满足那个网友的要求，他有192个表需要在一个事务里时出，用SQL*Plus太慢了，才找到我这个工具的，这样的需求是不是有一点点特殊? 还是大家都有同样的需求？
Tools2 Comments »
从MySQL数据库自由导出文本
Posted by anysql on 2013-01-18
    MySQL上处理一些简单的事务是不错的，但历史数据的保存不能靠MySQL，所以还是得将数据导出来，存放到其他数据库（Oracle）或数据仓库（HBase），MySQL本身虽然提供了生成文本文件的方法，但并不是很好用，比如将文本文件导入到Oracle的话，还需要一个控制文件，编写控制文件是一个比较麻烦的事情，SQL Server或Sybase也需要一个格式说明文件，才能方便地导入。为此将Oracle的文本导出工具改造了一下，发布了MySQL版的文本导出工具 -- MySQLULDR2。
SQL*UnLoader: Fast Oracle Text Unloader (GZIP, Parallel), Release 4.0.1
(@) Copyright Lou Fangxin (AnySQL.net) 2004 - 2010, all rights reserved.
Usage: MYSQLULDR2 keyword=value [,keyword=value,...]
Valid Keywords:
  user    = username/password@tnsname
  sql    = SQL file name
  query  = select statement
  field  = separator string between fields
  record  = separator string between records
  rows    = print progress for every given rows (default, 1000000)
  file    = output file name(default: uldrdata.txt)
  log    = log file name, prefix with + to append mode
  fast    = auto tuning the session level parameters(YES)
  text    = output type (MYSQL, CSV, MYSQLINS, ORACLEINS, FORM, SEARCH).
  charset = character set name of the target database.
  ncharset= national character set name of the target database.
  parfile = read command option from parameter file
  for field and record, you can use '0x' to specify hex character code,
  \r=0x0d \n=0x0a |=0x7c ,=0x2c, \t=0x09, :=0x3a, #=0x23, "=0x22 '=0x27
    使用方法很简单，指定一个连接信息（用户名/口令@主机:端口:数据库），并指定一个查询语句或者表名就可以了。比如：
D:\MyTools>mysqluldr2 /@::test query=emp_his file=emp_his.txt
      0 rows exported at 2013-01-18 07:56:14, size 0 MB.
  819200 rows exported at 2013-01-18 07:56:16, size 42 MB.
        output file emp_his.txt closed at 819200 rows, size 42 MB.
    直接指定表名时，会自动生成Oracle SQL*Loader的控制文件，内容如下：
OPTIONS(BINDSIZE=2097152,READSIZE=2097152,ERRORS=-1,ROWS=50000)
LOAD DATA
INFILE 'emp_his.txt' "STR X'0a'"
INSERT INTO TABLE emp_his
FIELDS TERMINATED BY X'2c' TRAILING NULLCOLS 
(
  empno CHAR(16) NULLIF empno=BLANKS,
  ename CHAR(10) NULLIF ename=BLANKS,
  job CHAR(9) NULLIF job=BLANKS,
  mgr CHAR(16) NULLIF mgr=BLANKS,
  hiredate DATE "YYYY-MM-DD HH24:MI:SS" NULLIF hiredate=BLANKS,
  sal CHAR(20) NULLIF sal=BLANKS,
  comm CHAR(20) NULLIF comm=BLANKS,
  deptno CHAR(16) NULLIF deptno=BLANKS
)
    可以下载Windows版本或Linux版本进行测试，商业环境使用请支持100RMB给开发者，以创造良好的技术生存环境。
ToolsNo Comments »
SQLULDR2的安全保密功能
Posted by anysql on 2013-01-14
    SQLULDR2也许是我所有工具中被使用最广泛的，因此也是最成熟的，上一次修改需求是在一年多以前，为MySQL的Insert语句导出功能增加Hex函数支持。不过用户的需求是无止境的，有网友要求增加一个安全保密功能，对导出的数据内容进行简单的加密操作,我觉得是合理的功能，就快速实现了。
    只需要在导出时加上"crack"选项，指定加密的KEY就可以了，不管生成的是格式化文本，还是Insert语句，所有内容都被加密了。
E:\>sqluldr2 user=dict/ali88@tooldb query=tab file=a.dat crack=anysql
      0 rows exported at 2013-01-14 16:28:06, size 0 MB.
    128 rows exported at 2013-01-14 16:28:06, size 0 MB.
        output file a.dat closed at 128 rows, size 0 MB.
    同样SQLULDR2也提供了解密功能，同样需要用"uncrack"选项来指定解密的KEY，以及用"file"选项来指定要解密的文件（可以接受标准输入），解密后的内容写出到标准输出设备。
E:\>sqluldr2 uncrack=anysql file=a.dat
TASK_INFO,TABLE,
ALI_SQLFILE,TABLE,
ALI_SQLSTATEMENT,TABLE,
TRANS_TMP_1,TABLE,
TRANS_TMP_2,TABLE,
......
    如果要接受标准输入来进行解释，则指定"file"选项的值为"-"就可以。
E:\>type a.dat | sqluldr2 uncrack=anysql file=-
TASK_INFO,TABLE,
ALI_SQLFILE,TABLE,
ALI_SQLSTATEMENT,TABLE,
TRANS_TMP_1,TABLE,
TRANS_TMP_2,TABLE,
......
    加密功能本身的逻辑比较简单，并且会影响性能，希望不是在巨量数据导出中使用。
Tools8 Comments »
Previous Entries
RSS Feeds
新浪微博(dbatools)
RSS 2.0


Donate Payment
AliPay: anysql@yahoo.com
PayPal: anysql@live.com
Contact Me
Name: Fangxin Lou
QQ: 37223884
MSN: anysql@live.com
Mail: anysql@gmail.com
Mobile: +86 15925611590
Top Download
AUL6 for Windows
AUL6 for Linux
AUL6 for Linux x86-64
SQLULDR2
Data Copy
Data Replication
DataReport
DataReport Upgrade
Oracle Monitor
Linux Performance Monitor
Gather Data Utility
New GetDDL
Schema Compare & Repair
ScanData Utility (HTTP)
Ora2MySQL Windows
Ora2MySQL Linux 32
Ora2MySQL Linux x86-64
MySQL Copy Windows
MySQL Copy Linux 32
MySQL Copy Linux x86-64
Categories
AnySQL (19)
AUL/MyDUL (76)
DBA (123)
Developer (75)
Life (115)
MySQL (16)
Oracle (93)
Photos (7)
Research (24)
Tools (148)
Weblog (48)
Links
DBA notes (Web 2.0)
DBA Tools (English)
Eygle (Oracle Life)
MySQL DBA 论坛
NinGoo.net (DBA)
Taobao DBA Team
eagle's fan (eBay DBA)
数据工人 (DBA Support)
玉面飞龙(经济与DBA)
sybase数据库恢复
DB Thinker (jametong)
Brotherxiao (AliPay DBA)
存贮部落 (sansky.net)
程序员兼职
Recent Posts

orastats & mysqlstats通用监控工具
03-19-2013
从MySQL迁移数据到Oracle库的工具
02-01-2013
按事务一致性导出的数据
01-31-2013
从MySQL数据库自由导出文本
01-18-2013
SQLULDR2的安全保密功能
01-14-2013
用自定义Tag在JSP中集成WebChart的图表功能
07-25-2012
让WebChart从本地文件读取数据
06-06-2012
使用mysqlcopy来迁移MySQL历史数据
06-05-2012
用squldr2进行Oracle到MySQL的数据迁移
05-17-2012
WebChart的JSON格式输出
12-09-2011
Recent Comments

cn0936it: HP-UX编译出错: Undeclared variable 'prepareSql'. Perhaps 'prepa...
cn0936it: hp-ux下编译提示： Error 203: "ociuldr.c", line 326 # Cannot assig...
anysql: 楼上的，你至少给个表结构，及SQL语句，我才能调试啊。...
Onion: 修改了SELECT 的查询语句，发现 - DATADATE DATE, – RCV_DATE VARCHAR2(4...
Onion: 现在使用的是1月31日编译的190147，C5039CC5 版本测试的。 问题，是有的linux 11g数据库连接...
anysql: 请使用最新的版本试一下。...
Onion: -- -- SQL*UnLoader: Fast Oracle Text Unloader (GZIP), Relea...
anysql: 32768的是因为long或lob字段的原因吧。...
Onion: 对了，环境是这样的，服务端HP-UX rx6600-2 B.11.31 U ia64 unlimited-user li...
Onion: 这两天在测试中发现使用SQLULDR2生成control文件时候,取出的字段VARCHAR2(32768),而实际的仅少...
Meta

Log in
Valid XHTML
XFN
WordPress
Entries RSS
Comments RSS
Wordpress Theme by Windows Vista Security (©)Copyright 2006-2010 AnySQL.net. All rights reserved.
========== http://www.cnblogs.com/gaizai/ ==========
Spiga
Posts - 119, Articles - 12, Comments - 772 Cnblogs Dashboard Login
HOMECONTACTGALLERY
RSS
我帅故我在
兼职SQL SERVER & MYSQL性能调优顾问。
[置顶]SQL Server 复制系列（文章索引）
2013-09-30 17:04 by 听风吹雨, 8 visits, 网摘, 收藏, 编辑
摘要：前言SQL Server的复制、日志传送、镜像等几个高级功能中，个人感觉复制是比较符合我的生产环境的要求的，其实搭建复制并不难，但是在网上关于：通过备份文件初始化复制、跨网段（跨机房）复制的文章会比较少，这里就着重讲讲这些内容；下图是一个关于SQL Server通过备份文件初始化复制的逻辑结构图：（Figure1：SQL Server备份文件初始化订阅逻辑结构图）为了与SQL Server的复制进行对比，我们去了解下一下MySQL的Master/Slave，下图是关于MySQL通过备份文件初始化复制的逻辑结构图：（Figure2：MySQL备份文件搭建Master/Slave逻辑图）系列文章索 阅读全文
0 Comment
Tags: SQL Server, 数据库
[置顶]Ubuntu12下挂载硬盘（9TB）（文章索引）
2013-02-16 17:41 by 听风吹雨, 732 visits, 网摘, 收藏, 编辑
摘要：前言在linux下挂载硬盘，很多人说使用mount，但是这个是挂载一个硬盘，如果想让服务器可以把硬盘都挂载到同一个目录下，mount是无法实现的，但是很多应用都有某个目录的空间足够大。下面的文章就是一步步教你怎么挂载的。实战说明经过实战，已经成功挂载了9TB的空间。（Figure：磁盘信息）系列文章索引Step1：Ubuntu12下挂载硬盘（9TB）Step2：Ubuntu12下未知驱动器处理Step3：Ubuntu12下重新挂载硬盘Step4：Ubuntu12下挂载存储柜硬盘Step5：Ubuntu12下挂载硬盘（9TB）Shell版 阅读全文
0 Comment
Tags: Ubuntu, Linux
[置顶]Ubuntu10下MySQL搭建Amoeba系列（文章索引）
2012-06-12 18:57 by 听风吹雨, 1142 visits, 网摘, 收藏, 编辑
摘要：前言使用了Amoeba有一段时间了，发现官方博客：Amoeba使用指南有很多地方都是错误的，在我实战中给到一些错误的指示，所以我想写些在搭建的实战中给大家一点指引。欢迎对我这个系列的文章提出批评和建议，特别是技术上的建议。Amoeba读写分离+分片逻辑图下面是我画得关于Amoeba读写分离和分片的逻辑图：系列文章索引Ubuntu10下安装JAVA JDKUbuntu10下MySQL搭建Amoeba_基础Ubuntu10下MySQL搭建Amoeba_分片Ubuntu10下MySQL搭建Amoeba_分片升级版Ubuntu10下MySQL搭建Amoeba_读写分离Ubuntu10下MySQL搭建A 阅读全文
4 Comment
Tags: MySQL, Amoeba, Ubuntu
[置顶]SQL Server 2005 性能优化实战系列（文章索引）
2012-01-20 14:54 by 听风吹雨, 3244 visits, 网摘, 收藏, 编辑
摘要：前言性能优化是数据库方向一个很重要的技能，这也是快速提供企业级应用性能最快捷的方式，所以性能优化的高低很大程度上表现了个人技能的高低。下面的文章是我在实际项目中性能优化的一些经验，希望对那些需要实战帮助的童鞋有一点提示和帮助。希望大家拍砖。系列文章索引SQL Server 2005表分区实战系列（文章索引）SQL Server 数据库服务器高性能设置SQL Server 2005 扩展函数的基本概念SQL Server 2005 使用扩展函数进行性能优化SQL Server 2005 Url正则表达式 内存常驻完美解决方案SQL Server 2005 索引中include的魅力（具有包含性列 阅读全文
5 Comment
Tags: SQL Server, 数据库
[置顶]SQL Server 维护计划备份主分区
2011-10-09 11:52 by 听风吹雨, 10422 visits, 网摘, 收藏, 编辑
摘要：一、场景经过一段时间表分区的实践，我们先对表进行分区（形成表分区模板）；表数据搬迁模板（迁移数据到新的分区表）；分区管理自动化（自动化进行交换分区）；详情请见：SQL Server 表分区实战系列（文章索引） 再进一步延伸，我们就需要对这些做了表分区的库进行备份了，之前写过一篇博文：SQL Server 备份和还原全攻略，这里描述了MSSQL的一些备份概念，今天这里虽然没有用到，但是像差异备份在备份比较大的情况下使用就会有很好的效果。 今天我们就来说说如何使用MSSQL的维护计划来备份表分区的。假设这样一个场景：一个数据库现在已经几十G（如图1），但是占用主要空间的就是一两个表的数据（流水记录 阅读全文
7 Comment
Tags: SQL Server, 解决方案, 备份, 维护
[置顶]SQL Server 设计开发系列（文章索引）
2011-08-29 15:47 by 听风吹雨, 2517 visits, 网摘, 收藏, 编辑
摘要：前言数据库的设计与开发包括了很多东西，也许就是一个设计思想：比如空间换时间方案，读写分离，水平切分表，HA群集等；开发方面就包括脚本的开发、扩展函数，涉及到一些SQL的使用。 该系列还在完善中，欢迎大家指出还缺少些什么内容的维护，我会在后面的文章中陆续补充的。系列文章索引SQL Server数据库帐号密码安全设计简单实用SQL脚本简单实用SQL脚本Part2：日期和时间函数简单实用SQL脚本Part：游标模板简单实用SQL脚本Part：查找SQL Server 自增ID值不连续记录简单实用SQL脚本Part：生成站点导航树形结构简单实用SQ脚本Part：sql多行转为一列的合并问题简单实用SQ 阅读全文
5 Comment
Tags: SQL Server, 数据库
[置顶]SQL Server 维护管理系列（文章索引）
2011-07-15 14:52 by 听风吹雨, 1917 visits, 网摘, 收藏, 编辑
摘要：前言数据库的维护其实包括很多方面，用户权限、数据备份等，这方面的积累也是必不可少的，所以这里把一些常用的的维护进行一些总结，这些文章的特点就是我会使用比较多的图片进行说明，大家看起来会比较直观。 该系列还在完善中，欢迎大家指出还缺少些什么内容的维护，我会在后面的文章中陆续补充的。系列文章索引SQL Server 数据库帐号密码生成SQL Server 维护计划实现数据库备份SQL Server 备份和还原全攻略SQL Server 数据库迁移偏方SQL Server 数据库最小宕机迁移方案SQL Server 数据库服务器高性能设置SQL Server 2005链接服务器SQL Server 阅读全文
2 Comment
Tags: SQL Server, 数据库, 维护
[置顶]SQL Server 表分区实战系列（文章索引）
2011-07-01 15:45 by 听风吹雨, 5621 visits, 网摘, 收藏, 编辑
摘要：前言前段时间在忙数据库的表分区，经常会去上网找资料，但是在找到都是测试表分区的文章，没有实战经验的，所以在我把表分区运用到实际项目中的时候遇到了很多问题。比如：如何确认分区字段？分区字段与聚集索引的区别与联系？如何存储分区索引？MSDN说交换分区是以秒计算，但执行40G交换分区超时？如何解决分区不断增长的问题？自动化交换分区的陷阱？这些问题都只能自己在实战中摸索答案，后来我写了几篇关于这些问题的博文，希望对那些需要实战帮助的童鞋有一点提示和帮助。希望大家拍砖。实战说明某生产数据库大小已经有800G了，每天进库数据量大概有150W条记录（数据空间大概为7G），而服务器现在已经没有太多的磁盘空间了 阅读全文
30 Comment
Tags: 数据库, 表分区
[置顶]简单实用SQL脚本
2010-04-09 18:32 by 听风吹雨, 14779 visits, 网摘, 收藏, 编辑
摘要：行列互转Code highlighting produced by Actipro CodeHighlighter (freeware)http://www.CodeHighlighter.com/-->createtabletest(idint,namevarchar(20),quarterint,profileint)insertintotestvalues(1,'a',1,1000)insertintotestvalues(1,'a',2,2000)insertintotestvalues(1,'a',3,4000)insertint 阅读全文
23 Comment
Tags: SQL Server, SQL脚本, 简单实用SQL脚本
SQL Server 复制系列（文章索引）
2013-09-30 17:04 by 听风吹雨, 8 visits, 网摘, 收藏, 编辑
摘要：前言SQL Server的复制、日志传送、镜像等几个高级功能中，个人感觉复制是比较符合我的生产环境的要求的，其实搭建复制并不难，但是在网上关于：通过备份文件初始化复制、跨网段（跨机房）复制的文章会比较少，这里就着重讲讲这些内容；下图是一个关于SQL Server通过备份文件初始化复制的逻辑结构图：（Figure1：SQL Server备份文件初始化订阅逻辑结构图）为了与SQL Server的复制进行对比，我们去了解下一下MySQL的Master/Slave，下图是关于MySQL通过备份文件初始化复制的逻辑结构图：（Figure2：MySQL备份文件搭建Master/Slave逻辑图）系列文章索 阅读全文
0 Comment
Tags: SQL Server, 数据库
SQL Server跨网段（跨机房）FTP复制
2013-09-24 17:53 by 听风吹雨, 797 visits, 网摘, 收藏, 编辑
摘要：一、 背景搭建SQL Server复制的时候，如果网络环境是局域网内，通过主机名就可以实现了，但是如果是跨网段、跨机房异地搭建复制的时候就需要注意了，因为SQL Server复制不支持通过IP连接分发服务器，那有什么办法解决跨网段、跨机房的问题呢？我在SQL Server跨网段（跨机房）复制已经讲到了两种解决方法，如果想用请求订阅模式，共享快照文件权限的配置比较麻烦，更好更安全的方式是通过FTP形式读取快照文件进行初始化；二、 搭建过程(一) 环境信息系统环境：Windows Server 2008 + SQL Server 2008发布服务器：192.168.1.101,1924，服务器名称 阅读全文
4 Comment
Tags: SQL Server, 数据库
SQL Server 跨网段（跨机房）复制
2013-09-18 15:30 by 听风吹雨, 938 visits, 网摘, 收藏, 编辑
摘要：一、 背景搭建SQL Server复制的时候，如果网络环境是局域网内，通过主机名就可以实现了，但是如果是跨网段、跨机房异地搭建复制的时候就需要注意了，因为SQL Server复制不支持通过IP连接分发服务器，那有什么办法解决跨网段、跨机房的问题呢？二、 解决方案在跨网段、跨机房进行SQL Server复制的时候需要区分两种情况：一种是外网IP的1433端口对应了这台机器SQL Server的数据库端口；另外一种情况是外网IP对应SQLServer机器的端口不是1433；下面是几种解决方案：A. 如果外网IP端口是1433，可以在Windows的host文件中指定IP地址与主机名的对应关系，主机 阅读全文
6 Comment
Tags: SQL Server, 数据库
SQL Server 通过备份文件初始化复制
2013-09-09 11:39 by 听风吹雨, 508 visits, 网摘, 收藏, 编辑
摘要：一、背景MySQL在对有历史数据的数据库进行搭建复制（Master/Slave）的时候，可以通过在Master服务器备份历史数据，利用这个备份文件在Slave进行还原；这样做的好处是可以更加快速的搭建好环境，因为可以对备份文件进行压缩、分包，并且可以使用FTP等工具保证传输过程的安全与快捷；详情可参考：Windows下搭建MySQL Master Slave当SQL Server遇到同样需要对历史数据库搭建复制，通常的做法是在本地发布快照，再由订阅传输数据，那SQL Server应该如何实现备份历史数据搭建复制（发布/订阅）呢？下图是备份文件初始化订阅的基本逻辑结构图：（Figure0：备份文 阅读全文
8 Comment
Tags: SQL Server, 数据库
SQL Server 复制：事务发布
2013-09-06 17:33 by 听风吹雨, 556 visits, 网摘, 收藏, 编辑
摘要：SQL Server 复制：事务发布一、背景在复制的运用场景中，事务发布是使用最为广泛的，我遇到这样一个场景：在Task数据库中有Basic与Group两个表，需要提供这两个表的部分字段给其它程序读取放入缓存，程序需要比较及时的获取到这些数据，作为DBA你需要从权限和性能控制的角度出发，我采用了SQL Server的事务复制技术和timestamp，下面只讲述事务复制的搭建过程；二、实现过程(一) 环境信息系统环境：Windows Server 2008 + SQL Server 2008 R2发布服务器：192.168.1.151，服务器名称：USER-H2B2A89PEK分发服务器：与发布 阅读全文
0 Comment
Tags: SQL Server, 数据库
SQL Server 2008 维护计划实现数据库备份
2013-08-29 09:08 by 听风吹雨, 688 visits, 网摘, 收藏, 编辑
摘要：一、背景之前写过一篇关于备份的文章：SQL Server 维护计划实现数据库备份，上面文章使用完整备份和差异备份基本上能解决数据库备份的问题，但是为了保障数据更加安全，我们需要再次完善我们的备份计划；下面这篇文章主要加入了日志备份，并对设计备份的频率和设计命名规范等问题进行实战；二、最佳实践(一) 备份计划1) 每周星期日的2:00:00执行数据库的完整备份；2) 每周星期一至星期六每天的2:00:00执行数据库的差异备份；3) 每天在8:00:00和23:59:59之间、每1小时执行数据库的日志备份；4) 每个月的最后一个星期日的1:00:00执行数据库的完整备份；(二) 计划讲解1. 根据 阅读全文
4 Comment
Tags: SQL Server, 数据库
Windows下搭建MySQL Master Slave
2013-08-09 14:35 by 听风吹雨, 657 visits, 网摘, 收藏, 编辑
摘要：一、背景服务器上放了很多MySQL数据库，为了安全，现在需要做Master/Slave方案，因为操作系统是Window的，所以没有办法使用keepalived这个HA工具，但是我们可以接受人工进行切换，有什么好的方案呢？二、几种Master/Slave逻辑架构图（Figure1：单Master-单Slave）（Figure2：单Master-多Slave）（Figure3：单Master-级联Slave）（Figure4：Master/Slave部署逻辑图）三、搭建过程环境：Windows Server 2008 R2 + mysql-5.5.22-winx64主服务器（Master）：192 阅读全文
2 Comment
Tags: 数据库, MySQL
SQL Server 自动增长过大
2013-08-07 12:32 by 听风吹雨, 121 visits, 网摘, 收藏, 编辑
摘要：一、背景我们遇到的问题如下图所示：自动增长无端端就按照这样的比例进行增长；（Figure1：问题所在）尝试使用SSMS修改自动增长值，就会出现下面的错误：（Figure2：错误信息）遇到上面的问题，我们需要解决两个问题：1. 把数据文件收缩到一定范围内的值，腾出磁盘空间；2. 重新设置自动增长的值，可以按照百分比，也可以使用指定的空间大小，我个人倾向使用n*1024M这样的值，仅供参考；3. 如果有需要你也可以进行日志文件的收缩；二、解决过程1. 使用下面的脚本修改自动增长的值：--1024ALTER DATABASE [DataBaseName]MODIFY FILE ( NAME = N& 阅读全文
0 Comment
SQL Server 迁移数据到MySQL
2013-08-05 11:59 by 听风吹雨, 1275 visits, 网摘, 收藏, 编辑
摘要：一、背景由于项目开始时候使用的数据库是SQL Server，后来把存储的数据库调整为MySQL，所以需要把SQL Server的数据转移到MySQL；由于涉及的表比较多，所以想在MySQL中生成对应表并导入数据；上网找了些资料，如：将ACCESS和MSSQL导入MYSQL中、MySQL Migration 实现 MSSQL 到 MySQL数据迁移，虽然不知道里面的做法是否可以成功转移，但是里面的过程比较复杂，没有去尝试，后来自己找到了方法，最重要就是简单和准确（暂时没发现明显的BUG），这里分享给大家。二、转移数据我使用了MySQL的Client的工具SQLyog，这个工具的安装很简单。安装完 阅读全文
11 Comment
Tags: SQL Server, MySQL
SQL Server 解读【已分区索引的特殊指导原则】（3） - 非聚集索引分区
2013-07-26 15:01 by 听风吹雨, 482 visits, 网摘, 收藏, 编辑
摘要：一、前言在MSDN上看到一篇关于SQL Server 表分区的文档：已分区索引的特殊指导原则，如果你对表分区没有实战经验的话是比较难理解文档里面描述的意思。这里我就里面的一些概念进行讲解，方便大家的交流。SQL Server 解读【已分区索引的特殊指导原则】（1）- 索引对齐SQL Server 解读【已分区索引的特殊指导原则】（2）- 唯一索引分区二、解读【对非聚集索引进行分区】“对唯一的非聚集索引进行分区时，索引键必须包含分区依据列。对非唯一的非聚集索引进行分区时，默认情况下 SQL Server 将分区依据列添加为索引的非键（包含性）列，以确保索引与基表对齐。如果索引中已经存在分区依据列 阅读全文
3 Comment
Tags: SQL Server, 数据库
SQL Server 解读【已分区索引的特殊指导原则】（2）- 唯一索引分区
2013-07-26 14:52 by 听风吹雨, 93 visits, 网摘, 收藏, 编辑
摘要：一、前言在MSDN上看到一篇关于SQL Server 表分区的文档：已分区索引的特殊指导原则，如果你对表分区没有实战经验的话是比较难理解文档里面描述的意思。这里我就里面的一些概念进行讲解，方便大家的交流。SQL Server 解读【已分区索引的特殊指导原则】（1）二、解读【对唯一索引进行分区】“对唯一索引（聚集或非聚集）进行分区时，必须从唯一索引键使用的分区依据列中选择分区依据列。此限制将使 SQL Server 只调查单个分区，以确保表中不存在重复的新键值。如果分区依据列不可能包含在唯一键中，则必须使用 DML 触发器，而不是强制实现唯一性。”你对这段描述是否有自己的理解呢？这段话你可以这样 阅读全文
0 Comment
Tags: SQL Server, 数据库
SQL Server 解读【已分区索引的特殊指导原则】（1）- 索引对齐
2013-07-25 16:51 by 听风吹雨, 541 visits, 网摘, 收藏, 编辑
摘要：一、前言在MSDN上看到一篇关于SQL Server 表分区的文档：已分区索引的特殊指导原则，如果你对表分区没有实战经验的话是比较难理解文档里面描述的意思。这里我就里面的一些概念进行讲解，方便大家的交流。（Figure0：索引与基表对齐）二、解读“索引要与其基表对齐，并不需要与基表参与相同的命名分区函数。但是，索引和基表的分区函数在实质上必须相同，即：1) 分区函数的参数具有相同的数据类型；2) 分区函数定义了相同数目的分区；3) 分区函数为分区定义了相同的边界值。”下面我们进行测试：--1.创建文件组ALTER DATABASE [Test]ADD FILEGROUP [FG_TestUni 阅读全文
2 Comment
Tags: SQL Server, 数据库
SQL Server 错误日志过滤（ERRORLOG）
2013-06-24 15:54 by 听风吹雨, 890 visits, 网摘, 收藏, 编辑
摘要：一、背景有一天我发现SQL Server服务器的错误日志中包括非常多关于sa用户的登陆错误信息：“Login failed for user 'sa'. 原因: 评估密码时出错。[客户端: XX.XX.XX.XX]”。可是我很久之前就已经禁用了sa用户，怎么还会有那么多的sa用户登陆信息呢？我猜想是有人在暴力破解我们数据库的sa用户的密码；关于这种攻击，大家有没好的解决方案呢？我查找了一些资料，暂时没有找到好的解决方案。我只想到一个暂时缓解压力的办法，那就是从错误信息中统计出登陆sa用户的客户端IP地址，再设置防火墙把这些IP过滤掉。那现在如何解决IP的统计呢？使用SSMS是根 阅读全文
2 Comment
Tags: SQL Server, 数据库
SQL Server 错误日志收缩（ERRORLOG）
2013-06-24 15:15 by 听风吹雨, 131 visits, 网摘, 收藏, 编辑
摘要：一、基础知识默认情况下，错误日志位于 ：C:\Program Files\Microsoft SQL Server\MSSQL.1\MSSQL\LOG\ERRORLOG和ERRORLOG.n 文件中。默认保留有7个 SQL Server 错误日志文件，分别是：ErrorLog，Errorlog.1～Errorlog.6 ，当前的错误日志（文件ErrorLog）没有扩展名。每当启动 SQL Server 实例时，将创建新的错误日志ErrorLog，并将之前的ErrorLog更名为ErrorLog.1，之前的ErrorLog.1更名为ErrorLog.2，依次类推，原先的ErroLog.6被删除。 阅读全文
2 Comment
Tags: SQL Server, 数据库
SQL Server 限制IP登陆
2013-05-23 16:51 by 听风吹雨, 1895 visits, 网摘, 收藏, 编辑
摘要：一、背景在MySQL的mysql.User表保存了登陆用户的权限信息，Host和User字段则是关于登陆IP的限制。但是在SQL Server没有这样一个表，那SQL Server有什么办法可以实现类似的安全控制的功能呢？SQL Server 包括三种常规类型的触发器：DML触发器、DDL触发器和登录触发器。DML触发器是比较常使用的，它通常在表或视图中修改数据（INSERT、UPDATE和DELETE 等）为了保证业务数据的完整性和一致性，可以对事务进行回滚等操作；如果你对DDL触发器感兴趣，可以参考：SQL Server DDL触发器运用，里面涉及到DDL触发器的知识；登陆触发器将在本文运 阅读全文
16 Comment
Tags: SQL Server, 数据库
SQL Server 查看所有数据库所有表大小信息（Sizes of All Tables in All Database）
2013-05-08 15:32 by 听风吹雨, 1447 visits, 网摘, 收藏, 编辑
摘要：一、背景之前写了篇关于：SQL Server 游标运用：查看一个数据库所有表大小信息（Sizes of All Tables in a Database）的文章，它罗列出某个数据所有表的信息，这些信息包括：表的记录数、数据记录占用空间、索引占用空间、没使用的空间等（如Figure1所示），现在我来讲述如何获取整个数据库实例中所有数据库所有表的信息（如Figure2所示）。（Figure1：某数据库所有表信息）（Figure2：所有数据库所有表信息）二、实现方法下面内容讲述了在实现Figure2过程中遇到的一些问题，如果你对这些问题不感兴趣可以直接看最后实现的SQL脚本。下面讲述了4种实现方法： 阅读全文
6 Comment
Tags: SQL Server, 数据库
SQL Server 游标运用：查看一个数据库所有表大小信息（Sizes of All Tables in a Database）
2013-05-07 12:09 by 听风吹雨, 1286 visits, 网摘, 收藏, 编辑
摘要：一、背景在性能调优或者需要了解某数据库表信息的时候，最直观的方式就是罗列出这个数据所有表的信息，这些信息包括：表的记录数、数据记录占用空间、索引占用空间、未使用的空间等（如Figure1所示），有了这些信息你可以简单的判断这个数据库来自数据上的压力可能是某个表造成的。因为表数据越大，对数据库性能的影响越大。要实现某个数据库所有表的信息，可以通过游标的形式获取相应的数据，下图Figure1返回某数据库中所有表的信息：（Figure1：某数据库所有表信息）也许你并不满足于Figure1的信息，你希望获取整个数据库实例中所有数据库所有表的信息（如Figure2所示），如果想了解里面的实现可以参考：S 阅读全文
6 Comment
Tags: SQL Server, 数据库
SQL Server 重置Identity标识列的值（INT爆了）
2013-04-23 17:45 by 听风吹雨, 2134 visits, 网摘, 收藏, 编辑
摘要：一、背景 SQL Server数据库中表A中Id字段的定义是：[Id] [int] IDENTITY(1,1)，随着数据的不断增长，Id值已经接近2147483647（int的取值范围为：-2 147 483 648 到 2 147 483 647）了，虽然已经对旧数据进行归档，但是这个表需要保留最近的1亿数据，有什么方法解决Id值就快爆的问题呢？ 解决上面的问题有两个办法：一个是修改表结构，把Id的int数据类型修改为bigint；第二个是重置Id（Identity标识列）的值，使它重新增长。 当前标识值：current identity value，用于记录和保存最后一次系统分配的I... 阅读全文
20 Comment
Tags: SQL Server, 数据库
MySQL表数据迁移自动化
2013-03-15 17:36 by 听风吹雨, 1021 visits, 网摘, 收藏, 编辑
摘要：一、背景之前我写过关于SQL Server的数据迁移自动化的文章：SQL Server 数据库迁移偏方，在上篇文章中设计了一张临时表，这个临时表记录搬迁的配置信息，用一个存储过程读取这张表进行数据的迁移，再由一个Job进行迭代调用这个存储过程。在这次MySQL的实战中，我的数据库已经做了4个分片，分布在不同的4台机器上，每台机器上的数据量有1.7亿（1.7*4=6.8亿），占用空间260G（260*4=1040G），这次迁移的目的就是删除掉一些历史记录，减轻数据库压力，有人说这为什么不使用表分区呢？这跟我们的业务逻辑有关造成无法使用表分区，至于为什么，参考阅读：MySQL表分区实战，其中最重要 阅读全文
0 Comment
Tags: 数据库, MySQL
Ubuntu12下挂载硬盘（9TB）（文章索引）
2013-02-16 17:41 by 听风吹雨, 732 visits, 网摘, 收藏, 编辑
摘要：前言在linux下挂载硬盘，很多人说使用mount，但是这个是挂载一个硬盘，如果想让服务器可以把硬盘都挂载到同一个目录下，mount是无法实现的，但是很多应用都有某个目录的空间足够大。下面的文章就是一步步教你怎么挂载的。实战说明经过实战，已经成功挂载了9TB的空间。（Figure：磁盘信息）系列文章索引Step1：Ubuntu12下挂载硬盘（9TB）Step2：Ubuntu12下未知驱动器处理Step3：Ubuntu12下重新挂载硬盘Step4：Ubuntu12下挂载存储柜硬盘Step5：Ubuntu12下挂载硬盘（9TB）Shell版 阅读全文
0 Comment
Tags: Ubuntu, Linux
下一页
About

目前工作：就职于广州XX软件公司，担任DBA；
经历描述：2年B/S项目开发经验，4年大型数据库性能优化、管理经验（亿级）；
主要技能：精通SQL Server性能调优、数据备份、数据容灾、数据迁移、故障诊断；擅长Profiler、执行计划调优，对Partition有丰富的经验，自主研发自动化切换表分区解决方案；熟悉MySQL Replication、Master/Slave、MySQ-Proxy、Sharding等；
关注方向：数据库Performance Tuning、High Performance、High Availability；
关注技术：MySQL、Redis、MongoDB、Hbase；
发展规划：对SQL Server和MySQL进行更加深入的探讨，关注NoSQL相关技术。
联系方式：EMAIL：GAIZAI@126.COM
                MSN：BBSPEDIY@HOTMAIL.COM

昵称：听风吹雨
园龄：4年7个月
荣誉：推荐博客
粉丝：432
关注：65
+加关注

最新随笔

SQL Server 复制系列（文章索引）
SQL Server跨网段（跨机房）FTP复制
SQL Server 跨网段（跨机房）复制
SQL Server 通过备份文件初始化复制
SQL Server 复制：事务发布
SQL Server 2008 维护计划实现数据库备份
Windows下搭建MySQL Master Slave
SQL Server 自动增长过大
SQL Server 迁移数据到MySQL
SQL Server 解读【已分区索引的特殊指导原则】（3） - 非聚集索引分区
SQL Server 解读【已分区索引的特殊指导原则】（2）- 唯一索引分区
SQL Server 解读【已分区索引的特殊指导原则】（1）- 索引对齐
SQL Server 错误日志过滤（ERRORLOG）
SQL Server 错误日志收缩（ERRORLOG）
SQL Server 限制IP登陆
SQL Server 查看所有数据库所有表大小信息（Sizes of All Tables in All Database）
SQL Server 游标运用：查看一个数据库所有表大小信息（Sizes of All Tables in a Database）
SQL Server 重置Identity标识列的值（INT爆了）
MySQL表数据迁移自动化
Ubuntu12下挂载硬盘（9TB）（文章索引）
最新评论

Re:SQL Server 跨网段（跨机房）复制 
实例名跟计算机名不一样的错误
分发服务器和订阅服务器上设置别名的时候，别名应该跟服务器的实例名要一致，不然会报下面的错误
这里为什么别名一定要跟服务器名一样呢？？？ -- 桦仔
Re:SQL Server跨网段（跨机房）FTP复制 
@桦仔算不上，只是记录而已。... -- 听风吹雨
Re:SQL Server跨网段（跨机房）FTP复制 
@_cc谢谢支持！... -- 听风吹雨
Re:SQL Server跨网段（跨机房）FTP复制 
过来支持一下！ -- _cc
Re:SQL Server跨网段（跨机房）FTP复制 
好文要顶 -- 桦仔
Re:SQL Server 2005 控制用户权限访问表 
好文章，正好要用到，多谢。
另外，请问楼主，用sql语句如何实现，谢谢 -- 忆起
Re:SQL Server 跨网段（跨机房）复制 
不错的文章，不过有个疑问，如果并发量足够大，跨网段的延迟会不会很厉害，会不会阻塞。 -- 鸽子飞扬
Re:SQL Server 当表分区遇上唯一约束 
@简单对的... -- 听风吹雨
Re:使用Excel批量生成SQL脚本（小技巧） 
@超缘同用！！... -- 听风吹雨
Re:SQL Server 当表分区遇上唯一约束 
@听风吹雨看来没问题了，主键和普通的唯一索引一样，通常会选择基表的同一分区方案，索引要分区就要对齐分区就必须包含分区列。按官方的说法是唯一索引键必须包含分区列，非唯一索引键可以不加分区列而是将分区列加... -- 简单
Re:使用Excel批量生成SQL脚本（小技巧） 
我也是使用
CONCATENATE(text1,text2,...) -- 超缘
Re:SQL Server 当表分区遇上唯一约束 
@简单你在创建唯一索引的时候指定到一个单独的分区方案，这样是可以的，只是没有索引对齐而已，你主键也是唯一的，如果分区依据列不是主键列，一样要在主键列包含分区依据列才能分区对齐的。... -- 听风吹雨
Re:SQL Server 跨网段（跨机房）复制 
@老牛吃肉看需求，如果有广域网的可以作为参考。... -- 听风吹雨
Re:SQL Server 跨网段（跨机房）复制 
@海南-胡勇老胡过奖了，只是一些实践而已，走通了而已。... -- 听风吹雨
Re:SQL Server 跨网段（跨机房）复制 
之前一直用的局域网内复制+1 -- 老牛吃肉
Re:SQL Server 跨网段（跨机房）复制 
此文有水平，必须推荐+1
（来源：.NET快速开发框架） -- 海南-胡勇
Re:SQL Server 当表分区遇上唯一约束 
@听风吹雨，谢谢答复。因为分区对齐的好处跟唯一索引从意义上来说是有点冲突的？有何冲突？我反复试了一下，在分区表中，唯一索引必须包含分区列强制分区对齐，但主键可以不包含分区列不对齐分区，也可以包含分区列... -- 简单
Re:SQL Server 当表分区遇上唯一约束 
@简单对的，分区对齐、唯一索引，需要做好这两个的权衡。... -- 听风吹雨
Re:SQL Server 通过备份文件初始化复制 
如果主库发布的表带有自增字段的，在订阅库中建表时要把自增属性去掉或者在建表后，更改表属性中的 “不用于复制”为“是”。不知道还有别的办法不 -- yingtaowz
Re:SQL Server 当表分区遇上唯一约束 
@听风吹雨分区后是可以创建主键，主键也是一种索引，我前面的意思是指主键必须创建为包含分区列的对齐索引型组合主键。原先的主键大多数情况下不是现在的分区列，比如RowID，OrderID或SN等，现在按日... -- 简单
随笔档案

2013年9月(5)
2013年8月(4)
2013年7月(3)
2013年6月(2)
2013年5月(3)
2013年4月(1)
2013年3月(1)
2013年2月(4)
2013年1月(1)
2012年12月(2)
2012年11月(3)
2012年10月(1)
更多...
日历

<	2013年10月	>
日	一	二	三	四	五	六
29	30	1	2	3	4	5
6	7	8	9	10	11	12
13	14	15	16	17	18	19
20	21	22	23	24	25	26
27	28	29	30	31	1	2
3	4	5	6	7	8	9
[01]SQL SERVER

Amaranthus
CareySon
claro
craigfr
DBFocus(知行思新)
iSQlServer
Keep Walking
navy887
nzperfect
OK_008
qanholas
rob_2010
Sai~(浪客剑心)
SQLSERVER MSDN论坛
SQLSERVER 官方博客
SQLSERVER中国研发中心
xwdreamer
安捷雨希
陈希章
飞洋过海
胡百敬
桦仔
黄钊吉
浪客剑心(数据库)
李爱武
思维酷(飞扬过海)
我爱菊花
小洋（燕洋天）
徐郞顾
邀月
邀月周记
邹建_CSDN
[04]博客

CoderZh(Python)
Eric Zhang(淘宝)
Eric Zhang(新博客)
Jackei(测试)
老赵
灵感之源
王涛
新颖(运维)
月光博客
[06]其它

博问
图灵教育
随笔分类

Rss00.SQL Server(91)
Rss00.SQL Server 安全(4)
Rss00.SQL Server 备份还原(4)
Rss00.SQL Server 表分区(13)
Rss00.SQL Server 复制(5)
Rss00.SQL Server 监控(2)
Rss00.SQL Server 设计开发(11)
Rss00.SQL Server 数据迁移(5)
Rss00.SQL Server 维护管理(6)
Rss00.SQL Server 性能优化(9)
Rss00.SQL Server 游标运用(4)
Rss01.MySQL(15)
Rss02.数据库性能调优(1)
Rss03.数据挖掘(3)
Rss04.Linux(7)
Rss05.读书笔记(11)
Rss06.中文分词(4)
Rss07.每日构建(2)
Rss08.软件测试(3)
Rss09.DotNET(13)
Rss10.常用工具(11)
Rss11.日志(10)
Rss12.Flex(1)
推荐排行榜

1. 简单实用SQL脚本(14)
2. SQL Server 索引中include的魅力（具有包含性列的索引）(11)
3. SQL Server 2005 分区模板与实例(11)
4. SQL Server 2005 控制用户权限访问表(10)
5. SQL Server 磁盘空间告急（磁盘扩容）(10)
6. SQL Server 表分区实战系列（文章索引）(10)
7. SQL Server 维护计划实现数据库备份(9)
8. SQL Server 备份和还原全攻略(8)
9. SQL Server 表分区注意事项(8)
10. SQL Server datetime数据类型设计、优化误区(8)
11. SQL Server 合并（删除）分区解惑(8)
12. SQL Server 2005 性能优化实战系列（文章索引）(8)
13. SQL Server 迁移数据到MySQL(8)
14. SQL Server 数据库最小宕机迁移方案(7)
15. SQL Server 数据库帐号密码生成(7)
16. SQL Server 数据库帐号密码安全设计(6)
17. SQL Server 当表分区遇上唯一约束(6)
18. SQL Server 置疑、可疑、正在恢复(6)
19. SQL Server数据库服务器高性能设置(6)
20. SQL Server 动态生成分区脚本(6)
阅读排行榜

1. 数据挖掘算法-Apriori Algorithm（关联规则）(15698)
2. 简单实用SQL脚本(14779)
3. SQL Server 2005 控制用户权限访问表(10602)
4. SQL Server 维护计划备份主分区(10422)
5. SQL Server 备份和还原全攻略(9921)
6. C#获取URL参数值(8707)
7. SQL Server 索引中include的魅力（具有包含性列的索引）(8488)
8. 很强悍的脑图（思维导图、心智图）(7498)
9. SQL Server datetime数据类型设计、优化误区(7427)
10. Firefox 扩展插件推荐(6636)
11. SQL Server 表分区实战系列（文章索引）(5621)
12. 使用Excel批量生成SQL脚本（小技巧）(5609)
13. SQL Server数据库服务器高性能设置(5102)
14. Windows与Linux拷贝数据(4510)
15. SQL Server 全文索引的硬伤(4305)
16. 简单实用SQL脚本Part：SQL Server 2005 链接服务器(4281)
17. SQL Server 合并（删除）分区解惑(4243)
18. 简单实用SQL脚本Part：查找SQL Server 自增ID值不连续记录(4191)
19. SQL Server 动态生成分区脚本(4024)
20. SQL Server 2005 分区模板与实例(3780)
[02]MYSQL

Alibaba DBA Team
HELLO DATABASE(MySQL)
MySQL 实验室
realzyy(MySQL/MongoDB)
简朝阳(MySQL)
一个故事@MySQL DBA
[03]数据库

buro79xxd(Oracle)
Dave(Oracle)
DBA成长日记
EricHu(Oracle)
killkill(Oracle)
NoSQLFan(NoSQL)
robinson_0612(Oracle)
Tyler‘s DoNet(SSIS)
wzy0623(Oracle)
XZC.Log(Oracle)
陈希章(BI)
孤独侠客(BI)
逖靖寒(NoSQL)
潇湘隐者(Oracle)
[05]门户

51CTO
ASP
cnbeta
DotBlogs
infoq
ITPUB
IT推动创新
mono
MSDN
sswug
TechNet
TT
wikipedia
豆丁
黑板报
www.spiga.com.mx
Copyright ©2013 听风吹雨
博客园
========== http://www.orczhou.com/ ==========
一个故事@MySQL DBA
日 志
Archive
Wish list
Works
关于
编译tcprstat 2013-07-11 10:27  |  分类：MySQL
在RHEL6.1(Red Hat Enterprise Linux Server)上静态编译并不容易。tcprstat编译也有这个问题。

源码下载：tcprstat@Launchpad 命令：bzr branch lp:tcprstat

编译命令：./bootstrap && ./configure && make

如果顺利的话，就结束了。不过在我的发行版会报如下错误：[......]

Read more

标签：Linux、MySQL Response Time、pthread、tcprstat1,604 views  |  3 条评论
如何从MySQL/InnoDB数据文件中的恢复数据 2013-07-8 21:09  |  分类：MySQL,技术细节
在上上周给下厨房做过一次数据恢复(故障回顾：故障发生的技术总结 致歉信)，恢复使用了开源工具Percona Data Recovery Tool for InnoDB(后面简称PDRTI)，这里分享一下期间的注意事项，和遇到MySQL数据丢失的一些应对。

本文主要介绍在使用Percona Data Recovery Tool for InnoDB时候的一些注意事项，并不包括具体的step by step的使用步骤，使用文档可以参考：Reference Manual and Documentation。[......]

Read more

标签：InnoDB、InnoDB data recovery、MySQL、Recovery2,433 views  |  6 条评论
在杭州工作 2013-04-27 14:13  |  分类：简单生活
从那次Z9来杭州，快四年了，最近有两个老同学都问我杭州好不好，去杭州工作怎样之类的，这里说说这四年对杭州的感受吧。都是些主观认识，谨慎参考。

在北京念书七年，因为种种“机缘巧合”，最终来了杭州。之前从不曾想过会因为工作来杭州，不过也没有想到这个城市给了我这么多惊喜。

1. 工作在杭州
先说工作，毕竟是因为这个原因来到这里的。相比北京，杭州的公司是要少很多的，所以工作机会也相对较少。一线的互联网公司，主要就是阿里巴巴和网易杭州研究院，不像北京几乎所有的公司都会在北京有办公地点，阿里在北京也有很大的办公地点。很少有人能够一辈子只在一家公司服务的，所以当打算换工作的时候，这就成为一个劣势了，选择较少，机会也较少。不过如果是电子商务的话，杭州的氛围还是很好的，我所知道的很多人/公司都在做围绕此创业(例如我不喜欢，但是很看好的蘑菇街)。

当然，杭州工作机会少，这是相对而言，如果不跟北上广深，杭州的工作环境应该也算是非常好的。

2. 生活在杭州

在生活方面，如果再跟北京比的话，杭州是分分钟就秒杀了北京。杭州城区不算大，周末如果朋友想聚会的话，一般不会超过半小时的车程，打个牌、吃个饭什么的非常方便。记得刚到杭州那会儿，每隔周五晚上都是有小赌怡情的牌局，现在一个个都结婚生小孩了，聚会的时间少了很多。以前在北京，同学聚会还是比较麻烦的，东西三环就很远了，更别说石景山了，所以北京的同学聚会貌似也基本上跟我去北京出差的频率差不太多，所以总能赶上。杭州周末聚会有更多的选择，可以去龙井/梅家坞/青之坞，环境都非常好，而且离城西也非常近，七八个好友玩个三国杀、吃个饭、爬个山都很惬意。

如果你喜欢运动，杭州也不会让你失望。西湖几乎四面环山，山不是很高，不过很长，适合周末慢慢爬。登山的路线也有很多，春秋季都很漂亮，很多杭州久住的人都喜欢爬山。[......]

Read more

2,229 views  |  5 条评论
《高性能MySQL》第三版 2013-04-22 15:00  |  分类：MySQL
本文是一篇写给《HPM 3rd 中文版》的软文，慎入。《HPM 3rd 中文版》已经开始正式发售了，不是预售：亚马逊 china-pub 当当网

从去年5月开始，与宁海元、翟卫祥、彭立勋、刘辉一起利用业余时间，经历了翻译，校对，校对，再校对，交叉校对，再交叉校对，到前两天亚马逊上正式开售(不是预售了)，前前后后也历经了大概一年。


在过去的两三年，MySQL的生态圈发生了很大的变化，出现了MariaDB，Percona/XtraDB等等分支，与官方的版本产生了一些竞争。目前为止这些竞争还是比较良性的，都大大推动了MySQL在各个方面的改进，包括MySQL的性能和新的功能，这期间在社区对于InnoDB的改进(例如XtraDB)，推进了MySQL/Oracle快速的推进了InnoDB Plugin的发展；MariaDB在优化器方面也做了很多工作，对应的MySQL/Oracle在5.6之后的版本也做了很多Server层(例如优化器、Group Commit等)的改进。

虽然经历了收购的风波，但在竞争压力下，过去两三年仍然是MySQL/MariaDB快速发展的时期。08年High Performance MySQL(简称HPM)发布第二版，时隔四年发布了第三版，第三版中新增了分区、视图、存储过程方面的改进，高可用、集群和复制方面的改进，优化器全文索引等改进，SSD和多核CPU利用方面的改进，在线备份和恢复的工具等。是一本非常值得阅读的MySQL书籍。

对于专注数据库领域的人来说，如果习惯阅读英文版本的，依旧推荐阅读英文版本，在亚马逊上可以买到HPM 3rd影印版的。如果不太习惯阅读英文版本的，我仍然强烈推荐阅读影印版，虽然这样可能会花更多的时间，但是可以大大锻炼一下自己的英文能力，相信你不会因为这个"浪费"时间而后悔的。

如果，你喜欢阅读中文书籍，或者希望能够快速阅读，那么这次翻译的HPM 3rd会是很好的选择。这次译者都是专业/一线的MySQL DBA或者开发人员，并进行了多次(交叉)校对，是一次高要求、高质量的翻译，不会让你失望。[......]

Read more

3,674 views  |  3 条评论
案例：MySQL优化器如何选择索引和JOIN顺序 2013-04-8 19:07  |  分类：MySQL
本文通过一个案例来看看MySQL优化器如何选择索引和JOIN顺序。表结构和数据准备参考本文最后部分"测试环境"。这里主要介绍MySQL优化器的主要执行流程，而不是介绍一个优化器的各个组件(这是另一个话题)。

我们知道，MySQL优化器只有两个自由度：顺序选择；单表访问方式；这里将详细剖析下面的SQL，看看MySQL优化器如何做出每一步的选择。

explain
select *
from
  employee as A,department as B
where
      A.LastName = 'zhou'
  and B.DepartmentID = A.DepartmentID
  and B.DepartmentName = 'TBX';

1. 可能的选择
这里看到JOIN的顺序可以是A|B或者B|A，单表访问方式也有多种，对于A表可以选择：全表扫描和索引`IND_L_D`(A.LastName = 'zhou')或者`IND_DID`(B.DepartmentID = A.DepartmentID)。对于B也有三个选择：全表扫描、索引IND_D、IND_DN。

2. MySQL优化器如何做
2.1 概述
MySQL优化器主要工作包括以下几部分：Query Rewrite(包括Outer Join转换等)、const table detection、range analysis、JOIN optimization(顺序和访问方式选择)、plan refinement。这个案例从range analysis开始。

2.2 range analysis
这部分包括所有Range和index merge成本评估(参考1 参考2)。这里，等值表达式也是一个range，所以这里会评估其成本，计算出found records(表示对应的等值表达式，大概会选择出多少条记录)。

本案例中，range analysis会针对A表的条件A.LastName = 'zhou'和B表的B.DepartmentName = 'TBX'分别做分析。其中：[......]

Read more

标签：index、MySQL、optimizer、Source Code4,061 views  |  发表评论
Oracle如何根据SQL_TEXT生成SQL_ID 2013-03-29 14:09  |  分类：MySQL,ORACLE,PHP
本文纯属八卦，基本没有任何实用价值。Oracle总是都会通过SQL_ID来标志一个唯一的SQL。SQL_ID与SQL_TEXT一一对应。如果两个SQL文本有任何不同，包括空格等任何不可见字符，都会导致SQL_ID不同。本文八卦的内容是：Oracle如何根据SQL_TEXT内容散列成一个13位的字符串。为什么这个字符串会是13位？为什么这个字符经常以数字开头？

本文参考TANEL PODER和Slavik的两篇介绍(1，2)，详细介绍转换原理，顺便给出PHP/Perl实现代码。

0. 概述
Oracle先计算SQL_TEXT的md5散列值；取散列值的低64位(bits)，每次取5位(最后一次4位)，使用Base32将其依次转换成可见字符，就是你最终看到的SQL_ID。原理就是这样。

不过实际转换过程中有一些要注意的事项：

(a) Oracle在计算md5散列时，会在SQL_TEXT末尾加一个不可见字符\0，AWR报表中经常有这样的SQL_TEXT

(b) 注意little-endian的问题

(c) Base32转码的可见字符为0123456789abcdfghjkmnpqrstuvwxyz

(d) 编写程序的时候需要注意大数精度的问题，本文中Perl/PHP程序都使用了数学大数处理函数[......]

Read more

标签：Oracle、SQLID、SQL_TEXT2,000 views  |  发表评论
Pages: 1 2 3 4 5 6 7 8 ...26 27 28 Next
无节操推荐
《高性能MySQL 第三版》 


  
 	
 Web	 orczhou.com


 
日志分类
Linux (16) MySQL (78) ORACLE (1) PHP (1) 代码细节 (14) 大千世界 (21) 技术细节 (23) 简单生活 (48)
最新日志
编译tcprstat
如何从MySQL/InnoDB数据文件中的恢复数据
在杭州工作
《高性能MySQL》第三版
案例：MySQL优化器如何选择索引和JOIN顺序
Oracle如何根据SQL_TEXT生成SQL_ID
冬去春来
index merge的补充说明
index merge的数据结构和成本评估
还有五天过年
最新评论
黑枸杞苗:黑枸杞苗http://www.heigouqi.cn，QQ171565
godsoul:你好，这书有没有配套的测试数据啊？很想对着书，操作一下，试试看哦。
mroff:10年的文章，内容稍微有点老。
mroff:挺好的内容，很少有人降到在create时，ssd的数据会被清空
mroff:很不错,yufeng推荐的
ray:雁过留痕
admin:是的!!! 是不是很残酷?
pingwater:我觉得 http://www.mysqlperformanceblog
georgexsh:不会是rpmfind随便down一个吧 rh官方仓库没有么
Cash Advance Loan:distinguished this contact form
热门日志
Chrome扩展一键翻墙 - 82,142 views
Linux iostat监测IO状态 - 54,420 views
Percona-Server/MySQL响应时间统计 - 27,711 views
Xtrabackup备份和恢复MySQL(上) - 26,554 views
innodb_flush_method 与 File I/O - 21,193 views
使用Cacti监控MySQL - 15,272 views
windows下如何使用C语言连接MySQL - 14,410 views
TCP/IP重传超时--RTO - 13,241 views
InnoDB Plugin安装 - 13,099 views
InnoDB Double write - 12,791 views
日志存档

标签云
ahtung.co wp hacked go00ogle.net backup Chrome dirty page File IO Flashcache go00ogle Google Group Commit index InnoDB InnoDB Plugin Linux Lost movie MyISAM MyISAM Key Buffer MySQL MySQL5.5 mysqldump MySQL InnoDB Tablespace optimizer Oracle PHP query cache redo log Replication semi-sync semi-sync replication shell Source Code sphinx SQL解析 XtraBackup 兰卡威 半同步 图解 备份 攻略 春节 生活 穷游 自助游 阿里巴巴 马来西亚
WP Cumulus Flash tag cloud by Roy Tanck requires Flash Player 9 or better.
友情链接
AloneAsk Maclean Homeblog of georgexshErlang非业余研究IntootheRain的博客Maclean Liu的博客MySQL中文网MySQL实验室NinGoo.netTaobao DBA TeamThinking of 褚人伟xdidd张铭新的所思所想惊涛拍岸方山子的博客运维和开发陶方的Blog风雪之隅
博客管理
登录
TOP
本作品采用进行许可。
Powered by WordPress. Theme Modified from Prower

========== http://imysql.cn/onlinedoc ==========
MySQL中文网 – 叶金荣的技术和生活

小叶子她爹,装过Linux,写过PHP,优化过MySQL,目前围绕运维领域打杂
菜单 跳至内容
有点尴尬诶。
我们可能无法找到您需要的内容。或许搜索功能可以帮到您。

搜索：  
自豪地采用WordPress
========== http://www.orczhou.com/index.php/2010/11/flashcache-configuration-how-to/ ==========
一个故事@MySQL DBA
日 志
Archive
Wish list
Works
关于
上一篇：一个有趣的perl函数 下一篇：Truth Seeker
Flashcache配置
2010-11-12  |  00:14分类：Linux,MySQL  |  标签：Flashcache  |  8,548 views
前面写了两篇文章，分别介绍了Flashcache的基本原理和编译安装，本文介绍一下Flashcache的配置。

假设现在你已经编译好了Flashcache，已经装好了ssd盘（假设是/dev/sdb）和sas盘（假设需要使用的是分区/dev/sda12，这可能是一个RAID组）。接下来，看看如何使用Flashcache将上面两个设备虚拟成一个带缓存的块设备。

1. 首次创建Flashcach设备
注：请备份你的数据先！！！特别是/dev/sdb，这个设备上的数据将会被清空；理论上/dev/sda12上的数据不会有任何丢失。

首先确保sda12没有被挂载，如果挂载了，使用umount卸载之，然后使用flashcache_create创建设备：

./flashcache_create cachedev /dev/sdb /dev/sda12
如果是sudo帐号可能会遇到如下的报错：

sh: dmsetup: command not found
可以设置PATH变量的办法，来避免：（感谢余峰帮助）

sudo PATH=/sbin ./flashcache_create cachedev /dev/sdb /dev/sda12
这样Linux就虚拟除了一个带缓存的块设备：

$ls -lah /dev/mapper/cachedev
brw-rw---- 1 root disk 253, 0 Oct 8 15:46 /dev/mapper/cachedev
2. 使用该设备
这样就可以像使用一般的块设备一样，来使用该设备了。如果原来分区/dev/sda12上已经有文件系统，mount后还可以正常使用；如果没有文件系统，也可以和一般的设备一样做先做文件系统，然后mount并使用之。

mount /dev/mapper/cachedev /u01
很简单吧:)

3. 如何重做Flashcache
首先需要umount相应分区，然后如果需要重新做Flashcache：

umount /u01
dmsetup remove cachedev
./flashcache_destroy /dev/sdb
如果需要重建，再安装上面的flashcache_create重建就可以了。

喜欢本文，那就收藏到：	 
Flashcace安装 How-to
Flachcache初探
随机日志
InnoDB之Dirty page、Redo log
MySQL源代码：关于MySQL的Item对象
Linux下MySQL 5.5编译安装
InnoDB Plugin文件格式(概述)
起源--Lost
3条评论 关于 “Flashcache配置”
Flashcache新版重大变化 | Erlang非业余研究 发表于： 七月 21st, 2011 10:45 
[...] facebook释出的flashcache见 https://github.com/facebook/flashcache， 也可以参考我之前写的 ppt 如何使用，或者参考我们的dba写的详细使用和配置，见 这里 [...]

antidote 发表于： 七月 30th, 2011 22:40 
请问下，你们那有flashcache 性能测试的方案吗？
我这段时间测的时候遇到一些问题，方便给我参考一下吗？

mroff 发表于： 九月 2nd, 2013 09:59 
挺好的内容，很少有人降到在create时，ssd的数据会被清空

发表您的评论
姓名

Mail

网站

评论内容


TOP
本作品采用进行许可。
Powered by WordPress. Theme Modified from Prower

========== http://www.tbdata.org/archives ==========

首页我们是谁产品与技术官方博客
« Older Entries
2013.06.28
集群资源调度系统简介与galaxy资源调度系统简介
by 仙隐 | 所有 | 添加评论 
仙隐@数据平台-数据交换平台-实时计算

图数据库neo4j介绍及测试(续)
by 光戈 | 图数据库 | 添加评论 

图数据库neo4j介绍及测试
by 光戈 | 图数据库 | 添加评论 
一,neo4j介绍

2013.06.27
分布式平台的下的数据模型特征
by jieran | ETL | 添加评论 
在讨论分布式平台的数据模型特征之前，我们来看看两个分布式平台和传统数据库之间的差异是什么。

ADC数据之夜酒会
by admin | 所有 | Comments (10) 
ADC数据之夜酒会
7月13-14日，由阿里巴巴集团主办的ADC阿里技术嘉年华将在杭州举行，ADC是一个崇尚开放分享，技术创新的大型互联网技术会议。同时ADC“数据之夜”酒会也将在7月13日晚6：30 ，在海外海皇冠假日酒店 5F 宴会厅举行。

2012.02.15
Spark 性能测试报告
by 玉泉 | dw架构,所有 | Comments (2) 
如有不对或不足的地方请指正。

2012.01.05
Storm配置项详解
by tuhai | 云计算 | Comments (1) 
什么是Storm? Storm是twitter开源的一套实时数据处理框架，基于该框架你可以通过简单的编程来实现对数据流的实时处理变换。 Storm的配置文件一般存放在$STORM_HOME/conf下，通常名为storm.yaml，它符合yaml格式要求。 配置项详解: 以下是从storm的backtype.storm.Config类中搜集的所有storm支持的配置项(Based storm 0.6.0): 配置项 配置说明 storm.zookeeper.servers ZooKeeper服务器列表 storm.zookeeper.port ZooKeeper连接端口 storm.local.dir storm使用的本地文件系统目录(必须存在并且storm进程可读写) storm.cluster.mode Storm集群运行模式([distributed|local]) storm.local.mode.zmq Local模式下是否使用ZeroMQ作消息系统，如果设置为false则使用java消息系统。默认为false storm.zookeeper.root ZooKeeper中Storm的根目录位置 storm.zookeeper.session.timeout 客户端连接ZooKeeper超时时间 storm.id 运行中拓扑的id,由storm name和一个唯一随机数组成。 nimbus.host nimbus服务器地址 nimbus.thrift.port nimbus的thrift监听端口 nimbus.childopts 通过storm-deploy项目部署时指定给nimbus进程的jvm选项 nimbus.task.timeout.secs 心跳超时时间，超时后nimbus会认为task死掉并重分配给另一个地址。 nimbus.monitor.freq.secs nimbus检查心跳和重分配任务的时间间隔.注意如果是机器宕掉nimbus会立即接管并处理。 nimbus.supervisor.timeout.secs supervisor的心跳超时时间,一旦超过nimbus会认为该supervisor已死并停止为它分发新任务. nimbus.task.launch.secs task启动时的一个特殊超时设置.在启动后第一次心跳前会使用该值来临时替代nimbus.task.timeout.secs. nimbus.reassign 当发现task失败时nimbus是否重新分配执行。默认为真，不建议修改。 nimbus.file.copy.expiration.secs nimbus判断上传/下载链接的超时时间，当空闲时间超过该设定时nimbus会认为链接死掉并主动断开 ui.port Storm UI的服务端口 drpc.servers DRPC服务器列表，以便DRPCSpout知道和谁通讯 drpc.port Storm DRPC的服务端口 supervisor.slots.ports supervisor上能够运行workers的端口列表.每个worker占用一个端口,且每个端口只运行一个worker.通过这项配置可以调整每台机器上运行的worker数.(调整slot数/每机) supervisor.childopts

阅读全文 >
2011.12.01
数据倾斜总结
by jijiannan | 所有 | Comments (5) 
   在做Shuffle阶段的优化过程中，遇到了数据倾斜的问题，造成了对一些情况下优化效果不明显。主要是因为在Job完成后的所得到的Counters是整个Job的总和，优化是基于这些Counters得出的平均值，而由于数据倾斜的原因造成map处理数据量的差异过大，使得这些平均值能代表的价值降低。Hive的执行是分阶段的，map处理数据量的差异取决于上一个stage的reduce输出，所以如何将数据均匀的分配到各个reduce中，就是解决数据倾斜的根本所在。规避错误来更好的运行比解决错误更高效。在查看了一些资料后，总结如下。 1数据倾斜的原因 1.1操作： 关键词 情形 后果 Join 其中一个表较小， 但是key集中 分发到某一个或几个Reduce上的数据远高于平均值 大表与大表，但是分桶的判断字段0值或空值过多 这些空值都由一个reduce处理，灰常慢 group by group by 维度过小， 某值的数量过多 处理某值的reduce灰常耗时 Count Distinct 某特殊值过多 处理此特殊值的reduce耗时 1.2原因： 1)、key分布不均匀 2)、业务数据本身的特性 3)、建表时考虑不周 4)、某些SQL语句本身就有数据倾斜 1.3表现： 任务进度长时间维持在99%（或100%），查看任务监控页面，发现只有少量（1个或几个）reduce子任务未完成。因为其处理的数据量和其他reduce差异过大。 单一reduce的记录数与平均记录数差异过大，通常可能达到3倍甚至更多。 最长时长远大于平均时长。 2数据倾斜的解决方案 2.1参数调节： hive.map.aggr = true Map 端部分聚合，相当于Combiner hive.groupby.skewindata=true 有数据倾斜的时候进行负载均衡，当选项设定为 true，生成的查询计划会有两个 MR Job。第一个 MR Job 中，Map 的输出结果集合会随机分布到 Reduce 中，每个 Reduce 做部分聚合操作，并输出结果，这样处理的结果是相同的 Group By

阅读全文 >
2011.08.15
动态实时跟踪你的java程序
by 聚石 | java | Comments (7) 
之前有写 基于AOP的日志调试 讨论一种跟踪Java程序的方法, 但不是很完美.后来发现了 Btrace , 由于它借助动态字节码注入技术 , 实现优雅且功能强大.
只不过, 用起来总是磕磕绊绊的, 时常为了跟踪某个问题, 却花了大把的时间调试Btrace的脚本. 为此, 我尝试将几种跟踪模式固化成脚本模板, 待用的时候去调整一下正则表达式之类的.
跟踪过程往往是假设与验证的螺旋迭代过程, 反复的用BTrace跟踪目标进程, 总有那么几次莫名其妙的不可用, 最后不得不重启目标进程. 若真是线上不能停的服务, 我想这种方式还是不靠谱啊.
为此, 据决定自己的搞个用起来简单, 又能良好支持反复跟踪而不用重启目标进程的工具.

2011.08.07
MapR初体验
by tuhai | 云计算 | Comments (15) 
一、MapR是什么？

MapR是MapR Technologies, Inc的一个产品，号称下一代Hadoop，使Hadoop变为一个速度更快、可靠性更高、更易于管理、使用更加方便的分布式计算服务和存储平台，同时性能也不断提高。它将极大的扩大了Hadoop的使用范围和方式。它包含了开源社区的许多流行的工具和功能，例如Hbase、Hive。它还100%和Apache Hadoop的API兼容。它能够为客户节约一半的硬件资源消耗，使更多的组织能够利用海量数据分析的力量提高竞争优势。目前有两个版本，M3和M5，其中M3是免费的，M5为收费版，有试用期。具体功能差别见：http://www.mapr.com/products/mapr-editions.html。

« Older Entries
 
分类目录

C/C++ (2)
dw架构 (20)
ETL (7)
greenplum (9)
hadoop (22)
Hive (14)
java (13)
云计算 (17)
图数据库 (2)
展现 (13)
开发技术 (2)
所有 (130)
招聘 (33)
推荐引擎 (10)
数据挖掘 (32)
高性能服务器 (15)
近期评论

边磊杰 发表在《ADC数据之夜酒会》
太玄 发表在《ADC数据之夜酒会》
李小藤 发表在《ADC数据之夜酒会》
刘婧 发表在《ADC数据之夜酒会》
陈俊良 发表在《ADC数据之夜酒会》
Tech@Alibaba

淘宝DBA
淘宝QA
淘宝UED
淘宝核心系统
友情链接

CNodeJS.ORG
www.dbanotes.net
数据魔方官方网站
量子官方博客
阿里巴巴数据仓库团队blog
功能

登录
文章 RSS
评论 RSS
WordPress.org
首页 | 部门介绍 | 团队文化 | 加入我们 | 产品与技术 | 官方博客
© 2013阿里集团数据平台 alidata.org
========== http://www.orczhou.com/index.php/2010/10/how-to-setup-flashcace/ ==========
一个故事@MySQL DBA
日 志
Archive
Wish list
Works
关于
上一篇：家里 下一篇：批量杀死MySQL连接
Flashcace安装 How-to
2010-10-8  |  18:28分类：Linux,MySQL  |  标签：Flashcache、Linux  |  9,043 views
Flashcache的安装在其README和README-CentOS5.4已经有一个很详细的说明了，但是实际操作并不是很顺利，而且有些同事表示在编译过程中仍遇到了一些问题，这里详细的记录一下自己的编译、安装过程。

1. 环境说明
使用的是RHEL5.4的系统：

$cat /etc/issue
Red Hat Enterprise Linux Server release 5.4 (Tikanga)
$uname -a
Linux myhost 2.6.18-164.el5 #1 SMP Tue Aug 18 15:51:48 EDT 2009 x86_64 x86_64 x86_64 GNU/Linux

2. 需要的RPM包
安装基本工具包：rpm-build redhat-rpm-config unifdef。一般情况这三个包都是安装过的，检查一下即可。

$sudo yum install rpm-build
Package rpm-build-4.4.2.3-18.el5.x86_64 already installed and latest version
$sudo yum install redhat-rpm-config
Package redhat-rpm-config-8.0.45-32.el5.noarch already installed and latest version
$sudo yum install unifdef
Package unifdef-1.171-5.fc6.x86_64 already installed and latest version
3. 下载并安装源码包
现在的RHEL发行版中，已经不再带源码包，所以需要单独下载，供Flashcache编译使用。

3.1 准备目录
[supu@host]$ cd
[supu@host]$ mkdir -p rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS}
[supu@host]$ echo '%_topdir %(echo $HOME)/rpmbuild' > .rpmmacros
3.2 下载源码包
可以在ftp://ftp.redhat.com/下载到对应的源码包。这里的内核版本号是：

$uname -r
2.6.18-164.el5
所以需要下载的是kernel-2.6.18-164.el5.src.rpm，完整的URL是：

ftp://ftp.redhat.com/pub/redhat/linux/enterprise/5Server/en/os/SRPMS/kernel-2.6.18-164.el5.src.rpm
注：最好选择合适的镜像下载，速度会差很多的。

3.3 安装源码包
有了前面的目录准备，现在可以安装源码包了

sudo rpm -i kernel-2.6.18-164.el5.src.rpm
cd ~/rpmbuild/SPECS
rpmbuild -bp --target=`uname -m` kernel-2.6.spec 2> prep-err.log | tee prep-out.log
OK，这时候源码包就安装到了如下目录：/home/supu/rpmbuild/BUILD/kernel-2.6.18/linux-2.6.18.x86_64

3.4 准备模块编译
在源码目录执行如下命令，主备Flashcache模块编译

cd ~/rpmbuild/BUILD/kernel-2.6.18/linux-2.6.18.x86_64
make oldconfig
make prepare
make modules_prepare
4. 编译Flashcache
可以在github上下载Flashcache的源代码，和Linux源码一起编译，编译完成后会生成三个可执行程序和一个可动态加载的内核模块：

flashcache_create
flashcache_load
flashcache_destroy
flashcache.ko
4.1 下载并准备编译
在在github上可以下载到Flashcache最新的源码。这里下载的是flashcache-1.0.11，解压后，有如下目录：

[supu@host facebook-flashcache-15adea8]$ ls
doc flashcache-wt LICENSE Makefile README README-CentOS5.4 README-DKMS src
其中src包含了普通的Flashcache（这里的普通指的是Write-back版本的Flashcache），flashcache-wt包含了Write-Through版本的源码；文件README-CentOS5.4中包含了在RHEL5.4下编译的注意事项，本文主要参考该文件。

按照README-CentOS5.4中的说明，修改文件src/Makefile，将行EXTRA_CFLAGS（第一行），用如下内容替换：

EXTRA_CFLAGS=-I$(KERNEL_TREE)/drivers/md -I$(KERNEL_TREE)/include/linux  -I./

注意：这里没有换行。
4.2 编译之
make KERNEL_TREE=/home/supu/rpmbuild/BUILD/kernel-2.6.18/linux-2.6.18.x86_64/
4.3 动态加载模块
最后需要将模块flashcache.ko加载到内核，这里可以将flashcache.ko拷贝到相应目录：

sudo cp flashcache.ko /lib/modules/2.6.18-164.el5/kernel/drivers/block
或者使用insmod命令，动态加载之：

sudo insmod flashcache.ko
Job Done! Enjoy!

参考：

1. Flashcache README-CentOS5.4

2. Flashcache README

3. Redhat enterprise Linux / CentOS installing kernel source code

喜欢本文，那就收藏到：	 
Flachcache初探
编译tcprstat
TCP/IP重传超时–RTO
Linux Top命令学习
Flashcache配置
Linux下使用od查看文件
How to kill an `uninterruptible sleep` process
使用getopts处理Shell脚本参数
Linux iostat监测IO状态
Linux本地磁盘（硬盘）介绍
随机日志
MySQL源码:JOIN顺序选择的复杂度
明天入职
strlen、mb_strlen计算中英文混排字符串长度
MySQL源码：索引相关的数据结构(后篇)
Linux下MySQL 5.5编译安装
3条评论 关于 “Flashcace安装 How-to”

P.Linux 发表于： 十月 26th, 2010 17:17 
insmod: error inserting 'flashcache.ko': -1 Unknown symbol in module
最后一步失败
深入浅出Flashcache（四） 发表于： 一月 10th, 2012 13:38 
[...] 年底事情比较多，中断了一段时间，这一篇总算要说到Flashcache本身了。由于是内核模块，安装的时候需要内核源码树。具体的安装过程可以参考这里。 [...]

mroff 发表于： 九月 2nd, 2013 09:55 
很不错,yufeng推荐的

发表您的评论
姓名

Mail

网站

评论内容


TOP
本作品采用进行许可。
Powered by WordPress. Theme Modified from Prower

========== http://hi.baidu.com/dzzzb/item/69f739f26c7c8710d6ff8ce4 ==========

相册广场游戏登录注册关注此空间
记忆永恒
2010-02-26 16:27 ubuntu下mysql配置
linux下mysql安装配置


1、下载MySQL的安装文件
安装MySQL需要下面两个文件：
MySQL-server-4.0.23-0.i386.rpm　　
MySQL-client-4.0.23-0.i386.rpm
下载地址为：http://www.mysql.com/downloads/mysql-4.0.html，打开此网页，下拉网页找到“Linux x86 RPM downloads”项，找到“Server”和“Client programs”项，下载需要的上述两个rpm文件。
2、安装MySQL
rpm文件是Red Hat公司开发的软件安装包，rpm可让Linux在安装软件包时免除许多复杂的手续。该命令在安装时常用的参数是 –ivh ,其中i表示将安装指定的rmp软件包，V表示安装时的详细信息，h表示在安装期间出现“#”符号来显示目前的安装过程。这个符号将持续到安装完成后才停止。
1）安装服务器端
在有两个rmp文件的目录下运行如下命令：
[root@test1 local]# rpm -ivh MySQL-server-4.0.23-0.i386.rpm
显示如下信息。
warning: MySQL-client-4.0.23-0.i386.rpm
signature: NOKEY, key ID 5072e1f5
Preparing...　　　　　　　########################################### [100%]
1:MySQL-server　　　　　########################################### [100%]
。。。。。。（省略显示）
/usr/bin/mysqladmin -u root password 'new-password'
/usr/bin/mysqladmin -u root -h test1 password 'new-password'
。。。。。。（省略显示）
Starting mysqld daemon with databases from /var/lib/mysql
如出现如上信息，服务端安装完毕。测试是否成功可运行netstat看Mysql端口是否打开，如打开表示服务已经启动，安装成功。Mysql默认的端口是3306。
[root@test1 local]# netstat -nat
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address　　　　　 Foreign Address　　　　 State　　　
tcp　　0　　0 0.0.0.0:3306　　　　 0.0.0.0:*　　　　　 LISTEN　　　
上面显示可以看出MySQL服务已经启动。
2）安装客户端
运行如下命令：
[root@test1 local]# rpm -ivh MySQL-client-4.0.23-0.i386.rpm
warning: MySQL-client-4.0.23-0.i386.rpm: V3 DSA signature: NOKEY, key ID 5072e1f5
Preparing...　　　　########################################### [100%]
1:MySQL-client　 ########################################### [100%]
显示安装完毕。
用下面的命令连接mysql,测试是否成功。
三、登录MySQL
登录MySQL的命令是mysql， mysql 的使用语法如下：
mysql [-u username] [-h host] [-p[password]] [dbname]
username 与 password 分别是 MySQL 的用户名与密码，mysql的初始管理帐号是root，没有密码，注意：这个root用户不是Linux的系统用户。MySQL默认用户是root，由于 初始没有密码，第一次进时只需键入mysql即可。
[root@test1 local]# mysql
Welcome to the MySQL monitor.　Commands end with ; or \g.
Your MySQL connection id is 1 to server version: 4.0.16-standard
Type 'help;' or '\h' for help. Type '\c' to clear the buffer.
mysql>
出现了“mysql>”提示符，恭喜你，安装成功！
增加了密码后的登录格式如下：
mysql -u root -p
Enter password: (输入密码)

其中-u后跟的是用户名，-p要求输入密码，回车后在输入密码处输入密码。
注意：这个mysql文件在/usr/bin目录下，与后面讲的启动文件/etc/init.d/mysql不是一个文件。

四、MySQL的几个重要目录
MySQL安装完成后不象SQL Server默认安装在一个目录，它的数据库文件、配置文件和命令文件分别在不同的目录，了解这些目录非常重要，尤其对于Linux的初学者，因为 Linux本身的目录结构就比较复杂，如果搞不清楚MySQL的安装目录那就无从谈起深入学习。
下面就介绍一下这几个目录。
1、数据库目录
/var/lib/mysql/
2、配置文件
/usr/share/mysql（mysql.server命令及配置文件）
3、相关命令
/usr/bin(mysqladmin mysqldump等命令)
4、启动脚本
/etc/rc.d/init.d/（启动脚本文件mysql的目录）
五、修改登录密码
MySQL默认没有密码，安装完毕增加密码的重要性是不言而喻的。
1、命令
usr/bin/mysqladmin -u root password 'new-password'
格式：mysqladmin -u用户名 -p旧密码 password 新密码
2、例子
例1：给root加个密码123456。
键入以下命令 ：
[root@test1 local]# /usr/bin/mysqladmin -u root password 123456
注：因为开始时root没有密码，所以-p旧密码一项就可以省略了。
3、测试是否修改成功
1）不用密码登录
[root@test1 local]# mysql
ERROR 1045: Access denied for user: 'root@localhost' (Using password: NO)
显示错误，说明密码已经修改。
2）用修改后的密码登录
[root@test1 local]# mysql -u root -p
Enter password: (输入修改后的密码123456)
Welcome to the MySQL monitor.　Commands end with ; or \g.
Your MySQL connection id is 4 to server version: 4.0.16-standard
Type 'help;' or '\h' for help. Type '\c' to clear the buffer.
mysql>
成功！
这是通过mysqladmin命令修改口令，也可通过修改库来更改口令。
六、启动与停止
1、启动
MySQL安装完成后启动文件mysql在/etc/init.d目录下，在需要启动时运行下面命令即可。
[root@test1 init.d]# /etc/init.d/mysql start
2、停止
/usr/bin/mysqladmin -u root -p shutdown
3、自动启动
1）察看mysql是否在自动启动列表中
[root@test1 local]#　sbin/chkconfig --list
2）把MySQL添加到你系统的启动服务组里面去
[root@test1 local]#　sbin/chkconfig --add mysql
3）把MySQL从启动服务组里面删除。
[root@test1 local]#　sbin/chkconfig --del mysql



七、更改MySQL目录
MySQL默认的数据文件存储目录为/var/lib/mysql。假如要把目录移到/home/data下需要进行下面几步： /usr/lib/mysql/data
1、home目录下建立data目录
cd /home
mkdir data
2、把MySQL服务进程停掉：
/usr/bin/mysqladmin -u root -p shutdown
3、把/var/lib/mysql整个目录移到/home/data
mv /var/lib/mysql　/home/data/
这样就把MySQL的数据文件移动到了/home/data/mysql下
4、找到my.cnf配置文件
如果/etc/目录下没有my.cnf配置文件，请到/usr/share/mysql/下找到*.cnf文件，拷贝其中一个到/etc/并改名为my.cnf)中。命令如下：
[root@test1 mysql]# cp /usr/share/mysql/my-medium.cnf　/etc/my.cnf
5、编辑MySQL的配置文件/etc/my.cnf
为保证MySQL能够正常工作，需要指明mysql.sock文件的产生位置。修改socket=/var/lib/mysql/mysql.sock一行中等号右边的值为：/home/mysql/mysql.sock 。操作如下：
vi　 my.cnf　　　 (用vi工具编辑my.cnf文件，找到下列数据修改之)
# The MySQL server
[mysqld]
port　　　= 3306
#socket　 = /var/lib/mysql/mysql.sock（原内容，为了更稳妥用“#”注释此行）
socket　 = /home/data/mysql/mysql.sock　　　（加上此行）
6、修改MySQL启动脚本/etc/rc.d/init.d/mysql
最后，需要修改MySQL启动脚本/etc/rc.d/init.d/mysql，把其中datadir=/var/lib/mysql一行中，等号右边的路径改成你现在的实际存放路径：home/data/mysql。
[root@test1 etc]# vi　/etc/rc.d/init.d/mysql
#datadir=/var/lib/mysql　　　　（注释此行）
datadir=/home/data/mysql　　 （加上此行）
7、重新启动MySQL服务
/etc/rc.d/init.d/mysql start
或用reboot命令重启Linux
如果工作正常移动就成功了，否则对照前面的7步再检查一下。


八、MySQL的常用操作
注意：MySQL中每个命令后都要以分号；结尾。
1、显示数据库
mysql> show databases;
+----------+
| Database |
+----------+
| mysql　　|
| test　　 |
+----------+
2 rows in set (0.04 sec)
Mysql刚安装完有两个数据库：mysql和test。mysql库非常重要，它里面有MySQL的系统信息，我们改密码和新增用户，实际上就是用这个库中的相关表进行操作。
2、显示数据库中的表
mysql> use mysql; （打开库，对每个库进行操作就要打开此库，类似于foxpro ）
Database changed
mysql> show tables;
+-----------------+
| Tables_in_mysql |
+-----------------+
| columns_priv　　|
| db　　　　　　　|
| func　　　　　　|
| host　　　　　　|
| tables_priv　　 |
| user　　　　　　|
+-----------------+
6 rows in set (0.01 sec)
3、显示数据表的结构：
describe 表名;
4、显示表中的记录：
select * from 表名;
例如：显示mysql库中user表中的纪录。所有能对MySQL用户操作的用户都在此表中。
Select * from user;

5、建库：
create database 库名;
例如：创建一个名字位dfg的库
mysql> create databases dfg;
6、建表：
use 库名；
create table 表名 (字段设定列表)；
例如：在刚创建的dfg库中建立表name,表中有id(序号，自动增长)，xm（姓名）,xb（性别）,csny（出身年月）四个字段
use dfg;
mysql> create table name (id int(3) auto_increment not null primary key, xm char(8),xb char(2),csny date);
可以用describe命令察看刚建立的表结构。
mysql> describe name;
+-------+---------+------+-----+---------+----------------+
| Field | Type　　| Null | Key | Default | Extra　　　　　|
+-------+---------+------+-----+---------+----------------+
| id　　| int(3)　|　　　| PRI | NULL　　| auto_increment |
| xm　　| char(8) | YES　|　　 | NULL　　|　　　　　　　　|
| xb　　| char(2) | YES　|　　 | NULL　　|　　　　　　　　|
| csny　| date　　| YES　|　　 | NULL　　|　　　　　　　　|
+-------+---------+------+-----+---------+----------------+
7、增加记录
例如：增加几条相关纪录。
mysql> insert into name values('','张三','男','1971-10-01');
mysql> insert into name values('','白云','女','1972-05-20');
可用select命令来验证结果。
mysql> select * from name;
+----+------+------+------------+
| id | xm　 | xb　 | csny　　　 |
+----+------+------+------------+
|　1 | 张三 | 男　 | 1971-10-01 |
|　2 | 白云 | 女　 | 1972-05-20 |
+----+------+------+------------+
8、修改纪录
例如：将张三的出生年月改为1971-01-10
mysql> update name set csny='1971-01-10' where xm='张三';
9、删除纪录
例如：删除张三的纪录。
mysql> delete from name where xm='张三';
10、删库和删表
drop database 库名;
drop table 表名


九、增加MySQL用户
格式：grant select on 数据库.* to 用户名@登录主机 identified by "密码"
例1、增加一个用户user_1密码为123，让他可以在任何主机上登录，并对所有数据库有查询、插入、修改、删除的权限。首先用以root用户连入MySQL，然后键入以下命令：
mysql> grant select,insert,update,delete on *.* to user_1@"%" Identified by "123";
例1增加的用户是十分危险的，如果知道了user_1的密码，那么他就可以在网上的任何一台电脑上登录你的MySQL数据库并对你的数据为所欲为了，解决办法见例2。
例2、增加一个用户user_2密码为123,让此用户只可以在localhost上登录，并可以对数据库dfg进行查询、插入、修改、删除的操作（localhost指本地主机，即MySQL数据库所在的那台主机），这样用户即使用知道user_2的密码，他也无法从网上直接访问数据库，只能通过 MYSQL主机来操作dfg库。
mysql>grant select,insert,update,delete on dfg.* to user_2@localhost identified by "123";
用新增的用户如果登录不了MySQL，在登录时用如下命令：
mysql -u user_1 -p　-h 192.168.113.50　（-h后跟的是要登录主机的ip地址）


十、备份与恢复
1、备份
例如：将上例创建的dfg库备份到文件back_dfg中
[root@test1 root]# cd　/home/data/mysql　(进入到库目录，本例库已由val/lib/mysql转到/home/data/mysql，见上述第七部分内容)
[root@test1 mysql]# mysqldump -u root -p --opt dfg > back_dfg
2、恢复
[root@test mysql]# mysql -u root -p ccc < back_dfg


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

在LINUX中安装 MySQL，可以在终端提示符后运行下列命令：

sudo apt-get install mysql-server
sudo apt-get install mysql-client
sudo apt-get install php5-mysql 
// 安装php5-mysql 是将php和mysql连接起来

一旦安装完成，MySQL 服务器应该自动启动。

您可以在终端提示符后运行以下命令来检查 MySQL 服务器是否正在运行：
sudo netstat -tap | grep mysql
当您运行该命令时，您可以看到类似下面的行：
tcp 0 0 localhost.localdomain:mysql *:* LISTEN -

如果服务器不能正常运行，您可以通过下列命令启动它：
sudo /etc/init.d/mysql start  启动mysql

我们可以用以下命令去查看当前Mysql的状态
sudo service mysql status

进入mysql
$mysql -uroot -p 管理员密码

配置 MySQL 的管理员密码：
sudo mysqladmin -u root password newpassword

安装MySQL Administrator 图形界面
在新立得软件下搜索mysql找到
mysql-admin包，选择安装后就可以，在应用程序／编程就可以运行。
您也可以安装mysql 的图形化管理工具 sudo apt-get mysql-admin mysql-query-browser

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
配置 mysql，让它支持其它客户端访问，如果你不需要就不用修改。
登录到MySQL服务器端，在mysql库下执行增加用户操作：
格式：grant select on 数据库.* to 用户名@登录主机 identified by "密码"

GRANT ALL ON dbname.* TO test@'%' IDENTIFIED BY '123456'
此命令创建用户test，并给它赋予访问数据库dbname的不受限制的权限，且可以在任何机器上访问

grant all on *.* to 'remote'@'172.16.21.39' identified by 'password';
如果要设置为任何客户端都可以以root连接的话，可以这么写：
grant all on *.* to 'root'@'%' identifiied by 'root的密码'

mysql>GRANT ALL PRIVILEGES ON *.* TO admin@localhost IDENTIFIED BY 'something' WITH GRANT OPTION;
mysql>GRANT ALL PRIVILEGES ON *.* TO admin@"%" IDENTIFIED BY 'something' WITH GRANT OPTION;
第二个或者用下面：
mysql>update user set host="%" where host="192.168.1.1";


类似这用方法的整理如下：
1。 改表法。可能是你的帐号不允许从远程登陆，只能在localhost。这个时候只要在localhost的那台电脑，登入mysql后，更改 "mysql" 数据库里的 "user" 表里的 "host" 项，从"localhost"改称"%"
mysql -u root -pvmwaremysql>use mysql;mysql>update user set host = '%' where user = 'root';mysql>select host, user from user;
2. 授权法。例如，你想myuser使用mypassword从任何主机连接到mysql服务器的话。
GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'%' IDENTIFIED BY 'mypassword' WITH GRANT OPTION;
如果你想允许用户myuser从ip为192.168.1.3的主机连接到mysql服务器，并使用mypassword作为密码
GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'192.168.1.3' IDENTIFIED BY 'mypassword' WITH GRANT OPTION; 


但问题仍没有解决：

找到 命令   mysql> flush privileges    //使修改生效

                显示影响了零行。

问题依然没有解决，重新启动mysql  
sudo /etc/init.d/mysql restart
还是不行。

了解到mysql有本机绑定，找到问题所在。
查找文件
skip-networking
修改为
#skip-networking
保存并关闭文件。
编辑 /etc/mysql/my.cnf
sudo gedit /etc/mysql/my.cnf

# Instead of skip-networking the default is now to listen only on
# localhost which is more compatible and is not less secure.
bind-address = 127.0.0.1

将”bind-address = 127.0.0.1“注释
sudo /etc/init.d/mysql restart
或者
service mysqld restart
重启即可远程访问

Mysql卸载：
apt-get autoremove mysql-server
apt-get autoremove mysql-client

首先试试
apt-get --reinstall install mysql-server???
不行时而且mysql关联少时，可以apt-get remove --purge mysql-server???然后再安装，关联多不能删时，dpkg -S /etc/init.d/mysql找到对应的包，apt-get -d --reinstall install mysql-server??? 然后将对应的deb解开将mysql复制过去
dpkg -x /var/cache/apt/archives/mysql-server???.deb /tmp/foo
cp /tmp/foo/etc/init.d/mysql /etc/init.d
还不行的话，终极解决是将/var/lib/dpkg/info下对应的东东删掉，删除和重装相应的包了事，而不会影响系统的
+++++++++++++++++++++++++++++++++++++++++++++++++++
修改数据库默认字符集以及解决phpmyadmin和mysql中文乱码：
安装后的数据库编码默认是latin1，这个在编码下，存储中文时是会乱码的，所以在使用时还得把数据库的字符集改成支持中文的字符集，下面以utf-8为例，简单记录下修改字符集需要的操作：
1) 登录数据库后，使用命令show variables like 'character%' 可以查看数据库使用字符集的情况，下面是在没有修改前mysql的字符集设置：
+--------------------------+----------------------------+
| Variable_name            | Value                      |
+--------------------------+----------------------------+
| character_set_client     | latin1                     |
| character_set_connection | latin1                     |
| character_set_database   | latin1                     |
| character_set_filesystem | binary                     |
| character_set_results    | latin1                     |
| character_set_server     | latin1                     |
| character_set_system     | utf8                       |
| character_sets_dir       | /usr/share/mysql/charsets/ |

2) 要把字符集换成utf-8的，我们只要修改/etc/mysql/下的配置文件my.cnf。
首先停止mysql服务[sudo /etc/init.d/mysql stop]，然后在my.cnf中加入下面的配置段：

[client]
default-character-set = utf8
[mysqld_safe]
default-character-set=utf8
[mysqld]
default-character-set=utf8
[mysql]
default-character-set=utf8

3) 完成上面的修改，保存后重启mysql
[sudo service mysql restart]
重新登录mysql后，在执行：show variables like 'character%'; 字符集应该是变成了utf8
phpmyadmin的连接校对选用：utf8_general_ci 默认即可。这样配置完毕中文乱码可以解决，也可以用phpmyadmin管理mysql数据库了。
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++



Mysql安装:
sudo apt-get install mysql-server
sudo apt-get install mysql-client

#Linux Os
分享到： 浏览(6451) 评论(1) 转载
你可能也喜欢

 
LOL台服有爱数据统计：提莫今年死亡1.5亿次
 
跑跑本周各服更新2013-8-16
 
简评《伊苏F》
 
苏博士评说世嘉官方历史年表（1951—1986）
 
　　也许这些经典老游戏可以在移动端复活!
 
Kingdom Rush Frontiers（王国保卫战：前线）
 
婴幼用品市场潜力巨大 哪种开店方式适合你？
本文最近访客

 
lynn幻想童话
11月26日
 
来两根香肠
11月20日
 
kirazn
11月13日
 
冒险家OL
11月10日
 
wodemoney
10月26日
评论

hanguangce1支持2011-05-06 17:38回复
帮助中心 | 空间客服 | 投诉中心 | 空间协议
©2013 Baidu

百度空间，让世界发现你
向世界展示自己，发布喜爱的图片、文字和音乐
简单注册登录

========== http://wonphe.blog.163.com/blog/static/216507942010410753788/ ==========
网易 
博客 
发现
小组
风格
 
旅行达人猫力，送签名版新书 >>
创建博客登录  加关注
菜鸟训练营
努力向老鸟进化吧！！！
首页
日志
相册
音乐
收藏
博友
关于我
  
日志
  
菜鸟
  加博友   关注他
最新日志
【转载】SQL获取系统年月日
C#实现打印功能实例详解
浅析C#打印和C#打印预览的实
c# winform 打印 窗体 及 窗
可拖动控件 C#实现
.NET(C#)连接各类数据库-集
博主推荐
让Firefox支持迷你迅雷
随机阅读
八年打得完抗战，为何复查不了一个聂树斌案？
同气质美女大PK 你最中意谁
谢娜否认怀孕 综艺一姐的私服甜美搭
资金回流美国 一切回到从前
外国女性如何舍身“套”色狼
信孚电讯（3.20）——神一样的砖家
首页推荐
罗永浩：土豪最认可品牌
古代妃子生理期如何侍寝
查小欣：范冰冰陷姐弟恋
杨澜：李亚鹏答感情风波
红楼梦演员今昔对比(图)
董卿全裸献出第一次(图)
更多>>



 Ubuntu Linux环境下MySQL数据库的安装与配置方法 mysql图形界面
ubuntu下mysql配置  

2010-05-10 19:53:07|  分类： LINUX相关 |字号 订阅
一). ubuntu下mysql安装布局:
/usr/bin                      客户端程序和mysql_install_db
/db                             数据库和日志文件
/var/run mysqld        服务器
/etc/mysql mysql       配置文件my.cnf
/usr/share/mysql       字符集，基准程序和错误消息
/etc/init.d/mysql        启动mysql服务器
二). 设置mysql服务器随开关机自动启动和关闭：
系统 －> 系统管理 －> 服务
进行到“服务设置”窗口后，激活mysql数据库服务即可
三). 修改mysql数据库文件的存储目录：
MySQL默认的数据文件存储目录为/var/lib/mysql。假如要把目录移到/home/data下需要进行下面几步：
1、home目录下建立data目录
cd /home
mkdir data
2、把MySQL服务进程停掉：
mysqladmin -u root -p shutdown
3、把/var/lib/mysql整个目录移到/home/data
mv /var/lib/mysql　/home/data/
这样就把MySQL的数据文件移动到了/home/data/mysql下
4、找到my.cnf配置文件
如果/etc/目录下没有my.cnf配置文件，请到/usr/share/mysql/下找到*.cnf文件，拷贝其中一个到/etc/并改名为my.cnf)中。命令如下：
[root@test1 mysql]# cp /usr/share/mysql/my-medium.cnf　/etc/my.cnf
5、编辑MySQL的配置文件/etc/my.cnf
为保证MySQL能够正常工作，需要指明mysql.sock文件的产生位置。修改socket=/var/lib/mysql/mysql.sock一行中等号右边的值为：/home/mysql/mysql.sock 。操作如下：
vi　 my.cnf　 (用vi工具编辑my.cnf文件，找到下列数据修改之)
# The MySQL server
[mysqld]　 port　= 3306
#socket　 = /var/lib/mysql/mysql.sock（原内容，为了更稳妥用“#”注释此行）
socket　 = /home/data/mysql/mysql.sock　（加上此行）
6、修改MySQL启动脚本/etc/init.d/mysql
最后，需要修改MySQL启动脚本/etc/init.d/mysql，把其中datadir=/var/lib/mysql一行中，等号右边的路径改成你现在的实际存放路径：home/data/mysql。
[root@test1 etc]# vi　/etc/init.d/mysql
#datadir=/var/lib/mysql（注释此行）
datadir=/home/data/mysql （加上此行）
7、重新启动MySQL服务
/etc/init.d/mysql　start
或用reboot命令重启Linux
如果工作正常移动就成功了，否则对照前面的7步再检查一下。还要注意目录的属主和权限。
四). 配置mysql数据库的INNODB存储引擎：
1 . 查看mysql存储引擎情况： 登录mysql数据库，在mysql>提示符下搞入show engines;命令。发现： InnoDB | YES，说明此mysql数据库服务器支持InnoDB引擎。
2. 设置InnoDB为默认引擎：在配置文件my.cnf中的 [mysqld] 下面加入default-storage-engine=INNODB 一句，保存。
3. 重启mysql服务器：mysqladmin -u root -p shutdown(回车)，sudo /etc/init.d/mysql start(回车)。
4. 登录mysql数据库，在mysql>提示符下搞入show engines;命令。如果出现 InnoDB |DEFAULT，则表示我们 设置InnoDB为默认引擎成功。
ps: 这里我用重启命令sudo /etc/init.d/mysql restart，出现错误信息, 所以用了上面（步骤3）那种关闭服务又启动的笨方法。
分享到：        阅读(693)| 评论(1)| 转载 (0) |举报
 Ubuntu Linux环境下MySQL数据库的安装与配置方法 mysql图形界面
最近读者
登录后，您可以在此留下足迹。 
庚少
  
σ從現在
  
zwd945@1
  
yaoyuche
  
WoW
  
huihades
 
gxyaccp2
  
garnetty
评论
点击登录|昵称：

 

2011-08-02 21:11
sunxch05
ubuntu10.10+mysql5.1中第六步设置：
datadir=/home/data/mysql
这句在：/etc/mysql/my.cnf ，和文中
root@test1 etc]# vi　/etc/init.d/mysql
有所不同。
_____________________________________学习了。谢谢！
回复
  
  
 
  
公司简介 - 联系方法 - 招聘信息 - 客户服务 - 隐私政策 - 博客风格 - 手机博客 - VIP博客 - 订阅此博客
网易公司版权所有 ©1997-2013

========== http://www.cnblogs.com/wuhou/archive/2008/09/28/1301071.html ==========
八卦阵
事在人为,莫道万般皆是命;境由心造,退后一步自然宽
博客园   首页   新随笔   新文章   联系   订阅   管理
posts - 16,comments - 12,trackbacks - 2

昵称：武侯
园龄：5年
粉丝：6
关注：0
+加关注
搜索

 
常用链接

我的随笔
我的评论
我的参与
最新评论
我的标签
随笔档案

2008年11月 (2)
2008年10月 (7)
2008年9月 (7)
最新评论

1. Re:Ubuntu安装配置Mysql
我想问一下为什么要新建一个mysql用户组并新建mysql用户？是为了后续什么情况做准备？
--紫零瓶
2. Re:Ubuntu安装配置Mysql
我在5.1.61下安装确实存在问题，到第十部出现问题，要添加--basedir=/usr/local/mysql才能通过。不过后来还是安装失败了。执行/usr/local/mysql/bin/mysqladmin -u root password 'password'出错：connect to server at 'localhost'failederror:'Can't connnect to ...
--泉水叮~咚
阅读排行榜

1. Ubuntu安装配置Mysql(75315)
2. JProfiler在Linux上的安装和使用(4889)
3. ubuntu安装和配置SVN(2646)
4. Cisco VPN Client安装时出线DNE错误的解决方法(2137)
5. Ubuntu(691)
评论排行榜

1. Ubuntu安装配置Mysql(3)
2. 谁能告诉我thsn还能有几个涨停？(3)
3. 乱了，懒了(2)
4. 着凉了(2)
5. 关于Skin，关于心情(2)
推荐排行榜

1. Ubuntu安装配置Mysql(6)
2. JProfiler在Linux上的安装和使用(1)
Ubuntu安装配置Mysql
三种安装方式：

　　1. 从网上安装 sudo apt-get install mysql-server。装完已经自动配置好环境变量，可以直接使用mysql的命令。

　　　　注：建议将/etc/apt/source.list中的cn改成us，美国的服务器比中国的快很多。

　　2. 安装离线包，以mysql-5.0.45-linux-i686-icc-glibc23.tar.gz为例。

　　3. 二进制包安装：安装完成已经自动配置好环境变量，可以直接使用mysql命令

网上安装和二进制包安装比较简单，重点说安装离线包。

　　1. groupadd mysql

　　2. mkdir /home/mysql

　　3. useradd -g mysql -d /home/mysql mysql

　　4. copy mysql-5.0.45-linux-i686-icc-glibc23.tar.gz到/usr/local目录

　　5. 解压：tar zxvf mysql-5.0.45-linux-i686-icc-glibc23.tar.gz

　　6. ln -s mysql-5.0.45-linux-i686-icc-glibc23 mysql

　　7. cd /usr/local/mysql

　　8. chown -R mysql .

　　9. chgrp -R mysql .

　　10. scripts/mysql_install_db --user=mysql (一定要在mysql目录下执行，注意输出的文字，里边有修改root密码和启动mysql的命令）

　　11. 为root设置密码： ./bin/mysqladmin -u root password 'passw0rd'

 

配置和管理msyql：

　　1. 修改mysql最大连接数：cp support-files/my-medium.cnf ./my.cnf，vim my.cnf，增加或修改max_connections=1024

　　关于my.cnf：mysql按照下列顺序搜索my.cnf:/etc,mysql安装目录，安装目录下的data。/etc下的是全局设置。

　　2. 启动mysql：/usr/local/mysql/bin/mysqld_safe --user=mysql &

　　　　查看mysql版本：mysqladmin -u root -p version

　　　　注：网上安装或者二进制安装的可以直接使用如下命令启动和停止mysql: /etc/init.d/mysql start|stop|restart

　　3. 停止mysql：mysqladmin -uroot -ppassw0rd shutdown 注意，u,p后没有空格

　　4. 设置mysql自启动：把启动命令加入/etc/rc.local文件中

　　5. 允许root远程登陆：

　　　　1）本机登陆mysql：mysql -u root -p （-p一定要有）；改变数据库：use mysql;

　　　　2）从所有主机：grant all privileges on *.* to root@"%" identified by "passw0rd" with grant option;

　　　　3）从指定主机：grant all privileges on *.* to root@"192.168.11.205" identified by "passw0rd" with grant option; flush privileges;

　　　　4)  进mysql库查看host为%的数据是否添加：use mysql; select * from user;

　　6. 创建数据库，创建user：

　　　　1)  建库：create database test1;

　　　　2)  建用户，赋权：grant all privileges on test1.* to user_test@"%" identified by "passw0rd" with grant option;

　　　　3）删除数据库：drop database test1;

　　7. 删除权限：

　　　　1) revoke all privileges on test1.* from test1@"%";

　　　　2) use mysql;

　　　　3) delete from user where user="root" and host="%";

　　　　4) flush privileges;

　　8. 显示所有的数据库：show databases; 显示库中所有的表：show tables;

　　9. 远程登录mysql：mysql -h ip -u user -p

　　10. 设置字符集（以utf8为例）：

　　　　1） 查看当前的编码：show variables like 'character%';

　　　　2)　修改my.cnf，在[client]下添加default-character-set=utf8

　　　　3） 在[server]下添加default-character-set=utf8，init_connect='SET NAMES utf8;'

　　　　4） 重启mysql。

　　　　注：只有修改/etc下的my.cnf才能使client的设置起效，安装目录下的设置只能使server的设置有效。

　　　　　　二进制安装的修改/etc/mysql/my.cnf即可

 　　11. 旧数据升级到utf8（旧数据以latin1为例）：

　　　　1） 导出旧数据：mysqldump --default-character-set=latin1 -hlocalhost -uroot -B dbname --tables old_table >old.sql

　　　　2） 转换编码(Linux和UNIX)：iconv -t utf-8 -f gb2312 -c old.sql > new.sql

　　　　　　这里假定原表的数据为gb2312，也可以去掉-f，让iconv自动判断原来的字符集。

　　　　3） 导入：修改new.sql，在插入或修改语句前加一句话："SET NAMES utf8;"，并修改所有的gb2312为utf8，保存。

　　　　　　mysql -hlocalhost -uroot -p dbname < new.sql

　　　　　　如果报max_allowed_packet的错误，是因为文件太大，mysql默认的这个参数是1M，修改my.cnf中的值即可（需要重启mysql)。

　　12. 支持utf8的客户端：Mysql-Front,Navicat,PhpMyAdmin，Linux Shell（连接后执行SET NAMES utf8;后就可以读写utf8的数据了。10.4设置完毕后就不用再执行这句话了）

　　13. 备份和恢复

　　　　备份单个数据库：mysqldump -uroot -p -B dbname > dbname.sql

　　　　备份全部数据库：mysqldump -uroot -p --all-databases > all.sql

　　　　备份表： mysqldump -uroot -p -B dbname --table tablename > tablename.sql

　　　　恢复数据库：mysql -uroot -p < name.sql

　　　　恢复表：mysql -uroot -p dbname < name.sql (必须指定数据库) 

　　14. 复制

　　　　Mysql支持单向的异步复制，即一个服务器做主服务器，其他的一个或多个服务器做从服务器。复制是通过二进制日志实现的，主服务器写入，从服务器读取。可以实现多个主　　　　服务器，但是会碰到单个服务器不曾遇到的问题（不推荐）。

　　　　1). 在主服务器上建立一个专门用来做复制的用户：grant replication slave on *.* to 'replicationuser'@'192.168.0.87' identified by 'iverson';

　　　　2). 刷新主服务器上所有的表和块写入语句：flush tables with read lock; 然后读取主服务器上的二进制二进制文件名和分支：SHOW MASTER STATUS;将File和Position的值记录下来。记录后关闭主服务器：mysqladmin -uroot -ppassw0rd shutdown

　　　　　　如果输出为空，说明服务器没有启用二进制日志，在my.cnf文件中[mysqld]下添加log-bin=mysql-bin，重启后即有。

　　　　3). 为主服务器建立快照（snapshot）

　　　　　　需要为主服务器上的需要复制的数据库建立快照，Windows可以使用zip格式，Linux和Unix最好使用tar命令。然后上传到从服务器mysql的数据目录，并解压。

　　　　　　cd mysql-data-dir

　　　　　　tar cvzf mysql-snapshot.tar ./mydb

　　　　　　注意：快照中不应该包含任何日志文件或*.info文件，只应该包含要复制的数据库的数据文件（*.frm和*.opt）文件。

　　　　　　可以用数据库备份(mysqldump)为从服务器做一次数据恢复，保证数据的一致性。

　　　　4). 确认主服务器上my.cnf文件的[mysqld]section包含log-bin选项和server-id，并启动主服务器：

　　　　　　[mysqld]

　　　　　　log-bin=mysql-bin

　　　　　　server-id=1

　　　　5). 停止从服务器，加入server-id，然后启动从服务器：

　　　　　　[mysqld]

　　　　　　server-id=2

　　　　　　注：这里的server-id是从服务器的id，必须与主服务器和其他从服务器不一样。

　　　　　　可以在从服务器的配置文件中加入read-only选项，这样从服务器就只接受来自主服务器的SQL，确保数据不会被其他途经修改。

　　　　6). 在从服务器上执行如下语句，用系统真实值代替选项：

　　　　　　change master to MASTER_HOST='master_host', MASTER_USER='replication_user',MASTER_PASSWORD='replication_pwd',

　　　　　　　　MASTER_LOG_FILE='recorded_log_file_name',MASTER_LOG_POS=log_position;

　　　　7). 启动从线程：mysql> START SLAVE; 停止从线程：stop slave;（注意：主服务器的防火墙应该允许3306端口连接）

　　　　验证：此时主服务器和从服务器上的数据应该是一致的，在主服务器上插入修改删除数据都会更新到从服务器上，建表，删表等也是一样的。

以下是几个有用的连接：

http://publish.it168.com/2006/0203/20060203001301.shtml?cChanNel=11&cpositioncode=296&hezuo=107

分类: Ubuntu, mysql
绿色通道： 好文要顶 关注我 收藏该文与我联系 
武侯
关注 - 0
粉丝 - 6
+加关注
6 0
(请您对文章做出评价)
« 上一篇：JProfiler在Linux上的安装和使用
» 下一篇：ubuntu安装和配置SVN
posted on 2008-09-28 23:29 武侯 阅读(75314) 评论(3) 编辑 收藏

FeedBack:
#1楼
2011-09-11 19:03 | ptsntwsz  
8. chown -R mysql .
9. chgrp -R mysql .
10. scripts/mysql_install_db --user=mysql

There are some problems with the three steps above. (Sorry I couldn't input Chinese characters right now ....)
支持(0)反对(0)
  
#2楼
2012-11-27 11:09 | 泉水叮~咚  
我在5.1.61下安装确实存在问题，到第十部出现问题，要添加--basedir=/usr/local/mysql才能通过。
不过后来还是安装失败了。
执行/usr/local/mysql/bin/mysqladmin -u root password 'password'
出错：connect to server at 'localhost'failed
error:'Can't connnect to local mysql server through socket 'ar/run/mysqld/mysqld.sock'(2)'
check that mysqld is running and that the socket 'var/run/mysqld/mysqld.sock' exists
支持(0)反对(0)
  
#3楼
2013-07-21 09:58 | 紫零瓶  
我想问一下为什么要新建一个mysql用户组并新建mysql用户？是为了后续什么情况做准备？
支持(0)反对(0)
  
刷新评论刷新页面返回顶部
注册用户登录后才能发表评论，请 登录 或 注册，访问网站首页。
博客园首页博问新闻闪存程序员招聘知识库

最新IT新闻:
· 谷歌未来全球增长面临的10大挑战
· Twitter创始人谈如何创造财富
· 花旗因证券研究违规被罚款3000万美元
· IE漏洞或被集成到开源工具 可引发大规模攻击
· 评论：微软之死
» 更多新闻...
最新知识库文章:
· 语法规范：BNF与ABNF
· 程序员的样子
· Hadoop之父Doug Cutting
· 从头到尾彻底解析Hash表算法
· Socket网络编程常用的结构及函数小结
» 更多知识库文章...
Copyright ©2013 武侯 Powered By博客园 模板提供：沪江博客
========== http://wenku.baidu.com/view/4597c60d7cd184254b353586.html ==========
========== http://qcenglish.com/# ==========

完整类别|最近更新|RSS|收藏本站
公告：关于部分浏览器下载时需要输入用户名、密码的解决方案
首页文学作品小说经典神秘惊悚科幻魔幻儿童读物浪漫爱情传记回忆录文学总论经管励志经济学管理学励志成功交际技巧处事哲学电脑网络程序和Web开发网络网站图形图像操作系统应用软件数据库硬件语言文字英语词汇英语语法英语语言英语应用考试小语种语言学生活休闲户外旅游饮食烹饪情感生活保健养生家庭妇女棋牌游戏体育运动哲学宗教哲学宗教人文社科历史地理政治心理学军事社会法律教育艺术社会科学总论自然科学数学医学物理化学生物科学天文学地球科学气象学建筑学工业技术交通运输超自然自然科学总论工具书词典百科全书参考书手册系列 失落的秘符 《失落的秘符》，又名《消失的符号》。哈佛大学符号学家罗伯特 兰登意外受邀在晚上到美国国会大厦做一个讲座。就在兰登到达的几分钟内，这一晚发生匪夷所思的变化。一个令人不安的物体在国会大厦内被发现，上面诡异的刻着五个符合。兰登知道这是一种古老的邀请方式。这时... 12345
欢迎访问七彩英语,我们为您精心准备了2537本英文原版电子书,快看看吧

﻿读者最喜欢的100本英文电子书：PDF格式 - TXT格式 我们为您推荐的100本英文电子书：PDF格式 - TXT格式
﻿

 
最近更新 Herland她乡 Charlotte Perkins Stetson Gilman夏洛特·P·S·吉小曼 [小说经典] This is written from memory, unfortunately. If I could have brought with me the material I so carefully prepared, this would be a very different story. Whole books full of notes, carefully copied recor Madam How and Lady Why怎么样夫人和为什么女士 Charles Kingsley查理斯·京士理 [儿童读物] Madam How and Lady Why: First Lessons in Earth Lore for Children is a classic book written by author Charles Kingsley. This title has long been a popular juvenile work dealing with natural phenomenon and gives them an excellent understanding The Great God Pan潘恩大帝 Arthur Machen亚瑟·玛臣 [小说经典] The Great God Pan is a novella written by Arthur Machen. On publication it was widely denounced by the press as degenerate and horrific because of its decadent style and sexual content, although it has since garnered a reputation as a classi The Heroes英雄们 Charles Kingsley查理斯·京士理 [小说经典] The Life and Perambulations of a Mouse小耗子游记 Dorothy Kilner桃乐茜·基尔纳 [儿童读物] This very interesting and charming narrative chronicles the life of a mouse. All the animals have been invested with a unique persona. The work is made unique by the fact that the attitudes, feelings and thoughts of the animal are presented

 
《攀爬植物的行为和习性》The Movements and Habits of Climbing Plants[生物科学]By Charles Darwin 查尔斯·达尔文 《马可·波罗》Messer Marco Polo[历史] 《卡尔维恩回忆录》Memoirs Of Carwin The Biloquist[小说经典] 《印度孩提时代》Indian Boyhood[历史] 《葬身海底》Riders to the Sea[小说经典] 《政坛上的利他主义》The Altruist in Politics[政治] 《人们的手段》The Ways of Men[小说经典] 《卡米勒》Camille (La Dame Aux Camilias)[小说经典] 《莱翁丝女士》The Lady of Lyons[历史] 《江湖骗子自白》The Autobiography Of A Quack And The Case Of George Dedlow[传记回忆录] 《一个即临种族》The Coming Race[小说经典] 《公正的大卫》Just David[小说经典] 《下来吧,哈拉》Dawn O’Hara The Girl Who Laughed[小说经典] 《约翰·约伯·奥斯塔》John Jacob Astor[传记回忆录] 《魔鬼一样的人》The Monster Men[科幻魔幻] 《一个工程师的家庭》Records of a Family of Engineers[历史] 《消失的大陆》The Lost Continent[科幻魔幻] 《回忆弗莱明·杰肯》Memoir of Fleeming Jenkin[传记回忆录] 《厄西亚房子的倒塌》The Fall of the House of Usher[小说经典] 《屈身求爱》She Stoops to Conquer[小说经典] 《曾达的囚徒》The Prisoner of Zenda[小说经典] 《梦境与现实》Dream Life and Real Life[历史] 《多情的丘比特》Frivolous Cupid[小说经典]
文学作品《巡鱼的故事》Tales of the Fish Patrol 《悬崖》The Precipice 《杜德里·沙顿神父》Urbain Grandier 《诽谤者自传》The Autobiography of a Slander 《黑星坠落》The Black Star Passes 《少年》A Raw Youth 《最后一个人和第一个人》Last and First Men 《汤姆·史威夫特和他的空战》Tom Swift & His Aerial Warship 《地下噬菌体》Metrophage 《消瘦幽灵和其他鬼故事》A Thin Ghost and Others 《未知卡达斯的幻梦探求》The Dream-Quest of Unknown Kadath 经管励志电脑网络语言文字生活休闲 作家
Edward Bulwer Lytton李顿·爱德华
L. Frank Baum莱曼·弗兰克·鲍姆
William Congreve威廉·康格里夫
Edgar Rice Burroughs埃德加·赖斯·巴勒斯
Zecharia Sitchin撒迦利亚·西琴
Sir Walter Scott瓦尔特·司各特
Charles Dickens查尔斯·狄更斯
J.K. RowlingJ.K.罗琳
Stephenie Meyer斯蒂芬妮·迈耶
Victor Appleton维克托·阿普尔顿
E. B. WhiteE.B.怀特
Bill Bryson比尔·布莱森
Dante Alighieri阿利盖利·但丁
Bret Harte布雷特·哈特
Charles Darwin查尔斯·达尔文

 
排行书籍
麦田里的守望者 小说经典
The Catcher in the RyeJ.D. SalingerJ·D·塞林格 了不起的盖茨比 小说经典 傲慢与偏见 小说经典 老人与海 小说经典 失落的秘符 神秘惊悚 哈利·波特与魔法石 儿童读物 国富论 经济学 英语语法手册 英语语法 乱世佳人 小说经典 简爱 小说经典 百年孤独 小说经典 权力的游戏（冰与火之歌第一部） 科幻魔幻 秘密 励志成功 世界是平的 经济学 万物简史 自然科学总论 她乡 小说经典 暮光之城Ⅰ暮色 科幻魔幻 达芬奇密码 神秘惊悚 夏洛的网 儿童读物 把妹达人 情感生活 让女人狂野的秘密 情感生活 谁动了我的奶酪 处事哲学 时间简史 物理 爱经 情感生活 动物庄园 小说经典 一九八四 小说经典 哈利·波特与密室 儿童读物 黑暗任务：NASA神秘的历史 自然科学总论 语法学习：如何写出漂亮句子 英语语法 证券分析 经济学 在路上 小说经典 经济学原理第三版 经济学 英语单词：历史与结构 英语词汇 富爸爸穷爸爸 励志成功 雾都孤儿 小说经典 哈姆雷特 小说经典 简爱 小说经典 揭秘英语语法：自学指南 英语语法 追风筝的人 小说经典 怎么样夫人和为什么女士 儿童读物 人性的枷锁 小说经典 把妹达人2：游戏规则 情感生活 爱丽丝漫游奇境记 儿童读物 小王子 儿童读物 梦的解析 心理学 福尔摩斯案卷 神秘惊悚 博迪投资学 经济学 实用中高级英语词汇 英语词汇 指环王前传霍比特人 科幻魔幻 人性的优点 处事哲学 系列和专题纳尼亚传奇牛津通识读本黑暗物质暮光之城莎士比亚四大悲剧绿野仙踪Frommer's 旅游指南指环王哈利·波特追忆似水年华冰与火之歌地球编年史友情链接可可英语 星火英语网 小马过河 英语学习网 摩西英语 沪江听力 四六级考试网 孕妇食谱 恒星英语 星沙英语 儿童英语乐园 快乐英语网 英语家园 同考英语 牛津英语网 英语听力 成都新航道 方向标英语 上海外教口语 非常英语 看电影学英语 玩游戏学英语 英语四级 99免费英语课 VOA慢速英语 Lucy陪你说英语 乐知英语 优学英语 恩京英语 VOA英语网 南京家教网 电话英语 普特英语听力 电话英语 英语教师网 新东方留学 留学中介 VERYPOD
完整类别
Categories

文学作品小说经典神秘惊悚科幻魔幻儿童读物浪漫爱情传记回忆录文学总论经管励志经济学管理学励志成功交际技巧处事哲学电脑网络程序和Web开发网络网站图形图像操作系统应用软件数据库硬件语言文字英语词汇英语语法英语语言英语应用考试小语种语言学生活休闲户外旅游饮食烹饪情感生活保健养生家庭妇女棋牌游戏体育运动哲学宗教哲学宗教人文社科历史地理政治心理学军事社会法律教育艺术社会科学总论自然科学数学医学物理化学生物科学天文学地球科学气象学建筑学工业技术交通运输超自然自然科学总论工具书词典百科全书参考书手册推荐系列牛津通识读本莎士比亚四大悲剧冰与火之歌纳尼亚传奇地球编年史与神对话追忆似水年华完全傻瓜指南黑暗物质指环王哈利·波特揭秘自学指南Frommer's 旅游指南莎士比亚四大喜剧暮光之城绿野仙踪七彩英语 - 英文电子书下载站 PDF|TXT格式英文原版原著下载本站由山东理工大学外国语学院学生设计维护关于我们|赞助我们|特别感谢|网站地图|常见问题 |友情链接
========== http://www.galaaa.com/ ==========
========== http://www.w3school.com.cn/css/index.asp ==========
w3school 在线教程 

 
HTML 系列教程
浏览器脚本
服务器脚本
ASP.NET 教程
XML 系列教程
Web Services 系列教程
建站手册
CSS 基础教程
CSS 教程
CSS 简介
CSS 基础语法
CSS 高级语法
CSS 派生选择器
CSS id 选择器
CSS 类选择器
CSS 属性选择器
CSS 创建
CSS 样式
CSS 背景
CSS 文本
CSS 字体
CSS 链接
CSS 列表
CSS 表格
CSS 轮廓
CSS 框模型
CSS 框模型概述
CSS 内边距
CSS 边框
CSS 外边距
CSS 外边距合并
CSS 定位
CSS 定位概述
CSS 相对定位
CSS 绝对定位
CSS 浮动
CSS 选择器
CSS 元素选择器
CSS 选择器分组
CSS 类选择器详解
CSS ID 选择器详解
CSS 属性选择器详解
CSS 后代选择器
CSS 子元素选择器
CSS 相邻兄弟选择器
CSS 伪类
CSS 伪元素
CSS 高级
CSS 对齐
CSS 尺寸
CSS 分类
CSS 导航栏
CSS 图片库
CSS 图片透明
CSS 媒介类型
CSS 注意事项
CSS 总结
CSS 实例
CSS 实例
CSS 参考手册
CSS 参考手册
CSS 打印
CSS 听觉
CSS 单位
CSS 颜色值
CSS 测验
CSS 测验
建站手册
网站构建
万维网联盟 (W3C)
浏览器信息
网站品质
语义网
职业规划
网站主机
关于 W3School
帮助 W3School
CSS 教程
CSS 教程
CSS 简介
CSS 教程
通过使用 CSS 来提升工作效率！
在我们的 CSS 教程中，您会学到如何使用 CSS 同时控制多重网页的样式和布局。
开始学习 CSS ！
CSS 实例
学习 70 个实例。您可以对 CSS 代码进行编辑，然后单击测试按钮来查看结果。
亲自试一下吧 ！
CSS 测验
在 W3School 测试您的 CSS 技能！
开始 CSS 测验！
CSS 参考手册
在 W3School，我们提供完整的 CSS 参考手册（已升级为 CSS3）。
CSS2 参考手册
CSS3 参考手册
CSS 教程
CSS 简介
SEARCH:
 
CSS 参考手册

CSS 实例

CSS 测验


 
W3School 提供的内容仅用于培训。我们不保证内容的正确性。通过使用本站内容随之而来的风险与本站无关。W3School 简体中文版的所有内容仅供测试，对任何法律问题及风险不承担任何责任。
当使用本站时，代表您已接受了本站的使用条款和隐私条款。版权所有，保留一切权利。 赞助商：上海赢科投资有限公司。 蒙ICP备06004630号
========== http://www.gbin1.com/technology/jquerytutorial/20120813-css-animation-timeline/ ==========
========== http://www.w3school.com.cn/js/index.asp ==========
w3school 在线教程 

 
HTML 系列教程
浏览器脚本
服务器脚本
ASP.NET 教程
XML 系列教程
Web Services 系列教程
建站手册
JS 教程
JS 教程
JS 简介
JS 实现
JS 输出
JS 语句
JS 注释
JS 变量
JS 数据类型
JS 对象
JS 函数
JS 运算符
JS 比较
JS If...Else
JS Switch
JS For
JS While
JS Break
JS 错误
JS 验证
JS HTML DOM
DOM 简介
DOM HTML
DOM CSS
DOM 事件
DOM 节点
JS 对象
JS 对象
JS 数字
JS 字符串
JS 日期
JS 数组
JS 逻辑
JS 算数
JS 正则表达式
JS Window
JS Window
JS Screen
JS Location
JS History
JS Navigator
JS PopupAlert
JS Timing
JS Cookies
JS 库
JS 库
JS jQuery
JS Prototype
JS 实例和测验
JS 实例
JS 对象实例
JS 测验
JS 总结
JS 参考手册
JavaScript 对象
HTML DOM 对象
JS 课外书
JS 高级教程
建站手册
网站构建
万维网联盟 (W3C)
浏览器信息
网站品质
语义网
职业规划
网站主机
关于 W3School
帮助 W3School
JavaScript 教程
JS 教程
JS 简介
JavaScript 是属于网络的脚本语言！
JavaScript 被数百万计的网页用来改进设计、验证表单、检测浏览器、创建cookies，以及更多的应用。
JavaScript 是因特网上最流行的脚本语言。
JavaScript 很容易使用！你一定会喜欢它的！
开始学习 JavaScript ！
JavaScript 实例
学习 100 个实例！使用我们的编辑器，你可以编辑源代码，然后单击 TIY 按钮来查看结果。
JavaScript 实例
JavaScript Object 实例
HTML DOM 实例
JavaScript 测试
在 W3School 测试你的 JavaScript 技能！
开始 JavaScript 测验 ！
JavaScript 参考手册
在 W3School，我们为您提供完整的 JavaScript 对象参考手册。
完整的 JavaScript 对象参考手册（包含实例）
完整的 HTML DOM 对象参考手册（包含实例）
JavaScript 课外书
如果您已经把我们的 JavaScript 教程学习完毕，并且需要更深入地学习这门语言，那么 w3school 提供的 《JavaScript 高级教程》绝对是您最好的选择。
本教程从 JavaScript 的历史开始讲起，直到当前它对 XML 和 Web 服务的支持。
您将学习到如何扩展该语言，以使它适应特殊的需求。
您还将学到如何使用 JavaScript 创建无缝的客户机 - 服务器通信。
本教程深入浅出，在您认真学习之后，一定会获益良多。
马上开始学习 JavaScript 高级教程吧 ！
JS 教程
JS 简介
SEARCH:
 
JavaScript 参考手册

JavaScript 实例

JavaScript 测验


 
W3School 提供的内容仅用于培训。我们不保证内容的正确性。通过使用本站内容随之而来的风险与本站无关。W3School 简体中文版的所有内容仅供测试，对任何法律问题及风险不承担任何责任。
当使用本站时，代表您已接受了本站的使用条款和隐私条款。版权所有，保留一切权利。 赞助商：上海赢科投资有限公司。 蒙ICP备06004630号
========== http://www.w3school.com.cn/jquery/index.asp ==========
w3school 在线教程 

 
HTML 系列教程
浏览器脚本
服务器脚本
ASP.NET 教程
XML 系列教程
Web Services 系列教程
建站手册
jQuery 教程
jQuery 教程
jQuery 简介
jQuery 安装
jQuery 语法
jQuery 选择器
jQuery 事件
jQuery 效果
jQuery 隐藏/显示
jQuery 淡入淡出
jQuery 滑动
jQuery 动画
jQuery stop()
jQuery Callback
jQuery Chaining
jQuery HTML
jQuery 获取
jQuery 设置
jQuery 添加
jQuery 删除
jQuery CSS 类
jQuery css()
jQuery 尺寸
jQuery 遍历
jQuery 遍历
jQuery 祖先
jQuery 后代
jQuery 同胞
jQuery 过滤
jQuery AJAX
jQuery AJAX 简介
jQuery 加载
jQuery Get/Post
jQuery 杂项
jQuery noConflict()
jQuery 实例
jQuery 实例
jQuery 测验
jQuery 参考手册
jQuery 参考手册
jQuery 选择器
jQuery 事件
jQuery 效果
jQuery 文档操作
jQuery 属性操作
jQuery CSS 操作
jQuery Ajax
jQuery 遍历
jQuery 数据
jQuery DOM 元素
jQuery 核心
jQuery 属性
建站手册
网站构建
万维网联盟 (W3C)
浏览器信息
网站品质
语义网
职业规划
网站主机
关于 W3School
帮助 W3School
jQuery 教程
jQuery 教程
jQuery 简介
jQuery 是一个 JavaScript 库。
jQuery 极大地简化了 JavaScript 编程。
jQuery 很容易学习。
每一章中用到的实例
<html>
<head>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript">
$(document).ready(function(){
  $("p").click(function(){
  $(this).hide();
  });
});
</script>
</head>

<body>
<p>If you click on me, I will disappear.</p>
</body>

</html> 
亲自试一试
通过点击 "TIY" 按钮来看看它是如何运行的。
您将学到什么
在本教程中，您将通过教程以及许多在线实例，学到如何通过使用 jQuery 应用 JavaScript 效果。
jQuery 是一个“写的更少，但做的更多”的轻量级 JavaScript 库。
基本上，您将学习到如何选取 HTML 元素，以及如何对它们执行类似隐藏、移动以及操作其内容等任务。
您需要具备的基础知识
在您开始学习 jQuery 之前，您应该对以下知识有基本的了解：
HTML
CSS
JavaScript
如果您需要首先学习这些科目，请在我们的 首页 查找这些教程。
jQuery 实例
通过实例来学习！在 W3School，您将找到许多可以在线编辑并测试的 jQuery 实例。
jQuery 实例
jQuery 参考手册
在 W3School，您将找到包含所有 jQuery 对象和函数的完整参考手册。
jQuery 参考手册
jQuery 教程
jQuery 简介
SEARCH:
 
jQuery 参考手册

jQuery 测验


 
W3School 提供的内容仅用于培训。我们不保证内容的正确性。通过使用本站内容随之而来的风险与本站无关。W3School 简体中文版的所有内容仅供测试，对任何法律问题及风险不承担任何责任。
当使用本站时，代表您已接受了本站的使用条款和隐私条款。版权所有，保留一切权利。 赞助商：上海赢科投资有限公司。 蒙ICP备06004630号
========== http://bbs.jquery.org.cn/forum.php?mod=viewthread&tid=8&extra=page%3D1 ==========
404 Not Found

The resource requested could not be found on this server!
Powered By LiteSpeed Web Server
LiteSpeed Technologies is not responsible for administration and contents of this web site!
========== http://www.miniui.com/index.html#tutorial ==========
jQuery MiniUI为什么选择MiniUI？首页产品示例文档下载论坛联系资质
MiniUI - 快速开发WebUI
快速开发，减少50%代码量
丰富组件库，高性能、低内存
支持 Java、.NET、PHP
支持 IE6+、FireFox、Chrome

快速开发
jQuery MiniUI - 快速开发WebUI。
它能缩短开发时间，减少代码量，使开发者更专注于业务和服务端，轻松实现界面开发，带来绝佳的用户体验。
面向企业
jQuery MiniUI致力降低企业应用的开发成本，丰富的UI控件、高度的稳定性、强大的扩展能力和平滑的版本升级能力，可满足大部分业务场景需求。
全面支持
5*8与7*24的电话支持服务、电子邮件服务、即时通讯服务、产品培训、现场疑难解答、按人月的项目现场开发服务、新功能定制研发服务、源代码讲解研发服务等
表单
DataBinding
Form
Button
CheckBox
ListBox
CheckBoxList
RadioButtonList
Calendar
ButtonEdit
PopupEdit
TextBox
Password
TextArea
TextBoxList
ComboBox
DatePicker
Spinner
TimeSpinner
TreeSelect
Lookup
HtmlFile
FileUpload
布局
Panel
Window
Splitter
Layout
Fit
导航
Pager
NavBar
Tree
Tabs
Menu
Toolbar
列表
DataGrid
Tree
TreeGrid
Copyright © 上海普加软件有限公司版权所有  沪ICP备11015788号-6 网站导航|支持服务|授权方式|联系我们
========== http://www.cnblogs.com/lhb25/archive/2012/03/26/30-fresh-and-outstanding-jquery-effects.html ==========

梦想天空关注前端开发技术 ◆ 分享网页设计资源 ◆ 推动 HTML5 & CSS3 技术发展 ◆ jizhula.com 你记住了吗：）
首页管理网页设计精美素材JavaScriptjQueryHTML5CSS3订阅

随笔- 1504  文章- 1  评论- 12690 
推荐30个新鲜出炉的精美 jQuery 效果
　　jQuery 是最流行和使用最广泛的 JavaScript 框架，它简化了HTML文档遍历，事件处理，动画以及Ajax交互，帮助Web开发人员更快速的实现各种精美的界面效果。jQuery 的易扩展性吸引了来自全球的开发者来共同编写 jQuery 插件，这些优秀的 jQuery 插件不仅能够增强网站的可用性，有效的改善用户体验，还可以加快开发速度，节省开发时间。

Image Slider, Light Boxes

01. 3D Gallery
 


 

02. Book Transition Pages
 


 

03. Image Hover Effects
 


 

04. Swish Zoom Hover Effect
 


 

05. Slider With Modern Effects
 


 

06. Elastic Image Slider
 


 

07. Awesome Slide Show
 


 

08. Flexible notifications
 


 

09. Powerful Scrolling
 


 

10. UI Bootstrap
 


 

11. Stylish Accordion
 


 

12. On-demand Search Box
 


 

13. Colorful Tool Tip
 


 

14. Shiny Knob Control
 


 

15. Thumbnail Proximity
 


 

16. Image Transitions
 


 

17. Multiple style Slideshow
 


 

18. Video Player
 


 

19. Photo Album
 


 

Form Effects

01. Cool Captcha
 


 

02. Apple Like Login Form
 


 

Menus Effects

01. list items menu
 


 

02. Simple Link Box navigation
 


 

03. Multi Level Hierarchical Menu
 


 

Text Effects

01. Curving Text
 


 

02. Text Scrollorama
 


 

03. Count Down Timer
 


 

04. Item Blur
 


 

05. Typography Effect
 


 

06. Smarter Text Input Fields
 


您你可能还喜欢

 

Web开发者必备的20款超赞 jQuery 插件
60款很酷的 jQuery 幻灯片演示和下载
30个最佳 jQuery Lightbox 效果插件
12个很棒的学习 jQuery 开发的网站推荐
15个款优秀的 jQuery 图片特效插件推荐
 

英文链接：30 and Outstanding Jquery Effects Roundups

编译来源：梦想天空 ◆ 关注前端开发技术 ◆ 分享网页设计资源

本周推荐博文

Web 前端工程师和设计师必读精华文章推荐
酷！15个精美的 HTML5 单页网站作品欣赏
炫！35个让人惊讶的 CSS3 动画效果演示
赞！30个与众不同的优秀视差滚动效果网站
靓！25个优秀的国外单页网站设计作品欣赏
帅！8个惊艳的 HTML5 和 JavaScript 特效
顶！35个很漂亮的国外 Flash 网站作品欣赏
哇！34个漂亮网站和应用程序后台管理界面

 
分享到：新浪微博 QQ空间 腾讯微博 人人网 开心网 豆瓣 1
作者：山边小溪 
出处：jizhula.com 记住啦：） 
欢迎任何形式的转载，但请务必注明出处。

分类: jQuery, 原创翻译
标签: jQuery, jQuery特效
绿色通道： 好文要顶 关注我 收藏该文与我联系 
梦想天空（山边小溪）
关注 - 16
粉丝 - 5877
+加关注
13 0
(请您对文章做出评价)
« 上一篇：分享45个非常有创意的网站底部设计案例
» 下一篇：《JavaScript 每周导读》【第一期】
posted @ 2012-03-26 09:10 梦想天空（山边小溪） 阅读(9436) 评论(24) 编辑 收藏

发表评论
   #1楼 2012-03-26 09:30 | artwl  
效果很赞，貌似前几天有人发过了：http://www.cnblogs.com/web8cn/archive/2012/03/23/2413113.html
支持(0)反对(0)

   #2楼[楼主] 2012-03-26 09:43 | 梦想天空（山边小溪）  
@artwl
是哦，这位兄弟博客皮肤和我弄得一样
支持(0)反对(0)

   #3楼 2012-03-26 11:20 | flowbywind  
很好哈
支持(0)反对(0)

   #4楼 2012-03-26 11:23 | coding as talking  
顶
支持(0)反对(0)

   #5楼[楼主] 2012-03-26 13:02 | 梦想天空（山边小溪）  
@flowbywind
谢谢关注！：）
支持(0)反对(0)

   #6楼[楼主] 2012-03-26 13:02 | 梦想天空（山边小溪）  
@coding as talking
谢谢支持！：）
支持(0)反对(0)

   #7楼 2012-03-26 15:18 | 来如风  
给用户用就很好了
支持(0)反对(0)

   #8楼 2012-03-26 17:20 | § 薄樱 §  
楼主V5。正好需要
支持(0)反对(0)

   #9楼 2012-03-26 18:08 | 给力的程序员  
顶啊，都是老外设计的吧
支持(0)反对(0)

   #10楼[楼主] 2012-03-27 08:51 | 梦想天空（山边小溪）  
@来如风
嗯，这个效果很实用！
支持(0)反对(0)

   #11楼[楼主] 2012-03-27 08:51 | 梦想天空（山边小溪）  
@&#167; 薄樱 &#167;
呵呵，在做啥项目啊？
支持(0)反对(0)

   #12楼[楼主] 2012-03-27 08:51 | 梦想天空（山边小溪）  
@&#167; 薄樱 &#167;
还是很忙吧？
支持(0)反对(0)

   #13楼[楼主] 2012-03-27 08:51 | 梦想天空（山边小溪）  
@给力的程序员
嗯，是国外的。
支持(0)反对(0)

   #14楼[楼主] 2012-03-27 08:52 | 梦想天空（山边小溪）  
@给力的程序员
这个系列的插件也有很用：40款非常有用的 jQuery 插件推荐
支持(0)反对(0)

   #15楼 2012-03-27 09:13 | 11ge  
图片看不到，可以的话用不要用链接，因为办公网络只能方位有限的网站
支持(0)反对(0)

   #16楼[楼主] 2012-03-27 09:24 | 梦想天空（山边小溪）  
@11ge
只能访问有限的网络，这个真没办法啊
支持(0)反对(0)

   #17楼 2012-03-27 09:52 | 李媛媛  
现在jQuery是很给力！很炫，解决了一些兼容性问题！
支持(0)反对(0)

   #18楼 2012-03-27 11:47 | xluo  
你怎么老喜欢分享这些东西啊？
支持(0)反对(0)

   #19楼[楼主] 2012-03-27 14:30 | 梦想天空（山边小溪）  
@xluo
呵呵，你对什么感兴趣？
支持(0)反对(0)

   #20楼[楼主] 2012-03-27 14:31 | 梦想天空（山边小溪）  
@李媛媛
嗯，Write Less,Do More!
支持(0)反对(0)

   #21楼 2012-03-28 12:56 | coding as talking  
汗 怎么下载源码啊？
支持(0)反对(0)

   #22楼[楼主] 2012-03-28 15:02 | 梦想天空（山边小溪）  
@coding as talking
这篇文章展示的是实现的效果，源码要自己分析出来，下载jQuery插件可以参考这篇文章：40款非常有用的 jQuery 插件推荐
支持(0)反对(0)

   #23楼 2012-08-03 10:54 | 德威  
文章不错！赞一个！
支持(0)反对(0)

   #24楼 2012-08-05 19:28 | omeweb  
文章不错！赞一个！
支持(0)反对(0)

刷新评论刷新页面返回顶部
注册用户登录后才能发表评论，请 登录 或 注册，访问网站首页。
博客园首页博问新闻闪存程序员招聘知识库
历史上的今天:
2011-03-26 分享30个优秀的 Photoshop 网页设计教程
2011年度十大杰出IT博客

新浪微博：weibo.com/iamlhb
昵称：梦想天空（山边小溪）
园龄：5年2个月
粉丝：5877
关注：16
+加关注
<	2012年3月	>
日	一	二	三	四	五	六
26	27	28	29	1	2	3
4	5	6	7	8	9	10
11	12	13	14	15	16	17
18	19	20	21	22	23	24
25	26	27	28	29	30	31
1	2	3	4	5	6	7
搜索
 
 
我的标签
网页设计(292)
jQuery(154)
javascript(125)
HTML5(121)
CSS3(90)
字体(74)
PSD(66)
css(43)
wordpress(35)
图标(34)
更多
随笔分类
Asp.net(24)
CSS3(199)
HTML5(165)
Infographics(6)
JavaScript(176)
jQuery(181)
Others(27)
WordPress(47)
创意欣赏(157)
开发技巧(20)
浏览器兼容(15)
前端文摘(34)
设计素材(11)
实用工具 (116)
数据库技术(11)
网络资源(270)
网页设计(674)
网站优化(14)
我的博文(432)
移动开发(52)
原创翻译(1047)
最新评论
1. Re:精心挑选的12款优秀 jQuery Ajax 分页插件和教程
@雪雨潇潇引用不错啊 1谢谢支持！：）
2. Re:60款很酷的 jQuery 幻灯片演示和下载
@般若一号引用太好了 jquery做出的效果真好嗯，都很炫！
3. Re:60款很酷的 jQuery 幻灯片演示和下载
太好了 jquery做出的效果真好
4. Re:精心挑选的12款优秀 jQuery Ajax 分页插件和教程
不错啊 1
5. Re:【精心推荐】几款极好的 JavaScript 文件上传插件
@龙~lulu引用只用过Uploadify 的flash上传，当时做的是电子商务 后台批量上传图片，才去公司的时候他们后台是一个个传的，看都蛋疼的很，我就给公司经理提出我想做一个批量传的，最后做出来了，用的就是这个，就因为他还得了500块的奖励，哈哈哈.....哈哈，Uploadify是好东西，我最近的项目也用这个。
阅读排行榜
1. 60款很酷的 jQuery 幻灯片演示和下载(143667)
2. 九个让人难以置信的HTML5和JavaScript实验(93114)
3. 《特别推荐》10套精美的免费网站后台管理系统模板(83665)
4. 高清壁纸大全：2013年新年桌面壁纸免费下载【上篇】(81376)
5. 34个漂亮的应用程序后台管理系统界面（系列二）(76743)
6. HTML5网站大观：10个精美的 HTML5 企业网站欣赏(69004)
7. 分享20款漂亮免费英文LOGO字体(66231)
8. 寻找网页设计灵感的27个最佳网站推荐(63486)
9. 12款很棒的浏览器兼容性测试工具推荐(63157)
10. 非常有用的免费UI设计工具和资源(61924)
11. 34个漂亮的应用程序后台管理界面（系列一）(60473)
12. 30个漂亮的免费 Flash 网站模板下载(59757)
13. 8个惊艳的 HTML5 和 JavaScript 特效(58380)
14. 推荐35个非常有创意的404错误页面(54395)
15. 推荐10款非常优秀的 HTML5 开发工具(52682)
推荐排行榜
1. 60款很酷的 jQuery 幻灯片演示和下载(130)
2. 【必备】史上最全的浏览器 CSS & JS Hack 手册(121)
3. 那些让人惊叹的的国外创意404错误页面设计(112)
4. 让人爱不释手的13套精美 Web 应用程序图标素材(104)
5. 45个纯 CSS 实现的精美边框效果【附源码】【上篇】(97)
6. 《特别推荐》10套精美的免费网站后台管理系统模板(93)
7. JavaScript初学者应注意的七个细节(93)
8. 期待已久的2012年度最佳 jQuery 插件揭晓(91)
9. 8款效果精美的 jQuery 加载动画和进度条插件(90)
10. 推荐35款精致的 CSS3 和 HTML5 网页模板(87)
11. 精心挑选的12款优秀 jQuery Ajax 分页插件和教程(83)
12. 实用技巧：Google 搜索打不开的解决方法【图文教程】(81)
13. 推荐十个拥有丰富 UI 组件的 JavaScript 开发框架(80)
14. 【今日推荐】10大流行的 Metro UI 风格的 Bootstrap 主题和模板(79)
15. 你想不到的！CSS 实现的各种球体效果【附在线演示】(76)
Copyright ©2013 梦想天空（山边小溪）

 

 
========== http://www.5198.com/space.php?uid=71&do=blog&id=1177/ ==========
首页站内导航 帮助欢迎您
登录 | 注册
登录站点
用户名

密码

记住我
 

Albert的日志
Albert的主页 » TA的所有日志 » 查看日志
21个超炫效果媲美Flash的jQuery特效
已有 3462 次阅读  2010-08-06 13:30   标签:  Flash  特效  jQuery  效果 
       以前，在制作网页时想拥有灵跃炫目的动感效果及直接实现一些人机交互的功能，多数会想到使用Flash ，这也是过去web设计师用来为网站添加交互及特殊效果的重要技术之一，但由于部份浏览器及手持流动上网设备（例如Ipad）不支持 Flash Player或兼容的原因， 间接促进了web开发的新技术研究及应用，用以替代FLASH而达至相同或类似功能和效果，例如：新的网页标准Html5、Ajax；其中应用了 以jQuery为 核心的特效插件更展示了其强大的功能和超炫效果，完全可以媲美Flash，以下精选了部份案例与众分享。

1. Flip! 一个 jQuery 插件
官网地址：http://lab.smashup.it/flip/

这个演示 模仿流行的卡片翻转的效果，可以360度旋转自身，x或y维度！



2.jQuery Quicksand plugin--Query Quicksand 插件
官网地址：http://razorjack.net/quicksand/
这是一个强大的插件用来在页面上排序数组的元素/图标,有酷的渐入 /渐出和动画特效！



3. ImageFlow
官网地址：http://imageflow.finnrudolph.de/
这个图像浏览器和苹果的CoverFlow界面很相似，让用户能够很熟悉他们的产品和应用！



4.Building an interactive map with jQuery instead of Flash--用jQuery代替flash建立一个交互性地图
官网地址：http://www.gethifi.com/blog/jquery-vs-flash-for-interactive-map
这个演示展示了jQuery用ajax技术创造迷人的界面的强大能力！



5.Slideout Tips With jQuery & CSS3--用jQuery & CSS3滑出消息
官网地址：http://tutorialzine.com/2010/04/slideout-context-tips-jquery-css3/
点击+号用漂亮的光滑的动画效果展示附加的信息！



6. Zoomer Gallery
官网地址：http://addyosmani.com/blog/zoomer-gallery-a-jquery-plugin-for-displaying-images-with-flash-like-zooming-effects/
在这个演示中看起来静态的画廊被multi-layer zoom特效变得富有交互性，当移到图像上时会产生缩放！



7. jQuery Circulate
官网地址 ：http://css-tricks.com/examples/Circulate/
这个演示展示了滚球的粒子效果，所有的特效都是用jQuery



8. Photo Zoom Out Effect
官网地址：http://tympanus.net/codrops/2010/03/07/photo-zoom-out-effect-with-jquery/
这个也是一个图像伸缩的特效，看起来静止的画面，会随着你的鼠标移过而变得富有生机！



9. Sliding Boxes and Captions with jQuery
官网地址：http://buildinternet.com/2009/03/sliding-boxes-and-captions-with-jquery/
这里我们可以看到原本只能被flash开发者创造的过渡特效，现在使用jQuery一样可以办到！



10. CSS3 Lightbox Gallery
官网地址：http://tutorialzine.com/2009/11/hovering-gallery-css3-jquery/
这个插件看起来是为媒体展示图片特别制作的，你可以任意拖拽图片达到图片拼接的效果，你还可以单击放大图片！这是一个强大的图片展示特效！你还可以 用API使用ajax技术让人们分享图片到Flickr，twitter，Facebook或者其他网站！当然中国的新浪微博、人人网、开心网也能！



11.Making a Photoshoot Effect With jQuery & CSS-用jQuery和CSS3创造一个拍照效果！
官网地址：http://tutorialzine.com/2010/02/photo-shoot-css-jquery/
一眼看去这个演示像游戏狙击，乍一看居然是拍照功能！这是一个很强大的工具，当用AJAX或者HTML5本地存储时，用来对付特别大的图像！



12. Awesome Bubble Navigation-可怕的泡沫导航效果
官网地址：http://www.tympanus.net/Tutorials/BubbleNavigation/
开发者用色彩变换和动画创造出一个非常吸引人的并且富有交互性的菜单！



13. Beautiful Background Image Navigation
官网地址：http://www.tympanus.net/Tutorials/BeautifulBackgroundImageNavigation/
酷炫的图片展示特效，用来做导航会有惊人的效果！



14. AviaSlider
官网地址：http://aviathemes.com/aviaslider/
AviaSlider采用经典的类似Flash的过渡效果，以强化滑块界面。



15. Background Image Slideshow
官网地址：http://www.marcofolio.net/webdesign/advanced_jquery_background_image_slideshow.html
动画背景的地方flash用来支配的网页设计之一。这里有一个例子使用jQuery代替。



16. Panning Slideshow
官网地址：http://buildinternet.com/2010/02/animate-panning-slideshow-with-jquery/
另一个独特采取典型幻灯片界面。在这里，笔者增加了对角线导航的接口，并使其脱颖而出。



17. jqFancyTransitions
官网地址：http://workshop.rs/2009/12/image-gallery-with-fancy-transitions-effects/
这个插件可以用来显示作为一个具有奇特法拉盛般的幻灯片过渡效果的照片。



18. iCarousel – Horizontal images slider
官方网址：http://zendold.lojcomm.com.br/icarousel/

另一个幻灯片，添加了缓和的过渡和真的挺身而出。这也难怪他们选择在此演示，展示性感的Mac产品。



19. Making an Interactive Picture with jQuery
官网地址：http://buildinternet.com/2009/11/making-an-interactive-picture-with-jquery/
该演示可用于拍摄的网站那里有很多优势的屏幕空间。该网站上发现的第一个模式框点击它显示更多关于点击部分的信息。



20. Cloud Zoom
官网地址：http://www.professorcloud.com/mainsite/cloud-zoom.htm
一个插件，看起来好像是在考虑电子商务设计。云缩放易于实现，能真正提高用户的体验。





21. Apple-like Retina Effect
官网地址：http://tutorialzine.com/2010/06/apple-like-retina-effect-jquery-css/
任何人谁使用了一iPhone，iPod的触摸，或ipad，将扩大在屏幕上时，你碰了长时间的面积小面积熟悉。此演示实现这个桌面效果。





分享举报

路过

鸡蛋

鲜花

握手

雷人
发表评论 评论 (0 个评论)
 涂鸦板 



全部 作者的其他最新日志

UChome smtp设置不能发送电邮解决方法
Google 高级搜索技巧100条
网页设计工具集
phpMailer 中文说明
phpmailer 中文使用说明
IIS服务器开启openssl 功能
热门日志导读

李敏敏: 我空间有红包哦
qq1026265815: 找朋友

5198互动社区 - 联系我们
Powered by UCenter Home 2.0 © 2001-2009 Comsenz Inc.
========== http://docs.kissyui.com/ ==========
========== http://blog.jobbole.com/13671/ ==========
========== http://www.w3school.com.cn/html5/html5_reference.asp ==========
w3school 在线教程 

 
HTML 系列教程
浏览器脚本
服务器脚本
ASP.NET 教程
XML 系列教程
Web Services 系列教程
建站手册
HTML5 教程
HTML5 教程
HTML5 简介
HTML5 视频
HTML5 视频/DOM
HTML5 音频
HTML5 拖放
HTML5 画布
HTML5 SVG
HTML5 画布 vs SVG
HTML5 地理定位
HTML5 Web 存储
HTML5 应用缓存
HTML5 Web Workers
HTML5 服务器发送事件
HTML5 表单
HTML5 输入类型
HTML5 表单元素
HTML5 表单属性
HTML5 测验
HTML5 测验
HTML5 参考手册
HTML5 标签
HTML5 属性
HTML5 事件
HTML5 视频/音频
HTML5 画布
HTML 有效 DTD
HTML5 标签
<!-->
<!DOCTYPE>
<a>
<abbr>
<acronym>
<address>
<applet>
<area>
<article>
<aside>
<audio>
<b>
<base>
<basefont>
<bdi>
<bdo>
<big>
<blockquote>
<body>
<br>
<button>
<canvas>
<caption>
<center>
<cite>
<code>
<col>
<colgroup>
<command>
<datalist>
<dd>
<del>
<details>
<dfn>
<dir>
<div>
<dl>
<dt>
<em>
<embed>
<fieldset>
<figcaption>
<figure>
<font>
<footer>
<form>
<frame>
<frameset>
<h1> - <h6>
<head>
<header>
<hgroup>
<hr>
<html>
<i>
<iframe>
<img>
<input>
<ins>
<keygen>
<kbd>
<label>
<legend>
<li>
<link>
<map>
<mark>
<menu>
<meta>
<meter>
<nav>
<noframes>
<noscript>
<object>
<ol>
<optgroup>
<option>
<output>
<p>
<param>
<pre>
<progress>
<q>
<rp>
<rt>
<ruby>
<s>
<samp>
<script>
<select>
<small>
<source>
<span>
<strike>
<strong>
<style>
<sub>
<summary>
<sup>
<table>
<tbody>
<td>
<textarea>
<tfoot>
<th>
<thead>
<time>
<title>
<tr>
<track>
<tt>
<u>
<ul>
<var>
<video>
<wbr>
HTML 5 参考手册
HTML5 测验
HTML5 属性
HTML 5
通过制定如何处理所有 HTML 元素以及如何从错误中恢复的精确规则，HTML 5 改进了互操作性，并减少了开发成本。
HTML 5 中的新特性包括了嵌入音频、视频和图形的功能，客户端数据存储，以及交互式文档。
HTML 5 还包含了新的元素，比如：<nav>, <header>, <footer> 以及 <figure> 等等。
HTML 5 工作组包括：AOL, Apple, Google, IBM, Microsoft, Mozilla, Nokia, Opera, 以及数百个其他的供应商。
注释：HTML 5 还没有成为 W3C 正式的推荐标准。
如需阅读更多有关 W3C HTML 5 活动的内容，请阅读我们的 W3C 教程。
按字母顺序排列的标签列表
new : HTML5 中的新标签。
标签	描述
<!--...-->	定义注释。
<!DOCTYPE> 	定义文档类型。
<a>	定义超链接。
<abbr>	定义缩写。
<acronym>	HTML 5 中不支持。定义首字母缩写。
<address>	定义地址元素。
<applet>	HTML 5 中不支持。定义 applet。
<area>	定义图像映射中的区域。
<article>	定义 article。
<aside>	定义页面内容之外的内容。
<audio>	定义声音内容。
<b>	定义粗体文本。
<base>	定义页面中所有链接的基准 URL。
<basefont>	HTML 5 中不支持。请使用 CSS 代替。
<bdi>	定义文本的文本方向，使其脱离其周围文本的方向设置。
<bdo>	定义文本显示的方向。
<big>	HTML 5 中不支持。定义大号文本。
<blockquote>	定义长的引用。
<body>	定义 body 元素。
<br>	插入换行符。
<button>	定义按钮。
<canvas>	定义图形。
<caption>	定义表格标题。
<center>	HTML 5 中不支持。定义居中的文本。
<cite>	定义引用。
<code>	定义计算机代码文本。
<col>	定义表格列的属性。
<colgroup>	定义表格列的分组。
<command>	定义命令按钮。
<datalist>	定义下拉列表。
<dd>	定义定义的描述。
<del>	定义删除文本。
<details>	定义元素的细节。
<dfn>	定义定义项目。
<dir>	HTML 5 中不支持。定义目录列表。
<div>	定义文档中的一个部分。
<dl>	定义定义列表。
<dt>	定义定义的项目。
<em>	定义强调文本。
<embed>	定义外部交互内容或插件。
<fieldset>	定义 fieldset。
<figcaption>	定义 figure 元素的标题。
<figure>	定义媒介内容的分组，以及它们的标题。
<font>	HTML 5 中不支持。
<footer>	定义 section 或 page 的页脚。
<form>	定义表单。
<frame>	HTML 5 中不支持。定义子窗口（框架）。
<frameset>	HTML 5 中不支持。定义框架的集。
<h1> to <h6>	定义标题 1 到标题 6。
<head>	定义关于文档的信息。
<header>	定义 section 或 page 的页眉。
<hgroup>	定义有关文档中的 section 的信息。
<hr>	定义水平线。
<html>	定义 html 文档。
<i>	定义斜体文本。
<iframe>	定义行内的子窗口（框架）。
<img>	定义图像。
<input>	定义输入域。
<ins>	定义插入文本。
<keygen>	定义生成密钥。
<isindex>	HTML 5 中不支持。定义单行的输入域。
<kbd>	定义键盘文本。
<label>	定义表单控件的标注。
<legend>	定义 fieldset 中的标题。
<li>	定义列表的项目。
<link>	定义资源引用。
<map>	定义图像映射。
<mark>	定义有记号的文本。
<menu>	定义菜单列表。
<meta>	定义元信息。
<meter>	定义预定义范围内的度量。
<nav>	定义导航链接。
<noframes>	HTML 5 中不支持。定义 noframe 部分。
<noscript>	定义 noscript 部分。
<object>	定义嵌入对象。
<ol>	定义有序列表。
<optgroup>	定义选项组。
<option>	定义下拉列表中的选项。
<output>	定义输出的一些类型。
<p>	定义段落。
<param>	为对象定义参数。
<pre>	定义预格式化文本。
<progress>	定义任何类型的任务的进度。
<q>	定义短的引用。
<rp>	定义若浏览器不支持 ruby 元素显示的内容。
<rt>	定义 ruby 注释的解释。
<ruby>	定义 ruby 注释。
<s>	HTML 5 中不支持。定义加删除线的文本。
<samp>	定义样本计算机代码。
<script>	定义脚本。
<section>	定义 section。
<select>	定义可选列表。
<small>	将旁注 (side comments) 呈现为小型文本。
<source>	定义媒介源。
<span>	定义文档中的 section。
<strike>	HTML 5 中不支持。定义加删除线的文本。
<strong>	定义强调文本。
<style>	定义样式定义。
<sub>	定义下标文本。
<summary>	定义 details 元素的标题。
<sup>	定义上标文本。
<table>	定义表格。
<tbody>	定义表格的主体。
<td>	定义表格单元。
<textarea>	定义 textarea。
<tfoot>	定义表格的脚注。
<th>	定义表头。
<thead>	定义表头。
<time>	定义日期/时间。
<title>	定义文档的标题。
<tr>	定义表格行。
<track>	定义用在媒体播放器中的文本轨道。
<tt>	HTML 5 中不支持。定义打字机文本。
<u>	HTML 5 中不支持。定义下划线文本。
<ul>	定义无序列表。
<var>	定义变量。
<video>	定义视频。
<xmp>	HTML 5 中不支持。定义预格式文本。
HTML5 测验
HTML5 属性
SEARCH:
 
HTML 5 参考手册

HTML5 测验


 
W3School 提供的内容仅用于培训。我们不保证内容的正确性。通过使用本站内容随之而来的风险与本站无关。W3School 简体中文版的所有内容仅供测试，对任何法律问题及风险不承担任何责任。
当使用本站时，代表您已接受了本站的使用条款和隐私条款。版权所有，保留一切权利。 赞助商：上海赢科投资有限公司。 蒙ICP备06004630号
========== http://jsfiddle.net/ ==========
========== http://jsbin.com/#javascript,html ==========
Failed!!
========== http://lifesinger.wordpress.com/2011/07/24/online-local-debug/ ==========
Failed!!
========== http://dribbble.com/pacoxiao ==========
Toggle navigation
Sign in
9,864 Followers 189 Following 43 Listed

Paco
Beijing,China
weibo.com/pacoxiao
pacoxiao
Shots
Likes
Tags
Buckets

Clock
Smartisan OS Clock Exclusive your clock.
May 06, 2013

Calculator for Smartis...
Calculator for Smartisan OS @2x
April 01, 2013

Smartisan OS
Smartisan OS Icons by Paco @2x
March 29, 2013

iOS Icons
January 22, 2013

Food Tag
There's always a chance :D
January 16, 2013

White Icons
January 15, 2013

Beats Audio
Beats By Dr. Dre Pill Bluetooth Wireless Audio System.I made a new design interpretation.Hope you like it :)
January 12, 2013

Skype
Skype Login for iOS.Hope you like it :)
January 10, 2013

Music Player
January 03, 2013

Icons
December 22, 2012

Twitterrific iOS Icon
Twitterrific Icon Redesign for iOS.Hope you like it :) @David Lanham
December 18, 2012

Fried Egg
You eat breakfast? Smile every day like a flower.Hope you like it :)
December 15, 2012
Older →
About Paco

pacoxiao@gmail.com
uiiconuxdesigniosapps
Recent Activity

Followed Kant Tse.
5 days ago
Liked a comment by Lionel
18 days ago

Show and tell for designers

What are you working on? Dribbble is a community of designers sharing screenshots of their work, process, and projects.

Company
About
Help
Contact
Terms
Privacy
Shop
Community
Blog
Meetups
Newsletter
Testimonials
Handbook
Brand Guidelines
Connect
Find Designers
Jobs for Designers
Go Pro
Teams
Advertise
API
150,317,999,578
pixels dribbbled

Copyright © 2009–2013 Dribbble LLC. All screenshots © their respective owners. Shipped from Salem, Mass. USA.

Follow Dribbble on Twitter
========== http://famo.us/ ==========
========== http://adgallery.codeplex.com/documentation ==========
CodePlexProject Hosting for Open Source SoftwareRegisterSign In
AD Gallery
HOME
 
SOURCE CODE
 
DOWNLOADS
 
DOCUMENTATION
 
DISCUSSIONS
 
ISSUES
 
PEOPLE
 
LICENSE
Page InfoChange History (all pages)
 Follow (40)
  Subscribe
Demo

http://coffeescripter.com/code/ad-gallery/
Browser compatibility

The script has currently been tested in Firefox 3/Win (and upwards), Firefox 3.5/Mac (and upwards), IE6 7 8 + 9/Win, Chrome 2/Win (and upwards), Safari 3/Win (and upwards), Safari 4/Mac (and upwards), Opera 9/Win (and upwards), Opera 9/Mac (and upwards). If you have seen it working correctly in some other browser, or on some other platform, please let me know.
Example code

Javascript
Don't worry, all of these options are optional. If you just want the standard options, this is enough:
var galleries = $('.ad-gallery').adGallery();

All options:
var galleries = $('.ad-gallery').adGallery({
  loader_image: 'loader.gif',
  // Width of the image, set to false and it will 
  // read the CSS width
  width: 600, 
  // Height of the image, set to false and it 
  // will read the CSS height
  height: 400, 
  // Opacity that the thumbs fades to/from, (1 removes fade effect)
  // Note that this effect combined with other effects might be 
  // resource intensive and make animations lag
  thumb_opacity: 0.7,
  // Which image should be displayed at first? 0 is the first image  
  start_at_index: 0, 
  // Whether or not the url hash should be updated to the current image
  update_window_hash: true, 
  // Either false or a jQuery object, if you want the image descriptions
  // to be placed somewhere else than on top of the image
  description_wrapper: $('#descriptions'), 
  // Should first image just be displayed, or animated in?
  animate_first_image: false,
  // Which ever effect is used to switch images, how long should it take?  
  animation_speed: 400, 
  // Can you navigate by clicking on the left/right on the image?
  display_next_and_prev: true, 
  // Are you allowed to scroll the thumb list?
  display_back_and_forward: true, 
  // If 0, it jumps the width of the container
  scroll_jump: 0, 
  slideshow: {
    enable: true,
    autostart: true,
    speed: 5000,
    start_label: 'Start',
    stop_label: 'Stop',
    // Should the slideshow stop if the user scrolls the thumb list?
    stop_on_scroll: true, 
    // Wrap around the countdown
    countdown_prefix: '(', 
    countdown_sufix: ')',
    onStart: function() {
      // Do something wild when the slideshow starts
    },
    onStop: function() {
      // Do something wild when the slideshow stops
    }
  },
  // or 'slide-vert', 'resize', 'fade', 'none' or false
  effect: 'slide-hori', 
  // Move to next/previous image with keyboard arrows?
  enable_keyboard_move: true, 
  // If set to false, you can't go from the last image to the first, and vice versa
  cycle: true, 
  // All hooks has the AdGallery objects as 'this' reference
  hooks: {
    // If you don't want AD Gallery to handle how the description
    // should be displayed, add your own hook. The passed image
    // image object contains all you need
    displayDescription: function(image) {
      alert(image.title +" - "+ image.desc);
    }
  },
  // All callbacks has the AdGallery objects as 'this' reference
  callbacks: {
    // Executes right after the internal init, can be used to choose which images
    // you want to preload
    init: function() {
      // preloadAll uses recursion to preload each image right after one another
      this.preloadAll();
      // Or, just preload the first three
      this.preloadImage(0);
      this.preloadImage(1);
      this.preloadImage(2);
    },
    // This gets fired right after the new_image is fully visible
    afterImageVisible: function() {
      // For example, preload the next image
      var context = this;
      this.loading(true);
      this.preloadImage(this.current_index + 1,
        function() {
          // This function gets executed after the image has been loaded
          context.loading(false);
        }
      );

      // Want slide effect for every other image?
      if(this.current_index % 2 == 0) {
        this.settings.effect = 'slide-hori';
      } else {
        this.settings.effect = 'fade';
      }
    },
    // This gets fired right before old_image is about to go away, and new_image
    // is about to come in
    beforeImageVisible: function(new_image, old_image) {
      // Do something wild!
    }
  }
});

// Set image description
some_img.data('ad-desc', 'This is my description!');

// Change effect on the fly
galleries[0].settings.effect = 'fade';


HTML
<div class="ad-gallery">
  <div class="ad-image-wrapper">
  </div>
  <div class="ad-controls">
  </div>
  <div class="ad-nav">
    <div class="ad-thumbs">
      <ul class="ad-thumb-list">
        <li>
          <a href="images/1.jpg">
            <img src="images/thumbs/t1.jpg" title="Title for 1.jpg">
          </a>
        </li>
        <li>
          <a href="images/2.jpg">
            <img src="images/thumbs/t2.jpg" longdesc="http://www.example.com" alt="Description of the image 2.jpg">
          </a>
        </li>
      </ul>
    </div>
  </div>
</div>

Linking

You can link to images, either by image index or by id. The syntax for linking to the fourth image is:
<a href="#ad-image-3">Fourth image</a>

AD Gallery listens to changes in the url, so you can have internal links on the gallery page to different images. If you don't wish to link by image index, you can give the anchor element in ad-thumb-list an id, and use the id in the link instead, like this:
<ul class="ad-thumb-list">
  <li>
    <a href="images/1.jpg" id="myimageid">
      <img src="images/thumbs/t1.jpg" class="image0">
    </a>
  </li>
</ul>

<a href="#ad-image-myimageid">Click me!</a>


The url hash is by default updated to the current image, which means that if you reload the page, you see the same image as before the refresh. This can be disabled by passing the update_window_hash setting, like this:
var galleries = $('.ad-gallery').adGallery({update_window_hash: false});

If you have multiple galleries on the same page, you probably want to disable this, unless you have ids on all anchor elements.
Customize

You can alter the way it looks by editing the CSS file, or overriding the default CSS rules. 
Image sizes

You probably want some other image size than the one in the demo above, and the only thing you need to do for this is to add this pice of CSS.

.ad-gallery {
  width: YOUR-IMAGE-WIDTHpx;
}
.ad-gallery .ad-image-wrapper {
  height: YOUR-IMAGE-HEIGHTpx;
}


Or you can specify it in the settings.width and settings.height. If you do that though, the gallery might flicker on page load, since it might take a while before that code runs, so I would suggest that you set it with CSS. If you want bigger thumbnails, the height of the thumb list adjusts itself to that, but you might want to position the arrows next to the list of your thumbs. You do that by adding this CSS and modifying to fit your needs.

.ad-gallery .ad-back {
  left: -20px;
  width: 13px;
  background: url(your_back_button.png) no-repeat;
}
.ad-gallery .ad-forward {
  right: -20px;
  width: 13px;
  background: url(your_forward_button.png) no-repeat;
}

Image descriptions

It's now possible (since 1.2.3) to have the image description somewhere else than on top of the big image. To to this, supply the description_wrapper config parameter, which should be a jQuery object, such as $('#descriptions'). Note that the old description isn't removed until the old image is removed. This to enable you to animate the descriptions. If you don't need it, just add: 
if (this.current_description) this.current_description.remove();

in the animations that you use.

If that isn't enough for you, and you need complete control over how to display or deal with descriptions, you can add your own hook for that, something like this:
var galleries = $('.ad-gallery').adGallery({
  hooks: {
    displayDescription: function(image) {
      console.log(image);
    }
  }
});

The passed image object contains all you need, and `this` inside the function points to the internal AD Gallery object.
Animations

You can now add your own animation, by doing something like this.

// The first argument is the name of your animation, which you then set in
// galleries[0].settings.effect
// The second argument is the function that handles the animation and it takes
// three arguments. The first is a jQuery object to the div that holds the image
// element and the image description element of the image that should be displayed
// The second is the direction, either 'left' or 'right'
// The third is the jQuery object that holds the description
// Your function should return an object like this:
// {old_image: {}, new_image: {}, speed: 100, easing: 'swing'}
// 'speed' and 'easing' are optional
// 'old_image' and 'new_image' are sent to the jQuery animate-method
// so use it just like you would use the $.animate-method
// This function gets executed with the gallery instance as its context
// so 'this' points to the gallery instance
galleries[0].addAnimation('wild',
  function(img_container, direction, desc) {
    var current_left = parseInt(img_container.css('left'), 10);
    var current_top = parseInt(img_container.css('top'), 10);
    if(direction == 'left') {
      var old_image_left = '-'+ this.image_wrapper_width +'px';
      img_container.css('left',this.image_wrapper_width +'px');
      var old_image_top = '-'+ this.image_wrapper_height +'px';
      img_container.css('top', this.image_wrapper_height +'px');
    } else {
      var old_image_left = this.image_wrapper_width +'px';
      img_container.css('left','-'+ this.image_wrapper_width +'px');
      var old_image_top = this.image_wrapper_height +'px';
      img_container.css('top', '-'+ this.image_wrapper_height +'px');
    };
    if(desc) {
      desc.css('bottom', '-'+ desc[0].offsetHeight +'px');
      desc.animate({bottom: 0}, this.settings.animation_speed * 2);
    };
    if(this.current_description) {
      this.current_description.css('bottom', '-'+ this.current_description[0].offsetHeight +'px');
    };
    img_container.css('opacity', 0);
    return {old_image: {left: old_image_left, top: old_image_top, opacity: 0},
            new_image: {left: current_left, top: current_top, opacity: 1},
            easing: 'easeInBounce',
            speed: 2500};
  }
);
galleries[0].settings.effect = 'wild';

Integrate with Fancybox

As reported by jasminj, you can integrate AD Gallery with Fancybox to open the main image in Fancybox when you click on it. Here's some example code:

$(".ad-gallery").on("click", ".ad-image", function() {
  $.fancybox.open({
    href : $(this).find("img").attr("src"),
    closeBtn: false,
    closeClick : true,
    openEffect : 'elastic',
    openSpeed  : 150,
    closeEffect : 'elastic',
    closeSpeed  : 150,
    helpers : {
      overlay : null
    }
  });
});


Be sure to add this piece of CSS as well to make the image seem clickable:
.ad-image {
  cursor: pointer;
}
Last edited May 12, 2012 at 8:24 AM by andersekdahl, version 14

comments

Maykel Sep 17 at 5:18 PM 
New tip to add a new Fancybox version:

$(".ad-gallery").on("click", ".ad-image", function()
{
$.fancybox('',{
'type': 'image',
'href':	$(this).find("img").attr("src")
});
});
bvinod554 Aug 30 at 10:27 AM 
How to add Close icon
tjelka Jun 10 at 3:19 PM 
if someone need support for Pretty Photo:
$(".ad-gallery").on("click", ".ad-image", function() {


var isrc=$(this).find("img").attr("src");
var iname=isrc.split('/')[1];
var ititle=$("img[src$='images/thumbs/t"+iname+"']").attr("title");
var idesc=$("img[src$='images/thumbs/t"+iname+"']").attr("alt");


$.prettyPhoto.open(isrc,ititle,idesc);
$.prettyPhoto.changePage('next');
$.prettyPhoto.changePage('previous');
$.prettyPhoto.close();
});
quark40 May 26 at 7:25 PM 
The thumbs are now in an horizontal row but I want to display them vertically. Is that possible and if so how? I'm very interested too
soundbwoy May 14 at 5:40 AM 
Is it possible to have the scroller continue after clicking on a thumbnail?
Sonikku Jan 7 at 3:45 PM 
Hi, how can I have the thumbnail scroller infinite scroll so it just repeats and not stops at the end? Thnks!
rtee Nov 23, 2012 at 5:32 AM 
Would it be possible to have image slideshow on FancyBox when clicking on large image and it will show the image through FancyBox and be able to scroll or click next or previous to view another picture in the list ...
gilberto_ba Sep 21, 2012 at 4:52 PM 
I would like to insert youtube videos but I can not.
qwyrp Aug 31, 2012 at 6:17 PM 
The thumbs are now in an horizontal row but I want to display them vertically. Is that possible and if so how?
Eswaran Jul 4, 2012 at 6:26 AM 
how to remove the gallary or reset
Replacement May 12, 2012 at 8:35 PM 
Awesome! Simply Awesome!!
Sign in to add a comment

system requirements

There are currently no defined requirements.
Ads by Developer Media
© 2006-2013 MicrosoftGet HelpPrivacy StatementTerms of UseCode of ConductAdvertise With UsVersion 10.3.2013.20798
========== http://www.jsfoot.com/jquery/demo/2012-06-07/demo.html ==========

动机的改变，面对英国美容
尝试等渗OPC-3今天更健康
今天释放等渗电力
WorldStores - 顶级品牌提供翌日
新！支持你的皮肤细胞水平上
新！得到报酬购物现金回赠
新！御温泉尽情享受豪华
与皇家温泉公主的感觉
新！让心智能必要的欧米茄三
新！在其最好的辐射防护
得到了春天的味道
保持精力充沛与等渗女王的银禧

========== http://darwinwen.blog.51cto.com/3029823/666913 ==========

每日博报 精彩不止一点
51cto博客

挨踢人物传
假期游玩，教你拍出好照片
项目管理之ERG理论
新型威胁分析与防范研究
华为数据中心：融合方案也分层次
2014年1月MVP开始申请啦！
51CTO首页51CTO博客我的博客 搜索 每日博报 社区：学院论坛博客下载更多 登录注册
IT快讯
http://darwinwen.blog.51cto.com 【复制】 【订阅】
原创:5翻译:1转载:24
博 客|图库|写博文|帮 助
首页|PHP|WEB前端|Linux|移动应用|Yii
darwinwen 的BLOG

写留言邀请进圈子发消息加友情链接进家园 加好友
博客统计信息
用户名：darwinwen
文章数：30
评论数：3
访问量：15405
无忧币：20
博客积分：162
博客等级：2
注册日期：2011-04-28
热门文章
详细教程使用jQuery jPla..
Yiiclipse 用于Yii Frame..
Yii 如何使用Swfupload和..
Yii 官方站点的目录结构
整理的16个有用的jQuery ..
Ucenter 1.6和Discuz X2..
jQuery非常有用的11个谷..
18本很好的HTML5电子书学..
搜索BLOG文章
 
我的技术圈(0)更多>>
最近访客

str0708

juban..

tcdwlid

lhjszz

xezw

幸福d..

nuist..

gksqjs

fang5..

小田..

hopesoft

81469..
最新评论
[匿名]isee：向楼主求教 QQ459811259
[匿名]isee：楼主install成功了？
[匿名]isee：不能用。zend studio 8.0 9.0都试过..
51CTO推荐博文更多>>
Javascript中的字符串链接和Array..
Mysql数据库存储引擎
PHP 代码审计
java 通配符解惑
基于Liferay的平台下，portlet在..
VirtuaNES.v0.97源码探究<3>..
mysql —— 分表分区（1）
Oracle 高可用技术与云基础架构引航
lnmp环境的搭建（源码）
利用OpenCV进行人脸识别
<Power Shell>21 如何从远..
友情链接
抚琴煮酒
51CTO博客开发
2013年10月MVP申请啦！[截止时间：10月11日] 【Android】精品课程等你来学习！博主的更多文章>>
 详细教程使用jQuery jPlayer插件给你的站点增加视频和音频功能
2011-09-17 09:08:29
标签：jQuery 职场 休闲 jPlayer
这篇文章将主要探计关于怎么增加自定义视频和语音播放功能在你的WEB网站里面。这个是一个非常好的jQuery新插件(jPlayer)， 包括很多功能 : 它允许你播放多媒体文件, 暂停，音量调整，它拥有视频和音频播放功能会用到的所有功能控掉，同样他允许你改变它的所有样式(styles),因为他的全部外观都是在一个css文件 里面。另外，它同样支持HTML5 和支持所有主流的浏览器。它目前支持的格式有: mp3, ogg, m4a, m4v, ogv, wav等等。


简短的介绍以后，我们开始详细编码过程:

1. HTML
首先开始HTML部件
 
<link rel="stylesheet" href="css/jplayer.blue.monday.css" type="text/css" media="all" /> 
<link rel="stylesheet" href="css/main.css" type="text/css" media="all" /> 
<script src="js/jquery.min.js" type="text/javascript"></script> 
<script src="js/jquery.jplayer.min.js" type="text/javascript"></script> 
<script src="js/main.js" type="text/javascript"></script> 
<div class="example"> 
    <div> 
        <div class="players"> 
            <h2>Audio player</h2> 
            <div class="jp-audio"> 
                <div class="jp-type-single"> 
                    <div id="jquery_jplayer_1" class="jp-jplayer"></div> 
                    <div id="jp_interface_1" class="jp-interface"> 
                        <ul class="jp-controls"> 
                            <li><a href="#" class="jp-play" tabindex="1">play</a></li> 
                            <li><a href="#" class="jp-pause" tabindex="1">pause</a></li> 
                            <li><a href="#" class="jp-stop" tabindex="1">stop</a></li> 
                            <li><a href="#" class="jp-mute" tabindex="1">mute</a></li> 
                            <li><a href="#" class="jp-unmute" tabindex="1">unmute</a></li> 
                        </ul> 
                        <div class="jp-progress"> 
                            <div class="jp-seek-bar"> 
                                <div class="jp-play-bar"></div> 
                            </div> 
                        </div> 
                        <div class="jp-volume-bar"> 
                            <div class="jp-volume-bar-value"></div> 
                        </div> 
                        <div class="jp-current-time"></div> 
                        <div class="jp-duration"></div> 
                    </div> 
                    <div id="jp_playlist_1" class="jp-playlist"> 
                        <ul> 
                            <li>Audio track</li> 
                        </ul> 
                    </div> 
                </div> 
            </div> 
        </div> 
        <div class="players"> 
            <h2>Video player</h2> 
            <div class="jp-video jp-video-270p"> 
                <div class="jp-type-single"> 
                    <div id="jquery_jplayer_2" class="jp-jplayer"></div> 
                    <div id="jp_interface_2" class="jp-interface"> 
                        <div class="jp-video-play"></div> 
                        <ul class="jp-controls"> 
                            <li><a href="#" class="jp-play" tabindex="1">play</a></li> 
                            <li><a href="#" class="jp-pause" tabindex="1">pause</a></li> 
                            <li><a href="#" class="jp-stop" tabindex="1">stop</a></li> 
                            <li><a href="#" class="jp-mute" tabindex="1">mute</a></li> 
                            <li><a href="#" class="jp-unmute" tabindex="1">unmute</a></li> 
                        </ul> 
                        <div class="jp-progress"> 
                            <div class="jp-seek-bar"> 
                                <div class="jp-play-bar"></div> 
                            </div> 
                        </div> 
                        <div class="jp-volume-bar"> 
                            <div class="jp-volume-bar-value"></div> 
                        </div> 
                        <div class="jp-current-time"></div> 
                        <div class="jp-duration"></div> 
                    </div> 
                    <div id="jp_playlist_2" class="jp-playlist"> 
                        <ul> 
                            <li>Tokyo weather</li> 
                        </ul> 
                    </div> 
                </div> 
            </div> 
        </div> 
    </div> 
</div>  
在上同画出2播放器 - 音频和视频，它们两个的代码类似.

2. CSS

需要用到的CSS样式
 
body{background:#eee;font-family:Verdana, Helvetica, Arial, sans-serif;margin:0;padding:0} 
.example{background:#FFF;width:1000px;height:500px;font-size:80%;border:1px #000 solid;margin:0.5em 10% 0.5em;padding:1em 2em 2em;-moz-border-radius:3px;-webkit-border-radius:3px} 
.example .players{float:left;margin:10px}  
其它css文件(相关的图片文件):
css/jplayer.blue.monday.css, css/jplayer.blue.monday.jpg, css/jplayer.blue.monday.video.play.png, css/jplayer.blue.monday.video.play.hover.png and css/pbar-ani.gif这些全部包括在源码包里面.

3. JS这里是全部需要用到的js文件在这个例子中.

js/main.js
 
$(document).ready(function(){ 
    $("#jquery_jplayer_1").jPlayer({ 
        ready: function () { 
            $(this).jPlayer("setMedia", { 
                mp3: "media/track.mp3", 
            }).jPlayer("play"); // auto play 
        }, 
        ended: function (event) { 
            $(this).jPlayer("play"); 
        }, 
        swfPath: "swf", 
        supplied: "mp3" 
    }) 
    .bind($.jPlayer.event.play, function() { // pause other instances of player when current one play 
            $(this).jPlayer("pauseOthers"); 
    }); 
    $("#jquery_jplayer_2").jPlayer({ 
        ready: function () { 
            $(this).jPlayer("setMedia", { 
                m4v: "media/tokyo.m4v", 
                ogv: "media/tokyo.ogv", 
                poster: "media/poster.jpg" 
            }); 
        }, 
        ended: function (event) { 
            $("#jquery_jplayer_2").jPlayer("play", 0); 
        }, 
        swfPath: "js", 
        supplied: "m4v, ogv", 
        cssSelectorAncestor: "#jp_interface_2" 
    }) 
    .bind($.jPlayer.event.play, function() { // pause other instances of player when current one play 
            $(this).jPlayer("pauseOthers"); 
    }); 
});  
js/jquery.min.js and js/jquery.jplayer.min.js这几个是公共的文件 - jQuery库与播放插件js文件.


4. SWF
使用flash swf文件: 例子中的主播放器.

swf/Jplayer.swf

到这里差不多全部完成. 所有测试的多媒体播放文件都放置在‘media’ 下面. 
音频文件 -  track.mp3,
视频文件: tokyo.m4v + tokyo.ogv, 
缩略图(poster): poster.jpg
如果你有遇到一个奇怪的问题和 ogg文件(oga, ogv, ogg) 不能使有，请尝试在你的 .htaccess 里面增加:
AddType audio/ogg .oga
AddType video/ogg .ogv .ogg
 
在线DEMO例子
 
转载请保留出自:   IT快讯网   |  原文地址: 详细教程使用jQuery jPlayer插件给你的站点增加视频和音频功能
 
 
 
 
 
 
 
 
	 更多 2	
	0人	了这篇文章
类别：WEB前端┆技术圈(0)┆阅读(1699)┆评论(0) ┆ 推送到技术圈┆返回首页
上一篇 20个非常漂亮实用的jQuery提示插件 下一篇 2011年9月最新整理的10个有趣的jQuery插件集合

相关文章
JQuery常用方法总结jquery窗帘式介绍框jQuery 学习jQuery中文入门指南，翻译加实例，jQuery的..26个Jquery使用小技巧(jQuery tips, tricks ..Jquery打造AdRotator轮转图片JQUERY文本框计算输入字数利用jQuery制作具有滑动动画效果的层
文章评论
 
 
发表评论            【有奖门诊】新技术时代，应用交付的未来在哪里？
昵  称：登录  快速注册
验证码：请点击后输入验证码博客过2级，无需填写验证码
内  容：

Copyright By 51CTO.COM 版权所有


========== http://www.softwareishard.com/har/viewer/ ==========

========== http://blogs.msdn.com/b/ieinternals/archive/2010/07/08/technical-information-about-conditional-http-requests-and-the-refresh-button.aspx ==========
Sign in  
IEInternals
A look at Internet Explorer from the inside out. Note: @EricLaw left Microsoft in 2012, but was named an IE MVP in 2013.
Translate This Page
翻译此页
Microsoft® Translator
Please read my blog's comment policy here.

Options
Blog Home
Email Blog Author
Share this
RSS for posts
Atom
RSS for comments
Search


 Search this blog  Search all blogs
Tags
ActiveX add-ons Best-Practices BetterInIE10 BetterInIE9 caching design dev downloads http https ie8 ie9 interop limitations networking performance problems Q&A Security standards troubleshooting webdev wininet Zones
Archive
September 2013 (5)
September 2012 (5)
August 2012 (2)
July 2012 (3)
June 2012 (3)
May 2012 (3)
April 2012 (2)
March 2012 (4)
February 2012 (1)
January 2012 (1)
August 2011 (7)
July 2011 (3)
June 2011 (5)
May 2011 (10)
April 2011 (8)
March 2011 (13)
February 2011 (7)
January 2011 (2)
November 2010 (2)
October 2010 (2)
September 2010 (6)
August 2010 (2)
July 2010 (3)
June 2010 (4)
May 2010 (3)
April 2010 (7)
March 2010 (3)
February 2010 (1)
January 2010 (2)
December 2009 (4)
November 2009 (4)
October 2009 (8)
September 2009 (11)
August 2009 (6)
July 2009 (9)
June 2009 (18)
May 2009 (3)
MSDN Blogs > IEInternals > Understanding Conditional Requests and Refresh
Understanding Conditional Requests and Refresh

 EricLaw [ex-MSFT] 8 Jul 2010 12:22 PM 14
Today's post is a collection of technical tidbits about conditional HTTP requests and the behavior of IE's Refresh button. It's probably of limited interest to most readers, but if you need to deeply understand either of these topics, hopefully you will find it helpful! 

Conditional Requests
Web browsers make two types of requests over HTTP and HTTPS—conditional requests and unconditional requests.

An unconditional request is made when the client browser does not have a cached copy of the resource available locally. In this case, the server is expected to return the resource with a HTTP/200 OK response. If the response’s headers permit it, the client may cache this response in order to reuse it later.

If the browser later needs a resource which is in the local cache, that resource’s headers are checked to determine if the cached copy is still fresh.  If the cached copy is fresh, then no network request is made and the client simply reuses the resource from the cache.

If the browser later needs a resource which is in the cache, but that response is expired (older than its max-age or past the Expires date), then the client will make a conditional request to the server to determine whether the previously cached response is still valid and should be reused. The conditional request contains an If-Modified-Since and/or If-None-Match header that indicates to the server what version of the content the browser already has in its cache. The server can indicate that the client’s copy is still fresh by returning HTTP/304 Not Modified headers with no body, or it can indicate that the client’s copy is stale by returning a HTTP/200 OK response with the new version of the resource.

Recently, someone asked why they see so many conditional requests in their server logs; they're setting proper far-future Expires headers and thus wouldn't expect IE to make any conditional requests for these resources.

There are a number of reasons why IE might make a conditional request for an item that is already in the cache:

The cached item is no longer fresh according to Cache-Control or Expires
The cached item was delivered with a VARY header
The containing page was navigated to via META REFRESH
JavaScript in the page called reload on the location object, passing TRUE for bReloadSource
The request was for a cross-host HTTPS resource on browser startup
The user refreshed the page

User-invoked Refresh
Now, in the case where the user refreshes a page, two of the multiple levels of refresh are relevant:

If the user clicks the refresh button or hits F5, IE will use OLECMDIDF_REFRESH_NO_CACHE.
If the user holds CTRL while clicking the button or while hitting F5, IE will use OLECMDIDF_REFRESH_COMPLETELY.
In the first case (Normal-Refresh), we will perform HTTP requests (conditional, if possible) to revalidate all of the resources on the page, regardless of freshness.

In the second case (Super-Refresh), we perform unconditional HTTP requests to redownload all of the content on the page, bypassing the cache altogether.

Notably, the latest versions of Firefox and Chrome both behave as IE does for both Normal Refresh and Super Refresh cases, so there’s a bit of a du jour standard for this behavior. 

There's actually a third type of refresh, which occurs when the user simply puts focus back in the address bar and hits ENTER, as if they were navigating to the page again. In that case, IE will use OLECMDIDF_REFRESH_RELOAD | OLECMDIDF_REFRESH_CLEARUSERINPUT. The first flag allows the browser to pull content from the cache if it's still fresh, while the latter flag clears any input fields on the document and resets the scroll position.

Refresh: Under the Covers
Internally, OLECMDIDF_REFRESH_NO_CACHE maps to the URLMon binding flags BINDF_RESYNCHRONIZE|BINDF_PRAGMA_NO_CACHE while OLECMDIDF_REFRESH_COMPLETELY maps to BINDF_GETNEWESTVERSION|BINDF_PRAGMA_NO_CACHE. (OLECMDIDF_REFRESH_RELOAD doesn't set any URLMon flags.) 

These URLMon flags get turned into WinINET flags, and that actually influences the network behavior.

BINDF_GETNEWESTVERSION gets turned into INTERNET_FLAG_RELOAD.
BINDF_RESYNCHRONIZE gets turned into INTERNET_FLAG_RESYNCHRONIZE.
BINDF_PRAGMA_NO_CACHE gets turned into INTERNET_FLAG_PRAGMA_NOCACHE.
These flags will influence WinINET’s behavior:

If INTERNET_FLAG_RESYNCHRONIZE is set:
WinINET will send an If-Modified-Since or If-None-Match request header to allow a 304 response.
WinINET may add a request header to help ensure that an intermediary (proxy) does not return a previously-cached result (see below)
If INTERNET_FLAG_PRAGMA_NOCACHE is set
If the request is going through a proxy or is HTTP/1.0, Pragma: no-cache is added. If the request is not going through a proxy and is HTTP/1.1, then Cache-Control: no-cache is added.
If INTERNET_FLAG_RELOAD is set:
WinINET will bypass the cache (redownloading all entries)
WinINET will not send an If-Modified-Since or If-None-Match request header on these requests (Unconditional request; server cannot return a HTTP/304).
WinINET will add a request headerto help ensure that an intermediary does not return a previously-cached result. 
If the request is going through a proxy or is HTTP/1.0, Pragma: no-cache is added. If the request is not going through a proxy and is HTTP/1.1, then Cache-Control: no-cache is added.
When the window.location.reload method is called, the different refresh flags are set depending on the value of the bReloadSource parameter:

True: OLECMDIDF_REFRESH_COMPLETELY|OLECMDIDF_REFRESH_CLEARUSERINPUT|OLECMDIDF_REFRESH_THROUGHSCRIPT
False: OLECMDIDF_REFRESH_NO_CACHE|OLECMDIDF_REFRESH_CLEARUSERINPUT|OLECMDIDF_REFRESH_THROUGHSCRIPT
 

Refresh: Resources that come down after page load
In IE9 and earlier, resources that are downloaded after the page downloads (e.g. XHR requests: http://www.stevesouders.com/blog/2009/08/11/f5-and-xhr-deep-dive/, or items pulled down by JavaScript) are not tagged with the BINDF_ flags that are set on resources that exist within the plain markup. This may be deemed undesirable: http://stackoverflow.com/questions/6775759/hard-refresh-and-xmlhttprequest-caching-in-internet-explorer-firefox/6879413 although the question of how long a "refresh" flag should persist is an open one.

Update: IE10 now will apply cache busting flags when XHR is used after a page is refreshed with CTRL+F5.

-Eric

proxy, networking, wininet, BetterInIE10
    
Comments
 Gopinath Varadharajan 8 Jul 2010 6:28 PM
Hi Eric,

Nice explanation about Request stack.

We're getting HTTP/304 Not Modified  in the following flow:

Normally the page's static resources (js, css etc) are long long time cached (30 days) and works fine.

As soon user opens a tab (IE 7 & 8) and opens an url with some windows or other authentication and logs in.

and comes back to the first tab and do a refresh, we get HTTP/304 Not Modified  for the static files?

Any ideas why IE has this behaviour?

Thanks,

Gopi

 EricLaw [ex-MSFT] 8 Jul 2010 6:33 PM
@Gopi: The bulk of this post is concerns IE's behavior upon a refresh; you should *expect* to see conditional requests for all of the page's resources upon Refresh, regardless of "other windows" "authentication", etc.

 Gopi 10 Jul 2010 2:02 PM
Eric,  Regular & conditional request works as you've explained, no issues here. We can do any number of regular refresh there wont be any 304's, if we do conditional requests all the files are re-downloaded... all are ok.

Now as soon as we open another tab and do an auth and login (diferent sites) and come back to first tab, and now do a Regular Refresh, now we're seeing all this 304's for (only) static files...?!! Cannot fig why only after opening (with auth) a tab, the first site throws 304's.

Thanks,

Gopi

 EricLaw [MSFT] 19 Jul 2010 3:37 PM
@Gopi: I think you misunderstand. If you refresh, you SHOULD be seeing conditional requests and HTTP/304 responses. If a conditional request cannot be made (because no Last-Modified or ETAG header was on the original response) you should see an unconditional request and a HTTP/200 response.

Now, the behavior in the face of *non-refresh* navigations DOES differ if a new tab is open and the original response did not have headers that specified cache lifetime. This is due to the behavior of Heuristic Expiration in IE8 which had a bug such that the "once per session" logic was interpreted as "Once per session or until a new tab is opened."

If you have a repro URL, I'd be happy to have a look.

 Tony 9 Mar 2011 7:19 AM
Eric, do you have more information or plan to write on how calls at the browser level map to wininet? For example when a user clicks on a link, how does that map behind the scenes - would it be the same as OLECMDIDF_REFRESH_RELOAD | OLECMDIDF_REFRESH_CLEARUSERINPUT

 EricLaw [MSFT] 9 Mar 2011 7:55 AM
@Tony: Link navigation wouldn't map to a refresh constant. Trident passes BINDF_HYPERLINK to URLMon, which gets converted to INTERNET_FLAG_HYPERLINK for WinINET.

 Tony 9 Mar 2011 8:18 AM
Thanks Eric! Is all this information available somewhere - or do we have to pick your brain everytime :)

[EricLaw]: Much of it is implied, but sadly not directly stated, in the MSDN documentation. I'm afraid picking my brain is often your best option.

 DaveK 10 Nov 2011 6:53 AM
Hi Eric, this is a great post and has filled in most of the large gaps in my knowledge.

One further question I'd like to understand the answer to is what IE does with the 304 response, other than getting the content for the original request from its cache?  Does it do anything to "freshen" the cache following the 304, as if it just downloaded the content for the first time and was setting its expiry based on max-age? - therefore avoiding future conditional requests until the content is once again not fresh

Thanks in advance!

 EricLaw [ex-MSFT] 10 Nov 2011 7:29 AM
@DaveK: Great question! When it gets a 304, WinINET will update the content's expiration using the Cache-Control or Expires headers specified on the 304. It also updates the "last-checked" time inside WinINET's metadata. The code does not update anything else on the cached response.

 Rakhesh 3 May 2012 1:04 PM
Eric,

We are facing issues with 304 which is resulting in Script Error on IE and the page does not load. We use the thirdpart FCKEditor in our pages, and the css, jss, and xml files have not changed in our side for a while. When ever users (not for all only for few) users hit the page, it does not load the text areas we have have in the webpage, troubleshooting this issue we found the following message. URL requested ... URL to the resource....then Staus 304.  

Any help would be appreciated.

thanks,

Rakhesh

 Pankaj Thakkar 21 Jun 2012 2:42 PM
Eric,

Can you please help understand why IE differs from FF and Chrome if user use F5 or refresh button to reload the page in following scenario?

Original request: Post,  Original Response: PDF

New Request on Refresh/F5 in IE: Get

New Request on Refresh/F5 in FF and Chrome: Post

 EricLaw [MSFT] 21 Jun 2012 3:33 PM
When you hit F5 and IE isn't showing HTML, the word gets infinitely more complicated, because it's up to the document object (e.g. the PDF DLL, in your case) to decide how it wants to interpret the request to refresh.

 David 15 Nov 2012 12:00 PM
Eric,

Wow...you've opened up a whole can of worms for me, but I'm hoping you can point me in the direction of what I should be looking for more than just thinking you can provide an answer.  I'm a network guy, not a web developer, but we have an issue in our company that is driving me nuts.  

We have a web application that users use.  The application is behind a load balancer and there are three web servers that traffic is sent to.  Essentially a user makes a request to http://site.com and gets redirected (via http 302) to https://site.com.  From there the user enters their username/password/domain and selects login.  

The problem I'm having is that a handful of users (all running windows 7 and all running IE9) will intermittently hit "Login" and the screen flashes and is back at the login prompt (read: it doesn't authenticate).  The weird part is that no one has experienced the issue using FF or Chrome, but a good amount of people see it with IE9.  I've had limited opportunity to debug it since I am one of the people that rarely if ever sees the traffic.  I did do some packet captures, but it doesn't look like lost packets so since the traffic is HTTPS my captures don't do much for me.  I have been using fiddler, but havn't been able to capture a failure since.  I did ask one co-worker who experiences the issue to use the "network capture" in the IE tools (F12) and they captured a succeessful and failed login.  The only thing I can see (and this jives with what MS claimed since we had them in house to run a bunch of tests) is that in the successful test the user hits "login" and then receives an https 302 redirecting them to "site.com/test.msv" and on the failed login attempt I just see an https 200 status "OK".

Interestingly enough (and the way I stumbled across this site) is that if the user opens another tab then they seem to be able to authenticate and login just fine.

Once again, the problem never occurs with other browsers, yet MS is adamant that one of the servers is sending back a bad header (or the load balancer, which is why I'm now involved)...yet the problem is so random and intermittent I'm at a loss as to where to focus on next.

Any guidance would be appreciated.

 EricLaw [ex-MSFT] 27 Nov 2012 9:04 AM
@David: I'm no longer at Microsoft. Ping me using the Help link in Fiddler and I'll help if I can.

Leave a Comment
Name

Comment

Post
© 2013 Microsoft Corporation. Terms of Use Trademarks Privacy & Cookies Report Abuse 5.6.426.415

========== http://jvectormap.com/maps/countries/china/ ==========

Home
Download
Maps
Documentation
Tutorials
Examples
Contacts
China
World
Europe
Whole World
Countries
Argentina
Australia
Austria
Belgium
Canada
China
Colombia
Denmark
France
Germany
India
Italy
Netherlands
New Zealand
Norway
Philippines
Poland
Portugal
South Africa
Spain
Sweden
Switzerland
Thailand Regions
Thailand
United Kingdom
USA
Venezuela
Cities
Chicago
New York City
Miller
Mercator
+−
Download (92 KB)

To render the map use the following code:

$('#map').vectorMap({map: 'cn_mill_en'});
This map is based on data available at http://www.naturalearthdata.com/downloads/10m-cultural-vectors/10m-admin-1-states-provinces/. Data is in public domain.

© Kirill Lebedev
========== http://www.nodebeginner.org/index-zh-cn.html#javascript-and-nodejs ==========
	
购买“Node入门”中文版电子书

$0.99


立即购买
本书共42页 
支持PDF格式，Kindle以及ePub格式 
直接下载，免费更新

Node入门

作者： Manuel Kiessling
翻译： goddyzhao & GrayZhang & MondayChen
关于

本书致力于教会你如何用Node.js来开发应用，过程中会传授你所有所需的“高级”JavaScript知识。本书绝不是一本“Hello World”的教程。

状态

你正在阅读的已经是本书的最终版。因此，只有当进行错误更正以及针对新版本Node.js的改动进行对应的修正时，才会进行更新。

本书中的代码案例都在Node.js 0.6.11版本中测试过，可以正确工作。

读者对象

本书最适合与我有相似技术背景的读者： 至少对一门诸如Ruby、Python、PHP或者Java这样面向对象的语言有一定的经验；对JavaScript处于初学阶段，并且完全是一个Node.js的新手。

这里指的适合对其他编程语言有一定经验的开发者，意思是说，本书不会对诸如数据类型、变量、控制结构等等之类非常基础的概念作介绍。要读懂本书，这些基础的概念我都默认你已经会了。

然而，本书还是会对JavaScript中的函数和对象作详细介绍，因为它们与其他同类编程语言中的函数和对象有很大的不同。

本书结构

读完本书之后，你将完成一个完整的web应用，该应用允许用户浏览页面以及上传文件。

当然了，应用本身并没有什么了不起的，相比为了实现该功能书写的代码本身，我们更关注的是如何创建一个框架来对我们应用的不同模块进行干净地剥离。 是不是很玄乎？稍后你就明白了。

本书先从介绍在Node.js环境中进行JavaScript开发和在浏览器环境中进行JavaScript开发的差异开始。

紧接着，会带领大家完成一个最传统的“Hello World”应用，这也是最基础的Node.js应用。

最后，会和大家讨论如何设计一个“真正”完整的应用，剖析要完成该应用需要实现的不同模块，并一步一步介绍如何来实现这些模块。

可以确保的是，在这过程中，大家会学到JavaScript中一些高级的概念、如何使用它们以及为什么使用这些概念就可以实现而其他编程语言中同类的概念就无法实现。

该应用所有的源代码都可以通过 本书Github代码仓库.

目录
关于
状态
读者对象
本书结构
JavaScript与Node.js
JavaScript与你
简短申明
服务器端JavaScript
“Hello World”
一个完整的基于Node.js的web应用
用例
应用不同模块分析
构建应用的模块
一个基础的HTTP服务器
分析HTTP服务器
进行函数传递
函数传递是如何让HTTP服务器工作的
基于事件驱动的回调
服务器是如何处理请求的
服务端的模块放在哪里
如何来进行请求的“路由”
行为驱动执行
路由给真正的请求处理程序
让请求处理程序作出响应
不好的实现方式
阻塞与非阻塞
以非阻塞操作进行请求响应
更有用的场景
处理POST请求
处理文件上传
总结与展望
JavaScript与Node.js

JavaScript与你

抛开技术，我们先来聊聊你以及你和JavaScript的关系。本章的主要目的是想让你看看，对你而言是否有必要继续阅读后续章节的内容。

如果你和我一样，那么你很早就开始利用HTML进行“开发”，正因如此，你接触到了这个叫JavaScript有趣的东西，而对于JavaScript，你只会基本的操作——为web页面添加交互。

而你真正想要的是“干货”，你想要知道如何构建复杂的web站点 —— 于是，你学习了一种诸如PHP、Ruby、Java这样的编程语言，并开始书写“后端”代码。

与此同时，你还始终关注着JavaScript，随着通过一些对jQuery，Prototype之类技术的介绍，你慢慢了解到了很多JavaScript中的进阶技能，同时也感受到了JavaScript绝非仅仅是window.open() 那么简单。 .

不过，这些毕竟都是前端技术，尽管当想要增强页面的时候，使用jQuery总让你觉得很爽，但到最后，你顶多是个JavaScript用户，而非JavaScript开发者。

然后，出现了Node.js，服务端的JavaScript，这有多酷啊？

于是，你觉得是时候该重新拾起既熟悉又陌生的JavaScript了。但是别急，写Node.js应用是一件事情；理解为什么它们要以它们书写的这种方式来书写则意味着——你要懂JavaScript。这次是玩真的了。

问题来了： 由于JavaScript真正意义上以两种，甚至可以说是三种形态存在（从中世纪90年代的作为对DHTML进行增强的小玩具，到像jQuery那样严格意义上的前端技术，一直到现在的服务端技术），因此，很难找到一个“正确”的方式来学习JavaScript，使得让你书写Node.js应用的时候感觉自己是在真正开发它而不仅仅是使用它。

因为这就是关键： 你本身已经是个有经验的开发者，你不想通过到处寻找各种解决方案（其中可能还有不正确的）来学习新的技术，你要确保自己是通过正确的方式来学习这项技术。

当然了，外面不乏很优秀的学习JavaScript的文章。但是，有的时候光靠那些文章是远远不够的。你需要的是指导。

本书的目标就是给你提供指导。

简短申明

业界有非常优秀的JavaScript程序员。而我并非其中一员。

我就是上一节中描述的那个我。我熟悉如何开发后端web应用，但是对“真正”的JavaScript以及Node.js，我都只是新手。我也只是最近学习了一些JavaScript的高级概念，并没有实践经验。

因此，本书并不是一本“从入门到精通”的书，更像是一本“从初级入门到高级入门”的书。

如果成功的话，那么本书就是我当初开始学习Node.js最希望拥有的教程。

服务端JavaScript

JavaScript最早是运行在浏览器中，然而浏览器只是提供了一个上下文，它定义了使用JavaScript可以做什么，但并没有“说”太多关于JavaScript语言本身可以做什么。事实上，JavaScript是一门“完整”的语言： 它可以使用在不同的上下文中，其能力与其他同类语言相比有过之而无不及。

Node.js事实上就是另外一种上下文，它允许在后端（脱离浏览器环境）运行JavaScript代码。

要实现在后台运行JavaScript代码，代码需要先被解释然后正确的执行。Node.js的原理正是如此，它使用了Google的V8虚拟机（Google的Chrome浏览器使用的JavaScript执行环境），来解释和执行JavaScript代码。

除此之外，伴随着Node.js的还有许多有用的模块，它们可以简化很多重复的劳作，比如向终端输出字符串。

因此，Node.js事实上既是一个运行时环境，同时又是一个库。

要使用Node.js,首先需要进行安装。关于如何安装Node.js，这里就不赘述了，可以直接参考官方的安装指南。安装完成后，继续回来阅读本书下面的内容。

“Hello World”

好了，“废话”不多说了，马上开始我们第一个Node.js应用：“Hello World”。

打开你最喜欢的编辑器，创建一个helloworld.js文件。我们要做就是向STDOUT输出“Hello World”，如下是实现该功能的代码：

console.log("Hello World");
保存该文件，并通过Node.js来执行：

node helloworld.js
正常的话，就会在终端输出Hello World 。

好吧，我承认这个应用是有点无趣，那么下面我们就来点“干货”。

一个完整的基于Node.js的web应用

用例

我们来把目标设定得简单点，不过也要够实际才行：

用户可以通过浏览器使用我们的应用。
当用户请求http://domain/start时，可以看到一个欢迎页面，页面上有一个文件上传的表单。
用户可以选择一个图片并提交表单，随后文件将被上传到http://domain/upload，该页面完成上传后会把图片显示在页面上。
差不多了，你现在也可以去Google一下，找点东西乱搞一下来完成功能。但是我们现在先不做这个。

更进一步地说，在完成这一目标的过程中，我们不仅仅需要基础的代码而不管代码是否优雅。我们还要对此进行抽象，来寻找一种适合构建更为复杂的Node.js应用的方式。

应用不同模块分析

我们来分解一下这个应用，为了实现上文的用例，我们需要实现哪些部分呢？

我们需要提供Web页面，因此需要一个HTTP服务器
对于不同的请求，根据请求的URL，我们的服务器需要给予不同的响应，因此我们需要一个路由，用于把请求对应到请求处理程序（request handler）
当请求被服务器接收并通过路由传递之后，需要可以对其进行处理，因此我们需要最终的请求处理程序
路由还应该能处理POST数据，并且把数据封装成更友好的格式传递给请求处理入程序，因此需要请求数据处理功能
我们不仅仅要处理URL对应的请求，还要把内容显示出来，这意味着我们需要一些视图逻辑供请求处理程序使用，以便将内容发送给用户的浏览器
最后，用户需要上传图片，所以我们需要上传处理功能来处理这方面的细节
我们先来想想，使用PHP的话我们会怎么构建这个结构。一般来说我们会用一个Apache HTTP服务器并配上mod_php5模块。
从这个角度看，整个“接收HTTP请求并提供Web页面”的需求根本不需要PHP来处理。

不过对Node.js来说，概念完全不一样了。使用Node.js时，我们不仅仅在实现一个应用，同时还实现了整个HTTP服务器。事实上，我们的Web应用以及对应的Web服务器基本上是一样的。

听起来好像有一大堆活要做，但随后我们会逐渐意识到，对Node.js来说这并不是什么麻烦的事。

现在我们就来开始实现之路，先从第一个部分--HTTP服务器着手。

构建应用的模块

一个基础的HTTP服务器

当我准备开始写我的第一个“真正的”Node.js应用的时候，我不但不知道怎么写Node.js代码，也不知道怎么组织这些代码。 
我应该把所有东西都放进一个文件里吗？网上有很多教程都会教你把所有的逻辑都放进一个用Node.js写的基础HTTP服务器里。但是如果我想加入更多的内容，同时还想保持代码的可读性呢？

实际上，只要把不同功能的代码放入不同的模块中，保持代码分离还是相当简单的。

这种方法允许你拥有一个干净的主文件（main file），你可以用Node.js执行它；同时你可以拥有干净的模块，它们可以被主文件和其他的模块调用。

那么，现在我们来创建一个用于启动我们的应用的主文件，和一个保存着我们的HTTP服务器代码的模块。

在我的印象里，把主文件叫做index.js或多或少是个标准格式。把服务器模块放进叫server.js的文件里则很好理解。

让我们先从服务器模块开始。在你的项目的根目录下创建一个叫server.js的文件，并写入以下代码：

var http = require("http");

http.createServer(function(request, response) {
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("Hello World");
  response.end();
}).listen(8888);
搞定！你刚刚完成了一个可以工作的HTTP服务器。为了证明这一点，我们来运行并且测试这段代码。首先，用Node.js执行你的脚本：

node server.js
接下来，打开浏览器访问http://localhost:8888/，你会看到一个写着“Hello World”的网页。

这很有趣，不是吗？让我们先来谈谈HTTP服务器的问题，把如何组织项目的事情先放一边吧，你觉得如何？我保证之后我们会解决那个问题的。

分析HTTP服务器

那么接下来，让我们分析一下这个HTTP服务器的构成。

第一行请求（require）Node.js自带的 http 模块，并且把它赋值给 http 变量。

接下来我们调用http模块提供的函数： createServer 。这个函数会返回一个对象，这个对象有一个叫做 listen 的方法，这个方法有一个数值参数，指定这个HTTP服务器监听的端口号。

咱们暂时先不管 http.createServer 的括号里的那个函数定义。

我们本来可以用这样的代码来启动服务器并侦听8888端口：

var http = require("http");

var server = http.createServer();
server.listen(8888);
这段代码只会启动一个侦听8888端口的服务器，它不做任何别的事情，甚至连请求都不会应答。

最有趣（而且，如果你之前习惯使用一个更加保守的语言，比如PHP，它还很奇怪）的部分是 createSever() 的第一个参数，一个函数定义。

实际上，这个函数定义是 createServer() 的第一个也是唯一一个参数。因为在JavaScript中，函数和其他变量一样都是可以被传递的。

进行函数传递

举例来说，你可以这样做：

function say(word) {
  console.log(word);
}

function execute(someFunction, value) {
  someFunction(value);
}

execute(say, "Hello");
请仔细阅读这段代码！在这里，我们把 say 函数作为execute函数的第一个变量进行了传递。这里返回的不是 say 的返回值，而是 say 本身！

这样一来， say 就变成了execute 中的本地变量 someFunction ，execute可以通过调用 someFunction() （带括号的形式）来使用 say 函数。

当然，因为 say 有一个变量， execute 在调用 someFunction 时可以传递这样一个变量。

我们可以，就像刚才那样，用它的名字把一个函数作为变量传递。但是我们不一定要绕这个“先定义，再传递”的圈子，我们可以直接在另一个函数的括号中定义和传递这个函数：

function execute(someFunction, value) {
  someFunction(value);
}

execute(function(word){ console.log(word) }, "Hello");
我们在 execute 接受第一个参数的地方直接定义了我们准备传递给 execute 的函数。

用这种方式，我们甚至不用给这个函数起名字，这也是为什么它被叫做 匿名函数 。

这是我们和我所认为的“进阶”JavaScript的第一次亲密接触，不过我们还是得循序渐进。现在，我们先接受这一点：在JavaScript中，一个函数可以作为另一个函数接收一个参数。我们可以先定义一个函数，然后传递，也可以在传递参数的地方直接定义函数。

函数传递是如何让HTTP服务器工作的

带着这些知识，我们再来看看我们简约而不简单的HTTP服务器：

var http = require("http");

http.createServer(function(request, response) {
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("Hello World");
  response.end();
}).listen(8888);
现在它看上去应该清晰了很多：我们向 createServer 函数传递了一个匿名函数。

用这样的代码也可以达到同样的目的：

var http = require("http");

function onRequest(request, response) {
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("Hello World");
  response.end();
}

http.createServer(onRequest).listen(8888);
也许现在我们该问这个问题了：我们为什么要用这种方式呢？

基于事件驱动的回调

这个问题可不好回答（至少对我来说），不过这是Node.js原生的工作方式。它是事件驱动的，这也是它为什么这么快的原因。

你也许会想花点时间读一下Felix Geisendörfer的大作Understanding node.js，它介绍了一些背景知识。

这一切都归结于“Node.js是事件驱动的”这一事实。好吧，其实我也不是特别确切的了解这句话的意思。不过我会试着解释，为什么它对我们用Node.js写网络应用（Web based application）是有意义的。

当我们使用 http.createServer 方法的时候，我们当然不只是想要一个侦听某个端口的服务器，我们还想要它在服务器收到一个HTTP请求的时候做点什么。

问题是，这是异步的：请求任何时候都可能到达，但是我们的服务器却跑在一个单进程中。

写PHP应用的时候，我们一点也不为此担心：任何时候当有请求进入的时候，网页服务器（通常是Apache）就为这一请求新建一个进程，并且开始从头到尾执行相应的PHP脚本。

那么在我们的Node.js程序中，当一个新的请求到达8888端口的时候，我们怎么控制流程呢？

嗯，这就是Node.js/JavaScript的事件驱动设计能够真正帮上忙的地方了——虽然我们还得学一些新概念才能掌握它。让我们来看看这些概念是怎么应用在我们的服务器代码里的。

我们创建了服务器，并且向创建它的方法传递了一个函数。无论何时我们的服务器收到一个请求，这个函数就会被调用。

我们不知道这件事情什么时候会发生，但是我们现在有了一个处理请求的地方：它就是我们传递过去的那个函数。至于它是被预先定义的函数还是匿名函数，就无关紧要了。

这个就是传说中的 回调 。我们给某个方法传递了一个函数，这个方法在有相应事件发生时调用这个函数来进行 回调 。

至少对我来说，需要一些功夫才能弄懂它。你如果还是不太确定的话就再去读读Felix的博客文章。

让我们再来琢磨琢磨这个新概念。我们怎么证明，在创建完服务器之后，即使没有HTTP请求进来、我们的回调函数也没有被调用的情况下，我们的代码还继续有效呢？我们试试这个：

var http = require("http");

function onRequest(request, response) {
  console.log("Request received.");
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("Hello World");
  response.end();
}

http.createServer(onRequest).listen(8888);

console.log("Server has started.");
注意：在 onRequest （我们的回调函数）触发的地方，我用 console.log 输出了一段文本。在HTTP服务器开始工作之后，也输出一段文本。

当我们与往常一样，运行它node server.js时，它会马上在命令行上输出“Server has started.”。当我们向服务器发出请求（在浏览器访问http://localhost:8888/ ），“Request received.”这条消息就会在命令行中出现。

这就是事件驱动的异步服务器端JavaScript和它的回调啦！

（请注意，当我们在服务器访问网页时，我们的服务器可能会输出两次“Request received.”。那是因为大部分服务器都会在你访问 http://localhost:8888 /时尝试读取 http://localhost:8888/favicon.ico )

服务器是如何处理请求的

好的，接下来我们简单分析一下我们服务器代码中剩下的部分，也就是我们的回调函数 onRequest() 的主体部分。

当回调启动，我们的 onRequest() 函数被触发的时候，有两个参数被传入： request 和 response 。

它们是对象，你可以使用它们的方法来处理HTTP请求的细节，并且响应请求（比如向发出请求的浏览器发回一些东西）。

所以我们的代码就是：当收到请求时，使用 response.writeHead() 函数发送一个HTTP状态200和HTTP头的内容类型（content-type），使用 response.write() 函数在HTTP相应主体中发送文本“Hello World"。

最后，我们调用 response.end() 完成响应。

目前来说，我们对请求的细节并不在意，所以我们没有使用 request 对象。

服务端的模块放在哪里

OK，就像我保证过的那样，我们现在可以回到我们如何组织应用这个问题上了。我们现在在 server.js 文件中有一个非常基础的HTTP服务器代码，而且我提到通常我们会有一个叫 index.js 的文件去调用应用的其他模块（比如 server.js 中的HTTP服务器模块）来引导和启动应用。

我们现在就来谈谈怎么把server.js变成一个真正的Node.js模块，使它可以被我们（还没动工）的 index.js 主文件使用。

也许你已经注意到，我们已经在代码中使用了模块了。像这样：

var http = require("http");

...

http.createServer(...);
Node.js中自带了一个叫做“http”的模块，我们在我们的代码中请求它并把返回值赋给一个本地变量。

这把我们的本地变量变成了一个拥有所有 http 模块所提供的公共方法的对象。

给这种本地变量起一个和模块名称一样的名字是一种惯例，但是你也可以按照自己的喜好来：

var foo = require("http");

...

foo.createServer(...);
很好，怎么使用Node.js内部模块已经很清楚了。我们怎么创建自己的模块，又怎么使用它呢？

等我们把 server.js 变成一个真正的模块，你就能搞明白了。

事实上，我们不用做太多的修改。把某段代码变成模块意味着我们需要把我们希望提供其功能的部分 导出 到请求这个模块的脚本。

目前，我们的HTTP服务器需要导出的功能非常简单，因为请求服务器模块的脚本仅仅是需要启动服务器而已。

我们把我们的服务器脚本放到一个叫做 start 的函数里，然后我们会导出这个函数。

var http = require("http");

function start() {
  function onRequest(request, response) {
    console.log("Request received.");
    response.writeHead(200, {"Content-Type": "text/plain"});
    response.write("Hello World");
    response.end();
  }

  http.createServer(onRequest).listen(8888);
  console.log("Server has started.");
}

exports.start = start;
这样，我们现在就可以创建我们的主文件 index.js 并在其中启动我们的HTTP了，虽然服务器的代码还在 server.js 中。

创建 index.js 文件并写入以下内容：

var server = require("./server");

server.start();
正如你所看到的，我们可以像使用任何其他的内置模块一样使用server模块：请求这个文件并把它指向一个变量，其中已导出的函数就可以被我们使用了。

好了。我们现在就可以从我们的主要脚本启动我们的的应用了，而它还是老样子：

node index.js
非常好，我们现在可以把我们的应用的不同部分放入不同的文件里，并且通过生成模块的方式把它们连接到一起了。

我们仍然只拥有整个应用的最初部分：我们可以接收HTTP请求。但是我们得做点什么——对于不同的URL请求，服务器应该有不同的反应。

对于一个非常简单的应用来说，你可以直接在回调函数 onRequest() 中做这件事情。不过就像我说过的，我们应该加入一些抽象的元素，让我们的例子变得更有趣一点儿。

处理不同的HTTP请求在我们的代码中是一个不同的部分，叫做“路由选择”——那么，我们接下来就创造一个叫做 路由 的模块吧。

如何来进行请求的“路由”

我们要为路由提供请求的URL和其他需要的GET及POST参数，随后路由需要根据这些数据来执行相应的代码（这里“代码”对应整个应用的第三部分：一系列在接收到请求时真正工作的处理程序）。

因此，我们需要查看HTTP请求，从中提取出请求的URL以及GET/POST参数。这一功能应当属于路由还是服务器（甚至作为一个模块自身的功能）确实值得探讨，但这里暂定其为我们的HTTP服务器的功能。

我们需要的所有数据都会包含在request对象中，该对象作为onRequest()回调函数的第一个参数传递。但是为了解析这些数据，我们需要额外的Node.JS模块，它们分别是url和querystring模块。

                               url.parse(string).query
                                           |
           url.parse(string).pathname      |
                       |                   |
                       |                   |
                     ------ -------------------
http://localhost:8888/start?foo=bar&hello=world
                                ---       -----
                                 |          |
                                 |          |
              querystring(string)["foo"]    |
                                            |
                         querystring(string)["hello"]
当然我们也可以用querystring模块来解析POST请求体中的参数，稍后会有演示。

现在我们来给onRequest()函数加上一些逻辑，用来找出浏览器请求的URL路径：

var http = require("http");
var url = require("url");

function start() {
  function onRequest(request, response) {
    var pathname = url.parse(request.url).pathname;
    console.log("Request for " + pathname + " received.");
    response.writeHead(200, {"Content-Type": "text/plain"});
    response.write("Hello World");
    response.end();
  }

  http.createServer(onRequest).listen(8888);
  console.log("Server has started.");
}

exports.start = start;
好了，我们的应用现在可以通过请求的URL路径来区别不同请求了--这使我们得以使用路由（还未完成）来将请求以URL路径为基准映射到处理程序上。

在我们所要构建的应用中，这意味着来自/start和/upload的请求可以使用不同的代码来处理。稍后我们将看到这些内容是如何整合到一起的。

现在我们可以来编写路由了，建立一个名为router.js的文件，添加以下内容：

function route(pathname) {
  console.log("About to route a request for " + pathname);
}

exports.route = route;
如你所见，这段代码什么也没干，不过对于现在来说这是应该的。在添加更多的逻辑以前，我们先来看看如何把路由和服务器整合起来。

我们的服务器应当知道路由的存在并加以有效利用。我们当然可以通过硬编码的方式将这一依赖项绑定到服务器上，但是其它语言的编程经验告诉我们这会是一件非常痛苦的事，因此我们将使用依赖注入的方式较松散地添加路由模块（你可以读读Martin Fowlers关于依赖注入的大作来作为背景知识）。

首先，我们来扩展一下服务器的start()函数，以便将路由函数作为参数传递过去：

var http = require("http");
var url = require("url");

function start(route) {
  function onRequest(request, response) {
    var pathname = url.parse(request.url).pathname;
    console.log("Request for " + pathname + " received.");

    route(pathname);

    response.writeHead(200, {"Content-Type": "text/plain"});
    response.write("Hello World");
    response.end();
  }

  http.createServer(onRequest).listen(8888);
  console.log("Server has started.");
}

exports.start = start;
同时，我们会相应扩展index.js，使得路由函数可以被注入到服务器中：

var server = require("./server");
var router = require("./router");

server.start(router.route);
在这里，我们传递的函数依旧什么也没做。

如果现在启动应用（node index.js，始终记得这个命令行），随后请求一个URL，你将会看到应用输出相应的信息，这表明我们的HTTP服务器已经在使用路由模块了，并会将请求的路径传递给路由：

bash$ node index.js
Request for /foo received.
About to route a request for /foo
（以上输出已经去掉了比较烦人的/favicon.ico请求相关的部分）。

行为驱动执行

请允许我再次脱离主题，在这里谈一谈函数式编程。

将函数作为参数传递并不仅仅出于技术上的考量。对软件设计来说，这其实是个哲学问题。想想这样的场景：在index文件中，我们可以将router对象传递进去，服务器随后可以调用这个对象的route函数。

就像这样，我们传递一个东西，然后服务器利用这个东西来完成一些事。嗨那个叫路由的东西，能帮我把这个路由一下吗？

但是服务器其实不需要这样的东西。它只需要把事情做完就行，其实为了把事情做完，你根本不需要东西，你需要的是动作。也就是说，你不需要名词，你需要动词。

理解了这个概念里最核心、最基本的思想转换后，我自然而然地理解了函数编程。

我是在读了Steve Yegge的大作名词王国中的死刑之后理解函数编程。你也去读一读这本书吧，真的。这是曾给予我阅读的快乐的关于软件的书籍之一。

路由给真正的请求处理程序

回到正题，现在我们的HTTP服务器和请求路由模块已经如我们的期望，可以相互交流了，就像一对亲密无间的兄弟。

当然这还远远不够，路由，顾名思义，是指我们要针对不同的URL有不同的处理方式。例如处理/start的“业务逻辑”就应该和处理/upload的不同。

在现在的实现下，路由过程会在路由模块中“结束”，并且路由模块并不是真正针对请求“采取行动”的模块，否则当我们的应用程序变得更为复杂时，将无法很好地扩展。

我们暂时把作为路由目标的函数称为请求处理程序。现在我们不要急着来开发路由模块，因为如果请求处理程序没有就绪的话，再怎么完善路由模块也没有多大意义。

应用程序需要新的部件，因此加入新的模块 -- 已经无需为此感到新奇了。我们来创建一个叫做requestHandlers的模块，并对于每一个请求处理程序，添加一个占位用函数，随后将这些函数作为模块的方法导出：

function start() {
  console.log("Request handler 'start' was called.");
}

function upload() {
  console.log("Request handler 'upload' was called.");
}

exports.start = start;
exports.upload = upload;
这样我们就可以把请求处理程序和路由模块连接起来，让路由“有路可寻”。

在这里我们得做个决定：是将requestHandlers模块硬编码到路由里来使用，还是再添加一点依赖注入？虽然和其他模式一样，依赖注入不应该仅仅为使用而使用，但在现在这个情况下，使用依赖注入可以让路由和请求处理程序之间的耦合更加松散，也因此能让路由的重用性更高。

这意味着我们得将请求处理程序从服务器传递到路由中，但感觉上这么做更离谱了，我们得一路把这堆请求处理程序从我们的主文件传递到服务器中，再将之从服务器传递到路由。

那么我们要怎么传递这些请求处理程序呢？别看现在我们只有2个处理程序，在一个真实的应用中，请求处理程序的数量会不断增加，我们当然不想每次有一个新的URL或请求处理程序时，都要为了在路由里完成请求到处理程序的映射而反复折腾。除此之外，在路由里有一大堆if request == x then call handler y也使得系统丑陋不堪。

仔细想想，有一大堆东西，每个都要映射到一个字符串（就是请求的URL）上？似乎关联数组（associative array）能完美胜任。

不过结果有点令人失望，JavaScript没提供关联数组 -- 也可以说它提供了？事实上，在JavaScript中，真正能提供此类功能的是它的对象。

在这方面，http://msdn.microsoft.com/en-us/magazine/cc163419.aspx有一个不错的介绍，我在此摘录一段：

在C++或C#中，当我们谈到对象，指的是类或者结构体的实例。对象根据他们实例化的模板（就是所谓的类），会拥有不同的属性和方法。但在JavaScript里对象不是这个概念。在JavaScript中，对象就是一个键/值对的集合 -- 你可以把JavaScript的对象想象成一个键为字符串类型的字典。

但如果JavaScript的对象仅仅是键/值对的集合，它又怎么会拥有方法呢？好吧，这里的值可以是字符串、数字或者……函数！

好了，最后再回到代码上来。现在我们已经确定将一系列请求处理程序通过一个对象来传递，并且需要使用松耦合的方式将这个对象注入到route()函数中。

我们先将这个对象引入到主文件index.js中：

var server = require("./server");
var router = require("./router");
var requestHandlers = require("./requestHandlers");

var handle = {}
handle["/"] = requestHandlers.start;
handle["/start"] = requestHandlers.start;
handle["/upload"] = requestHandlers.upload;

server.start(router.route, handle);
虽然handle并不仅仅是一个“东西”（一些请求处理程序的集合），我还是建议以一个动词作为其命名，这样做可以让我们在路由中使用更流畅的表达式，稍后会有说明。

正如所见，将不同的URL映射到相同的请求处理程序上是很容易的：只要在对象中添加一个键为"/"的属性，对应requestHandlers.start即可，这样我们就可以干净简洁地配置/start和/的请求都交由start这一处理程序处理。

在完成了对象的定义后，我们把它作为额外的参数传递给服务器，为此将server.js修改如下：

var http = require("http");
var url = require("url");

function start(route, handle) {
  function onRequest(request, response) {
    var pathname = url.parse(request.url).pathname;
    console.log("Request for " + pathname + " received.");

    route(handle, pathname);

    response.writeHead(200, {"Content-Type": "text/plain"});
    response.write("Hello World");
    response.end();
  }

  http.createServer(onRequest).listen(8888);
  console.log("Server has started.");
}

exports.start = start;
这样我们就在start()函数里添加了handle参数，并且把handle对象作为第一个参数传递给了route()回调函数。

然后我们相应地在route.js文件中修改route()函数：

function route(handle, pathname) {
  console.log("About to route a request for " + pathname);
  if (typeof handle[pathname] === 'function') {
    handle[pathname]();
  } else {
    console.log("No request handler found for " + pathname);
  }
}

exports.route = route;
通过以上代码，我们首先检查给定的路径对应的请求处理程序是否存在，如果存在的话直接调用相应的函数。我们可以用从关联数组中获取元素一样的方式从传递的对象中获取请求处理函数，因此就有了简洁流畅的形如handle[pathname]();的表达式，这个感觉就像在前方中提到的那样：“嗨，请帮我处理了这个路径”。

有了这些，我们就把服务器、路由和请求处理程序在一起了。现在我们启动应用程序并在浏览器中访问http://localhost:8888/start，以下日志可以说明系统调用了正确的请求处理程序：

Server has started.
Request for /start received.
About to route a request for /start
Request handler 'start' was called.
并且在浏览器中打开http://localhost:8888/可以看到这个请求同样被start请求处理程序处理了：

Request for / received.
About to route a request for /
Request handler 'start' was called.
让请求处理程序作出响应

很好。不过现在要是请求处理程序能够向浏览器返回一些有意义的信息而并非全是“Hello World”，那就更好了。

这里要记住的是，浏览器发出请求后获得并显示的“Hello World”信息仍是来自于我们server.js文件中的onRequest函数。

其实“处理请求”说白了就是“对请求作出响应”，因此，我们需要让请求处理程序能够像onRequest函数那样可以和浏览器进行“对话”。

不好的实现方式

对于我们这样拥有PHP或者Ruby技术背景的开发者来说，最直截了当的实现方式事实上并不是非常靠谱： 看似有效，实则未必如此。

这里我指的“直截了当的实现方式”意思是：让请求处理程序通过onRequest函数直接返回（return()）他们要展示给用户的信息。

我们先就这样去实现，然后再来看为什么这不是一种很好的实现方式。

让我们从让请求处理程序返回需要在浏览器中显示的信息开始。我们需要将requestHandler.js修改为如下形式：

function start() {
  console.log("Request handler 'start' was called.");
  return "Hello Start";
}

function upload() {
  console.log("Request handler 'upload' was called.");
  return "Hello Upload";
}

exports.start = start;
exports.upload = upload;
好的。同样的，请求路由需要将请求处理程序返回给它的信息返回给服务器。因此，我们需要将router.js修改为如下形式：

function route(handle, pathname) {
  console.log("About to route a request for " + pathname);
  if (typeof handle[pathname] === 'function') {
    return handle[pathname]();
  } else {
    console.log("No request handler found for " + pathname);
    return "404 Not found";
  }
}

exports.route = route;
正如上述代码所示，当请求无法路由的时候，我们也返回了一些相关的错误信息。

最后，我们需要对我们的server.js进行重构以使得它能够将请求处理程序通过请求路由返回的内容响应给浏览器，如下所示：

var http = require("http");
var url = require("url");

function start(route, handle) {
  function onRequest(request, response) {
    var pathname = url.parse(request.url).pathname;
    console.log("Request for " + pathname + " received.");

    response.writeHead(200, {"Content-Type": "text/plain"});
    var content = route(handle, pathname)
    response.write(content);
    response.end();
  }

  http.createServer(onRequest).listen(8888);
  console.log("Server has started.");
}

exports.start = start;
如果我们运行重构后的应用，一切都会工作的很好：请求http://localhost:8888/start,浏览器会输出“Hello Start”，请求http://localhost:8888/upload会输出“Hello Upload”,而请求http://localhost:8888/foo 会输出“404 Not found”。

好，那么问题在哪里呢？简单的说就是： 当未来有请求处理程序需要进行非阻塞的操作的时候，我们的应用就“挂”了。

没理解？没关系，下面就来详细解释下。

阻塞与非阻塞

正如此前所提到的，当在请求处理程序中包括非阻塞操作时就会出问题。但是，在说这之前，我们先来看看什么是阻塞操作。

我不想去解释“阻塞”和“非阻塞”的具体含义，我们直接来看，当在请求处理程序中加入阻塞操作时会发生什么。

这里，我们来修改下start请求处理程序，我们让它等待10秒以后再返回“Hello Start”。因为，JavaScript中没有类似sleep()这样的操作，所以这里只能够来点小Hack来模拟实现。

让我们将requestHandlers.js修改成如下形式：

function start() {
  console.log("Request handler 'start' was called.");

  function sleep(milliSeconds) {
    var startTime = new Date().getTime();
    while (new Date().getTime() < startTime + milliSeconds);
  }

  sleep(10000);
  return "Hello Start";
}

function upload() {
  console.log("Request handler 'upload' was called.");
  return "Hello Upload";
}

exports.start = start;
exports.upload = upload;
上述代码中，当函数start()被调用的时候，Node.js会先等待10秒，之后才会返回“Hello Start”。当调用upload()的时候，会和此前一样立即返回。

（当然了，这里只是模拟休眠10秒，实际场景中，这样的阻塞操作有很多，比方说一些长时间的计算操作等。）

接下来就让我们来看看，我们的改动带来了哪些变化。

如往常一样，我们先要重启下服务器。为了看到效果，我们要进行一些相对复杂的操作（跟着我一起做）： 首先，打开两个浏览器窗口或者标签页。在第一个浏览器窗口的地址栏中输入http://localhost:8888/start， 但是先不要打开它！

在第二个浏览器窗口的地址栏中输入http://localhost:8888/upload， 同样的，先不要打开它！

接下来，做如下操作：在第一个窗口中（“/start”）按下回车，然后快速切换到第二个窗口中（“/upload”）按下回车。

注意，发生了什么： /start URL加载花了10秒，这和我们预期的一样。但是，/upload URL居然也花了10秒，而它在对应的请求处理程序中并没有类似于sleep()这样的操作！

这到底是为什么呢？原因就是start()包含了阻塞操作。形象的说就是“它阻塞了所有其他的处理工作”。

这显然是个问题，因为Node一向是这样来标榜自己的：“在node中除了代码，所有一切都是并行执行的”。

这句话的意思是说，Node.js可以在不新增额外线程的情况下，依然可以对任务进行并行处理 —— Node.js是单线程的。它通过事件轮询（event loop）来实现并行操作，对此，我们应该要充分利用这一点 —— 尽可能的避免阻塞操作，取而代之，多使用非阻塞操作。

然而，要用非阻塞操作，我们需要使用回调，通过将函数作为参数传递给其他需要花时间做处理的函数（比方说，休眠10秒，或者查询数据库，又或者是进行大量的计算）。

对于Node.js来说，它是这样处理的：“嘿，probablyExpensiveFunction()（译者注：这里指的就是需要花时间处理的函数），你继续处理你的事情，我（Node.js线程）先不等你了，我继续去处理你后面的代码，请你提供一个callbackFunction()，等你处理完之后我会去调用该回调函数的，谢谢！”

（如果想要了解更多关于事件轮询细节，可以阅读Mixu的博文——理解node.js的事件轮询。）

接下来，我们会介绍一种错误的使用非阻塞操作的方式。

和上次一样，我们通过修改我们的应用来暴露问题。

这次我们还是拿start请求处理程序来“开刀”。将其修改成如下形式：

var exec = require("child_process").exec;

function start() {
  console.log("Request handler 'start' was called.");
  var content = "empty";

  exec("ls -lah", function (error, stdout, stderr) {
    content = stdout;
  });

  return content;
}

function upload() {
  console.log("Request handler 'upload' was called.");
  return "Hello Upload";
}

exports.start = start;
exports.upload = upload;
上述代码中，我们引入了一个新的Node.js模块，child_process。之所以用它，是为了实现一个既简单又实用的非阻塞操作：exec()。

exec()做了什么呢？它从Node.js来执行一个shell命令。在上述例子中，我们用它来获取当前目录下所有的文件（“ls -lah”）,然后，当/startURL请求的时候将文件信息输出到浏览器中。

上述代码是非常直观的： 创建了一个新的变量content（初始值为“empty”），执行“ls -lah”命令，将结果赋值给content，最后将content返回。

和往常一样，我们启动服务器，然后访问“http://localhost:8888/start” 。

之后会载入一个漂亮的web页面，其内容为“empty”。怎么回事？

这个时候，你可能大致已经猜到了，exec()在非阻塞这块发挥了神奇的功效。它其实是个很好的东西，有了它，我们可以执行非常耗时的shell操作而无需迫使我们的应用停下来等待该操作。

（如果想要证明这一点，可以将“ls -lah”换成比如“find /”这样更耗时的操作来效果）。

然而，针对浏览器显示的结果来看，我们并不满意我们的非阻塞操作，对吧？

好，接下来，我们来修正这个问题。在这过程中，让我们先来看看为什么当前的这种方式不起作用。

问题就在于，为了进行非阻塞工作，exec()使用了回调函数。

在我们的例子中，该回调函数就是作为第二个参数传递给exec()的匿名函数：

function (error, stdout, stderr) {
  content = stdout;
}
现在就到了问题根源所在了：我们的代码是同步执行的，这就意味着在调用exec()之后，Node.js会立即执行 return content ；在这个时候，content仍然是“empty”，因为传递给exec()的回调函数还未执行到——因为exec()的操作是异步的。

我们这里“ls -lah”的操作其实是非常快的（除非当前目录下有上百万个文件）。这也是为什么回调函数也会很快的执行到 —— 不过，不管怎么说它还是异步的。

为了让效果更加明显，我们想象一个更耗时的命令： “find /”，它在我机器上需要执行1分钟左右的时间，然而，尽管在请求处理程序中，我把“ls -lah”换成“find /”，当打开/start URL的时候，依然能够立即获得HTTP响应 —— 很明显，当exec()在后台执行的时候，Node.js自身会继续执行后面的代码。并且我们这里假设传递给exec()的回调函数，只会在“find /”命令执行完成之后才会被调用。

那究竟我们要如何才能实现将当前目录下的文件列表显示给用户呢？

好，了解了这种不好的实现方式之后，我们接下来来介绍如何以正确的方式让请求处理程序对浏览器请求作出响应。

以非阻塞操作进行请求响应

我刚刚提到了这样一个短语 —— “正确的方式”。而事实上通常“正确的方式”一般都不简单。

不过，用Node.js就有这样一种实现方案： 函数传递。下面就让我们来具体看看如何实现。

到目前为止，我们的应用已经可以通过应用各层之间传递值的方式（请求处理程序 -> 请求路由 -> 服务器）将请求处理程序返回的内容（请求处理程序最终要显示给用户的内容）传递给HTTP服务器。

现在我们采用如下这种新的实现方式：相对采用将内容传递给服务器的方式，我们这次采用将服务器“传递”给内容的方式。 从实践角度来说，就是将response对象（从服务器的回调函数onRequest()获取）通过请求路由传递给请求处理程序。 随后，处理程序就可以采用该对象上的函数来对请求作出响应。

原理就是如此，接下来让我们来一步步实现这种方案。

先从server.js开始：

var http = require("http");
var url = require("url");

function start(route, handle) {
  function onRequest(request, response) {
    var pathname = url.parse(request.url).pathname;
    console.log("Request for " + pathname + " received.");

    route(handle, pathname, response);
  }

  http.createServer(onRequest).listen(8888);
  console.log("Server has started.");
}

exports.start = start;
相对此前从route()函数获取返回值的做法，这次我们将response对象作为第三个参数传递给route()函数，并且，我们将onRequest()处理程序中所有有关response的函数调都移除，因为我们希望这部分工作让route()函数来完成。

下面就来看看我们的router.js:

function route(handle, pathname, response) {
  console.log("About to route a request for " + pathname);
  if (typeof handle[pathname] === 'function') {
    handle[pathname](response);
  } else {
    console.log("No request handler found for " + pathname);
    response.writeHead(404, {"Content-Type": "text/plain"});
    response.write("404 Not found");
    response.end();
  }
}

exports.route = route;
同样的模式：相对此前从请求处理程序中获取返回值，这次取而代之的是直接传递response对象。

如果没有对应的请求处理器处理，我们就直接返回“404”错误。

最后，我们将requestHandler.js修改为如下形式：

var exec = require("child_process").exec;

function start(response) {
  console.log("Request handler 'start' was called.");

  exec("ls -lah", function (error, stdout, stderr) {
    response.writeHead(200, {"Content-Type": "text/plain"});
    response.write(stdout);
    response.end();
  });
}

function upload(response) {
  console.log("Request handler 'upload' was called.");
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("Hello Upload");
  response.end();
}

exports.start = start;
exports.upload = upload;
我们的处理程序函数需要接收response参数，为了对请求作出直接的响应。

start处理程序在exec()的匿名回调函数中做请求响应的操作，而upload处理程序仍然是简单的回复“Hello World”，只是这次是使用response对象而已。

这时再次我们启动应用（node index.js），一切都会工作的很好。

如果想要证明/start处理程序中耗时的操作不会阻塞对/upload请求作出立即响应的话，可以将requestHandlers.js修改为如下形式：

var exec = require("child_process").exec;

function start(response) {
  console.log("Request handler 'start' was called.");

  exec("find /",
    { timeout: 10000, maxBuffer: 20000*1024 },
    function (error, stdout, stderr) {
      response.writeHead(200, {"Content-Type": "text/plain"});
      response.write(stdout);
      response.end();
    });
}

function upload(response) {
  console.log("Request handler 'upload' was called.");
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("Hello Upload");
  response.end();
}

exports.start = start;
exports.upload = upload;
这样一来，当请求http://localhost:8888/start的时候，会花10秒钟的时间才载入，而当请求http://localhost:8888/upload的时候，会立即响应，纵然这个时候/start响应还在处理中。

更有用的场景

到目前为止，我们做的已经很好了，但是，我们的应用没有实际用途。

服务器，请求路由以及请求处理程序都已经完成了，下面让我们按照此前的用例给网站添加交互：用户选择一个文件，上传该文件，然后在浏览器中看到上传的文件。 为了保持简单，我们假设用户只会上传图片，然后我们应用将该图片显示到浏览器中。

好，下面就一步步来实现，鉴于此前已经对JavaScript原理性技术性的内容做过大量介绍了，这次我们加快点速度。

要实现该功能，分为如下两步： 首先，让我们来看看如何处理POST请求（非文件上传），之后，我们使用Node.js的一个用于文件上传的外部模块。之所以采用这种实现方式有两个理由。

第一，尽管在Node.js中处理基础的POST请求相对比较简单，但在这过程中还是能学到很多。 
第二，用Node.js来处理文件上传（multipart POST请求）是比较复杂的，它不在本书的范畴，但，如何使用外部模块却是在本书涉猎内容之内。

处理POST请求

考虑这样一个简单的例子：我们显示一个文本区（textarea）供用户输入内容，然后通过POST请求提交给服务器。最后，服务器接受到请求，通过处理程序将输入的内容展示到浏览器中。

/start请求处理程序用于生成带文本区的表单，因此，我们将requestHandlers.js修改为如下形式：

function start(response) {
  console.log("Request handler 'start' was called.");

  var body = '<html>'+
    '<head>'+
    '<meta http-equiv="Content-Type" content="text/html; '+
    'charset=UTF-8" />'+
    '</head>'+
    '<body>'+
    '<form action="/upload" method="post">'+
    '<textarea name="text" rows="20" cols="60"></textarea>'+
    '<input type="submit" value="Submit text" />'+
    '</form>'+
    '</body>'+
    '</html>';

    response.writeHead(200, {"Content-Type": "text/html"});
    response.write(body);
    response.end();
}

function upload(response) {
  console.log("Request handler 'upload' was called.");
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("Hello Upload");
  response.end();
}

exports.start = start;
exports.upload = upload;
好了，现在我们的应用已经很完善了，都可以获得威比奖（Webby Awards）了，哈哈。（译者注：威比奖是由国际数字艺术与科学学院主办的评选全球最佳网站的奖项，具体参见详细说明）通过在浏览器中访问http://localhost:8888/start就可以看到简单的表单了，要记得重启服务器哦！

你可能会说：这种直接将视觉元素放在请求处理程序中的方式太丑陋了。说的没错，但是，我并不想在本书中介绍诸如MVC之类的模式，因为这对于你了解JavaScript或者Node.js环境来说没多大关系。

余下的篇幅，我们来探讨一个更有趣的问题： 当用户提交表单时，触发/upload请求处理程序处理POST请求的问题。

现在，我们已经是新手中的专家了，很自然会想到采用异步回调来实现非阻塞地处理POST请求的数据。

这里采用非阻塞方式处理是明智的，因为POST请求一般都比较“重” —— 用户可能会输入大量的内容。用阻塞的方式处理大数据量的请求必然会导致用户操作的阻塞。

为了使整个过程非阻塞，Node.js会将POST数据拆分成很多小的数据块，然后通过触发特定的事件，将这些小数据块传递给回调函数。这里的特定的事件有data事件（表示新的小数据块到达了）以及end事件（表示所有的数据都已经接收完毕）。

我们需要告诉Node.js当这些事件触发的时候，回调哪些函数。怎么告诉呢？ 我们通过在request对象上注册监听器（listener） 来实现。这里的request对象是每次接收到HTTP请求时候，都会把该对象传递给onRequest回调函数。

如下所示：

request.addListener("data", function(chunk) {
  // called when a new chunk of data was received
});

request.addListener("end", function() {
  // called when all chunks of data have been received
});
问题来了，这部分逻辑写在哪里呢？ 我们现在只是在服务器中获取到了request对象 —— 我们并没有像之前response对象那样，把 request 对象传递给请求路由和请求处理程序。

在我看来，获取所有来自请求的数据，然后将这些数据给应用层处理，应该是HTTP服务器要做的事情。因此，我建议，我们直接在服务器中处理POST数据，然后将最终的数据传递给请求路由和请求处理器，让他们来进行进一步的处理。

因此，实现思路就是： 将data和end事件的回调函数直接放在服务器中，在data事件回调中收集所有的POST数据，当接收到所有数据，触发end事件后，其回调函数调用请求路由，并将数据传递给它，然后，请求路由再将该数据传递给请求处理程序。

还等什么，马上来实现。先从server.js开始：

var http = require("http");
var url = require("url");

function start(route, handle) {
  function onRequest(request, response) {
    var postData = "";
    var pathname = url.parse(request.url).pathname;
    console.log("Request for " + pathname + " received.");

    request.setEncoding("utf8");

    request.addListener("data", function(postDataChunk) {
      postData += postDataChunk;
      console.log("Received POST data chunk '"+
      postDataChunk + "'.");
    });

    request.addListener("end", function() {
      route(handle, pathname, response, postData);
    });

  }

  http.createServer(onRequest).listen(8888);
  console.log("Server has started.");
}

exports.start = start;
上述代码做了三件事情： 首先，我们设置了接收数据的编码格式为UTF-8，然后注册了“data”事件的监听器，用于收集每次接收到的新数据块，并将其赋值给postData 变量，最后，我们将请求路由的调用移到end事件处理程序中，以确保它只会当所有数据接收完毕后才触发，并且只触发一次。我们同时还把POST数据传递给请求路由，因为这些数据，请求处理程序会用到。

上述代码在每个数据块到达的时候输出了日志，这对于最终生产环境来说，是很不好的（数据量可能会很大，还记得吧？），但是，在开发阶段是很有用的，有助于让我们看到发生了什么。

我建议可以尝试下，尝试着去输入一小段文本，以及大段内容，当大段内容的时候，就会发现data事件会触发多次。

再来点酷的。我们接下来在/upload页面，展示用户输入的内容。要实现该功能，我们需要将postData传递给请求处理程序，修改router.js为如下形式：

function route(handle, pathname, response, postData) {
  console.log("About to route a request for " + pathname);
  if (typeof handle[pathname] === 'function') {
    handle[pathname](response, postData);
  } else {
    console.log("No request handler found for " + pathname);
    response.writeHead(404, {"Content-Type": "text/plain"});
    response.write("404 Not found");
    response.end();
  }
}

exports.route = route;
然后，在requestHandlers.js中，我们将数据包含在对upload请求的响应中：

function start(response, postData) {
  console.log("Request handler 'start' was called.");

  var body = '<html>'+
    '<head>'+
    '<meta http-equiv="Content-Type" content="text/html; '+
    'charset=UTF-8" />'+
    '</head>'+
    '<body>'+
    '<form action="/upload" method="post">'+
    '<textarea name="text" rows="20" cols="60"></textarea>'+
    '<input type="submit" value="Submit text" />'+
    '</form>'+
    '</body>'+
    '</html>';

    response.writeHead(200, {"Content-Type": "text/html"});
    response.write(body);
    response.end();
}

function upload(response, postData) {
  console.log("Request handler 'upload' was called.");
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("You've sent: " + postData);
  response.end();
}

exports.start = start;
exports.upload = upload;
好了，我们现在可以接收POST数据并在请求处理程序中处理该数据了。

我们最后要做的是： 当前我们是把请求的整个消息体传递给了请求路由和请求处理程序。我们应该只把POST数据中，我们感兴趣的部分传递给请求路由和请求处理程序。在我们这个例子中，我们感兴趣的其实只是text字段。

我们可以使用此前介绍过的querystring模块来实现：

var querystring = require("querystring");

function start(response, postData) {
  console.log("Request handler 'start' was called.");

  var body = '<html>'+
    '<head>'+
    '<meta http-equiv="Content-Type" content="text/html; '+
    'charset=UTF-8" />'+
    '</head>'+
    '<body>'+
    '<form action="/upload" method="post">'+
    '<textarea name="text" rows="20" cols="60"></textarea>'+
    '<input type="submit" value="Submit text" />'+
    '</form>'+
    '</body>'+
    '</html>';

    response.writeHead(200, {"Content-Type": "text/html"});
    response.write(body);
    response.end();
}

function upload(response, postData) {
  console.log("Request handler 'upload' was called.");
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("You've sent the text: "+
  querystring.parse(postData).text);
  response.end();
}

exports.start = start;
exports.upload = upload;
好了，以上就是关于处理POST数据的全部内容。

处理文件上传

最后，我们来实现我们最终的用例：允许用户上传图片，并将该图片在浏览器中显示出来。

回到90年代，这个用例完全可以满足用于IPO的商业模型了，如今，我们通过它能学到这样两件事情： 如何安装外部Node.js模块，以及如何将它们应用到我们的应用中。

这里我们要用到的外部模块是Felix Geisendörfer开发的node-formidable模块。它对解析上传的文件数据做了很好的抽象。 其实说白了，处理文件上传“就是”处理POST数据 —— 但是，麻烦的是在具体的处理细节，所以，这里采用现成的方案更合适点。

使用该模块，首先需要安装该模块。Node.js有它自己的包管理器，叫NPM。它可以让安装Node.js的外部模块变得非常方便。通过如下一条命令就可以完成该模块的安装：

npm install formidable
如果终端输出如下内容：

npm info build Success: formidable@1.0.9
npm ok
就说明模块已经安装成功了。

现在我们就可以用formidable模块了——使用外部模块与内部模块类似，用require语句将其引入即可：

var formidable = require("formidable");
这里该模块做的就是将通过HTTP POST请求提交的表单，在Node.js中可以被解析。我们要做的就是创建一个新的IncomingForm，它是对提交表单的抽象表示，之后，就可以用它解析request对象，获取表单中需要的数据字段。

node-formidable官方的例子展示了这两部分是如何融合在一起工作的：

var formidable = require('formidable'),
    http = require('http'),
    sys = require('sys');

http.createServer(function(req, res) {
  if (req.url == '/upload' && req.method.toLowerCase() == 'post') {
    // parse a file upload
    var form = new formidable.IncomingForm();
    form.parse(req, function(err, fields, files) {
      res.writeHead(200, {'content-type': 'text/plain'});
      res.write('received upload:\n\n');
      res.end(sys.inspect({fields: fields, files: files}));
    });
    return;
  }

  // show a file upload form
  res.writeHead(200, {'content-type': 'text/html'});
  res.end(
    '<form action="/upload" enctype="multipart/form-data" '+
    'method="post">'+
    '<input type="text" name="title"><br>'+
    '<input type="file" name="upload" multiple="multiple"><br>'+
    '<input type="submit" value="Upload">'+
    '</form>'
  );
}).listen(8888);
如果我们将上述代码，保存到一个文件中，并通过node来执行，就可以进行简单的表单提交了，包括文件上传。然后，可以看到通过调用form.parse传递给回调函数的files对象的内容，如下所示：

received upload:

{ fields: { title: 'Hello World' },
  files:
   { upload:
      { size: 1558,
        path: '/tmp/1c747974a27a6292743669e91f29350b',
        name: 'us-flag.png',
        type: 'image/png',
        lastModifiedDate: Tue, 21 Jun 2011 07:02:41 GMT,
        _writeStream: [Object],
        length: [Getter],
        filename: [Getter],
        mime: [Getter] } } }
为了实现我们的功能，我们需要将上述代码应用到我们的应用中，另外，我们还要考虑如何将上传文件的内容（保存在/tmp目录中）显示到浏览器中。

我们先来解决后面那个问题： 对于保存在本地硬盘中的文件，如何才能在浏览器中看到呢？

显然，我们需要将该文件读取到我们的服务器中，使用一个叫fs的模块。

我们来添加/showURL的请求处理程序，该处理程序直接硬编码将文件/tmp/test.png内容展示到浏览器中。当然了，首先需要将该图片保存到这个位置才行。

将requestHandlers.js修改为如下形式：

var querystring = require("querystring"),
    fs = require("fs");

function start(response, postData) {
  console.log("Request handler 'start' was called.");

  var body = '<html>'+
    '<head>'+
    '<meta http-equiv="Content-Type" '+
    'content="text/html; charset=UTF-8" />'+
    '</head>'+
    '<body>'+
    '<form action="/upload" method="post">'+
    '<textarea name="text" rows="20" cols="60"></textarea>'+
    '<input type="submit" value="Submit text" />'+
    '</form>'+
    '</body>'+
    '</html>';

    response.writeHead(200, {"Content-Type": "text/html"});
    response.write(body);
    response.end();
}

function upload(response, postData) {
  console.log("Request handler 'upload' was called.");
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("You've sent the text: "+
  querystring.parse(postData).text);
  response.end();
}

function show(response, postData) {
  console.log("Request handler 'show' was called.");
  fs.readFile("/tmp/test.png", "binary", function(error, file) {
    if(error) {
      response.writeHead(500, {"Content-Type": "text/plain"});
      response.write(error + "\n");
      response.end();
    } else {
      response.writeHead(200, {"Content-Type": "image/png"});
      response.write(file, "binary");
      response.end();
    }
  });
}

exports.start = start;
exports.upload = upload;
exports.show = show;
我们还需要将这新的请求处理程序，添加到index.js中的路由映射表中：

var server = require("./server");
var router = require("./router");
var requestHandlers = require("./requestHandlers");

var handle = {}
handle["/"] = requestHandlers.start;
handle["/start"] = requestHandlers.start;
handle["/upload"] = requestHandlers.upload;
handle["/show"] = requestHandlers.show;

server.start(router.route, handle);
重启服务器之后，通过访问http://localhost:8888/show，就可以看到保存在/tmp/test.png的图片了。

好，最后我们要的就是：

在/start表单中添加一个文件上传元素
将node-formidable整合到我们的upload请求处理程序中，用于将上传的图片保存到/tmp/test.png
将上传的图片内嵌到/uploadURL输出的HTML中
第一项很简单。只需要在HTML表单中，添加一个multipart/form-data的编码类型，移除此前的文本区，添加一个文件上传组件，并将提交按钮的文案改为“Upload file”即可。 如下requestHandler.js所示：

var querystring = require("querystring"),
    fs = require("fs");

function start(response, postData) {
  console.log("Request handler 'start' was called.");

  var body = '<html>'+
    '<head>'+
    '<meta http-equiv="Content-Type" '+
    'content="text/html; charset=UTF-8" />'+
    '</head>'+
    '<body>'+
    '<form action="/upload" enctype="multipart/form-data" '+
    'method="post">'+
    '<input type="file" name="upload">'+
    '<input type="submit" value="Upload file" />'+
    '</form>'+
    '</body>'+
    '</html>';

    response.writeHead(200, {"Content-Type": "text/html"});
    response.write(body);
    response.end();
}

function upload(response, postData) {
  console.log("Request handler 'upload' was called.");
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.write("You've sent the text: "+
  querystring.parse(postData).text);
  response.end();
}

function show(response, postData) {
  console.log("Request handler 'show' was called.");
  fs.readFile("/tmp/test.png", "binary", function(error, file) {
    if(error) {
      response.writeHead(500, {"Content-Type": "text/plain"});
      response.write(error + "\n");
      response.end();
    } else {
      response.writeHead(200, {"Content-Type": "image/png"});
      response.write(file, "binary");
      response.end();
    }
  });
}

exports.start = start;
exports.upload = upload;
exports.show = show;
很好。下一步相对比较复杂。这里有这样一个问题： 我们需要在upload处理程序中对上传的文件进行处理，这样的话，我们就需要将request对象传递给node-formidable的form.parse函数。

但是，我们有的只是response对象和postData数组。看样子，我们只能不得不将request对象从服务器开始一路通过请求路由，再传递给请求处理程序。 或许还有更好的方案，但是，不管怎么说，目前这样做可以满足我们的需求。

到这里，我们可以将postData从服务器以及请求处理程序中移除了 —— 一方面，对于我们处理文件上传来说已经不需要了，另外一方面，它甚至可能会引发这样一个问题： 我们已经“消耗”了request对象中的数据，这意味着，对于form.parse来说，当它想要获取数据的时候就什么也获取不到了。（因为Node.js不会对数据做缓存）

我们从server.js开始 —— 移除对postData的处理以及request.setEncoding （这部分node-formidable自身会处理），转而采用将request对象传递给请求路由的方式：

var http = require("http");
var url = require("url");

function start(route, handle) {
  function onRequest(request, response) {
    var pathname = url.parse(request.url).pathname;
    console.log("Request for " + pathname + " received.");
    route(handle, pathname, response, request);
  }

  http.createServer(onRequest).listen(8888);
  console.log("Server has started.");
}

exports.start = start;
接下来是 router.js —— 我们不再需要传递postData了，这次要传递request对象：

function route(handle, pathname, response, request) {
  console.log("About to route a request for " + pathname);
  if (typeof handle[pathname] === 'function') {
    handle[pathname](response, request);
  } else {
    console.log("No request handler found for " + pathname);
    response.writeHead(404, {"Content-Type": "text/html"});
    response.write("404 Not found");
    response.end();
  }
}

exports.route = route;
现在，request对象就可以在我们的upload请求处理程序中使用了。node-formidable会处理将上传的文件保存到本地/tmp目录中，而我们需要做的是确保该文件保存成/tmp/test.png。 没错，我们保持简单，并假设只允许上传PNG图片。

这里采用fs.renameSync(path1,path2)来实现。要注意的是，正如其名，该方法是同步执行的， 也就是说，如果该重命名的操作很耗时的话会阻塞。 这块我们先不考虑。

接下来，我们把处理文件上传以及重命名的操作放到一起，如下requestHandlers.js所示：

var querystring = require("querystring"),
    fs = require("fs"),
    formidable = require("formidable");

function start(response) {
  console.log("Request handler 'start' was called.");

  var body = '<html>'+
    '<head>'+
    '<meta http-equiv="Content-Type" content="text/html; '+
    'charset=UTF-8" />'+
    '</head>'+
    '<body>'+
    '<form action="/upload" enctype="multipart/form-data" '+
    'method="post">'+
    '<input type="file" name="upload" multiple="multiple">'+
    '<input type="submit" value="Upload file" />'+
    '</form>'+
    '</body>'+
    '</html>';

    response.writeHead(200, {"Content-Type": "text/html"});
    response.write(body);
    response.end();
}

function upload(response, request) {
  console.log("Request handler 'upload' was called.");

  var form = new formidable.IncomingForm();
  console.log("about to parse");
  form.parse(request, function(error, fields, files) {
    console.log("parsing done");
    fs.renameSync(files.upload.path, "/tmp/test.png");
    response.writeHead(200, {"Content-Type": "text/html"});
    response.write("received image:<br/>");
    response.write("<img src='/show' />");
    response.end();
  });
}

function show(response) {
  console.log("Request handler 'show' was called.");
  fs.readFile("/tmp/test.png", "binary", function(error, file) {
    if(error) {
      response.writeHead(500, {"Content-Type": "text/plain"});
      response.write(error + "\n");
      response.end();
    } else {
      response.writeHead(200, {"Content-Type": "image/png"});
      response.write(file, "binary");
      response.end();
    }
  });
}

exports.start = start;
exports.upload = upload;
exports.show = show;
好了，重启服务器，我们应用所有的功能就可以用了。选择一张本地图片，将其上传到服务器，然后浏览器就会显示该图片。

总结与展望

恭喜，我们的任务已经完成了！我们开发完了一个Node.js的web应用，应用虽小，但却“五脏俱全”。 期间，我们介绍了很多技术点：服务端JavaScript、函数式编程、阻塞与非阻塞、回调、事件、内部和外部模块等等。

当然了，还有许多本书没有介绍到的： 如何操作数据库、如何进行单元测试、如何开发Node.js的外部模块以及一些简单的诸如如何获取GET请求之类的方法。

但本书毕竟只是一本给初学者的教程 —— 不可能覆盖到所有的内容。

幸运的是，Node.js社区非常活跃（作个不恰当的比喻就是犹如一群有多动症小孩子在一起，能不活跃吗？）， 这意味着，有许多关于Node.js的资源，有什么问题都可以向社区寻求解答。 其中Node.js社区的wiki以及 NodeCloud就是最好的资源。

	
购买“Node入门”中文版电子书

$0.99


立即购买
本书共42页 
支持PDF格式，Kindle以及ePub格式 
直接下载，免费更新



The Node Beginner Book by Manuel Kiessling (see Google+ profile) is licensed under a 
Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License. 
Permissions beyond the scope of this license may be available at manuel@kiessling.net.
========== http://docs.cnodejs.net/cman/ ==========
========== http://www.cnblogs.com/ziyunfei/archive/2012/09/28/2706061.html ==========
  
源代码 文档 API 例子 FAQ
完整的web栈
无需浏览器

PhantomJS是一个无界面的WebKit浏览器引擎,还有配套的JavaScript API.它原生支持各种web标准技术: DOM处理, CSS选择器, JSON, Canvas, 以及SVG.
PhantomJS的作者是Ariya Hidayat.

下载 v1.7 开始使用
简单的Javascript例子

console.log('Loading a web page');
var page = require('webpage').create();
var url = 'http://www.phantomjs.org/';
page.open(url, function (status) {
    //Page is loaded!
    phantom.exit();
});
交流: 查看发布日志 加入邮件讨论组 提交bug
PhantomJS是下列任务的最佳解决方案

无界面的网站测试
进行框架进行功能性测试,比如Jasmine, QUnit, Mocha, Capybara, WebDriver, 以及其他. 查看更多
网页截屏
以编程的方式给页面内容抓屏,还可以操作SVG和Canvas.创建网站缩略图预览. 查看更多
页面自动化
使用标准的DOM API访问和操作页面内容,还可以使用熟悉的框架比如jQuery. 
查看更多
网络监控
监控页面加载,将统计结果导出为标准的HAR文件.使用YSlow和Jenkins进行自动性能分析. 查看更多
PhantomJS作为许多开源项目的测试工具:
Modernizr, CodeMirror, Ember.js, YUI3, 还有 更多.
© Copyright 2010-2012 Ariya Hidayat — 网站设计: Maurice Svay


========== http://www.khotyn.com/2011/08/24/btrace_introductio/ ==========
Failed!!
========== http://blog.bluedavy.com/?p=300 ==========
Failed!!
========== http://agapple.iteye.com/blog/962119 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
agapple
博客微博相册收藏留言关于我
  
btrace记忆

博客分类： btrace
脚本HTML 
上周五接近6个小时都在开会，悲剧阿。 美好的一天又这样被浪费了。
 
还好开会的时候自带了笔记本，闲来无聊又重新把btrace的内容重新梳理了一遍。
 
ps : 以前虽然看过btrace的使用，但根本是一种阅读者的态度，并没有反编译btrace源码进行查看。 还有就是实际也没写过几个btrace脚本，很多使用就显得很生疏。所以需要多加强下，只能多看过个2,3遍。
 
更详细，更精彩的一些btrace内容，请查看：  btrace一些你不知道的事(源码入手)
 
 
 
几个常用url : 
1. javadoc文档： http://btrace.kenai.com/javadoc/1.2/index.html
2. UserGuide :  http://kenai.com/projects/btrace/pages/UserGuide
3. DeveloperGuide : http://kenai.com/projects/btrace/pages/DeveloperGuide
4. jvisualvm plugins :  http://visualvm.java.net/pluginscenters.html  , http://visualvm.java.net/plugins.html
 
 
 


几个使用注意点：

1.  Kind.CALL 和 Kind.ENTRY的使用理解
Kind.ENTRY意指进入匹配probe点，跟你@Location设置的clazz和method没有任何关系。
Kind.CALL意指从某个匹配probe的方法中调用了匹配A class method的点，一定要和clazz,method配合使用。clazz和method的默认值为""，所以不能被匹配。
说白了一个就是跟踪A和B的调用关系，另一个只是关注调用了B的方法。

2.  @ProbeClassName 和 @ProbeMethodName的理解
因为btrace的probe点，clazz和method都支持正则匹配，clazz还支持super class or inteface匹配。所以对应匹配该probe的点会不同。
@ProbeClassName :  就是具体匹配对应的clazz规则的class name。如果没配置正则，则就是Probe clazz自己。
@ProbeMethodName :  就是具体匹配对应的method规则的method name。如果没配置正则，则就是Probe method自己。
3.  @TargetInstance 和 @TargetMethodOrField的理解
这个可以结合Kind.CALL进行说明，如果是probe A class的方法中调用了匹配B class。 @TargetInstance 返回的就是B class的实例，@Self返回的就是A class
@TargetInstance : 就是probe点内部间接调用class的对象引用
@TargetMethodOrField ： 就是probe点内部间接调用class的方法或者对象属性。
说明： @TargetInstance和@TargetMethodOrField，必须结合Kind.CALL模式进行使用，具体原因看一下其代表的意思也就很明确了。 

4.  @Return , @Duration  和 方法参数AnyType的理解
可以理解下，我们常见的日志记录的需求，一般要求记录请求参数和返回结果，再加上对应的处理时间。那这时@Return , @Duration就派上用场了
@Return ： 就是获取方法的返回对象。
@Duration :  就是整个Probe method调用所耗费的时间，单位us。
AnyType ：  就是获取对应请求的参数，可以泛指任意类型。 同样你如果明确参数对象的，可以强制指定具体参数的类型
一般常见的使用： public static void log(@Return Object result, Object proxy, Method method, Object[] args, @Duration long durationL) 
说明： @Return和@Duration，必须结合Kind.Return模式进行使用，具体原因也挺明确了

5. @OnEvent的理解
就是和命令行进行交互，对事件的响应处理。比如btrace运行后，通过Ctrl + C指令，会有如下提示：
Java代码  
Please enter your option:  
    1. exit  
    2. send an event  
    3. send a named event  
 如果你选择2或者3，就是对btrace client发起一个event事件。也挺好理解的
Java代码  
@OnEvent  
 public static void event() {  
     println("event");  
 }  
  
 @OnEvent("A")  // 相应name A event  
 public static void eventA() {  
     println("eventA");  
 }  
  
 @OnEvent("B") // 相应name B event  
 public static void eventB() {  
     println("eventB");  
 }  
 
说明： 一般可通过event事件，控制一下输出统计的内容信息。
 
6. @OnExit的理解
老实说，我也并不是非常理解。只知道通过OnExit可以监控btrace脚本发起的exit()调用，在btrace client退出之前做点事情。暂没想到特定的应用场景，数据清理？
Java代码  
@OnExit  
 public static void onexit(int code) {  
     println("exit");  
 }  
  
 @OnTimer(1000)  
 public static void ontime() {  
     println(i++);  
     if (i == 5) {  
         println("do exit");  
         exit(0);  
     }  
 }  

推荐jvisualvm btrace GUI



1. 启动，关闭，Event事件发送都挺方便的。
2. 不用每次vi 打开java文件进行编辑，修改script就方便多了
常用btrace监控脚本： 

1.  Jetty监控request/response buffer，有项目在使用中发现出现http 413错误(Request entity too large) , http://www.checkupdown.com/status/E413_cn.html
 
   初步怀疑是和buffer参数有关，原先使用jboss的参数为maxHttpHeadSize=8196，所以写了脚本提取了下线上的jetty参数，后面就修改了jetty参数为8k，解决了问题
 
 
Java代码  
@BTrace  
public class JettyHeadBufferTracer {  
  
    @OnMethod(clazz = "org.eclipse.jetty.http.HttpBuffers", method = "/.*get.*Buffers/", location = @Location(value = Kind.ENTRY))  
    public static void bufferMonitor(@Self Object self) {  
        Field requestBuffersField = field("org.eclipse.jetty.http.HttpBuffers", "_requestBuffers");  
        Field responseBuffersField = field("org.eclipse.jetty.http.HttpBuffers", "_responseBuffers");  
  
        Field bufferSizeField = field("org.eclipse.jetty.io.ThreadLocalBuffers", "_bufferSize");  
        Field headerSizeField = field("org.eclipse.jetty.io.ThreadLocalBuffers", "_headerSize");  
        Object requestBuffers = get(requestBuffersField, self);  
        int requestBufferSize = (Integer) get(bufferSizeField, requestBuffers);  
        int requestHeaderSize = (Integer) get(headerSizeField, requestBuffers);  
        Object responseBuffers = get(responseBuffersField, self);  
        int responseBufferSize = (Integer) get(bufferSizeField, responseBuffers);  
        int responseHeaderSize = (Integer) get(headerSizeField, responseBuffers);  
  
        println(strcat(strcat(strcat("requestBufferSize : ", str(requestBufferSize)), " requestHeaderSize : "),  
                       str(requestHeaderSize)));  
        println(strcat(strcat(strcat("responseBufferSize : ", str(responseBufferSize)), " responseHeaderSize : "),  
                       str(responseHeaderSize)));  
    }  
}  
 
结果： 
 
Java代码  
requestBufferSize : 8192 requestHeaderSize : 6144  
responseBufferSize : 12288 responseHeaderSize : 6144  
 
 
2. 项目中使用了dbcp做为数据库连接池，但对于连接池大小是否够用没有很直观的数据可以提供，所以写了个脚本提取一下数据
主要的数据内容：
   * maxActive(最大连接池大小)，numActive(目前处于使用中),numIdle(处于空闲状态的连接数)
   * maxTotal(开启ps的最大值)，totalActive(目前处于使用ps的总数)，keyActive(当前sql的ps使用数),keyIdle(当前sql的ps空闲数)  针对开启了ps cache
 
Java代码  
<bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close">    
....     
    <property name="poolPreparedStatements" value="true" />    
    <property name="maxOpenPreparedStatements" value="10" />    
....    
</bean>    
 
 
 
Java代码  
@BTrace  
public class DbcpTracer {  
  
    @OnMethod(clazz = "org.apache.commons.pool.impl.GenericObjectPool", method = "/.*Object/", location = @Location(value = Kind.ENTRY))  
    public static void poolMonitor(@Self Object self) {  
        Field maxActiveField = field("org.apache.commons.pool.impl.GenericObjectPool", "_maxActive");  
        Field numActiveField = field("org.apache.commons.pool.impl.GenericObjectPool", "_numActive");  
        Field poolField = field("org.apache.commons.pool.impl.GenericObjectPool", "_pool");  
        Field sizeField = field("org.apache.commons.pool.impl.CursorableLinkedList", "_size");  
        int maxActive = (Integer) get(maxActiveField, self);  
        int numActive = (Integer) get(numActiveField, self);  
        int numIdle = (Integer) get(sizeField, get(poolField, self));  
  
        println(strcat(strcat(strcat(strcat(strcat("maxActive : ", str(maxActive)), " numActive : "), str(numActive)),  
                              " numIdle : "), str(numIdle)));  
    }  
  
    @OnMethod(clazz = "org.apache.commons.pool.impl.GenericKeyedObjectPool", method = "/.*Object/", location = @Location(value = Kind.ENTRY))  
    public static void psMonitor(@Self Object self, Object key) {  
        Field maxTotalField = field("org.apache.commons.pool.impl.GenericKeyedObjectPool", "_maxTotal"); // connectio的maxActive  
        Field totalActiveField = field("org.apache.commons.pool.impl.GenericKeyedObjectPool", "_totalActive"); // connectio的active  
        Field poolMapField = field("org.apache.commons.pool.impl.GenericKeyedObjectPool", "_poolMap"); // connectio的active  
  
        Field keyActiveField = field("org.apache.commons.pool.impl.GenericKeyedObjectPool$ObjectQueue", "activeCount"); // key的active  
        Field keyIdleField = field("org.apache.commons.pool.impl.GenericKeyedObjectPool$ObjectQueue", "queue"); // key的idle  
        Field keyIdleSizeField = field("org.apache.commons.pool.impl.CursorableLinkedList", "_size");  
  
        Field sqlField = field("org.apache.commons.dbcp.PoolingConnection$PStmtKey", "_sql");  
  
        int maxTotal = (Integer) get(maxTotalField, self);  
        int totalActive = (Integer) get(totalActiveField, self);  
        Map<Object, Object> poolMap = (Map<Object, Object>) get(poolMapField, self);  
        int keyActive = 0, keyIdle = 0;  
        if (poolMap != null) {  
            Object queue = get(poolMap, key);  
            if (queue != null) { // ObjectQueue  
                keyActive = (Integer) get(keyActiveField, queue);  
                keyIdle = (Integer) get(keyIdleSizeField, get(keyIdleField, queue));  
            }  
        }  
        println(strcat(strcat(strcat(strcat(strcat(strcat(strcat("maxTotal : ", str(maxTotal)), " totalActive : "),  
                                                   str(totalActive)), " keyActive : "), str(keyActive)), " keyIdle "),  
                       str(keyIdle)));  
  
        println(strcat("Ps Key: ", str(get(sqlField, key))));  
    }  
  
}  
 
 
 
查看图片附件

分享到：    
jdk中cocurrent下的AbstractQueuedSynchr ... | apache log引发io问题
2011-03-14 20:37浏览 3499评论(2)分类:编程语言相关推荐
评论
2 楼 sswh 2013-01-30  
写的很好，感谢分享~~

~~~~分割线~~~~~~~

引用
1.  Kind.CALL 和 Kind.ENTRY的使用理解
Kind.ENTRY意指进入匹配probe点，跟你@Location设置的clazz和method没有任何关系。
Kind.CALL意指从某个匹配probe的方法中调用了匹配A class method的点，一定要和clazz,method配合使用。clazz和method的默认值为""，所以不能被匹配。

下面的理解更简单一些：
Kind.ENTRY 是和 Kind.RETURN 对应的
@OnMethod(location = @Location(Kind.RETURN)) 目标方法返回时触发；

@OnMethod(location = @Location(Kind.ENTRY)) 等价于
@OnMethod(location = @Location)等价于
@OnMethod
上面三种写法是等价的，都是指目标方法被调用时触发；

Kind.CALL 和 Kind.LINE 作用类似
@OnMethod(location = @Location(value = Kind.CALL, clazz = "a", method = "b")) 指目标方法体如果调用了a.b()方法时触发；

@OnMethod(location = @Location(value = Kind.LINE, line = 5)) 指目标方法体执行到第n行代码时触发
1 楼 ilfmonday 2012-05-05  
写的很好~~非常受教
顺便问问博主用的思维导图软件是什么呢？感觉非常清爽，我自己一般用iMindMap
发表评论
  您还没有登录,请您登录后再发表评论

agapple
浏览: 297201 次
性别: 
来自: 杭州

最近访客 更多访客>>
hlclcmdylinshi126wushaodong323hanjiangit
文章分类
全部博客 (123)
opensource (24)
java (64)
linux (22)
distributed (15)
database (17)
velocity (4)
btrace (2)
项目管理 (3)
配置 (3)
闲聊 (3)
服务器 (4)
社区版块
我的资讯 (0)
我的论坛 (370)
我的问答 (12)
存档分类
2013-08 (1)
2013-04 (2)
2013-03 (1)
更多存档...
评论排行榜
zookeeper OOM问题排查
阿里巴巴开源项目: 基于mysql数据库binlog ...
最新评论
agapple： 命中注定1314 写道确实阿 ，现在暂时想的不用BTrace的 ...
btrace一些你不知道的事(源码入手)
命中注定1314： 确实阿 ，现在暂时想的不用BTrace的远程agent, 自己 ...
btrace一些你不知道的事(源码入手)
agapple： 命中注定1314 写道师兄你修改过远程的Btrace吗你需要做 ...
btrace一些你不知道的事(源码入手)
命中注定1314： 师兄你修改过远程的Btrace吗
btrace一些你不知道的事(源码入手)
khotyn： anxiety 是曹帅写的吗？求源码地址~
btrace一些你不知道的事(源码入手)
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== http://developer.51cto.com/art/201103/251295.htm ==========
首页技术频道51CTO旗下网站地图  论坛博客下载视频课程更多 登录注册

PureSystem技术公开课 开课啦！
高效的Office 365免费试用
揭开5G技术的神秘面纱
WindowsServer2012R2预览版下载

首页 | Java | .NET | Web | XML | 语言工具 | 测试 | 游戏 | 移动 | 架构 | 项目管理 | 全部文章


您所在的位置：开发 > Java > 开发工具 > 线上排查问题的利器——Btrace
线上排查问题的利器——Btrace
2011-03-28 10:03 ZavaKid JavaEye博客 我要评论(0) 字号：T | T

Btrace 是一个安全，可以动态跟踪 java 程序的一种工具。他的操作不会对原有 java 进程产生影响，不用关闭正在运行的 java 进程，也不会修改 java 进程中的逻辑和数据。因此，也就成为我们线上跟踪生产代码的有力工具!
AD：2013云计算架构师峰会精彩课程曝光
之前 Btrace 只是听说过，但还没有具体的用到。最近在排查线上问题的时候，使用了 Btrace ，发现 Btrace 真是在关键时候的利器。

Btrace 是一个安全，可以动态跟踪 java 程序的一种工具。

他的操作不会对原有 java 进程产生影响，不用关闭正在运行的 java 进程，也不会修改 java 进程中的逻辑和数据。

因此，也就成为我们线上跟踪生产代码的有力工具!

Btrace 的脚本编写也非常简单：和写 Java 代码一样的，因此对于我们，学习的曲线几乎是平坦的。

下面就分享一下 Btrace 的一些用法：

如何使用 Btrace

基本用法： trace

其中， btrace 是在 btrace 下载包中的命令 , pid 是 JVM 的进程 id ， btrace-script 是编写的 btrace 脚本。

Btrace 中的一些概念

Probe Point ： 关注点。就是我们要关注应用程序中要执行的“地方”，或者是一些“事件”的发生。

Trace Action ： 就是触发了 probe point 的时候，我们所要执行的动作。

Action Methods ：我们的 trace action 都是写在某个类的静态方法中的，这个静态方法，就是 action method 。

Btrace 中的一些限制：

Btrace 的初衷是要“跟踪代码”，而不是修改代码，因此他要保证我们注入的脚本，是安全的，对应用程序来说是“只读”的。也就是说不能修改应用程序的代码或者数据。因此 Btrace 中有一些限制，主要有：

不能新建对象

不能抛异常

不能 catch 异常

不能调用实例方法和静态方法。只能调用 Btrace 提供的 com.sun.btrace.BTraceUtils 中的方法和自己在脚本中定义的方法。

不能有循环

不能有断言

……

初看起来，好像限制蛮多的。不过， com.sun.btrace.BTraceUtils 提供的方法很多，足够我们来“跟踪”代码了。而且，这些限制也是必要的，因为我们只是到那个 JVM 去看看，看看而已。

一个简单的 Btrace 脚本例子，其实就是 Java 代码


其中：

其中类名需要加上 @Btrace 的注释，以表示是 Btrace 脚本

OnMethod 表示一个 probe point ，这个就表示当执行到 java.awt.Component 这个类的 方法(这个是 Component 的构建方法)时，就触发 func 方法。

@Self 表示这个被实例化的 Component 的引用

@OnTimer 表示事件(通过时间)触发的 probe point ，每隔 2 秒触发一次

相信程序不用做过多解释，大家都知道，终端将会打印出从跟踪开始， Component 被实例化的个数。

支持的跟踪类型

Btrace 支持的跟踪类型有很多了，包括可以跟踪：

跟踪到某个实例方法的触发

跟踪到某个接口方法的触发

跟踪到触发方法的参数，返回值

可以将当前触发的线程堆栈打印出来

设置还可以跟踪某个方法中的哪一行代码被执行到

Btrace 的 User Guide

http://kenai.com/projects/btrace/pages/UserGuide

关于 Btrace 的原理

详情可见： http://victorzhzh.javaeye.com/blog/965789

什么时候用 Btrace

虽然 Btrace 在关键时候能起到迅速排查问题的作用，但我个人感觉，这还是不到万不得已才使用的好。

首先，我们代码上线前，应该充分 review ，充分和相关方进行沟通，以避免不必要的问题发生。

其次，我们应该养成记 log 的良好习惯。遇到问题，如果有相关日志可以排查，是最方便的，同时，也是最安全，成本最低的一种排查方法。

最后，我们可以结合 btrace 和 jdk 自带的 tool 来排查问题，比如 jstack ， jstat 等等，快速的定位问题。

以上就是本人刚开始使用 Btrace 的一些成果，希望能对大家排查问题带来一些作用 。


【编辑推荐】

MyEclipse 8.6 for Spring发布 新增iPhone工具
MyEclipse 8.6正式版发布 以Eclipse 3.5.2为核心
MyEclipse 8.6 M1发布 支持更多服务器
【责任编辑：金贺 TEL：（010）68476606】

原文：线上排查问题的利器——Btrace返回开发首页
 
分享到： 0 收藏|打印|复制

给力
(42票)

动心
(41票)

废话
(42票)

专业
(41票)

标题党
(42票)

路过
(43票)
关于Btrace的更多文章
WebGL难以置信的神奇效果

WebGL是一种3D绘图标准，这种绘图技术标准允许把JavaScript和Ope[详细]
网友评论TOP5查看所有评论（0）
提交评论
通行证： 密码：   注册通行证


验证码：		请点击后输入验证码		匿名发表	
栏目热门更多>>
IntelliJ IDEA 12将集成Android UI设计器
guzz 1.3.1 发布，优秀的Java ORM 框架
Wabacus 3.4发布，开发效率提高5倍以上
Hibernate 4.16.Final 发布
JFinal 1.1.0 发布,Java极速WEB+ORM框架
同期最新更多>>
tomcat插件与Jrebel插件整合
分享Tomcat源码系列三部曲
善用Eclipse的代码模板功能
Tomcat 7.0.11发布,修复安全漏洞
Tomcat 7.0.10 发布
开发频道导航
JavaJava开发|Java基础|Java EE开发|Java框架|设计模式
WEB开发PHP开发|Python|Ruby|JSP|HTML 5|DIV+CSS
综合.NET开发|嵌入式开发|项目管理|架构设计
热点推荐

Android开发应用详解

那些性感的让人尖叫的程序员

HTML5 下一代Web开发标准详解

高性能WEB开发应用指南

Ubuntu开源技术交流频道
热门标签： windows频道移动开发云计算objective-ctp-link路由器设置图解html5

头条《开发月刊》2013年9月刊发布
本期《开发月刊》的专题内容是关于面试相关技能，描述了互联网公司的面试经历，给大家分…
《开发月刊》2013年8月刊发布
VS 2013软件生命周期管理的改进

文章排行本月本周24小时
Eclipse插件大全 挑选最牛的TOP30
2014年八大最热门IT技能
将会改变未来IT世界的十种编程语言
做为技术人员为什么要写博客
谁说设计师不会写代码？—Photoshop脚
Java数组声明、创建、初始化
盖茨承认 Ctrl+Alt+Del 是失误
IT界那些性感的让人尖叫的程序员
JDK最新版本下载及JDK安装与配置
技术人血泪史：七种IT失误让你直接走人
热点专题更多>>

从未离开过的JavaScri
你可以利用JavaScript轻易的做出亲切的欢迎讯息、漂亮

51CTO六一策划专题：
十年时间，可以让乔布斯透过iPad和iPhone成就苹果的再

大数据“三重门”
大数据时代来临，Hadoop等已成为炙手可热的技术词汇。
热点标签
编程语言排行榜 敏捷开发 Eclipse 3.6 PHP设计模式 NetBeans 7 Java7 Scala编程语言 Python编程世界 Ruby On Rails开发 LINQ ASP.NET视频教程 Visual Studio 智能手机 软件下载
点击这里查看样刊

全站热点

网络基础协议手册：BGP协议

还在局限于APT攻击吗？
数据恢复关键技术与实战指南
HTML5游戏开发实践指南
七个开源的企业ERP系统
Cisco/H3C交换机高级配置与管理技术
兼容ARM9的软核处理器设计：基于FPGA
读书

网管员必读——网络组建
本书以一个模拟局域网组建为思路，介绍了与局域网组建各主要方面相关的知识及组建、配置方法。本书所介绍的内容主要包括：局域网
网管员必读——故障排除
构件中国：面向构件的方法与实践
网管员必读—-网络安全
《网管员必读——网络管理》
博文推荐更多>>
监理人员是否知道的电源设备安装及设
如何将自己编写的软件放在真机上运行
varnish完全配置详解1
逛世博痛并快乐着
最新热帖更多>>
请问武汉是否有需要人的工作地方呢？
求合作--游戏开发人员（哈尔滨）
如何恢复已删除的 Linux下的 普通文
【Linux视频教程下载】针对于Linux学

51CTO旗下网站
领先的IT技术网站 51CTO 领先的中文存储媒体 WatchStor 中国首个CIO网站 CIOage 中国首家数字医疗网站 HC3i 移动互联网生活门户 灵客风LinkPhone
Copyright©2005-2013 51CTO.COM 版权所有 未经许可 请勿转载

========== http://www.ruanyifeng.com/blog/2012/02/6_online_playgrounds_for_web_developing.html ==========
阮一峰的网络日志 » 首页 » 档案
 
上一篇：Unix目录结构的来历
下一篇：墙上的44句话    
分类： JavaScript
网页开发的6种在线调试环境
作者： 阮一峰
日期： 2012年2月13日
如今的网页代码，一般由三个部分组成：
　　* HTML，语义层，提供网页的内容。
　　* CSS，表现层，规定网页的外观。
　　* Javascript，动作层，定义用户与网页的互动。
理想的开发环境，应该既可以分别调试这三种代码，又可以轻松查看它们合并在一起的整体效果。
浏览器是最合适的效果查看工具，所以很多人想到，代码调试环境也可以直接部署在浏览器中，以网站的形式提供服务。
下面，我根据Design Shack的文章，总结一下目前最常见的6种网页开发在线调试环境。它们大大方便了网页设计师的工作，极大地提供了工作效率。
一、CSSDesk
网址：http://cssdesk.com/ （需翻墙）

这个网站是最早出现的在线调试环境之一，主要用于调试CSS。

左侧两个面板，可以分别输入html和css代码，但不支持Javascript调试。

你可以改变"预览区"的背景颜色，可以保存或下载调试完成的代码。
二、Dabblet
网址：http://dabblet.com/

Dabblet也是一个CSS调试环境，不支持Javascript调试。

它将网页效果分成"CSS效果"、"HTML效果"和"整体效果"三个面板，方便单独调试。

它最大的特点有两个，一是动态显示代码效果，代码一输入，效果就自动显示出来；二是显示CSS提示，比如上图的字体效果和长度效果。
三、JS Bin
网址：http://jsbin.com

这是一个较早出现的Javascript在线调试环境。

它分成Javascript、html和"效果预览"三个区域，你可以自行勾选显示哪些区域。它没有独立的CSS代码区，CSS代码必须嵌入html代码，这点很不方便。

它支持加载常用的Javascript库。除此以外，其他特色不多。
四、jsFiddle
网址：http://jsfiddle.net/

jsFiddle是目前最受欢迎的在线调试环境。

它的默认界面分成5个区域，左边是参数设置，右边依次是HTML、Javascript、CSS和"效果预览区"。

除了加载常见的Javascript库，它还支持SCSS代码和CoffeeScript代码。你甚至可以把它的窗口嵌入自己的网页。
五、Tinkerbin
网址：http://tinkerbin.com/

Tinkerbin很像jsFiddle，也是分成HTML、Javascript、CSS和"效果预览区"。

它的特点在于，你可以选择某种代码独占整个编辑区，这样就增大了代码编辑的可视空间。另外，它可以实时显示代码运行结果，这是jsFiddle不支持的。

它支持的代码种类相当多，比如 HAML、SCSS、LESS和CoffeeScript。
六、Rendur
网址：http://rendur.com/

Rendur是一个轻量级在线调试环境，功能不多，但是加载和运行都很快。

用户可以在HTML、CSS、Javascript三个面板中切换，输入相应代码。代码的运行结果，会自动显示在背景网页上。最后一个面板，显示的是整个网页的源码。
（完）
文档信息
版权声明：自由转载-非商用-非衍生-保持署名 | Creative Commons BY-NC-ND 3.0
原文网址：http://www.ruanyifeng.com/blog/2012/02/6_online_playgrounds_for_web_developing.html
最后修改时间：2013年8月27日 23:43
付费支持： | 

相关文章
2013.09.02: JavaScript与有限状态机
有限状态机（Finite-state machine）是一个非常有用的模型，可以模拟世界上大部分事物。
2013.07.16: 如何让搜索引擎抓取AJAX内容？
越来越多的网站，开始采用"单页面结构"（Single-page application）。
功能链接
前一篇：Unix目录结构的来历
后一篇：墙上的44句话
更多内容请访问：首页 » 档案 » JavaScript
站内搜索： 
Feed订阅：  
广告（购买广告位）

留言（19条）
学徒 说：
深入一点就好了
2012年2月13日 17:10 | 档案 | 引用
jankerli 说：
了解一下
2012年2月13日 18:20 | 档案 | 引用
怡红公子 说：
第一次知道还有这么好的东西，调试JS什么的方便很多额。
2012年2月13日 18:39 | 档案 | 引用
岭南六少 说：
学习啦，感觉做web的要学习的东西太多啦
2012年2月13日 18:55 | 档案 | 引用
sunjourney 说：
其实有chrome就了可以了。
2012年2月13日 23:12 | 档案 | 引用
LungZeno 说：
引用sunjourney的发言：
其实有chrome就了可以了。
線上偵錯可以給網路彼端的伙伴或別人看。
2012年2月14日 01:52 | 档案 | 引用
刘永新 说：
支持阮老师，我是来学习的！
2012年2月14日 11:00 | 档案 | 引用
sokoban 说：
昨日买亚马逊买书，没到免费配送的额度，就买了一本阮兄翻译的《黑客与画家》凑数。
书到手后，原先想买的书令我失望。阮兄的译作倒是爱不释手。
2012年2月14日 11:45 | 档案 | 引用
wong2 说：
要是有Chrome扩展会更好。。就可以离线搞了，速度也会快很多
2012年2月14日 12:23 | 档案 | 引用
Kane 说：
Eclipse.org下的Orion好像更强大，能开发调试php，python，跟git集成
http://www.eclipse.org/orion/
2012年2月15日 13:48 | 档案 | 引用
fx 说：
通常都用fiddler
2012年2月15日 14:39 | 档案 | 引用
jlake 说：
http://rendera.heroku.com/
这个也不错。
2012年2月16日 16:29 | 档案 | 引用
小Z的藏经阁 说：
工欲善其事必先利其器、 呵呵。。
2012年2月23日 21:59 | 档案 | 引用
lioff 说：
一直用JSBIN 真心觉得不错
2012年3月 5日 17:04 | 档案 | 引用
hasbee 说：
请教一下，这些在线调试工具和浏览器自带的开发人员工具相比有什么长处呢？
2012年3月17日 10:06 | 档案 | 引用
Yoya 说：
引用hasbee的发言：
请教一下，这些在线调试工具和浏览器自带的开发人员工具相比有什么长处呢？
同问。
2012年4月 1日 09:16 | 档案 | 引用
SmallDong 说：
引用LungZeno的发言：

線上偵錯可以給網路彼端的伙伴或別人看。
对啊,尤其是做一些教程示例,或者在线提问啊,解答之类的很方便
2012年11月 5日 15:33 | 档案 | 引用
hidoos 说：
最近，也看到一个不错的在线调试工具，叫做codepen.io，还挺不错的。
优点的话，html输入支持zen-coding的写法，输入之后动态啊刷新就可以看到效果。
总之，挺不错的。
2013年4月22日 13:50 | 档案 | 引用
caicai 说：
这六个工具，不知道如何选择？ 谁能再进一步作指教一下。
2013年8月27日 23:43 | 档案 | 引用
我要发表看法
您的留言 （HTML标签部分可用）

您的大名：
 «-必填
电子邮件：
 «-必填，不公开
个人网址：
 «-我信任你，不会填写广告链接
记住个人信息？
 «- 点击按钮
联系方式 | ruanyifeng.com 2003 - 2013  


========== http://rdc.taobao.com/team/jm/archives/684 ==========
淘宝网综合业务平台团队博客 致力于成为中国最强大的JAVA技术团队
跳转到内容
首页
关于我们
招聘
← 高质量软件，从点点滴滴做起ConcurrentHaspLRUHashMap实现初探 →
两个OOM Cases排查过程的分享
日期：2011-01-13 作者：bluedavy
分享一下两个OOM Cases的查找过程，一个应用是Native OOM；另外一个应用其实没有OOM，只是每隔一段时间就会出现频繁FGC的现象，OOM的查找已经具备了不错的工具，但有些时候还是会出现很难查的现象，希望这两个排查过程的分享能给需要的同学带来一些帮助。

Native OOM的排查Case
之前的几个PPT里我都说到了，目前查找Native OOM最好的方法就是用google perftools了，于是挂上google perftools，等待应用再次native oom，很幸运，两天后，应用就再次native oom了，于是分析crash之前那段时间谁在不断的分配堆外的内存，pprof看到的结果主要是java.util.Inflater造成的，由于之前已经碰到过类似的case，知道如果使用了Inflater，但不显式的调用Inflater.end的话，确实会造成这个现象。
于是剩下的问题就是找出代码里什么地方调用了Inflater，这种时候btrace这个神器就可以发挥作用了，一个简单的btrace脚本：

import static com.sun.btrace.BTraceUtils.*;
import com.sun.btrace.annotations.*;
 
@BTrace public class Trace{
   @OnMethod(
      clazz="java.util.zip.Inflater",
      method="/.*/"
   )
   public static void traceExecute(@ProbeMethodName String methodName){
     println(concat("who call Inflater.",methodName));
     jstack();
   }
}
执行后很快就找到了代码什么地方调用了Inflater，于是加上了显式的调用Inflater.end，搞定收工。

偶尔频繁FGC的排查Case
这个Case就没上面的那个那么顺利了，查了有接近一个月才查出最终的原因。
当这个应用出现频繁FGC时，dump了内存，用MAT分析后，看到内存被消耗完的原因是由于几个线程内的ThreadLocalMap中有大量的数据，ThreadLocal中消耗最多内存的主要是一个HashMap，这里面有大量的数据。
于是当时想到的第一个方法就是查查应用里面什么地方往ThreadLocal里放了HashMap，杯具的是，当查找代码后发现应用本身的代码并没有往 ThreadLocal里放HashMap，那就只能是应用依赖的其他jar包做了这样的事了，但不可能去抓出这个应用依赖的所有的jar的源码来扫描，于是继续借助BTrace，写了个脚本来跟踪这类型的线程中谁调用了ThreadLocal.set，并且放的是HashMap，btrace脚本如下：

import static com.sun.btrace.BTraceUtils.*;
import com.sun.btrace.annotations.*;
 
@BTrace public class Trace{
   @OnMethod(
      clazz="java.lang.ThreadLocal",
      method="set"
   )
   public static void traceExecute(Object value){
      if(startsWith(name(currentThread()),"xxx") && startsWith("java.util.HashMap",name(classOf(value))) ){
           println("-------------------------");
           jstack();
           println();
      }
   }
}
OK，开始运行上面的脚本，发现竟然一直都没打印出什么内容，只能一直等了，杯具的是一直到了一周后再次出现频繁FGC时，这个脚本都没输出任何的东西，于是只好转换思路。

既然是HashMap里put了大量的某种类型的数据，那干脆用btrace来看看是谁在往HashMap里put这些数据，于是又写了一个 btrace脚本，执行后，很快就看到了是代码中什么地方在put这些数据，但是从抓到的调用者来看，不仅仅是目前有大量数据的这类型的线程会调，其他类型的线程也会调用，如果这个地方有问题的话，应该就全部有问题了，于是跳过这里。

回到MAT看到的现象，会不会是因为代码什么地方用ThreadLocal的方式不对，又或是什么地方往ThreadLocal里放了东西，又忘了清除呢，因此要做的就是找出这个应用中所有属性为ThreadLocal的地方，来人肉分析了，于是写了一个jsp，扫描所有的classloader中的所有class，找出属性类型为ThreadLocal的，扫描后找到了一些，还真发现有一个和现在HashMap中放的数据一样的private ThreadLocal，这种用法在线程复用的情况下，如果是每次new ThreadLocal的话，会导致ThreadLocal放的东西一直不释放，兴奋的以为已经发现原因了，可惜和业务方一确认，这个类借助Spring 保证了singleton的，因此不会有问题。
好吧，到这一步，只能猜想是由于某种参数请求的时候造成业务上会获得大量的数据了，于是想着要找业务方来分析代码了，这个非常麻烦，于是到此就几乎停滞不前了。

今天静下心来，重新仔细的看了下MAT分析的结果，决定仍然用btrace跟踪下之前往HashMap中put数据的那个业务代码，突然发现，在 web类型的处理线程中它借助的是filter去clear数据的，而杯具的是出问题的这种类型线程的处理机制是没有filter机制的，因此猜测问题估计出在这里了，继续btrace，看看这种类型的线程中是不是只有人调put，没人调clear，btrace脚本运行，很快就验证了这个猜测，于是相应的解决掉了这个case，搞定收工。

在这第二个case中，可见在频繁FGC或者OOM时，很有可能MAT只能告诉你初步的原因，但要对应到代码上到底是什么地方造成的，还得花很大精力分析了，这个时候BTrace通常能帮上很大的忙。

该文章发布在 jvm和java底层, 性能调优，标签：btrace, OOM。收藏该永久链接。
← 高质量软件，从点点滴滴做起ConcurrentHaspLRUHashMap实现初探 →
没有评论

名称 (Required)
Mail (Required, will not be published)
网址

 
最新文章
淘宝中间件团队新版博客上线
综合业务部-中间件平台-产品黄页
天心阁吉他神秘人专访
业界动态
关于大区间过滤优化内存设计
最新评论
pythonee 发布于《ZooKeeper的一个性能测试》
tonni 发布于《一种可以避免数据迁移的分库分表scale-out扩容方式》
tonni 发布于《diamond专题（二）– 核心原理介绍》
baoshengdeer 发布于《一种可以避免数据迁移的分库分表scale-out扩容方式》
李 鼎 发布于《代理重定向策略及其用户感受的分析》
标签
actor aviator btrace concurrent diamond专题 extends filter gc guice HandlerSocket hotswap hs4j ipfilter jamwiki java JavaOne jrockit kafka kilim LinkedList Lucene makefile monitor mysql netty nio nosql OOM osgi outing Paxos peaberry Solr spark TimeTunnel zookeeper 千岛湖 实习 总结 成长 指南 权限 设计 豪赌之旅 质量
链接
淘宝DBA团队
淘宝QA团队
淘宝UED团队
淘宝开放平台团队
淘宝核心系统团队
淘宝网综合业务平台团队博客 由 WordPress 强力驱动。
========== http://singleant.iteye.com/blog/1169160 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
singleAnt
博客微博相册收藏留言关于我
  
[监控]Btrace监控简单笔记

博客分类： 性能\监控java基础、规范
btrace监控sample例子 
前阵子看了公司网站的一个cache 命中率统计的btrace监控脚本，感觉这个玩意功能挺强大，对应用监控有很大实践意义。也顺便把btrace简单学习了一下，未涉及原理方面的内容，只是使用层面的东西，简单笔记总结一下。
 
安装
Linux下：
在http://kenai.com/projects/btrace下载btrace-bin.tar.gz，并解压，设置环境变量：
Java代码  
export BTRACE_HOME=/home/yblin/workspace/btrace/btrace-bin  
export PATH=$BTRACE_HOME/bin:$PATH  
 

敲入btrace命令看到提示，说明安装正常。
简介
是一个安全动态的监控工具。通过动态的修改运行时的java字节码，可以在运行时代码中插入监控行为。

几个概念
探测点 (probe point)：用于表示需要被探测监控的位置或者事件。
探测行为 (action)：探测点触发时进行的探测行为。如计时等等。
探测方法 (method)：当探测点触发的时候，需要触发的探测行为所定义在的那个方法。
 
 
代码结构和例子
Btrace代码结构(1.2之后static可以去掉 )
Java代码  
//annotation defined here  
public static void trace(){  
//actions defined here  
}  
 
注：以上是一个探测方法，方法的注解annotation用来指示探测点，即要探测的位置；方法体的内容，是探测点触发之后的探测行为。

以下是一个例子：
待测试代码：
Java代码  
package btrace.test;  
  
public class MyBtraceTest {  
  
    public void execute() {  
        int i = (int) (Math.random() * 1000);  
        System.out.println(i);  
        try {  
            Thread.sleep(Math.abs(i));  
        } catch (InterruptedException e) {  
            e.printStackTrace();  
        }  
    }  
  
    public void loopExcute() {  
        while (true) {  
            execute();  
        }  
    }  
  
    public static void main(String[] args) {  
        MyBtraceTest m = new MyBtraceTest();  
        m.loopExcute();  
    }  
}  
 
要测试待测代码里excute方法的执行时间，并每次打出方法栈，监控代码如下：
 
Java代码  
package btrace.test;  
  
import static com.sun.btrace.BTraceUtils.jstack;  
import static com.sun.btrace.BTraceUtils.println;  
import static com.sun.btrace.BTraceUtils.str;  
import static com.sun.btrace.BTraceUtils.strcat;  
import static com.sun.btrace.BTraceUtils.timeMillis;  
  
import com.sun.btrace.annotations.BTrace;  
import com.sun.btrace.annotations.Kind;  
import com.sun.btrace.annotations.Location;  
import com.sun.btrace.annotations.OnMethod;  
import com.sun.btrace.annotations.TLS;  
  
@BTrace  
public class TraceMethodTime {  
  
    @TLS  
    static long beginTime;  
  
    @OnMethod(clazz = "btrace.test.MyBtraceTest", method = "execute")  
    public static void traceExecuteBegin() {// 在方法btrace.test.MyBtraceTest.execute()执行之前进行监控。  
        println("method start!");  
        beginTime = timeMillis();  
        // 监控行为是记录一个开始时间。  
    }  
  
    // OnMethod代表运行一个方法的时候进行监控，location @Location(Kind.RETURN)代表在方法返回的时候触发监控行为。  
    @OnMethod(clazz = "btrace.test.MyBtraceTest", method = "execute", location = @Location(Kind.RETURN))  
    public static void traceExcute() {  
        // 监控行为是根据开始时间计算出方法运行时间。  
        println(strcat(strcat("btrace.test.MyBtraceTest.execute time is:", str(timeMillis() - beginTime)), "ms"));  
        println("method end!");  
        jstack();//打印方法栈  
    }  
}  
 

先运行 MyBtraceTest，通过jps拿到进程id，再通过

btrace  11059 btrace/test/TraceMethodTime.java

命令进行监控。可以得到结果：
 


参考
Btrace的注解方式有很多，意义各不同，同时也有很多现成例子，能帮助实现各种监控场景。
参考官网：http://kenai.com/projects/btrace/pages/UserGuide
 
 
查看图片附件

0 
顶0 
踩 分享到：    
【Spring】IOC核心源码学习（二）：容器初 ... | 【设计】一个有意思的服务方法入参设计
2011-09-09 10:57浏览 1168评论(0)分类:编程语言相关推荐
评论
发表评论
  您还没有登录,请您登录后再发表评论

singleant
浏览: 63841 次
性别: 
来自: 杭州

最近访客 更多访客>>
dylinshi126caozhenguychanger0702asia2815
文章分类
全部博客 (40)
java基础、规范 (22)
JavaEE (8)
Linux/shell (2)
软件构建、管理 (1)
设计模式 (7)
数据库 (4)
AJAX(JS/CSS/HTML/XML) (1)
tomcat,jboss,jetty (2)
性能\监控 (5)
开源框架 (3)
开发工具(vim\emacs等) (2)
NoSQL、分布式数据 (1)
java 并发实践 (3)
模块化、OSGI (0)
http、web相关 (1)
总结 (1)
ruby (4)
社区版块
我的资讯 (0)
我的论坛 (40)
我的问答 (8)
存档分类
2012-12 (1)
2012-11 (1)
2012-09 (3)
更多存档...
最新评论
islove1945： 很不错，言简意赅
【JVM】HotSpot JVM内存管理和GC策略总结
san_yun： 应用做到平滑停止还是挺麻烦的，博主只提到了触发应用停机的入口， ...
【java基础】如何设计java应用程序的平滑停止
txbhcml： 写的相当的好  清晰的和那 
【Spring】IOC核心源码学习（二）：容器初始化过程
baitian： 引用3.       增加一个 NamespaceHandle ...
【Spring】IOC核心源码学习（三）：bean标签和自定义标签实现原理
tianhandigeng： 写得很不错，学习了
【Spring】IOC核心源码学习（三）：bean标签和自定义标签实现原理
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== http://blog.csdn.net/mgoann/article/details/7268508 ==========
========== http://victorzhzh.iteye.com/blog/965789 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
victorzhzh
博客微博相册收藏留言关于我
  
Btrace系列之一：Btrace的基本原理

博客分类： Btrace系列
脚本虚拟机SUNJVM
 
写在前面的话：Btrace系列是我将平时里学习和使用Btrace的一些经验的总结，拿出来和大家一起交流一下，希望在这个过程中能找寻出自己理解或使用上的错误之处。
 
一、Btrace的简介：
    Btrace是由Kenai 开发的一个开源项目，是一种动态跟踪分析JAVA源代码的工具。它可以用来帮我们做运行时的JAVA程序分析，监控等等操作，当然，它也不是万能的，BTrace也有一些使用上的限制，如：不能在脚本中新建类等等，这些在官方网站上有很详细的介绍，大家有兴趣可以查看：http://kenai.com/projects/btrace/pages/UserGuide。
 
二、JDK6的几个新特性：
     Btrace是由：Attach API + BTrace脚本解析引擎 + ASM + JDK6 Instumentation组成，这里要注意最后一项是JDK6的Instumentation，为什么一定要是JDK6呢？我们就要来看一下JDK6为我们提供了什么：
1、虚拟机启动后的Instumentation：
        Instumentation早在JDK5的时候就已经提出了，但是它有个局限性，premain函数只能在main函数之前被运行（对于Instumentation不熟悉的请去Sun官网查看），而JDK6之后提供了一个叫做agentmain的函数，它可以在main函数运行后在运行，代码如下：
Java代码  
public static void agentmain(String args, Instrumentation inst)  
public static void agentmain(String args)  
 这个函数的功能通premain函数一样，可以对类进行各种操作。同premain函数一样，在manifest 文件里面设置“Agent-Class”来指定包含 agentmain 函数的类。
2、Instumentation提供的新方法retransformClasses：
        这个新方法可以在agentmain函数中调用，它的功能和redefineClasses 一样，可以修改类的定义且是批量的。        
3、BootClassPath和SystemClassPath的动态指定：
       在JDK6之前，我们知道可以通过系统参数或者虚拟机启动参数，设置一个虚拟机运行时的boot class加载路径和system class加载路径，但是在启动后，这个路径是不可以修改的，并且，我们要在启动后再去加载一个*.jar文件是不可能的，但是在JDK6以后，这个规定被打破了，可以使用Instrumentation的appendToBootstrapClassLoaderSearch和appendToSystemClassLoaderSearch来修改路径或加载新的*.jar（注意：虽然实际的classpath被修改了，但是在property中的java.class.path却没有受任何影响）。
 
正因为以上的新特性，才缔造出了Btrace的想法以至于最后的实现。
 
三、Btrace的原理：
Btrace首先是通过Attach API中提供的VirtualMachine.attach(PID)方法来获得要监控的JVM，然后使用VirtualMachine.loadAgent("*.jar")方法来加载jar文件，这个jar文件中会包含Btrace的一个很重要的类com.sun.btrace.agent.Main，这个类里定义了如下的函数：
Java代码  
public static void premain(String args, Instrumentation inst) {  
        main(args, inst);  
 }  
  
public static void agentmain(String args, Instrumentation inst) {  
       main(args, inst);  
}  
 这里两个函数都调用了一个main方法，如下：
Java代码  
private static synchronized void main(final String args, final Instrumentation inst) {  
......  
inst.appendToBootstrapClassLoaderSearch(new JarFile(new File(path)));  
......  
inst.appendToSystemClassLoaderSearch(new JarFile(new File(path)));  
......  
startServer();  
}  
 这里省去了不必要的代码，主要三行代码，头两行不用解释，上面已经说过用途了，第三行解释一下，代码如下：
Java代码  
private static void startServer() {  
......  
while (true) {  
            try {  
......  
                handleNewClient(client);  
            } catch (RuntimeException re) {  
                if (isDebug()) debugPrint(re);  
            } catch (IOException ioexp) {  
                if (isDebug()) debugPrint(ioexp);  
            }  
        }  
}  
 关键看一下handleNewClient(client)方法的调用，这个是修改类定义的地方，如下：
Java代码  
private static void handleNewClient(final Client client) {  
......  
inst.addTransformer(client, true);  
......  
inst.retransformClasses(classes);  
}  
 这两句话就实现了对现有内存中的类定义的替换，当在一次调用new创建一个新对象时就会使用新的类定义，而老的已经生成的类对象是不会收到干扰的。
那又是谁取执行了对类定义的修改呢，这个是由BTrace脚本解析引擎 + ASM来实现的，脚本引擎负责解析我们所写的脚本，而ASM来对JAVA的字节码进行增强修改。你在Btrace的com.sun.btrace.agent.Client中可以看到ASM的影子，代码如下：
Java代码  
abstract class Client implements ClassFileTransformer, CommandListener {  
static {  
        ClassFilter.class.getClass();  
        ClassReader.class.getClass();  
        ClassWriter.class.getClass();  
......  
    }  
  
 private byte[] instrument(Class clazz, String cname, byte[] target) {  
        byte[] instrumentedCode;  
        try {  
            ClassWriter writer = InstrumentUtils.newClassWriter(target);  
            ClassReader reader = new ClassReader(target);  
            Instrumentor i = new Instrumentor(clazz, className,  btraceCode, onMethods, writer);  
......  
    }  
 现在我们在回顾一下整个流程，用Attach API附加*.jar然后使用BTrace脚本解析引擎 + ASM来实现对类的修改，在使用Instumentation实现类的内存替换，完毕！perfect！BTrace原来也就这么回事，但是我们不得不佩服开发团队的思维和整合能力，向牛人致敬！

分享到：    
左式堆学习 | 从周易浅看“开闭原则”
2011-03-17 21:28浏览 2259评论(0)分类:编程语言相关推荐
评论
发表评论
  您还没有登录,请您登录后再发表评论

victorzhzh
浏览: 31361 次
来自: ...

最近访客 更多访客>>
dylinshi126bruceyuxuzeweiryxxlong
文章分类
全部博客 (21)
ASM系列 (5)
Apache服务器 (1)
设计模式 (1)
数据挖掘 (0)
Btrace系列 (1)
数据结构 (1)
hadoop系列 (4)
并发编程 (5)
设计模式与并发 (0)
JAVA基础 (2)
社区版块
我的资讯 (0)
我的论坛 (1)
我的问答 (1)
存档分类
2012-08 (1)
2011-11 (1)
2011-10 (1)
更多存档...
最新评论
uoton： 谢谢PO主的分享.
定时且周期性的任务研究II--ScheduledThreadPoolExecutor
oh_boo：   急求怎么操作修改带有返回值的方法??我有个子类继承父类,然 ...
ASM系列之五：操作类方法
pjfox163： primes.put(b); 这里try一下就可以了，原因是 ...
阻塞方法引起的任务无法结束
Blackbaby： 你好  想请问下怎么通过asm读取到Annotation默认值 ...
ASM系列之五：操作类方法
luoaz： 楼主，这个问题怎么解决的啊，能不能分享一下，我们现在遇到了这个 ...
阻塞方法引起的任务无法结束
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== http://blog.csdn.net/qyongkang/article/details/6090488 ==========
========== http://exceptioneye.iteye.com/blog/1315117 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
To Strive To Seek To Find Not To Yield
博客微博相册收藏留言关于我
  
JAVA线程池ThreadPoolExecutor

博客分类： 多线程
 
java.util.concurrent.ThreadPoolExecutor相关基础介绍和使用示例。 
[ 一 ]、常用线程池 
最常用构造方法为：
Java代码   
ThreadPoolExecutor( int  corePoolSize,   
                    int  maximumPoolSize,   
                    long  keepAliveTime,   
                   TimeUnit unit,   
                   BlockingQueue<Runnable> workQueue,   
                   RejectedExecutionHandler handler)  
Java代码  
ThreadPoolExecutor(int corePoolSize,  
                   int maximumPoolSize,  
                   long keepAliveTime,  
                   TimeUnit unit,  
                   BlockingQueue<Runnable> workQueue,  
                   RejectedExecutionHandler handler)  


JDK自带的配置好的线程池：
Java代码   
// 固定工作线程数量的线程池   
ExecutorService executorService1 = Executors.newFixedThreadPool( 3 );   
  
// 一个可缓存的线程池   
ExecutorService executorService2 = Executors.newCachedThreadPool();   
  
// 单线程化的Executor   
ExecutorService executorService3 = Executors.newSingleThreadExecutor();   
  
// 支持定时的以及周期性的任务执行   
ExecutorService executorService4 = Executors.newScheduledThreadPool( 3 );  
Java代码  
// 固定工作线程数量的线程池  
ExecutorService executorService1 = Executors.newFixedThreadPool(3);  
  
// 一个可缓存的线程池  
ExecutorService executorService2 = Executors.newCachedThreadPool();  
  
// 单线程化的Executor  
ExecutorService executorService3 = Executors.newSingleThreadExecutor();  
  
// 支持定时的以及周期性的任务执行  
ExecutorService executorService4 = Executors.newScheduledThreadPool(3);  

这些预定义好的线程池服务也是基于ThreadPoolExecutor配置的，所以我们应该从最基本的参数着手了解 ，如下： 

参数详细说明 ： 
[ 1 ]、corePoolSize ： 线程池维护线程的最少数量 
[ 2 ]、maximumPoolSize ：线程池维护线程的最大数量 
[ 3 ]、keepAliveTime ： 线程池维护线程所允许的空闲时间 
[ 4 ]、unit ： 线程池维护线程所允许的空闲时间的单位，unit可选的参数为java.util.concurrent.TimeUnit中的几个静态属性：
NANOSECONDS
MICROSECONDS
MILLISECONDS
SECONDS
[ 5]、workQueue ： 线程池所使用的缓冲队列，常用的是：java.util.concurrent.ArrayBlockingQueue 
[ 6 ]、handler ： 线程池对拒绝任务的处理策略，有四个选择如下：
ThreadPoolExecutor.AbortPolicy()：抛出java.util.concurrent.RejectedExecutionException异常
ThreadPoolExecutor.CallerRunsPolicy()：重试添加当前的任务，他会自动重复调用execute()方法
ThreadPoolExecutor.DiscardOldestPolicy()：抛弃旧的任务
ThreadPoolExecutor.DiscardPolicy()：抛弃当前的任务
[ 二 ]、详细说明 
[ 1 ]、当一个任务通过execute(Runnable)方法欲添加到线程池时：
如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。
如果此时线程池中的数量等于 corePoolSize，但是缓冲队列 workQueue未满，那么任务被放入缓冲队列。
如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。
如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maximumPoolSize，那么通过 handler所指定的策略来处理此任务。也就是：处理任务的优先级为：核心线程corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务。
当线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数。
[ 2 ]、核心和最大池大小 
ThreadPoolExecutor 将根据 corePoolSize（参见 getCorePoolSize()）和 maximumPoolSize（参见 getMaximumPoolSize()）设置的边界自动调整池大小。当新任务在方法 execute(java.lang.Runnable) 中提交时，如果运行的线程少于 corePoolSize，则创建新线程来处理请求，即使其他辅助线程是空闲的。如果运行的线程多于 corePoolSize 而少于 maximumPoolSize，则仅当队列满时才创建新线程。如果设置的 corePoolSize 和 maximumPoolSize 相同，则创建了固定大小的线程池。如果将 maximumPoolSize 设置为基本的无界值（如 Integer.MAX_VALUE），则允许池适应任意数量的并发任务。在大多数情况下，核心和最大池大小仅基于构造来设置，不过也可以使用 setCorePoolSize(int) 和 setMaximumPoolSize(int) 进行动态更改。 
[ 3 ]、排队及策略 
所有 BlockingQueue 都可用于传输和保持提交的任务。可以使用此队列与池大小进行交互：
如果运行的线程少于 corePoolSize，则 Executor 始终首选添加新的线程，而不进行排队。
如果运行的线程等于或多于 corePoolSize，则 Executor 始终首选将请求加入队列，而不添加新的线程。
如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。
排队有三种通用策略：
直接提交。工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集合时出现锁定。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。
无界队列。使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙的情况下将新任务加入队列。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize 的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。
有界队列。当使用有限的 maximumPoolSizes 时，有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O 边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。
[ 4 ]、拒绝任务的处理策略 （这个和参数handler设置相关） 
当 Executor 已经关闭，并且 Executor 将有限边界用于最大线程和工作队列容量，且已经饱和时，在方法 execute(java.lang.Runnable) 中提交的新任务将被拒绝。在以上两种情况下，execute 方法都将调用其 RejectedExecutionHandler 的 RejectedExecutionHandler.rejectedExecution(java.lang.Runnable, java.util.concurrent.ThreadPoolExecutor) 方法。下面提供了四种预定义的处理程序策略：
在默认的 ThreadPoolExecutor.AbortPolicy 中，处理程序遭到拒绝将抛出运行时 RejectedExecutionException。
在 ThreadPoolExecutor.CallerRunsPolicy 中，线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。
在 ThreadPoolExecutor.DiscardPolicy 中，不能执行的任务将被删除。
在 ThreadPoolExecutor.DiscardOldestPolicy 中，如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程）。
定义和使用其他种类的 RejectedExecutionHandler 类也是可能的，但这样做需要非常小心，尤其是当策略仅用于特定容量或排队策略时。

[ 三 ]、简单示例 
JavaThreadPool.java
Java代码   
package  michael.thread.pool;   
  
import  java.util.Date;   
import  java.util.concurrent.ArrayBlockingQueue;   
import  java.util.concurrent.ThreadPoolExecutor;   
import  java.util.concurrent.TimeUnit;   
  
  
/**  
 * @see http://sjsky.iteye.com  
 * @author michael sjsky007@gmail.com  
 */   
public   class  JavaThreadPool {   
  
     /**  
     * @param args  
     */   
     public   static   void  main(String[] args) {   
  
        ThreadPoolExecutor threadPool =  new  ThreadPoolExecutor( 3 ,  5 ,  60 ,   
                TimeUnit.SECONDS,  new  ArrayBlockingQueue<Runnable>( 10 ),   
                 new  ThreadPoolExecutor.CallerRunsPolicy());   
         for  ( int  i =  0 ; i <  10 ; i++) {   
            System.out.println( "add job_"  + i +  " at:"  +  new  Date());   
            SimplePrintJob job =  new  SimplePrintJob( "job_"  + i);   
            threadPool.execute(job);   
        }   
        System.out.println( "execute all job" );   
        threadPool.shutdown();   
        System.out.println( "main program end-----------" );   
    }   
  
}  
Java代码  
package michael.thread.pool;  
  
import java.util.Date;  
import java.util.concurrent.ArrayBlockingQueue;  
import java.util.concurrent.ThreadPoolExecutor;  
import java.util.concurrent.TimeUnit;  
  
  
/** 
 * @see http://sjsky.iteye.com 
 * @author michael sjsky007@gmail.com 
 */  
public class JavaThreadPool {  
  
    /** 
     * @param args 
     */  
    public static void main(String[] args) {  
  
        ThreadPoolExecutor threadPool = new ThreadPoolExecutor(3, 5, 60,  
                TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(10),  
                new ThreadPoolExecutor.CallerRunsPolicy());  
        for (int i = 0; i < 10; i++) {  
            System.out.println("add job_" + i + " at:" + new Date());  
            SimplePrintJob job = new SimplePrintJob("job_" + i);  
            threadPool.execute(job);  
        }  
        System.out.println("execute all job");  
        threadPool.shutdown();  
        System.out.println("main program end-----------");  
    }  
  
}  

SimplePrintJob.java
Java代码   
package  michael.thread.pool;   
  
import  java.util.Random;   
  
  
/**  
 * @see http://sjsky.iteye.com  
 * @author michael sjsky007@gmail.com  
 */   
public   class  SimplePrintJob  implements  Runnable {   
  
     private  String jobName;   
  
     /**  
     * @param jobName  
     */   
     public  SimplePrintJob(String jobName) {   
         this .jobName = jobName;   
    }   
  
     /**  
     * @see java.lang.Runnable#run()  
     */   
     public   void  run() {   
        System.out.println( "[ "  + jobName +  " ] start..." );   
         int  random =  0 ;   
         try  {   
            Random r =  new  Random();   
            random = r.nextInt( 10 );   
            Thread.sleep(random * 1000L);   
        }  catch  (Exception e) {   
            e.printStackTrace();   
        }   
        System.out.println( "[ "  + jobName +  " ] end with sleep:"  + random);   
    }   
}  
Java代码  
package michael.thread.pool;  
  
import java.util.Random;  
  
  
/** 
 * @see http://sjsky.iteye.com 
 * @author michael sjsky007@gmail.com 
 */  
public class SimplePrintJob implements Runnable {  
  
    private String jobName;  
  
    /** 
     * @param jobName 
     */  
    public SimplePrintJob(String jobName) {  
        this.jobName = jobName;  
    }  
  
    /** 
     * @see java.lang.Runnable#run() 
     */  
    public void run() {  
        System.out.println("[ " + jobName + " ] start...");  
        int random = 0;  
        try {  
            Random r = new Random();  
            random = r.nextInt(10);  
            Thread.sleep(random * 1000L);  
        } catch (Exception e) {  
            e.printStackTrace();  
        }  
        System.out.println("[ " + jobName + " ] end with sleep:" + random);  
    }  
}  

运行结果如下：
引用
add job_0 at:Sun Jun 19 00:52:02 CST 2011 
add job_1 at:Sun Jun 19 00:52:02 CST 2011 
add job_2 at:Sun Jun 19 00:52:02 CST 2011 
[ job_0 ] start... 
add job_3 at:Sun Jun 19 00:52:02 CST 2011 
add job_4 at:Sun Jun 19 00:52:02 CST 2011 
add job_5 at:Sun Jun 19 00:52:02 CST 2011 
add job_6 at:Sun Jun 19 00:52:02 CST 2011 
add job_7 at:Sun Jun 19 00:52:02 CST 2011 
add job_8 at:Sun Jun 19 00:52:02 CST 2011 
add job_9 at:Sun Jun 19 00:52:02 CST 2011 
execute all job 
[ job_2 ] start... 
[ job_0 ] end with sleep:0 
[ job_3 ] start... 
[ job_2 ] end with sleep:0 
[ job_4 ] start... 
main program end----------- 
[ job_1 ] start... 
[ job_4 ] end with sleep:1 
[ job_5 ] start... 
[ job_5 ] end with sleep:6 
[ job_6 ] start... 
[ job_1 ] end with sleep:7 
[ job_7 ] start... 
[ job_3 ] end with sleep:8 
[ job_8 ] start... 
[ job_6 ] end with sleep:4 
[ job_9 ] start... 
[ job_7 ] end with sleep:6 
[ job_8 ] end with sleep:7 
[ job_9 ] end with sleep:5 


我们可以自己更改 RejectedExecutionHandler handler这个参数，来观察运行结果会有什么不同。
 
==============转载http://sjsky.iteye.com/blog/1100208==================
 
==============转载: 讨论帖 http://www.iteye.com/topic/1118660==================
背景

前段时间一个项目中因为涉及大量的线程开发，把jdk cocurrent的代码重新再过了一遍。这篇文章中主要是记录一下学习ThreadPoolExecutor过程中容易被人忽略的点，Doug Lea的整个类设计还是非常nice的
 
正文

先看一副图，描述了ThreadPoolExecutor的工作机制: 

 
整个ThreadPoolExecutor的任务处理有4步操作：
 
第一步，初始的poolSize < corePoolSize，提交的runnable任务，会直接做为new一个Thread的参数，立马执行
第二步，当提交的任务数超过了corePoolSize，就进入了第二步操作。会将当前的runable提交到一个block queue中
第三步，如果block queue是个有界队列，当队列满了之后就进入了第三步。如果poolSize < maximumPoolsize时，会尝试new 一个Thread的进行救急处理，立马执行对应的runnable任务
第四步，如果第三步救急方案也无法处理了，就会走到第四步执行reject操作。
几点说明：(相信这些网上一搜一大把，我这里简单介绍下，为后面做一下铺垫)
block queue有以下几种实现：
1. ArrayBlockingQueue :  有界的数组队列
2. LinkedBlockingQueue : 可支持有界/无界的队列，使用链表实现
3. PriorityBlockingQueue : 优先队列，可以针对任务排序
4. SynchronousQueue : 队列长度为1的队列，和Array有点区别就是：client thread提交到block queue会是一个阻塞过程，直到有一个worker thread连接上来poll task。
RejectExecutionHandler是针对任务无法处理时的一些自保护处理：
1. Reject 直接抛出Reject exception
2. Discard 直接忽略该runnable，不可取
3. DiscardOldest 丢弃最早入队列的的任务
4. CallsRun 直接让原先的client thread做为worker线程，进行执行

容易被人忽略的点：
1.  pool threads启动后，以后的任务获取都会通过block queue中，获取堆积的runnable task.

所以建议： block size >= corePoolSize ，不然线程池就没任何意义
2.  corePoolSize 和 maximumPoolSize的区别， 和大家正常理解的数据库连接池不太一样。
  *  据dbcp pool为例，会有minIdle , maxActive配置。minIdle代表是常驻内存中的threads数量，maxActive代表是工作的最大线程数。
  *  这里的corePoolSize就是连接池的maxActive的概念，它没有minIdle的概念(每个线程可以设置keepAliveTime，超过多少时间多有任务后销毁线程，但不会固定保持一定数量的threads)。 
  * 这里的maximumPoolSize，是一种救急措施的第一层。当threadPoolExecutor的工作threads存在满负荷，并且block queue队列也满了，这时代表接近崩溃边缘。这时允许临时起一批threads，用来处理runnable，处理完后立马退出。

所以建议：  maximumPoolSize >= corePoolSize =期望的最大线程数。 (我曾经配置了corePoolSize=1, maximumPoolSize=20, blockqueue为无界队列，最后就成了单线程工作的pool。典型的配置错误)

3. 善用blockqueue和reject组合. 这里要重点推荐下CallsRun的Rejected Handler，从字面意思就是让调用者自己来运行。
我们经常会在线上使用一些线程池做异步处理，比如我前面做的(业务层)异步并行加载技术分析和设计 ,  将原本串行的请求都变为了并行操作，但过多的并行会增加系统的负载(比如软中断，上下文切换)。所以肯定需要对线程池做一个size限制。但是为了引入异步操作后，避免因在block queue的等待时间过长，所以需要在队列满的时，执行一个callsRun的策略，并行的操作又转为一个串行处理，这样就可以保证尽量少的延迟影响。

所以建议：  RejectExecutionHandler = CallsRun ,  blockqueue size = 2 * poolSize (为啥是2倍poolSize，主要一个考虑就是瞬间高峰处理，允许一个thread等待一个runnable任务)
Btrace容量规划

再提供一个btrace脚本，分析线上的thread pool容量规划是否合理，可以运行时输出poolSize等一些数据。
 
 
Java代码   
import   static  com.sun.btrace.BTraceUtils.addToAggregation;   
import   static  com.sun.btrace.BTraceUtils.field;   
import   static  com.sun.btrace.BTraceUtils.get;   
import   static  com.sun.btrace.BTraceUtils.newAggregation;   
import   static  com.sun.btrace.BTraceUtils.newAggregationKey;   
import   static  com.sun.btrace.BTraceUtils.printAggregation;   
import   static  com.sun.btrace.BTraceUtils.println;   
import   static  com.sun.btrace.BTraceUtils.str;   
import   static  com.sun.btrace.BTraceUtils.strcat;   
  
import  java.lang.reflect.Field;   
import  java.util.concurrent.atomic.AtomicInteger;   
  
import  com.sun.btrace.BTraceUtils;   
import  com.sun.btrace.aggregation.Aggregation;   
import  com.sun.btrace.aggregation.AggregationFunction;   
import  com.sun.btrace.aggregation.AggregationKey;   
import  com.sun.btrace.annotations.BTrace;   
import  com.sun.btrace.annotations.Kind;   
import  com.sun.btrace.annotations.Location;   
import  com.sun.btrace.annotations.OnEvent;   
import  com.sun.btrace.annotations.OnMethod;   
import  com.sun.btrace.annotations.OnTimer;   
import  com.sun.btrace.annotations.Self;   
  
/**  
 * 并行加载监控  
 *   
 * @author jianghang 2011-4-7 下午10:59:53  
 */   
@BTrace   
public   class  AsyncLoadTracer {   
  
     private   static  AtomicInteger rejecctCount = BTraceUtils.newAtomicInteger( 0 );   
     private   static  Aggregation   histogram    = newAggregation(AggregationFunction.QUANTIZE);   
     private   static  Aggregation   average      = newAggregation(AggregationFunction.AVERAGE);   
     private   static  Aggregation   max          = newAggregation(AggregationFunction.MAXIMUM);   
     private   static  Aggregation   min          = newAggregation(AggregationFunction.MINIMUM);   
     private   static  Aggregation   sum          = newAggregation(AggregationFunction.SUM);   
     private   static  Aggregation   count        = newAggregation(AggregationFunction.COUNT);   
  
     @OnMethod (clazz =  "java.util.concurrent.ThreadPoolExecutor" , method =  "execute" , location =  @Location (value = Kind.ENTRY))   
     public   static   void  executeMonitor( @Self  Object self) {   
        Field poolSizeField = field( "java.util.concurrent.ThreadPoolExecutor" ,  "poolSize" );   
        Field largestPoolSizeField = field( "java.util.concurrent.ThreadPoolExecutor" ,  "largestPoolSize" );   
        Field workQueueField = field( "java.util.concurrent.ThreadPoolExecutor" ,  "workQueue" );   
  
        Field countField = field( "java.util.concurrent.ArrayBlockingQueue" ,  "count" );   
         int  poolSize = (Integer) get(poolSizeField, self);   
         int  largestPoolSize = (Integer) get(largestPoolSizeField, self);   
         int  queueSize = (Integer) get(countField, get(workQueueField, self));   
  
        println(strcat(strcat(strcat(strcat(strcat( "poolSize : " , str(poolSize)),  " largestPoolSize : " ),   
                                     str(largestPoolSize)),  " queueSize : " ), str(queueSize)));   
    }   
  
     @OnMethod (clazz =  "java.util.concurrent.ThreadPoolExecutor" , method =  "reject" , location =  @Location (value = Kind.ENTRY))   
     public   static   void  rejectMonitor( @Self  Object self) {   
        String name = str(self);   
         if  (BTraceUtils.startsWith(name,  "com.alibaba.pivot.common.asyncload.impl.pool.AsyncLoadThreadPool" )) {   
            BTraceUtils.incrementAndGet(rejecctCount);   
        }   
    }   
  
     @OnTimer ( 1000 )   
     public   static   void  rejectPrintln() {   
         int  reject = BTraceUtils.getAndSet(rejecctCount,  0 );   
        println(strcat( "reject count in 1000 msec: " , str(reject)));   
        AggregationKey key = newAggregationKey( "rejectCount" );   
        addToAggregation(histogram, key, reject);   
        addToAggregation(average, key, reject);   
        addToAggregation(max, key, reject);   
        addToAggregation(min, key, reject);   
        addToAggregation(sum, key, reject);   
        addToAggregation(count, key, reject);   
    }   
  
     @OnEvent   
     public   static   void  onEvent() {   
        BTraceUtils.truncateAggregation(histogram,  10 );   
        println( "---------------------------------------------" );   
        printAggregation( "Count" , count);   
        printAggregation( "Min" , min);   
        printAggregation( "Max" , max);   
        printAggregation( "Average" , average);   
        printAggregation( "Sum" , sum);   
        printAggregation( "Histogram" , histogram);   
        println( "---------------------------------------------" );   
    }   
}  
Java代码  
import static com.sun.btrace.BTraceUtils.addToAggregation;  
import static com.sun.btrace.BTraceUtils.field;  
import static com.sun.btrace.BTraceUtils.get;  
import static com.sun.btrace.BTraceUtils.newAggregation;  
import static com.sun.btrace.BTraceUtils.newAggregationKey;  
import static com.sun.btrace.BTraceUtils.printAggregation;  
import static com.sun.btrace.BTraceUtils.println;  
import static com.sun.btrace.BTraceUtils.str;  
import static com.sun.btrace.BTraceUtils.strcat;  
  
import java.lang.reflect.Field;  
import java.util.concurrent.atomic.AtomicInteger;  
  
import com.sun.btrace.BTraceUtils;  
import com.sun.btrace.aggregation.Aggregation;  
import com.sun.btrace.aggregation.AggregationFunction;  
import com.sun.btrace.aggregation.AggregationKey;  
import com.sun.btrace.annotations.BTrace;  
import com.sun.btrace.annotations.Kind;  
import com.sun.btrace.annotations.Location;  
import com.sun.btrace.annotations.OnEvent;  
import com.sun.btrace.annotations.OnMethod;  
import com.sun.btrace.annotations.OnTimer;  
import com.sun.btrace.annotations.Self;  
  
/** 
 * 并行加载监控 
 *  
 * @author jianghang 2011-4-7 下午10:59:53 
 */  
@BTrace  
public class AsyncLoadTracer {  
  
    private static AtomicInteger rejecctCount = BTraceUtils.newAtomicInteger(0);  
    private static Aggregation   histogram    = newAggregation(AggregationFunction.QUANTIZE);  
    private static Aggregation   average      = newAggregation(AggregationFunction.AVERAGE);  
    private static Aggregation   max          = newAggregation(AggregationFunction.MAXIMUM);  
    private static Aggregation   min          = newAggregation(AggregationFunction.MINIMUM);  
    private static Aggregation   sum          = newAggregation(AggregationFunction.SUM);  
    private static Aggregation   count        = newAggregation(AggregationFunction.COUNT);  
  
    @OnMethod(clazz = "java.util.concurrent.ThreadPoolExecutor", method = "execute", location = @Location(value = Kind.ENTRY))  
    public static void executeMonitor(@Self Object self) {  
        Field poolSizeField = field("java.util.concurrent.ThreadPoolExecutor", "poolSize");  
        Field largestPoolSizeField = field("java.util.concurrent.ThreadPoolExecutor", "largestPoolSize");  
        Field workQueueField = field("java.util.concurrent.ThreadPoolExecutor", "workQueue");  
  
        Field countField = field("java.util.concurrent.ArrayBlockingQueue", "count");  
        int poolSize = (Integer) get(poolSizeField, self);  
        int largestPoolSize = (Integer) get(largestPoolSizeField, self);  
        int queueSize = (Integer) get(countField, get(workQueueField, self));  
  
        println(strcat(strcat(strcat(strcat(strcat("poolSize : ", str(poolSize)), " largestPoolSize : "),  
                                     str(largestPoolSize)), " queueSize : "), str(queueSize)));  
    }  
  
    @OnMethod(clazz = "java.util.concurrent.ThreadPoolExecutor", method = "reject", location = @Location(value = Kind.ENTRY))  
    public static void rejectMonitor(@Self Object self) {  
        String name = str(self);  
        if (BTraceUtils.startsWith(name, "com.alibaba.pivot.common.asyncload.impl.pool.AsyncLoadThreadPool")) {  
            BTraceUtils.incrementAndGet(rejecctCount);  
        }  
    }  
  
    @OnTimer(1000)  
    public static void rejectPrintln() {  
        int reject = BTraceUtils.getAndSet(rejecctCount, 0);  
        println(strcat("reject count in 1000 msec: ", str(reject)));  
        AggregationKey key = newAggregationKey("rejectCount");  
        addToAggregation(histogram, key, reject);  
        addToAggregation(average, key, reject);  
        addToAggregation(max, key, reject);  
        addToAggregation(min, key, reject);  
        addToAggregation(sum, key, reject);  
        addToAggregation(count, key, reject);  
    }  
  
    @OnEvent  
    public static void onEvent() {  
        BTraceUtils.truncateAggregation(histogram, 10);  
        println("---------------------------------------------");  
        printAggregation("Count", count);  
        printAggregation("Min", min);  
        printAggregation("Max", max);  
        printAggregation("Average", average);  
        printAggregation("Sum", sum);  
        printAggregation("Histogram", histogram);  
        println("---------------------------------------------");  
    }  
}  
 
运行结果：
 
Java代码   
poolSize :  1  , largestPoolSize =  10  , queueSize =  10   
reject count in  1000  msec:  0   
Java代码  
poolSize : 1 , largestPoolSize = 10 , queueSize = 10  
reject count in 1000 msec: 0  
 
说明：
1. poolSize 代表为当前的线程数
2. largestPoolSize 代表为历史最大的线程数
3. queueSize 代表blockqueue的当前堆积的size
4. reject count 代表在1000ms内的被reject的数量
 
 
 
 
1.ThreadPoolExecutor 
Spring中的ThreadPoolTaskExecutor是借助于JDK并发包中的java.util.concurrent.ThreadPoolExecutor来实现的.下面先学习下ThreadPoolExecutor中的相关信息.ThreadPoolExecutor构造函数如下: 
Java代码   
public  ThreadPoolExecutor( int  corePoolSize,   
                           int  maximumPoolSize,   
                           long  keepAliveTime,   
                          TimeUnit unit,   
                          BlockingQueue<Runnable> workQueue,   
                          ThreadFactory threadFactory,   
                          RejectedExecutionHandler handler) {   
Java代码  
public ThreadPoolExecutor(int corePoolSize,  
                          int maximumPoolSize,  
                          long keepAliveTime,  
                          TimeUnit unit,  
                          BlockingQueue<Runnable> workQueue,  
                          ThreadFactory threadFactory,  
                          RejectedExecutionHandler handler) {  


下面分别说下各项代表的具体意义: 

int corePoolSize:线程池维护线程的最小数量. 
int maximumPoolSize:线程池维护线程的最大数量. 
long keepAliveTime:空闲线程的存活时间. 
TimeUnit unit: 时间单位,现有纳秒,微秒,毫秒,秒枚举值. 
BlockingQueue<Runnable> workQueue:持有等待执行的任务队列. 
RejectedExecutionHandler handler: 
用来拒绝一个任务的执行，有两种情况会发生这种情况。 
一是在execute方法中若addIfUnderMaximumPoolSize(command)为false，即线程池已经饱和； 
二是在execute方法中, 发现runState!=RUNNING || poolSize == 0,即已经shutdown,就调用ensureQueuedTaskHandled(Runnable command)，在该方法中有可能调用reject。 

Reject策略预定义有四种： 
(1)ThreadPoolExecutor.AbortPolicy策略，是默认的策略,处理程序遭到拒绝将抛出运行时 RejectedExecutionException。 
(2)ThreadPoolExecutor.CallerRunsPolicy策略 ,调用者的线程会执行该任务,如果执行器已关闭,则丢弃. 
(3)ThreadPoolExecutor.DiscardPolicy策略，不能执行的任务将被丢弃. 
(4)ThreadPoolExecutor.DiscardOldestPolicy策略，如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程）. 


2. Spring中ThreadPoolTaskExecutor的使用 
最常用方式就是做为BEAN注入到容器中,如下代码:
Java代码   
<bean id= "threadPoolTaskExecutor"   
     class = "org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor" >   
    <property name= "corePoolSize"  value= "10"  />   
    <property name= "maxPoolSize"  value= "15"  />   
    <property name= "queueCapacity"  value= "1000"  />   
</bean>  
Java代码  
<bean id="threadPoolTaskExecutor"  
    class="org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor">  
    <property name="corePoolSize" value="10" />  
    <property name="maxPoolSize" value="15" />  
    <property name="queueCapacity" value="1000" />  
</bean>  

           
ThreadPoolExecutor执行器的处理流程: 
(1)当线程池大小小于corePoolSize就新建线程，并处理请求. 
(2)当线程池大小等于corePoolSize，把请求放入workQueue中，池子里的空闲线程就去从workQueue中取任务并处理. 
(3)当workQueue放不下新入的任务时，新建线程加入线程池，并处理请求，如果池子大小撑到了maximumPoolSize就用RejectedExecutionHandler来做拒绝处理. 
(4)另外，当线程池的线程数大于corePoolSize的时候，多余的线程会等待keepAliveTime长的时间，如果无请求可处理就自行销毁. 


了解清楚了ThreadPoolExecutor的执行流程,开头提到的org.springframework.core.task.TaskRejectedException异常也就好理解和解决了.ThreadPoolTaskExecutor类中使用的 
就是ThreadPoolExecutor.AbortPolicy()策略,直接抛出异常. 
 
 
分享到：    
Sping3+CXF Web应用 | ThreadLocal-分析-总结
2011-12-17 22:43浏览 1448评论(0)分类:编程语言相关推荐
评论
发表评论
  您还没有登录,请您登录后再发表评论

温柔的羊
浏览: 132099 次
性别: 
来自: 北京

最近访客 更多访客>>
wanghaoalaindylinshi126yangfuchao418紫_色
文章分类
全部博客 (251)
WebService (17)
IBatis (22)
Hibernate (1)
SpringMVC - 基础篇 (32)
Spring (15)
Java (11)
JVM及调优 - 基础篇 (4)
集群 (14)
数据库 (17)
WebSphere (5)
多线程 (4)
集合、容器 (2)
DB Pool (1)
Power Designer (5)
Maven基础 (5)
JS (14)
WEB 前端 (5)
实用小工具 (17)
社会、人 (2)
乱七八糟 (18)
ASM&CGLIB - 基础篇 (12)
缓存 (1)
性能 (1)
设计之殇 (1)
分布式事务 (1)
单点登录 (11)
分布式 Session (4)
Memcached - 基础篇 (6)
社区版块
我的资讯 (0)
我的论坛 (6)
我的问答 (0)
存档分类
2013-09 (4)
2013-08 (10)
2013-07 (11)
更多存档...
最新评论
宋建勇： ...
SpringMVC拦截器简单使用
软件天皇： : 0    [b]  400 Bad Request  : ...
WebService CXF SOAP基本结构
tanghanlin： 你这个自己测试过吗？我设置后还是无效
SpringMVC 异常处理初探
crise： 问题已经解决，我改了wcf的返回方式，不用string来返回， ...
Ajax跨域访问解决方案
crise： 温柔的羊 写道crise 写道crise 写道您好！ 分析非常 ...
Ajax跨域访问解决方案
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== http://www.howsky.net/index.php/archives/4490 ==========
昊天软件
蒋智昊的博客

主菜单
跳至主内容区域
跳至副内容区域
首页
关于
有点尴尬诶。
我们可能无法找到您需要的内容。或许下面的链接和搜索功能可以帮到您。

搜索 
近期文章

女儿出生了
启动买车计划准备试驾
结合管理者必备五种观念反思自己
年会我很小的一个镜头
协同管理平台完成工作流及表单开发
将ping命令结果保存到txt文本文件
我们聚餐在喜来登温泉度假酒店
软件项目实施步骤总结
协同管理平台自定义首页新增网上调查
忙碌的一年结束了
常用分类目录

信息技术 (19)
心情随笔 (7)
文章归档

试试在月度归档中寻找。 


标签

RSSFeed Login 
Copyright 2012 HowSky.org All Rights Reserved.
========== http://rdc.taobao.com/team/jm/ ==========
淘宝网综合业务平台团队博客 致力于成为中国最强大的JAVA技术团队
跳转到内容
首页
关于我们
招聘
淘宝中间件团队新版博客上线
日期：2013-05-27 作者：jm
hi，
各位读者。
感谢你一如既往的支持淘宝中间件团队，支持技术分享。

很高兴的告诉你，我们的新版博客正式上线了。前往访问：http://jm.taobao.org 。从今天开始，新文章的分享和对读者评论的处理，我们都将移步新站点。

博客地址变了，但是我们对技术分享的热情却始终没有变化。同时也希望你能一直关注，支持我们。

淘宝中间件团队

2013-05-27

分类：团队活动和event	 | 标签：博客	 | 发表评论
综合业务部-中间件平台-产品黄页
日期：2012-12-19 作者：jm
(一) 数据层产品
——TL沈询

1) TDDL/Cobar/malanda/TDDLSequence
分布式数据层 对应cobar
特性是无server. 多层结构

支持直接简单主备Mysql 直连。
也支持分库分表。
还有sequence 。 都是这套组件上的东东啦。

相关文档:http://baike.corp.taobao.com/index.php/TDDL
TL：沈询
主要联系人：君瑜 捷辰 雷文 齐昊
ata : http://www.alibabatech.org/gprofile/480

2) 精卫/erosa/eromonga
数据分发总线，需要接oracle / mysql / hbase 找我们就行了。

主要联系人: 齐昊 朔海 雷文

相关文档:http://baike.corp.taobao.com/index.php/TDDL_mysql_replicator
ata : http://www.alibabatech.org/gprofile/480

3) 愚公
数据扩容缩容、去o迁移等事项。

主要联系人 ：捷辰 雷文 君瑜
相关文档:http://baike.corp.taobao.com/index.php/YuGong
ata : http://www.alibabatech.org/gprofile/480

(二) 服务框架产品
——TL 玄宵
1) HSF
远程方式的服务调用，支持tcp，webservice，c++，php等远程方式调用，支持基于接口，方法，参数的路由规则，限流规则，归组，虚机房等软负载规则

支持：玄宵 空冥，思邪
旺旺：741409765
密码：taobao1234
邮件： taobao-rd-jm-sf@list.alibaba-inc.com
2) Dubbo
远程方式的服务调用，功能支持tcp，http，webservice，thrift等方式，支持多注册中心，多序列化协议等
支持：玄宵 草谷
旺旺：94735824
密码：dubbo1234
邮件：taobao-rd-jm-sf@list.alibaba-inc.com

3) 分布式日志跟踪系统（eagleeye）
基于分布式服务框架基础上实现的“分布式跟踪系统”，提供所有tcp调用链跟踪，分析及监控 系统rpc服务依赖，性能调优，风险控制等

主要联系人：姬风，神锋
邮件地址：taobao-rd-jm-sf@list.alibaba-inc.com
(三) 软负载配置中心产品
——TL九任

1) ConfigServer 非持久数据的配置中心：
支持数据聚合，数据生命周期和连接挂钩，无master集群，Server主动推送。场景如HSF软负载中心，搜索qp软负载
主要联系人：玄胤，九任
邮件地址 taobao-rd-jm-cs@ali.com

2) Diamond 持久数据配置中心：
数据持久保存，支持数据聚合， Client主动拉,保存各种业务配置，比如tbsession配置，Notify订阅关系等

主要联系人：九任，曼红
邮件地址 taobao-rd-jm-cs@ali.com

3) Normandy
持久数据配置中心，把打包配置项放在Normandy，目前该产品的功能会往diamond上迁
主要联系人：九任，曼红

(四) 消息中间产品
——TL 韩彰

1) Notify
notify，适用于事务型消息，高可靠，支持复杂过滤，消息持久化，采用server推送给消费者，支持一对多订阅，不保证消息顺序，不保证消息重投，不支持消息优先级，不适合于大规模堆积在server端，目前有mysql存储和file存储两种方式；目前应用于淘宝交易，商品等需要异步消息的几百个系统，目前每天发布20亿的消息量，订阅量在100亿

主要联系人：水寒，文诏，文婷
旺旺支持群：notify答疑，消息中间件交流群
Ata地址：http://www.alibabatech.org/MQ
邮件地址：淘宝-中间件&稳定性平台-消息中间件

2) MetaQ
MetaQ适用于需要支持顺序消息，需要大量堆积，支持组播，支持一定的过滤能力，采用客户端consumer主动拉取的方式，支持一对多订阅，不保证消息重投，不支持事务，不支持优先级，目前采用file存储方式；目前应用于淘宝上顺序消息，组播，大量消息等一系列场景，目前每天发布10亿左右的消息量
主要联系人：誓嘉，兰生，平威
旺旺支持群：meta答疑，消息中间件交流群
Ata地址：http://www.alibabatech.org/MQ
邮件地址：淘宝-Java中间件-Meta

3) MPP
MPP，面向用户的消息推送系统，支持向浏览器用户推送消息，向手机用户推送消息，支持一对一推送，一对多推送，根据地域推送等等，适合大规模在线用户支持，目前部署在了淘宝，天猫和一淘，共400多万同时在线用户，支持了拍卖，etao消息中心，淘宝sns及手机无线等消息推送

主要联系人：韩林
旺旺支持群：mpp交流
Ata地址：http://www.alibabatech.org/gprofile/182

分类：未分类	 | 发表评论
天心阁吉他神秘人专访
日期：2012-12-19 作者：zhongting
引言：

坊间传闻，每天中午时候，创业大厦10楼的会议室（天心阁）内都会准时响起吉他的声音，风格飘逸，曲风多变，令人神往。为了探知这个神秘人是谁，Vi展开了自己的调查，层层之后，终于发现…

九章和他的音乐生活

大家好，我是Vi，是淘宝综合业务平台部门的一员。千万别问我为啥叫Vi，就像你永远不知道Pi为什么叫Pi一样。受人委托，我负责调查创业10楼神秘吉他声事件。经过我的努力，终于发现了这个人的真实身份，他就是淘宝网综合业务平台中间件团队的技术专家-九章，并且对他做了一次采访，如下：

Vi：九章，终于找到你了，想大家介绍一下你自己吧！

九章：怎么说呢，我就一个普通得不能再普通的技术男，扔在大街上瞬间湮没的那种。现在主要负责淘桌面系列产品的设计及开发，已上线的产品有“淘桌面（演示版）”及“开发者桌面”，目前正全力以赴新旺铺应用中心（卖家桌面）系统的测试及上线。该WebOS系列产品基于我此前的开源框架ToyBricks，希望大家多关注她！

Vi：哈哈，太谦虚了。看你就是个有生活的人。怎么样，谈谈你的爱好吧~

九章：这么多年来，我爱过太多的事物：画画、文学、哲学、电子、武术、音乐，到今天只有音乐坚持下来了。最初是玩笛子，那会真是痴迷，每天早晨天不亮起床去山上练习，泰安的冬天很冷，手指都僵掉了，可老师说：天气越冷越练功夫。也没想太多，就坚持下来了。后来开始转玩吉他，转变的主要原因有两个。一个是笛子声音穿透力太强、容易影响到邻居。另外一个是现代音乐大多数在西方，和声性乐器的表现力比较强。咬咬牙，放下笛子开始练吉他。

Vi：真心果断啊，在学吉他的过程中一定遇到了一些困难吧？

九章： 开始的时候很开心，一直沉浸在追求指法技巧的乐趣中，神马轮指、轮扫、三连泛音都统统拿下。可是慢慢的我觉得不对劲，觉得盲目追求技巧不应该是我学习音乐的目的。为此我迷茫，困惑了很久。最后，我终于想明白了，我学音乐的目的其实就是音乐本身。我要的是像写作时那种创世的快乐，那种感觉就像上帝，设计各个角色、然后让他们爱恨交织各种纠结。于是乎我转向了民谣及电吉他，学习各种音乐风格，用大量的时间练吉他基本功及即兴演奏，心态也平和下来了，现在也是按照这个思路进行着。

Vi: 我觉得这和写代码也有些像，与其追求各种框架，不如先苦练内功。听说你参加了一个乐队？

九章：嗯，我一直都想玩乐队，就是没有机会。来淘宝后，遇到了铁锤、玉郎、元赛几个人。他们本来有一个乐队，但后来乐队的吉他手离职了。所以有一天铁锤找到我，说想不想一块玩？我当然想，于是就一起玩，排练了两首感觉还不错，于是就成为了乐队的一员，主要负责乐队的主音和节奏。

Vi: 玩音乐会很耗时间，淘宝这边工作很忙，你是怎么处理工作和业余爱好的关系呢？

九章：说到工作与业余爱好的关系，要协调好确实要花点心思的，我就是因为回家懒得练琴才把吉他带到公司里来，“强迫”自己在中午休息的时间练习，有时候打扰了靠近几个会议室的同学了，不好意思了。我虽然算不上很用功（之前乐队的主音吉他陈睿据说每天练琴3小时以上），不过还是很用心的，比如最近我在思考我怎么走出目前即兴的套路窠臼，怎么能弹得再“华丽”一点，怎么用7、9和弦来美化solo等。除此之外，我一直在做的一件事情（我称之为 “打通各种任督二脉”）。从音乐上来讲，一段好听的旋律应该是疏密相间、张弛有道的，一个优雅的架构、甚至说一个Class的代码结构也是符合这种美学原则的，万物复杂（数量累积）到一定程度必然呈现出“有序”的结构，起码软件是这样的，那么音乐肯定也是这样，我曾经从这个角度来理解乐理，其实说白了就是如果超越了“术”，在“道”这个层面上万物的理论都差不多，这时候好玩的东西就衍生出来了。

Vi：不只是音乐和编程，很多看起来复杂，甚至大相径庭的事物，究其本质往往都是一个非常简单的道理。九章你不只看起来文艺，你真是个文艺青年啊。哈哈。最后给你留个时间打个广告，有什么要和大家说的没？

九章：我个人给综合业务平台的兄弟姐妹们的一个建议就是：去找到一样你喜欢的爱好吧，啥都行，但是一定要好玩，而且是持续的好玩，重要的是你一定要坚持下去（很多事情都是满足一万小时定律的），区分好爱好与工作的关系，慢慢你会发现，你得到的回报要远远的超出你的投入。其实，我们团队藏龙卧虎，“爱弹玻璃球”的同学很多，比如明风的摄影、聚石的太极、决尘的古典吉他、雷文的唱歌、应辉的书法、银时等人的桌上足球等，都是名声在外的。我综合业务平台部门何等人才济济！待在这个部门，让我觉得相当的爽。

Vi：大家都很爽，哈哈。多谢九章。

Vi：最后，咱综合业务平台藏龙卧虎，希望大家不要吝惜展现自己的才华的机会，多多投稿，多多推荐身边的牛人。被点名的几位弟兄，你们准备好了吗？Vi会去找你们的，嘿嘿~

分类：团队活动和event	 | 标签：itech, 团队生活	 | 发表评论
业界动态
日期：2012-12-19 作者：jm
1.软件开发工程师最重要的4项技能：不是某种技术，而是解决问题、自我学习、命名能力、与人合作。
http://java.dzone.com/articles/4-most-important-skills
2.最长递增子序列算法：
http://architects.dzone.com/articles/algorithm-week-longest?mz=36885-nosql
3.增加安卓开发工具和一些遗留bug修复
4.Spring for Android 1.0.1 发布，简化安卓app的开发
5.Spring Tool Suite and Groovy Tool Suite 3.2.0.M1 发布
6.MObile SCRipting Framework 跨平台的移动开发框架，只需要开发一个程序，就可以实现各种移动平台的运行
http://www.infoq.com/articles/Moscrif
7.Linux Kernel 3.7 正式发布

分类：未分类	 | 发表评论
关于大区间过滤优化内存设计
日期：2012-12-10 作者：hongzhen
主要对一般docId为下标对应域值的结构做了改造，如果大家有更好的建议，欢迎大家提议和拍砖。

主要思路：

生成一个下标为
域 Term 遍历的Postion 且值为域值的数组:

A[p]=field value 

因为域值并不会像docId一样为唯一键递增，所以在创建的时候

初始化:

Int [] A = new Int[reader.maxDoc()]

结束的时候如果 p<A.length(因为肯定有多个DocId对应相同域值)

则释放那些空闲空间


整个内存使用率取决于该值的重复率，重复越多则内存越节省，从我们接入绝大多数业务的类型需要进行大区间过滤的使用场景看都是最近几年的时间类型，类似于20101202，所以这样的数据重复率还是很高的。

 

第二个Int数组是以DocId为数组下标，域的遍历Postion为值的数组列表。


这样做的好处是将原来如果域为Long型的数组转变成了Int数组，节省了一倍的内存开销。

另外这里不是一次性初始化开辟reader.maxDoc()大小的数组，而是通过懒加载逐步将这个数组列表填满。

实现方式：

数组个数：N = reader.maxDoc()/K （K为可配置大小，主要是将一个大数组分隔成多个小数组的关键因子，设置的小理论上会更节省内存），如下所示：


每次查询例如 l_t:[ 20101202 TO 20111202]，查询这个区间内的DocId分布在那几个数组内，然后将DocId减去归属第N个数组的起始偏移量做为数组下标，域值的遍历Postion做为值填充数组。

如果下一个区间查询
例如是l_t:[20091202 TO 20101203],如果恰巧归属的数组已经创建过了，那么只需要填充20091202 To 20101201的归属数组，否则创建数组列表中还没有创建过的数组，并填充相应域的遍历Postion值。

接下来的查询如果是在已填充的区间内的区间查询则不需要再填充，其他查询情况以此类推。

最坏情况是查询条件导致这个数组列表的所有数组全部生成并填充完毕。

大小为Int[maxDoc]。

查询过滤：

根据查询区间的最小值和最大值，查询出2值对应Term遍历的postion值, Low=minPostion,

High=maxPostion

在根据query后得到的docList 进行过滤，通过docId 定位到数组列表的对应数组单元的域值Term 的postion 值，如果满足
minPostion<=currentPostion<=maxPostion则代表满足区间。（因为sortable的域在构建索引已经是按照大小排序好存储）


将获取到的pn 跟之前的minPostion和maxPostion比较，发现只有p2<p3<p5,那么满足条件的doc 有doc3,doc4,doc5,doc7,doc8 doc9，其他的将其过滤。

最后附上获取域Term的postion代码

Java代码
 TermDocs termDocs = reader.termDocs();  
      TermEnum termEnum = reader.terms (new Term (field));  
      long[] mterms = new long [reader.maxDoc()];  
  
try {  
        do {  
          Term term = termEnum.term();  
          if (term==null || term.field() != field || t >= mterms.length) break;  
  
          // store term text  
          mterms[p] = NumberUtils  
                                .SortableStr2long(term.text());  
  
          termDocs.seek (termEnum);  
          while (termDocs.next()) {  
            retArray(termDocs.doc(),p);//填充以(docId-offset)为下标，postion为值的数组列表。  
          }  
  
          p++;  
        } while (termEnum.next());  
      } finally {  
        termDocs.close();  
        termEnum.close();  
      }  
  
if (p < mterms.length) {  
        // //terms 在docment中有大量重复,那么p肯定远小于maxdoc,那么截断多余出来的内存空间  
        long [] terms = new long [p];  
        System.arraycopy (mterms, 0, terms, 0, p);  
        mterms = terms;  
      }  
分类：未分类	 | 发表评论
SolrCore2.9.1源码分析备忘
日期：2012-12-10 作者：yingyuan
Solr2.9.1 
代码 下面的分析有点散，围绕solrcore展开，重点是query流程，细入是getSearcher


内容中有一些直接从参考链接里面拷贝的。

【1】SolrCore功能点

   
0.JMX的初始化—》远程监控使用
进入参考链接http://lucidworks.lucidimagination.com/display/solr/Using+JMX+with+Solr
默认情况下不会起到JMX

   
1.初始化加载solrconfig.xml 
配置信息—-》整个检索层的配置

2.updatehandler  –》写索引，关联的updateProcessorchains，内部重新打开索引writer。

Commit的时候会getSearcher从而打开新的reader视图，solrIndexSearcher之后就可见。

3 SolrIndexSearcher—》查询索引的入口，关联  
查询解析的QquerParse、高亮、searchComponent、【读reader共享、写需要同步reader，SolrIndexSearch打开的都是readonlyreader
线程安全并且单例，提升性能】

4 
事件支持：firstSearcherListeners、newSearcherListeners
这里可以作为扩展自己的reader服务的入口

5. 
查询返回的responseWriter

   
6 
前提准备索位置Directory、索引reader的readerfactory 
，间接关联reader管理，

7 
索引的删除策略加载


【2】execute分析


在SolrCore中有两个execute方法：

    1.
execute(SolrQueryRequest req, SolrQueryResponse rsp)

   
2.execute(SolrRequestHandler handler, SolrQueryRequest req,
SolrQueryResponse rsp)


对于第一个方法，没有像第二个方法那样的handler参数，但是其实其内部通过这样一个方法来获得handler 
的：SolrRequestHandler
handler = getRequestHandler(req.getQueryType())。也就是说我们通过在req中指定qt参数的值就可以获得我们想要的处理

器，当然这些处理器需要在solrconfig.xml的

requestHandler元素中定义（配置文件中有大量requestHandler）。这样服务器在建立时才能建立相应的处理器实例。

  这里我发现在获取处理器时，参数为“”，null还是standard都能得到StandardRequestHandler的实例

SolrCore::execute的流程

   1.进行handler合法性的检查，不能为null，否则抛出错误。

2.final NamedListresponseHeader = new
SimpleOrderedMap()；

      
rsp.add(“responseHeader”, responseHeader);

      

建立一个单序映射表并将其作为响应头加入到rsp中。

3.NamedList toLog = rsp.getToLog();

 获得rsp的ToLog对象，并从请求中获得一些相关信息加入，这些信息有webapp,path,params。

4.handler.handleRequest(req,rsp);

5.StringBuilder sb = new
StringBuilder();….

  
从rsp的ToLog中获得信息并将其加入到sb中，然后在日志中输出。


分析了SolrCore中的execute方法的流程，而且可以看到具体执行查询过程的语句是:handler.handleRequest(req,rsp)。请注意查询时候，这里的变量的类型是：

handler：StandardRequestHandler

req:SolrRequestParsers类中的一个匿名类。

rsp:SolrQueryResponse

 query调用流

StandardRequestHandler extends
SearchHandler，solrcore::execute.handler.handlerRequest(),


转为solrcore::execute.StandardRequestHandler.handlerRequest


转为SearchHandler.handlerRequest() 
而SearchHandler extends
RequestHandlerBase


转为RequestHandlerBase.handlerRequest() 
真正执行handlerRequest()


在RequestHandlerBase.handlerRequest()中

设置httpcaching、handleRequestBody(),


抽象的handlerRequestBody()在子类SearchHandler中实现了，


转回SearchHandler.handlerRequestBody(),其中对QueryComponent 
执行prepare、process


在prepare中生成QParser，注意只有queryComponent中生成了Qparser，其他的没有生成。并且Qparser 
是从static的getParser() 
中拿到，而Qparser.getParser()中又是从SolrCore.getQueryPlugin() 
通过solrconfig.xml中配置获取。

SolrCore 中 Searcher
Control部分有点复杂

—-getSearcher的逻辑

getSearcher – (forceNew,
returnSearcher, waitSearcher-Futures)


关注solr全局三个点调用getSearcher函数
: solrCore初始化时(false, false, null)，QueryComponent处理查询请求时(false, true, null)，UpdateHandler在处理commit请求时(true, false, new Future[1])


外部调用

EmbededSolrServer.request–>在执行core.execute() 
之前，从core中getRequestHandler，_parser中buildRequestFrom(), new SolrQueryResponse()

返回SolrQueryRequestBase，

SolrQueryRequestBase
中
protected RefCounted searcherHolder;

  publicSolrIndexSearcher getSearcher()
{

   
if(core == null) return null;//a request for a core admin
will no have a core

   
// should this reach out and get a
searcher from the core singleton, or

   
// should the core populate one in a
factory method to create requests?

   
// or there could be a setSearcher()
method that Solr calls

   
if(searcherHolder==null) {

     
searcherHolder= core.getSearcher();

   
}

   
returnsearcherHolder.get();

  }
 
 public void close() {

   
if(searcherHolder!=null) {

     
searcherHolder.decref();

     
searcherHolder= null;

   
}

  }
当调用SolrQueryRequestBase的getSearcher()时，如果是第一次调用，会转而调用core.getSearcher()，
其会使得到的searcherHolder的引用计数增一。而对称的，SolrQueryRequestBase的close()方法使 searcherHolder的引用计数减一，一增一减平衡了。
这也使得当新的索引到来时，仍旧提供查询服务的SolrIndexSearcher不会立 即关闭，直到其引用计数减为0才关闭。所以，在使用SolrQueryRequest时，要确保请求的最后调用其close方法，否则那些无用的 SolrIndexSearcher就不会被释放，直到句柄耗尽或者OOM掉。
 

引用对象

引用对象的典型使用是SolrCore，看下相关代码：

private final AtomicInteger refCount = new AtomicInteger(1);
 
  final void open() {
    refCount.incrementAndGet();
  }
  public void close() {
    int count = refCount.decrementAndGet();
    if (count > 0) return; // close is called often, and only actually closes if nothing is using it.
    if (count <</span> 0) {
      log.error("Too many close [count:{}] on {}. Please report this exception to solr-user@lucene.apache.org", count, this );
      return;
    }
    //释放对象和资源
  }
引用计数就是refCount了。SolrCore实例的获得是通过调用CoreContainer的 SolrCore getCore(String name)得到，其实现是：

public SolrCore getCore(String name) {
    synchronized(cores) {
      SolrCore core = cores.get(name);
      if (core != null)
        core.open();  // increment the ref count while still synchronized
      return core;
    }
  }
也就是说CoreContainer显示的open了SolrCore，所以在得到SolrCore实例后，也需要显示的close它。因为 SolrQueryRequestBase用到了SolrCore，所以在处理请求的最后，要确保调用了SolrCore的close方法。当然，对于查 询端，SolrCore实例在整个生命周期内通常并不会真正被close，除非显示的调用了reload等操作。

下一篇 SolrCore getSearcher


参考链接

http://www.cnblogs.com/mandela/archive/2011/05/10/2041754.html

http://www.kafka0102.com/2010/11/401.html

分类：未分类	 | 1 条评论
solr长文本搜索问题
日期：2012-12-10 作者：yingyuan

多关键词搜索排序质量一直一个疼痛的问题，已经频繁遇到，目前还没来得及系统解决。


针对之前的解决经验，做一个小节，后面可能随着对排序质量的提高，会越来越突出。


请大家拍砖和丰富这方面的经验，提升解决需求的效率。


分析


当前默认都是phrasequery执行，对指定域先分词，然后按照短语去查询，当出现分词交叉后，结果就悲剧了。


当非自动生成phrasequery时候，指定域也会分词，然后按照
AND 
或者 OR

拼接起来去查，此时，短语的关联性丢失，挨在一起的可能没有排在前面，尽管有结果。


当不自动生成phrasequery时候，\”  \” 
将查询出当做整体，此时依然会分词，只是查询时分词后的拼接去查。例如 “交易成功” 
转为 “交易

成功”


当扩展查询串去查，可能结果来自扩展串，有结果但不一定就是期望。


改为 
建索引最多分词、查询最长匹配，能解压一部分场景需求，对于精准查询的短语、长文本尤其效果好，对于追求结果最多不适应。


或者 
业务执行分词然后按照业务需求执行坡度或者相关性激励来调整相关性。例如 (交易

成功)~12 And

交易^10

成功^2

 


总结：


新业务依赖长文本查询的，需要daily仔细测试，对多关键词的抽样测试不可少。

    

新的对精准匹配要求高的检验使用IK分词，分别配置建索引和查询的分词模式。

    
DismaxQueryparse 
能有效的减少查询IO和“去重“，完全可以替代
OR 
扩展查询，目前发现一个不友好，例如 
“成功页面 
交易成功”，这个串中“成功”分量非常大，导致


结果排序有点糟糕。

    
Dismaqueryparse覆盖lucenequeryparse全部功能，同时提供更丰富的查询相关性设置, 
分词内部关系式OR

，一定能保证有结果，


配饰使用方法，在solrconfig.xml  requesthandler

中配置 edismax

Phrasequery 
不启用，一种方法是schema
verison定义为1.4就可以了，另外是
fieldtype中显示定义不生成，同时solrconfig中配置lucene 
版本34


问题背景


使用paoding分词，默认AND 
，autogeneralPhrasequery
= true


搜“交易成功 
幻灯片” 
没有结果       –》AND之后幻灯片部分没有结果导致没有结果


搜“交易成功” 
有结果 


搜“幻灯片” 
没有结果—-》原因是分词交叉

 


使用paoding分词，autogeneralPhrasequery = false


搜“交易成功 
幻灯片” 
有结果        

结果来自交易成功部分


搜“交易成功”        有结果


搜“幻灯片”          没有结果      

交叉依然没有结果

 


使用paoding分词，autogeneralPhrasequery = false  扩展OR


搜“交易成功 
幻灯片” 
扩展为 
“交易成功 
幻灯片” OR  \“交易成功

幻灯片\”    有结果，结果排序严重受关键词、索引影响


搜“交易成功”        扩展为“交易成功”
OR   \“

交易成功\”   有结果
  多余IO出现了


搜“幻灯片”          扩展为“幻灯片”
  OR
 \“

幻灯片\”   有结果  

结果排序与期望相差很远，排在一起的没在前面

 

分类：未分类	 | 发表评论
Apache MINA (3) NioSocketAcceptor初始化
日期：2012-12-10 作者：chiyan
上一篇博客Apache MINA (2) Hello World! 以一个例子实现了mina客户端和服务端的通讯，现在通过源码来了解建立连接和通讯的过程（基于tcp/ip的实现）。

服务端通过创建一个NioSocketAcceptor来接受请求，客户端通过创建NioSocketConnector来连接服务端并发送请求，从整体的体系结构来看二者的关系。

IoService是对于服务器端接受连接和客户端发起连接两类行为的一个抽象。IoServer用来执行真正的 I/O 操作，以及管理 I/O 会话。两个子接口为IoAcceptor和IoConnector。IoAcceptor用来接受连接，与客户端进行通讯。IoConnector用来发起连接，与服务端进行通讯。IoAcceptor和IoConnector都分别有基于TCP/IP协议协议，UDP/IP协议以及虚拟机管道通讯的子接口。Hello World例子里面实现的是基于TCP/IP协议的通讯，用了mina默认的实现类NioSocketAcceptor和NioSocketConnector。

首先从服务端的NioSocketAcceptor开始：

1. NioSocketAcceptor的父类为AbstractPollingIoAcceptor，很多实现是在父类中实现的。在构造此类的时候，同时也构造了NioProcessor类

NioSocketAcceptor
Java代码
public NioSocketAcceptor() {  
        super(new DefaultSocketSessionConfig(), NioProcessor.class);  
        ((DefaultSocketSessionConfig) getSessionConfig()).init(  
}
AbstractPollingIoAcceptor

Java代码
protected AbstractPollingIoAcceptor(IoSessionConfig sessionConfig,  
            Class<? extends IoProcessor<S>> processorClass) {  
        this(sessionConfig, null, new SimpleIoProcessorPool<S>(processorClass),  
                true);  
}  
SimpleIoProcessorPool

Java代码
private static final int DEFAULT_SIZE = Runtime.getRuntime().availableProcessors() + 1;  
……  
public SimpleIoProcessorPool(Class<? extends IoProcessor<S>> processorType) {  
        this(processorType, null, DEFAULT_SIZE);  
}
初始化NioProcessor，个数为cpu个数+1，为每个IoProcessor初始化一个默认的Excutor

this.executor = Executors.newCachedThreadPool();

初始化cpu+1个放到private final IoProcessor<S>[] pool 中，用来处理NioSession，所以S为NioSession

Java代码
public final class NioProcessor extends AbstractPollingIoProcessor<NioSession>…
2. 初始化完SimpleIoProcessorPool，回到AbstractPollingIoAcceptor的构造方法中,调用NioSocketAcceptor中的init()方法打开selector通道，完成NioSocketAcceptor的构造。

3. 然后在上一篇Hello World的例子中设置了SocketSessionConfig的readBufferSize；

接收数据的过滤器，例子中设置的是TextLineCodecFactory（按照行一行为一个单位读取数据）；

实现IoHandlerAdapter来处理客户的请求。

4. 最后执行acceptor.bind(new InetSocketAddress(SERVER_PORT))，指定服务提供绑定的端口，同时执行AbstractPollingIoAcceptor中的bindInternal方法,

调用startupAcceptor()负责初始化内部线程类Acceptor，Acceptor主要负责轮询处理注册过连接事件的请求建立起连接，即整个监听的主线程，Acceptor会开一个Selector，用来监听NIO中的ACCEPT事件，调用NioSocketAcceptor中的open()方法来打开NIO的socketChinal
Java代码
……  
ServerSocketChannel channel = ServerSocketChannel.open();  
……  
然后配制socket的一些基本属性，并注册此事件是可连接的事件

Java代码
// This is a non blocking socket channel  
       channel.configureBlocking(false);  
     
       // Configure the server socket,  
       ServerSocket socket = channel.socket();  
         
       // Set the reuseAddress flag accordingly with the setting  
       socket.setReuseAddress(isReuseAddress());  
         
       // and bind.  
       socket.bind(localAddress, getBacklog());  
         
       // Register the channel within the selector for ACCEPT event  
       channel.register(selector, SelectionKey.OP_ACCEPT);  
当接收到请求时调用accept()方法法处理接收连接，把SocektChannel绑定到NioSession中

Java代码
@Override  
protected NioSession accept(IoProcessor<NioSession> processor,  
        ServerSocketChannel handle) throws Exception {  
  
    SelectionKey key = handle.keyFor(selector);  
      
    if ((key == null) || (!key.isValid()) || (!key.isAcceptable()) ) {  
        return null;  
    }  
  
    // accept the connection from the client  
    SocketChannel ch = handle.accept();  
      
    if (ch == null) {  
        return null;  
    }  
  
    return new NioSocketSession(this, processor, ch);  
}   
5. 绑定完成后唤醒NIO的selector开始接收请求

Java代码
selector.wakeup();   
小结：

通过解析 NioSocketAcceptor的构造方法，bind()等代码大概了解了mina服务端初始化相关的一些信息，同时涉及了mina框架相关的IoProcessor IoSession IoServiceListener 等，在下一篇文章中会再做进一步的分析接收到最终的处理请求的过程。

分类：未分类	 | 1 条评论
关于两种限流模式
日期：2012-12-10 作者：shiming
流量预警和限流方案中，比较常用的有两种。第一种滑窗模式，通过统计多个单元时间的访问次数来进行控制，当单位时间的访问次数达到的某个峰值时进行限流。第二种为响应模式，通过控制当前活跃请求数，来进行流量控制。下面来简单分析下两种的优缺点。

1、滑窗模式

模式分析:

在每次有访问进来时，我们判断前N个单位时间里总访问量是否超过了设置的阈值，若超过则不允许执行。

这种模式的实现的方式更加契合流控的本质意义。理解较为简单。但由于访问量的预先不可预见性，会发生单位时间的前半段有大量的请求涌入，而后半段则拒绝所有请求的情况发生。（一般，需要会将单位时间切的足够的细来解决这个问题）其次，我们很难确定这个阈值设置在多少比较合适，只能通过经验或者模拟（如压测）来进行估计，不过即使是压测也很难估计的准确，线上每台机器的硬件参数的不同，或者同一台机子在不同的时间点其可以接受的阈值也不尽相同（系统中），每个时间点导致能够承受的最大阈值也不尽相同，我们无法考虑的周全。

所以滑窗模式往往用来对某一资源的保护上（或者说是承诺比较合适：我对某一接口的提供者承诺过，最高调用量不超过XX），如对db的保护，对某一服务的调用的控制上。因为对于我们应用来说，db或某一接口就是一共单一的整体。

代码实现思路：

每一个窗（单位时间）就是一个独立的计数器（原子计数器），用以数组保存。将当前时间以某种方式（比如取模）映射到数组的一项中。每次访问先对当前窗内计数器+1，再计算前N个单元格的访问量综合，超过阈值则限流。

这里有个问题，时间永远是递增的，单纯的取模，会导致数组过长，使用内存过多，我们可以用环形队列来解决这个问题。

2、响应模式

模式分析：

每次操作执行时，我们通过判断当前正在执行的访问数是否超过某个阈值在决定是否限流。

该模式看着思路比较的另类，但却有其独到之处。实际上我们限流的根本是为了保护资源，防止系统接受的请求过多，应接不暇，拖慢系统中其他接口的服务，造成雪崩。也就是说我们真正需要关心的是那些运行中的请求，而那些已经完成的请求已是过去时，不再是需要关心的了。

我们来看看其阈值的计算方式，对于一个请求来说，响应时间rt/qps是一个比较容易获取的参数，那么我们这样计算：qps/1000*rt。

此外，一个应用往往是个复杂的系统，提供的服务或者暴露的请求、资源不止一个。内部GC、定时任务的执行、其他服务访问的骤增，外部依赖方、db的抖动，抑或是代码中不经意间的一个bug。都可能导致相应时间的变化，导致系统同时可以执行请求的变化。而这种模式，则能恰如其分的自动做出调整，当系统不适时，rt增加时，会自动的对qps做出适应。

代码实现思路:

当访问开始时，我们对当前计数器（原子计数器）+1，当完成时，-1。该计数器即为当前正在执行的请求数。只需判断这个计数器是否超过阈值即可。

分类：未分类	 | 发表评论
代理重定向策略及其用户感受的分析
日期：2012-12-08 作者：李 鼎
大家会碰到类似这样的事情，比如，找你的租房中介负责人让处理一下空调坏了，中介负责人回答你说“我现在不负责你了 ，你去联系A。”你觉得这件事有些不爽，没办法，去联系A。说不定A又会说自己不负责了，让你联系B。

碰到这种“你去联系XXX”的情况，我想没有人会开心的。

如果这样的“重定向”形成了环，那么用户一直被“踢皮球”，不会得到处理。用户就要抓狂了！

PS：是不是想到了有关部门的处理方式，哈哈

作为客户，是体验差的问题；作为服务方，其实意味着客户的流失！

我们把这个问题，称为“事务转手”，服务方的负责人称为“代理”。“事务转手”的情况常常会有，“代理”如何处理才合理呢？

代理的处理方式及分析

1) 一杆到底

代理把问题提给接手的同学，处理完了，再把结果反馈给用户。

即代理“一杆到底”都处理了，用户不需要感知有转手这件事，体验最好。但问题是

每次这样的处理，多了一次传手，效率低。
如果每次都这么处理，事务便没有办法转交出去了，一直陷在里面。
2) 重定向用户到下一任去

重定向，即让用户去联系下一任。上文也提到可以会出现“踢皮球”的风险（这是一个不能接受的情况）。

另外，之前代理承诺了是负责该用户的，用户在要代理处理事务时，用户如果没有被事先告知代理有变化，那么之前代理承诺是没有变化的。所以，用户在要代理处理事务时，用户被重定向到A，代理并没有负责处理好（用户要做额外的联系工作，并不期望要做），这个“用户被重定向”是代理违背了自己的承诺！

PS： 这让我想到了“契约精神”！

上面2种处理方式很容易想到，但存在问题。从方法2的分析可以看出，一个关键点是“事先告知用户代理有变化”，展开说明如下：

如果事先告知了用户，那么用户应该去联系下一任，
如果没有事先告知了用户，那么这次处理用户不能被重定向。
结合上面的2点，得到了第三种处理方式。

3) 本次“一杆到底”处理；找出真正可以处理代理A并告知用户以后的事务已转交A

可以看出这个处理方式包含了1方式和2方式的内容。能避免前两种方式中会有的问题：

只有第一次有传手，不会每次都效率低。
避免 代理无法转交业务的问题（方法1）。代理处理了这一次，以后不用再处理这个用户了，业务转交成功。
代理没有违背承诺。
避免“踢皮球”这样恶性情况！因为使用这种方式，本次事务一定会得到直接处理。
细心的你可能发现，这种方式代理的第二步骤是

找出真正可以处理代理A”并告知用户以后的事务已转交A

为什么不是

告知用户以后的事务已转交自己的下一任

原因是这样可以避免下面的情况：

用户会连续多次被告知业务交给了下一任（当次的事务会被直接处理），如果下一任也转交了任务。

总结

从上面给出的方法中可以看到，应该提前通知用户事务转交的事情，让用户早有准备。

# 即广播变化后的代理信息。

当然最好的情况还是避免告知用户转交这种情况的发生。可以方法有：

用户联系的是一个稳定信息比如服务中心（像10086），而不是某个直接某个代理。

# 即从一个中心获得代理信息，而不是直接联系代理。

当然服务中心本身的信息同样面临这个问题，即可以会变更转手，不能使用服务中心的方式（否则这是死循环的方法了）。这是个小概率事件，并且要慎重处理。

事务处理关心的指标

用户的体验：被重定向的次数、响应时间
系统成本：处理效率/所用的资源
后记

这段时间在调研Paxos，看了Paxos相关论文。Paxos包含了很多代理间的交互，触发了生活中代理问题（由租房中介的事引起）的思考。

后面会整理出一系列Paxos分享来 

PS: 本文也放在我的个人博客：事务转手策略及其用户感受的分析。

分类：分布式和集群	 | 标签：代理, 契约, 契约精神, 用户, 设计, 踢皮球, 重定向	 | 3 条评论
← 较老日志
最新文章
淘宝中间件团队新版博客上线
综合业务部-中间件平台-产品黄页
天心阁吉他神秘人专访
业界动态
关于大区间过滤优化内存设计
最新评论
pythonee 发布于《ZooKeeper的一个性能测试》
tonni 发布于《一种可以避免数据迁移的分库分表scale-out扩容方式》
tonni 发布于《diamond专题（二）– 核心原理介绍》
baoshengdeer 发布于《一种可以避免数据迁移的分库分表scale-out扩容方式》
李 鼎 发布于《代理重定向策略及其用户感受的分析》
标签
actor aviator btrace concurrent diamond专题 extends filter gc guice HandlerSocket hotswap hs4j ipfilter jamwiki java JavaOne jrockit kafka kilim LinkedList Lucene makefile monitor mysql netty nio nosql OOM osgi outing Paxos peaberry Solr spark TimeTunnel zookeeper 千岛湖 实习 总结 成长 指南 权限 设计 豪赌之旅 质量
链接
淘宝DBA团队
淘宝QA团队
淘宝UED团队
淘宝开放平台团队
淘宝核心系统团队
淘宝网综合业务平台团队博客 由 WordPress 强力驱动。
========== https://github.com/taobao/TProfiler/wiki ==========
Sign up Sign in
Explore
Features
Enterprise
Blog

This repository
Star 1 Fork 4 PUBLIC taobao/TProfiler
Home Pages History New Page
Page History Clone URL
Home

Welcome to the TProfiler wiki!
Last edited by taobao, 7 months ago
Status API Training Shop Blog About © 2013 GitHub, Inc. Terms Privacy Security Contact
========== http://jsczxy2.iteye.com/blog/784475 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
jsczxy2
博客微博相册收藏留言关于我
  
tomcat频繁内存溢出，但是查看jvm并没有不够用，怎么回事？请来设置下启动参数吧

博客分类： java
JVMTomcatOSJNIthread 
XSocket内存泄漏问题深度分析

大概一个月前在一个数据迁移的过程中，在数据迁移到900多W的时候程序崩溃了，系统最后记录的日志是这样的：
 Exception in thread "xDispatcher#CLIENT" java.lang.OutOfMemoryError
        at sun.misc.Unsafe.allocateMemory(Native Method)
        at java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:99)
        at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:288)
        at org.xsocket.connection.spi.AbstractMemoryManager.newBuffer(AbstractMemoryManager.java:219)
        at.......
从 中不难看出这是xsocket的内存管理层程序通过JVM的nio创建DirectByteBuffer时抛出了错误。在这里先要说明一下的是，当时的系 统使用的xsocket2.0版，2.0版连接读取数据默认就是使用DirectByteBuffer的，目前2.4.X版已经默认都改为使用 ByteBuffer，而不再是DirectByteBuffer了。
DirectByteBuffer是由jvm调用jni程序在操作系统内存 中分配的空间的，不需要占用JVM的Heap Size。当程序需要读取Big Size或者Huge Size数据的时候，使用DirectByteBuffer优势尤其明显。但使用DirectByteBuffer会产生一个问题，当JVM的空间还没满 但系统内存空间已经被消耗的差不多的时候，gc如何被触发呢。这个问题在一个叫Harmony的开源Java SE项目的mail list中曾进行过热烈的讨论。参考资料1中有当时讨论过程的链接。
在跟踪JVM的一些源码后，发现，很庆幸，sun的jvm已经解决这个问题 了。但是对于尚不清楚其内存处理机制的开发人员来说。在使用DirectByteBuffer是还是很可能把系统置身于莫大的风险中。而很不幸这个问题隐 藏的相当的隐秘，对于不明就里的人，最后可能只好采取定时重启系统或者在系统中设定一些条件显式调用gc来曲线解决资源释放的问题。

题外话说了不少，下面我们直接从JVM的一些代码片段去分析文章最开始的Exception是在什么条件下引发的。首先我们来看看DirectByteBuffer的构建函数代码：
     DirectByteBuffer(int cap) {
        super(-1, 0, cap, cap, false);
        Bits.reserveMemory(cap); 
        int ps = Bits.pageSize();
        long base = 0;
        try {
            base = unsafe.allocateMemory(cap + ps); 
        } catch (OutOfMemoryError x) {
            Bits.unreserveMemory(cap);
            throw x;
        }
        unsafe.setMemory(base, cap + ps, (byte) 0);
        if (base % ps != 0) {
            // Round up to page boundary
            address = base + ps - (base & (ps - 1));
        } else {
            address = base;
        }
        cleaner = Cleaner.create(this, new Deallocator(base, cap));
    }
注意以上片段中红色加亮的部分，然后我们再来看看Bits.reserveMemory这个方法的代码：
     // -- Direct memory management --

    // A user-settable upper limit on the maximum amount of allocatable
    // direct buffer memory.  This value may be changed during VM
    // initialization if it is launched with "-XX:MaxDirectMemorySize=<size> ".
    private static volatile long maxMemory = VM.maxDirectMemory(); 
    private static volatile long reservedMemory = 0;
    private static boolean memoryLimitSet = false;

    // These methods should be called whenever direct memory is allocated or
    // freed.  They allow the user to control the amount of direct memory
    // which a process may access.  All sizes are specified in bytes.
    static void reserveMemory(long size) {
        synchronized (Bits.class) {
            if (!memoryLimitSet && VM.isBooted()) {
            maxMemory = VM.maxDirectMemory();
            memoryLimitSet = true;
            }
            if (size <= maxMemory - reservedMemory) {
            reservedMemory += size;
            return;
            }
        }

        System.gc(); 
        try {
            Thread.sleep(100);
        } catch (InterruptedException x) {
            // Restore interrupt status
            Thread.currentThread().interrupt();
        }
        synchronized (Bits.class) {
            if (reservedMemory + size > maxMemory)
            throw new OutOfMemoryError("Direct buffer memory");
            reservedMemory += size;
        }
    }
从 以上代码我们可以看到，JVM在通过DirectByteBuffer使用OS内存时（无论是分配还是释放），是有统计的，通过跟可使用的最大OS内存 （VM.maxDirectMemory())作比较，如果不够用，那显式调用gc，如果经过gc后还是没有足够的空分配内存，那么从Bit抛出 Exception。注意：这一步并未真正的像OS申请内存，只是VM通过计算得出的结论。而真正想OS申请内存是在 unsafe.allocateMemory这个方法里面通过JNI实现的。显然，文章最初的Exception是由Unsafe抛出而不是Bit抛出。 也就是说JVM认为OS还有足够的可分配内存，而当JVM真正向OS申请内存分配的时候却出错了。那么接下来我们就得看看，这个max direct memory值是如何设定的。

现在我们看看VM.java的代码：
   private static long directMemory = 67108864L; 
  ...
  public static long maxDirectMemory()
  {
    if (booted)
      return directMemory;
    Properties localProperties = System.getProperties();
    String str = (String)localProperties.remove("sun.nio.MaxDirectMemorySize");
    System.setProperties(localProperties);
    if (str != null)
      if (str.equals("-1"))
      {
        directMemory = Runtime.getRuntime().maxMemory(); 
      } else {
        long l = Long.parseLong(str); 
        if (l > -1L)
          directMemory = l;
      }
    return directMemory;
  }
可以看出来，max direct memory可以有三种值：
1）默认值，64M；
2）maxMemory，也就是通过-Xmx设定的值，默认也是64M；
3）通过-XX:MaxDirectMemorySize=<size>指定的值；

问 题到这里基本就是水落石出了，当时系统启动的时候设定-Xmx2048M，未指定MaxDirectMemorySize，也就是说max direct memory被认为是2048M，整个系统的物理内存为4G，除掉系统进程占用的内存，剩下的物理内存加上swap空间也就接近3G。设想JVM的 heap size占用了1.5G，direct memory使用了1.5G，这时候程序申请一200M的direct内存，在这种情况下无论是JVM heap size还是direct memory不满足触发gc的条件，于是jvm向os申请分配内存，OS无可分配的内存了就会抛出OOM错误。

补 充说明一下：在OS已经把物理内存+Swap都耗光都不足够分配内存空间的时候，不同OS可能会有不同的表现。LInux的内核有可能会尝试努力腾出更多 的内存空间。可能会杀掉某些进程。（这是参考资料一中Ivan Volosyuk所提出来的问题）。而我在使用以下程序进行测试时，出现整个OS系统假死的状况，过一段时间回复过来了。但整个过程可以肯定的一件事是 gc始终没有被触发到。

以下是我用来验证我的以上分析的测试程序：
 import java.lang.management.ManagementFactory;
import java.nio.ByteBuffer;
import java.util.logging.Logger;

import com.sun.management.OperatingSystemMXBean;

public class TestMemoryLeak {
    private static Logger logger = Logger.getAnonymousLogger();

    public static void main(String[] args) throws Exception{
        OperatingSystemMXBean osmb = (OperatingSystemMXBean) ManagementFactory
                .getOperatingSystemMXBean();
        System.out.println("Total physic memory:"
                + osmb.getTotalPhysicalMemorySize() / 1024 / 1024 + "MB");
        System.out.println("Free physic memory:"
                + osmb.getFreePhysicalMemorySize() / 1024 / 1024 + "MB");
        System.out.println("Max memory:" + Runtime.getRuntime().maxMemory());
        System.out
                .println("Total memory:" + Runtime.getRuntime().totalMemory());
        System.out.println("Free memory:" + Runtime.getRuntime().freeMemory());
        System.out.println("====================================");
        
        //testDirectByteBuffer();
        testByteBuffer();
        
        System.out.println("====================================");
        System.out.println("Free physic memory:"
                + osmb.getFreePhysicalMemorySize() / 1024 / 1024 + "MB");
    }
    
    public static void testDirectByteBuffer(){
        try{
            ByteBuffer bb1 = ByteBuffer.allocateDirect(1024 * 100000 * 4);
            bb1 = null;
            System.out.println("Free memory:" + Runtime.getRuntime().freeMemory());
            ByteBuffer bb2 = ByteBuffer.allocateDirect(1024 * 100000 * 5);
            bb2 = null;
            System.out.println("Free memory:" + Runtime.getRuntime().freeMemory());
            //System.gc();
            //pause expect for gc
            Thread.sleep(1000*6);
            ByteBuffer bb3 = ByteBuffer.allocateDirect(1024 * 100000 * 8);
            System.out.println("Free memory:" + Runtime.getRuntime().freeMemory());    
        }catch(Exception e){
            e.printStackTrace();
        }
    }    
    public static void testByteBuffer(){
        try{
            ByteBuffer bb1 = ByteBuffer.allocate(1024 * 100000 * 4);
            bb1 = ByteBuffer.allocate(1024 * 10 * 4);
            System.out.println("Free memory:" + Runtime.getRuntime().freeMemory());
            ByteBuffer bb2 = ByteBuffer.allocate(1024 * 100000 * 3);
            bb1 = ByteBuffer.allocate(1024 * 10 * 3);
            System.out.println("Free memory:" + Runtime.getRuntime().freeMemory());
            //System.gc();
            //pause expect for gc
            Thread.sleep(1000*6);
            ByteBuffer bb3 = ByteBuffer.allocate(1024 * 100000 * 6);
            System.out.println("Free memory:" + Runtime.getRuntime().freeMemory());    
        }catch(Exception e){
            e.printStackTrace();
        }        
    }

}
程序启动需用如下命令：
java -verbose:gc -Xms64M -Xmx512M -XX:MaxDirectMemorySize=1000M TestMemoryLeak
-verbose:gc用于开启gc运行情况的输出，可以帮助我们了解jvm垃圾收集的运作情况；
其他参数值应该你机器的实际情况设定。

最后我想总结的是，当我们在使用DirectByteBuffer的时候一定要注意：
1）谨慎设定JVM运行参数，最好用-XX:MaxDirectMemorySize进行设定，否则你就得清楚你设定的mx不单单制定了heap size的最大值，它同时也是direct memory的最大值；
2）在密集型访问中（例如数据迁移工具）适当增加对gc的显式调用，保证资源的释放；

参考资料：
[VM]How to trigue GC while free native memory is low.
分享到：    
在linux下查看tomcat的链接数 | linux下查看jvm使用内存状况
2010-10-14 10:20浏览 2432评论(1)分类:企业架构相关推荐
评论
1 楼 smalleyeit 2012-08-21  

发表评论
  您还没有登录,请您登录后再发表评论

jsczxy2
浏览: 185594 次
性别: 
来自: 常州

最近访客 更多访客>>
dylinshi126lyh061619yefonechc340121
文章分类
全部博客 (384)
java (70)
linux (71)
Oracle (12)
ext (14)
javascript (29)
虚拟机 (1)
搜索引擎 (1)
struts2 (10)
设计模式 (9)
mysql (21)
nginx (11)
tomcat (5)
随想 (10)
spring (18)
svn (1)
flash (2)
UML (1)
数据结构 (7)
算法 (2)
网摘 (5)
数据库 (14)
ibatis (3)
jquery (26)
lucene (1)
hibernate (12)
Myeclipse (4)
线程 (7)
jbpm (4)
重构 (1)
mantis (3)
MediaWiki (4)
ExtMail (1)
MDaemon (1)
egit (1)
dwr (6)
sitemesh (2)
mybatis (1)
ico (1)
hadoop (3)
jsoup (1)
urlrewrite (2)
jstl (1)
spring3 (2)
aop (2)
定时器 (1)
Quartz (2)
apache (1)
php (1)
security (1)
iptables (2)
QQ (1)
mysqldump (1)
vim (1)
memcached (2)
jad (1)
微博 (1)
html5 (1)
css3 (1)
httpclient (4)
google (1)
shortUrl (1)
json (2)
virtualBox (1)
mantisBT (2)
htmlunit (1)
selenium (1)
mail (1)
正则表达式 (4)
html (2)
css (2)
jatoolsPrinter (1)
图片处理 (1)
hql (1)
webservice (1)
分词 (1)
短信 (1)
VPS (1)
事务 (1)
广告 (1)
画廊 (1)
git (1)
github (1)
openshift (1)
缓存 (1)
web (1)
android (1)
c3p0 (1)
邮箱 (1)
memcache (1)
windows (1)
js (3)
编辑器 (1)
打印 (1)
centos (4)
boneCP (1)
连接池 (1)
sql (1)
nosql (1)
MongoDB (1)
社区版块
我的资讯 (0)
我的论坛 (30)
我的问答 (8)
存档分类
2013-09 (8)
2013-08 (9)
2013-07 (10)
更多存档...
最新评论
jsczxy2： jsczxy2 写道snailxr 写道 <! ...
jbpm4.4整合spring2.5(ibatis与hibernate全整合)
jsczxy2： snailxr 写道 <!-- 事务代理拦截器 ...
jbpm4.4整合spring2.5(ibatis与hibernate全整合)
snailxr： <!-- 事务代理拦截器的配置 --> ...
jbpm4.4整合spring2.5(ibatis与hibernate全整合)
zbb153268521： 貌似不错啊
jbpm4.4整合spring2.5(ibatis与hibernate全整合)
abcgoup： 你说的不对吧。 两种功能是一样的。只是第二种风格不推荐。请参考 ...
Thread.sleep()和Thread.currentThread().sleep()区别
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== http://coderplay.iteye.com/blog/1481211 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
Everything can be distributed
博客微博相册收藏留言关于我
  
从Java视角理解CPU上下文切换(Context Switch)

博客分类： java
上下文切换context switchjava多线程 
从Java视角理解系统结构连载, 关注我的微博(链接)了解最新动态 

在高性能编程时,经常接触到多线程. 起初我们的理解是, 多个线程并行地执行总比单个线程要快, 就像多个人一起干活总比一个人干要快. 然而实际情况是, 多线程之间需要竞争IO设备, 或者竞争锁资源，导致往往执行速度还不如单个线程. 在这里有一个经常提及的概念就是: 上下文切换(Context Switch). 

上下文切换的精确定义可以参考: http://www.linfo.org/context_switch.html. 下面做个简单的介绍. 多任务系统往往需要同时执行多道作业.作业数往往大于机器的CPU数, 然而一颗CPU同时只能执行一项任务, 如何让用户感觉这些任务正在同时进行呢? 操作系统的设计者巧妙地利用了时间片轮转的方式, CPU给每个任务都服务一定的时间, 然后把当前任务的状态保存下来, 在加载下一任务的状态后, 继续服务下一任务. 任务的状态保存及再加载, 这段过程就叫做上下文切换. 时间片轮转的方式使多个任务在同一颗CPU上执行变成了可能, 但同时也带来了保存现场和加载现场的直接消耗. 
(Note. 更精确地说, 上下文切换会带来直接和间接两种因素影响程序性能的消耗. 直接消耗包括: CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉; 间接消耗指的是多核的cache之间得共享数据, 间接消耗对于程序的影响要看线程工作区操作数据的大小). 


在linux中可以使用vmstat观察上下文切换的次数. 执行命令如下: 
Shell代码  
$ vmstat 1  
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----  
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa  
 1  0      0 4593944 453560 1118192    0    0    14    12  238   30  6  1 92  1  
 0  0      0 4593212 453568 1118816    0    0     0    96  958 1108  4  1 94  2  
 0  0      0 4593360 453568 1118456    0    0     0     0  895 1044  3  1 95  0  
 1  0      0 4593408 453568 1118456    0    0     0     0  929 1073  4  1 95  0  
 0  0      0 4593496 453568 1118456    0    0     0     0 1133 1363  6  1 93  0  
 0  0      0 4593568 453568 1118476    0    0     0     0  992 1190  4  1 95  0  

vmstat 1指每秒统计一次, 其中cs列就是指上下文切换的数目. 一般情况下, 空闲系统的上下文切换每秒大概在1500以下. 

对于我们经常使用的抢占式操作系统来说, 引起上下文切换的原因大概有以下几种: 1. 当前执行任务的时间片用完之后, 系统CPU正常调度下一个任务 2. 当前执行任务碰到IO阻塞, 调度器将挂起此任务, 继续下一任务 3. 多个任务抢占锁资源, 当前任务没有抢到,被调度器挂起, 继续下一任务 4. 用户代码挂起当前任务, 让出CPU时间 5. 硬件中断. 前段时间发现有人在使用futex的WAIT和WAKE来测试context switch的直接消耗(链接), 也有人使用阻塞IO来测试context switch的消耗(链接).那么Java程序怎么测试和观察上下文切换的消耗呢? 

我做了一个小实验, 代码很简单, 有两个工作线程. 开始时，第一个线程挂起自己; 第二个线程唤醒第一个线程，再挂起自己; 第一个线程醒来之后唤醒第二个线程, 再挂起自己. 就这样一来一往,互相唤醒对方, 挂起自己. 代码如下: 
Java代码  
import java.util.concurrent.atomic.AtomicReference;  
import java.util.concurrent.locks.LockSupport;  
  
public final class ContextSwitchTest {  
    static final int RUNS = 3;  
    static final int ITERATES = 1000000;  
    static AtomicReference turn = new AtomicReference();  
  
    static final class WorkerThread extends Thread {  
        volatile Thread other;  
        volatile int nparks;  
  
        public void run() {  
            final AtomicReference t = turn;  
            final Thread other = this.other;  
            if (turn == null || other == null)  
                throw new NullPointerException();  
            int p = 0;  
            for (int i = 0; i < ITERATES; ++i) {  
                while (!t.compareAndSet(other, this)) {  
                    LockSupport.park();  
                    ++p;  
                }  
                LockSupport.unpark(other);  
            }  
            LockSupport.unpark(other);  
            nparks = p;  
            System.out.println("parks: " + p);  
  
        }  
    }  
  
    static void test() throws Exception {  
        WorkerThread a = new WorkerThread();  
        WorkerThread b = new WorkerThread();  
        a.other = b;  
        b.other = a;  
        turn.set(a);  
        long startTime = System.nanoTime();  
        a.start();  
        b.start();  
        a.join();  
        b.join();  
        long endTime = System.nanoTime();  
        int parkNum = a.nparks + b.nparks;  
        System.out.println("Average time: " + ((endTime - startTime) / parkNum)  
                + "ns");  
    }  
  
    public static void main(String[] args) throws Exception {  
        for (int i = 0; i < RUNS; i++) {  
            test();  
        }  
    }  
}  

编译后,在我自己的笔记本上( Intel(R) Core(TM) i5 CPU M 460  @ 2.53GHz, 2 core, 3M L3 Cache) 用测试几轮，结果如下: 
Shell代码  
java -cp . ContextSwitchTest  
parks: 953495  
parks: 953485  
Average time: 11373ns  
parks: 936305  
parks: 936302  
Average time: 11975ns  
parks: 965563  
parks: 965560  
Average time: 13261ns  
我们会发现这么简单的for循环, 线性执行会非常快,不需要1秒, 而执行这段程序需要几十秒的耗时. 每个上下文切换需要耗去十几us的时间,这对于程序吞吐量的影响很大. 

同时我们可以执行vmstat 1 观查一下上下文切换的频率是否变快 
Shell代码  
$ vmstat 1  
procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----  
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa  
 1  0      0 4424988 457964 1154912    0    0    13    12  252   80  6  1 92  1  
 0  0      0 4420452 457964 1159900    0    0     0     0 1586 2069  6  1 93  0  
 1  0      0 4407676 457964 1171552    0    0     0     0 1436 1883  8  3 89  0  
 1  0      0 4402916 457964 1172032    0    0     0    84 22982 45792  9  4 85  2  
 1  0      0 4416024 457964 1158912    0    0     0     0 95382 198544 17 10 73  0  
 1  1      0 4416096 457964 1158968    0    0     0   116 79973 159934 18  7 74  0  
 1  0      0 4420384 457964 1154776    0    0     0     0 96265 196076 15 10 74  1  
 1  0      0 4403012 457972 1171096    0    0     0   152 104321 213537 20 12 66  2  


再使用strace观察以上程序中Unsafe.park()究竟是哪道系统调用造成了上下文切换: 
Shell代码  
$strace -f java -cp . ContextSwitchTest  
[pid  5969] futex(0x9571a9c, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x9571a98, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1  
[pid  5968] <... futex resumed> )       = 0  
[pid  5969] futex(0x9571ad4, FUTEX_WAIT_PRIVATE, 949, NULL <unfinished ...>  
[pid  5968] futex(0x9564368, FUTEX_WAKE_PRIVATE, 1) = 0  
[pid  5968] futex(0x9571ad4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x9571ad0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1} <unfinished ...>  
[pid  5969] <... futex resumed> )       = 0  
[pid  5968] <... futex resumed> )       = 1  
[pid  5969] futex(0x9571628, FUTEX_WAIT_PRIVATE, 2, NULL <unfinished ...>  
果然还是futex. 

再使用perf看看上下文对于Cache的影响: 
Shell代码  
$ perf stat -e cache-misses   java -cp . ContextSwitchTest  
parks: 999999  
parks: 1000000  
Average time: 16201ns  
parks: 998930  
parks: 998926  
Average time: 14426ns  
parks: 998034  
parks: 998204  
Average time: 14489ns  
  
 Performance counter stats for 'java -cp . ContextSwitchTest':  
  
         2,550,605 cache-misses                                                  
  
      90.221827008 seconds time elapsed  
1分半钟内有255万多次cache未命中. 

嗯, 貌似太长了, 可以结束了. 接下来会继续几篇博文继续分析一些有意思的东西. 
(1) 从Java视角看内存屏障 (Memory Barrier) 
(2) 从java视角看CPU亲缘性 (CPU Affinity) 
等..敬请关注 


PS. 其实还做了一个实验, 测试CPU Affinity对于Context Switch的影响. 
Shell代码  
$ taskset -c 0 java -cp . ContextSwitchTest  
parks: 992713  
parks: 1000000  
Average time: 2169ns  
parks: 978428  
parks: 1000000  
Average time: 2196ns  
parks: 989897  
parks: 1000000  
Average time: 2214ns  
这个命令把进程绑定在0号CPU上,结果Context Switch的消耗小了一个数量级, 什么原因呢? 卖个关子, 在谈到CPU Affinity的博文再说
查看图片附件

分享到：    
从Java视角理解CPU缓存(CPU Cache) | 抛砖引玉, 淘宝统一离线数据分析平台设计
2012-04-11 15:35浏览 7041评论(13)分类:编程语言相关推荐
评论
13 楼 lovegq 2013-02-24  
请教个问题, 关于切换的 那副图片 是楼主原创的,还是其他资料里的,想看看原始的文档。
12 楼 fh63045 2012-10-31  
求问: 这么绑定到指定CPU执行?
11 楼 coderplay 2012-04-25  
fuyou001 写道
绑定到特定的cpu 与不绑定cpu cache-misses相差不大

能告诉我你的CPU型号吗?
10 楼 fuyou001 2012-04-25  
绑定到特定的cpu 与不绑定cpu cache-misses相差不大:
Java代码  
yubaofu@java$perf stat -e cache-misses java -cp . ContextSwitchTest  
parks: 990309  
parks: 989792  
Average time: 6750ns  
parks: 1000000  
parks: 1000001  
Average time: 6030ns  
parks: 998608  
parks: 998506  
Average time: 6320ns  
  
 Performance counter stats for 'java -cp . ContextSwitchTest':  
  
           889,137 cache-misses                                                  
  
      38.123576396 seconds time elapsed  
  
yubaofu@java$taskset -c 0 perf stat -e cache-misses java -cp . ContextSwitchTest   
parks: 996891  
parks: 992637  
Average time: 1832ns  
parks: 997725  
parks: 981451  
Average time: 1855ns  
parks: 990237  
parks: 1000001  
Average time: 1791ns  
  
 Performance counter stats for 'java -cp . ContextSwitchTest':  
  
           735,660 cache-misses                                                  
  
      10.929714636 seconds time elapsed  

绑定到特定的cpu 与不绑定cpu context-switch 相差也不大
Java代码  
yubaofu@java$taskset -c 0 perf stat -e cs java -cp . ContextSwitchTest  
parks: 996667  
parks: 996658  
Average time: 1921ns  
parks: 997488  
parks: 979789  
Average time: 1927ns  
parks: 987008  
parks: 1000001  
Average time: 1871ns  
  
 Performance counter stats for 'java -cp . ContextSwitchTest':  
  
         6,102,090 cs                                                            
  
      11.402238007 seconds time elapsed  
  
yubaofu@java$perf stat -e cs java -cp . ContextSwitchTest  
parks: 949590  
parks: 949608  
Average time: 5680ns  
parks: 956224  
parks: 955899  
Average time: 5581ns  
parks: 941611  
parks: 942028  
Average time: 5578ns  
  
 Performance counter stats for 'java -cp . ContextSwitchTest':  
  
         5,708,444 cs                                                            
  
      32.024738227 seconds time elapsed  

9 楼 rain2005 2012-04-16  
mineral 写道
请教一个问题，tomcat的线程池设置大小，需要用什么工具/方法来确定最优化的数值，达到最少context switch？

对于访问数据库的应用来说，根据context switch来判断线程数太不科学了，一般动态内容线程数要大点100到150左右。，静态内容单线程
8 楼 coderplay 2012-04-15  
任何系统调用都会被统计为一次软中断, 这个完全正确. LockSupport.unpark()不一定调用了futex系统调用, 有可能一直在用户态. 我刚才strace了我的Westmere机器, 几乎没有看到futex系统调用, vmstat 1和刚才回复的一样; 但i5的机器却是有很多futex系统调用. 
看样子我的理解还有些问题, 得查查jvm和pthread代码. 
7 楼 zldeng1984 2012-04-15  
我和你i5的机器结果类似，interrupt的效果是这样的（部分）：
Bash代码  
256:  560188959          0          0          0     Dynamic-irq  timer0  
257:   12289018          0          0          0     Dynamic-irq  resched0  
258:         30          0          0          0     Dynamic-irq  callfunc0  

观察了下和resched基本成正比。

不过估计我有一个误区，我以前以为linux的系统调用是通过软中断触发的，所以任何系统调用都会被统计为一次软中断，现在看来理解有问题。这里能帮忙科普下么？
6 楼 coderplay 2012-04-15  
zldeng1984 写道
请教下上面例子中vmstat的in和cs为什么是一个大概1：2的关系，一次futex系统调用导致一次软中断和一次上下文切换为什么不是1：1？

futex本身不造成软中断, 示例的测试是在我本子上的i5 M460. 引起中断的原因有可能是因为程序导致Rescheduling interrupts. 通过命令看到Rescheduling interrupt变化比较和程序context switch貌似成正比, 具体原因还需要调查.
Shell代码  
   
$ watch -n 1 cat /proc/interrupts  
           CPU0       CPU1       CPU2       CPU3         
  0:         43         12          4          2   IO-APIC-edge      timer  
  1:         10          8       8112        996   IO-APIC-edge      i8042  
  8:          0          1          0          0   IO-APIC-edge      rtc0  
  9:       4397        175        162        165   IO-APIC-fasteoi   acpi  
12:       2772        624        618        617   IO-APIC-edge      i8042  
16:       2774         26         18         15   IO-APIC-fasteoi   mei  
19:      80883         18         97         74   IO-APIC-fasteoi   ehci_hcd:usb2, ips  
23:         56         58         61         64   IO-APIC-fasteoi   ehci_hcd:usb1  
40:          4       2807          2          1   PCI-MSI-edge      eth0  
41:     103696     109390       1288       1298   PCI-MSI-edge      ahci  
42:     243335        163        186        173   PCI-MSI-edge      iwlagn  
43:     113608     214462       5338       3386   PCI-MSI-edge      i915  
44:         48         50         49         50   PCI-MSI-edge      hda_intel  
NMI:          0          0          0          0   Non-maskable interrupts  
LOC:    1286586    1178311     666412     660720   Local timer interrupts  
SPU:          0          0          0          0   Spurious interrupts  
PMI:          0          0          0          0   Performance monitoring interrupts  
IWI:          0          0          0          0   IRQ work interrupts  
RES:    2231272    2272751    4771974    4726837   Rescheduling interrupts  
CAL:       2773       2443       7234       8466   Function call interrupts  
TLB:      16529      17714      16475      11142   TLB shootdowns  
TRM:          0          0          0          0   Thermal event interrupts  
THR:          0          0          0          0   Threshold APIC interrupts  
MCE:          0          0          0          0   Machine check exceptions  
MCP:         20         20         20         20   Machine check polls  

另外我在一台 Westmere机器上测试同样的程序,是不会造成中断的.
Shell代码  
$ vmstat 1  
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------  
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st  
1  0    368 169140 2005776 21162064    0    0     0     2    0    0  0  0 100  0  0  
1  0    368 169140 2005776 21162072    0    0     0    24 1023 290984  2  4 95  0  0  
1  0    368 169140 2005776 21162072    0    0     0   144 1024 295536  1  3 95  0  0  
1  0    368 169140 2005780 21162072    0    0     0    84 1030 344833  2  4 95  0  0  
1  0    368 169140 2005780 21162072    0    0     0    64 1022 302313  2  4 95  0  0  
2  0    368 169140 2005780 21162072    0    0     0    88 1027 299323  1  4 95  0  0  

不知道你那儿情况如何?
5 楼 zldeng1984 2012-04-15  
请教下上面例子中vmstat的in和cs为什么是一个大概1：2的关系，一次futex系统调用导致一次软中断和一次上下文切换为什么不是1：1？
4 楼 coderplay 2012-04-15  
wang_scu 写道
很期待内存屏障的讲解 有个问题请教一下  用volatile字段来保证写线程在volatile写操作之前的数据能被读线程在读volatile后看到  这样的方法来跨越内存屏障 volatile 如果常常修改会有啥后果?


后面会详细说到volatile与memory barrier之间的关系, 使用volatile不管有没有冲突都会比线性执行普通变量的操作要慢10多倍, 同时还很有可能会引起false sharing.
3 楼 coderplay 2012-04-15  
mineral 写道
请教一个问题，tomcat的线程池设置大小，需要用什么工具/方法来确定最优化的数值，达到最少context switch？

sorry,我没从事过web开发, 没用过tomcat, 所以.... 我一般是使用vmstat, perf和Intel Vtune这几种工具发现问题, 然后再查看源码.
2 楼 wang_scu 2012-04-15  
很期待内存屏障的讲解 有个问题请教一下  用volatile字段来保证写线程在volatile写操作之前的数据能被读线程在读volatile后看到  这样的方法来跨越内存屏障 volatile 如果常常修改会有啥后果?

1 楼 mineral 2012-04-14  
请教一个问题，tomcat的线程池设置大小，需要用什么工具/方法来确定最优化的数值，达到最少context switch？
发表评论
  您还没有登录,请您登录后再发表评论

coderplay
浏览: 315229 次
性别: 
来自: 广州杭州

最近访客 更多访客>>
dylinshi126douglas_lhs龙隐士此人柚子
文章分类
全部博客 (103)
erlang (25)
obfuscator (3)
redpoll (10)
mapreduce&parallel (29)
java (5)
linux (3)
lucene&nutch (12)
mathematics (3)
misc (11)
社区版块
我的资讯 (0)
我的论坛 (9)
我的问答 (0)
存档分类
2013-01 (1)
2012-10 (1)
2012-04 (3)
更多存档...
评论排行榜
文件在使用FileChannel.map后不能被删除(W ...
警惕使用jvm参数CMSRefProcTaskProxy
最新评论
laputa73： chuqingq 写道有个疑问，端口数最多不超过65536个， ...
erlang网络编程的几个性能调优和注意点
forenroll： 请问楼主的那个分析工具cachemiss.bin是什么啊？
从Java视角理解CPU缓存(CPU Cache)
lmc_wy： 感觉很深入，崇拜
警惕使用jvm参数CMSRefProcTaskProxy
dacoolbaby： 请问楼主大大有做过实验，使用HiveServer2做表级别的权 ...
hive权限控制
左门马： hey！我在源码里插标记测试了一下，好像并不会调用 DFSIn ...
Hadoop的Mapper是怎么从HDFS上读取TextInputFormat数据的
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== http://rdc.taobao.com/blog/cs/?p=893 ==========
淘宝核心系统团队博客
基础 极致 分享
HOME
招聘信息
淘宝核心系统团队介绍
« 开源混合存储方案(Flashcache)IP地址库介绍 »
latencytop深度了解你的Linux系统的延迟
我们在系统调优或者定位问题的时候，经常会发现多线程程序的效率很低，但是又不知道问题出在哪里，就知道上下文切换很多，但是为什么上下文切换，是谁导致切换，我们就不知道了。上下文切换可以用dstat这样的工具查看，比如：

1
2
3
4
5
6
7
8
9
10
11
12
13
14
$dstat
----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--
usr sys idl wai hiq siq| read  writ| recv  send|  in   out | int   csw 
  9   2  87   2   0   1|7398k   31M|   0     0 | 9.8k   11k|  16k   64k
 20   4  69   3   0   4|  26M   56M|  34M  172M|   0     0 |  61k  200k
 21   5  64   6   0   3|  26M  225M|  35M  175M|   0     0 |  75k  216k
 21   5  66   4   0   4|  25M  119M|  34M  173M|   0     0 |  66k  207k
 19   4  68   5   0   3|  23M   56M|  33M  166M|   0     0 |  60k  197k
 
#或者用systemtap脚本来看
$sudo stap -e 'global cnt; probe scheduler.cpu_on {cnt<<<1;} probe timer.s(1){printf("%d\n", @count(cnt)); delete cnt;}'
217779
234141
234759
每秒高达200k左右的的上下文切换， 谁能告诉我发生了什么? 好吧，latencytop来救助了!

它的官网：http://www.latencytop.org/

Skipping audio, slower servers, everyone knows the symptoms of latency. But to know what’s going on in the system, what’s causing the latency, how to fix it… that’s a hard question without good answers right now.

LatencyTOP is a Linux* tool for software developers (both kernel and userspace), aimed at identifying where in the system latency is happening, and what kind of operation/action is causing the latency to happen so that the code can be changed to avoid the worst latency hiccups.

它是Intel贡献的另外一个性能查看器，还有一个是powertop,都是很不错的工具.

Latencytop通过在内核上下文切换的时候，记录被切换的进程的内核栈，然后通过匹配内核栈的函数来判断是什么原因导致上下文切换，同时他把几十种容易引起切换的场景的函数都记录起来，这样在判断系统问题的时候能容易定位到问题。

latencytop分成2个部分，内核部分和应用部分。内核部分负责调用栈的收集并且通过/proc来暴露， 应用部分负责显示.

工作界面截图如下:

latencytop在2.6.256后被内核吸收成为其中一部分，只要编译的时候打开该选项就好，如何确认呢？

1
2
$ cat /proc/latency_stats
Latency Top version : v0.1
看到这个就好了, 遗憾的是RHEL6竟然带了latencytop应用部分，而没有打开编译选项，让我们情何以堪呢？
在ubuntu下可以这么安装：

1
2
3
4
$ uname -r
2.6.38-yufeng
$ apt-get install latencytop
$ sudo latencytop #就可以使用了
但是latencytop比较傻的是默认是开图像界面的，我们很不习惯，我们要文本界面, 自己动手把!

1
2
3
4
5
6
7
8
9
10
11
$ apt-get source latencytop
$ diff -up Makefile.orig Makefile
--- Makefile.orig   2011-03-29 20:10:29.025845447 +0800
+++ Makefile    2011-03-28 14:48:11.232318002 +0800
@@ -1,5 +1,5 @@
 # FIXME: Use autoconf ?
-HAS_GTK_GUI = 0
+#HAS_GTK_GUI = 0
  
 DESTDIR =
 SBINDIR = /usr/sbin
重新make下就好了, 文本界面出现了. 具体使用参看 man latencytop。

fcicq同学说：
加个 –nogui 参数就好了. 不需要重新编译.
谢谢！

好了,那么latencytop支持多少种的延迟原因呢？让latencytop.trans告诉你，我们也可以自己修改这个文件，把新的延迟原因加上去。

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
$ cat /usr/share/latencytop/latencytop.trans 
#
1   vfs_read        Reading from file
1   vfs_write       Writing to file
1   __mark_inode_dirty  Marking inode dirty
1   vfs_readdir     Reading directory content
1   vfs_unlink      Unlinking file
1   blocking_notifier_call_chain    Blocking notifier
1   lock_super      Superblock lock contention
1   vfs_create      Creating a file
1   KAS_ScheduleTimeout Binary AMD driver delay
1   firegl_lock_device  Binary AMD driver delay
#
2   __bread         Synchronous buffer read
2   do_generic_mapping_read Reading file data
2   sock_sendmsg        Sending data over socket
2   do_sys_open     Opening file
2   do_sys_poll     Waiting for event (poll)
2   core_sys_select     Waiting for event (select)
2   proc_reg_read       Reading from /proc file
2   __pollwait      Waiting for event (poll)
2   sys_fcntl       FCNTL system call
2   scsi_error_handler  SCSI error handler
2   proc_root_readdir   Reading /proc directory
2   ksoftirqd       Waking ksoftirqd
2   worker_thread       .
2   do_unlinkat     Unlinking file
2   __wait_on_buffer    Waiting for buffer IO to complete
2   pdflush         pdflush() kernel thread
2   kjournald       kjournald() kernel thread
2   blkdev_ioctl        block device IOCTL
2   kauditd_thread      kernel audit daemon
2   tty_ioctl       TTY IOCTL
2   __filemap_fdatawrite_range fdatasync system call
2   do_sync_write       synchronous write
2   kthreadd        kthreadd kernel thread
2   usb_port_resume     Waking up USB device
2   usb_autoresume_device   Waking up USB device
2   kswapd          kswapd() kernel thread
2   md_thread       Raid resync kernel thread
2   i915_wait_request   Waiting for GPU command to complete
2   request_module      Loading a kernel module
 
#
3   tty_wait_until_sent Waiting for TTY to finish sending
3   pipe_read       Reading from a pipe
3   pipe_write      Writing to a pipe
3   pipe_wait       Waiting for pipe data
3   read_block_bitmap   Reading EXT3 block bitmaps
3   scsi_execute_req    Executing raw SCSI command
3   sys_wait4       Waiting for a process to die
3   sr_media_change     Checking for media change
3   sr_do_ioctl     SCSI cdrom ioctl
3   sd_ioctl        SCSI disk ioctl
3   sr_cd_check     Checking CDROM media present
3   ext3_read_inode     Reading EXT3 inode
3   htree_dirblock_to_tree  Reading EXT3 directory htree
3   ext3_readdir        Reading EXT3 directory
3   ext3_bread      Synchronous EXT3 read
3   ext3_free_branches  Unlinking file on EXT3
3   ext3_get_branch     Reading EXT3 indirect blocks
3   ext3_find_entry     EXT3: Looking for file
3   __ext3_get_inode_loc    Reading EXT3 inode
3   ext3_delete_inode   EXT3 deleting inode
3   sync_page       Writing a page to disk
3   tty_poll        Waiting for TTY data
3   tty_read        Waiting for TTY input
3   tty_write       Writing data to TTY
3   update_atime        Updating inode atime
3   page_cache_sync_readahead   Pagecache sync readahead
3   do_fork         Fork() system call
3   sys_mkdirat     Creating directory
3   lookup_create       Creating file
3   inet_sendmsg        Sending TCP/IP data
3   tcp_recvmsg     Receiving TCP/IP data
3   link_path_walk      Following symlink
3   path_walk       Walking directory tree
3   sys_getdents        Reading directory content
3   unix_stream_recvmsg Waiting for data on unix socket
3   ext3_mkdir      EXT3: Creating a directory
3   journal_get_write_access    EXT3: Waiting for journal access
3   synchronize_rcu     Waiting for RCU
3   input_close_device  Closing input device
3   mousedev_close_device   Closing mouse device
3   mousedev_release    Closing mouse device
3   mousedev_open       Opening mouse device
3   kmsg_read       Reading from dmesg
3   sys_futex       Userspace lock contention
3   do_futex        Userspace lock contention
3   vt_waitactive       vt_waitactive IOCTL
3   acquire_console_sem Waiting for console access
3   filp_close      Closing a file
3   sync_inode      (f)syncing an inode to disk
3   ata_exec_internal_sg    Executing internal ATA command
3   writeback_inodes    Writing back inodes
3   ext3_orphan_add     EXT3 adding orphan
3   ext3_mark_inode_dirty   EXT3 marking inode dirty
3   ext3_unlink         EXT3 unlinking file
3   ext3_create     EXT3 Creating a file
3   log_do_checkpoint   EXT3 journal checkpoint
3   generic_delete_inode    Deleting an inode
3   proc_delete_inode   Removing /proc file
3   do_truncate     Truncating file
3   sys_execve      Executing a program
3   journal_commit_transaction  EXT3: committing transaction
3   __stop_machine_run  Freezing the kernel (for module load)
3   sys_munmap      unmapping memory
3   sys_mmap        mmaping memory
3   sync_buffer     Writing buffer to disk (synchronous)
3   inotify_inode_queue_event   Inotify event
3   proc_lookup     Looking up /proc file
3   generic_make_request    Creating block layer request
3   get_request_wait    Creating block layer request
3   alloc_page_vma      Allocating a VMA
#3  __d_lookup      Looking up a dentry
3   blkdev_direct_IO    Direct block device IO
3   sys_mprotect        mprotect() system call
3   shrink_icache_memory    reducing inode cache memory footprint
3   vfs_stat_fd     stat() operation
3   cdrom_open      opening cdrom device
3   sys_epoll_wait      Waiting for event (epoll)
3   sync_sb_inodes      Syncing inodes
3   tcp_connect     TCP/IP connect
3   ata_scsi_ioctl      ATA/SCSI disk ioctl
3   do_rmdir        Removing directory
3   vfs_rmdir       Removing directory
3   sys_flock       flock() on a file
3   usbdev_open     opening USB device
3   lock_kernel     Big Kernel Lock contention
3   blk_execute_rq      Submitting block IO
3   scsi_cmd_ioctl      SCSI ioctl command
3   acpi_ec_transaction ACPI hardware access
3   journal_get_undo_access Waiting for EXT3 journal undo operation
3   i915_irq_wait       Waiting for GPU interrupt
3   i915_gem_throttle_ioctl Throttling GPU while waiting for commands
 
#
#
5   do_page_fault       Page fault
5   handle_mm_fault     Page fault
5   filemap_fault       Page fault
5   sync_filesystems    Syncing filesystem
5   sys_nanosleep       Application requested delay
5   sys_pause       Application requested delay
5   evdev_read      Reading keyboard/mouse input
5   do_fsync        fsync() on a file (type 'F' for details)
5   __log_wait_for_space    Waiting for EXT3 journal space
延迟原因非常的详细.

本来到这里,我要介绍的要介绍了,但是且慢,由于这个东西要在2.6.26后的系统上使用,我们的线上系统大部分是RHEL 5U4, 2.6.18的, 我们如何使用呢?

这时候 systemtap 一如既往的前来救助了!

systemtap 1.4版本以后带了个latencytop.stp, 也是intel的贡献. 那我们试验下穷人家的latencytop.
它在那里呢?

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
$ uname -r
2.6.18-164.el5
 
$ stap -V
Systemtap translator/driver (version 1.5 /0.137 non-git sources)
Copyright (C) 2005-2011 Red Hat, Inc. and others
This is free software; see the source for copying conditions.
enabled features: AVAHI LIBRPM LIBSQLITE3 NSS BOOST_SHARED_PTR TR1_UNORDERED_MAP NLS
 
$ ls -al /usr/share/doc/systemtap/examples/profiling/latencytap.stp 
-rwxr-xr-x 1 chuba users 16240 Feb 17 22:02/usr/share/doc/systemtap/examples/profiling/latencytap.stp 
 
$ sudo stap -t --all-modules /usr/share/doc/systemtap/examples/profiling/latencytap.stp 
ERROR: Skipped too many probes, check MAXSKIPPED or try again with stap -t for more details.
WARNING: Number of errors: 0, skipped probes: 101
WARNING: Skipped due to global 'dequeue' lock timeout: 2
WARNING: Skipped due to global 'this_sleep' lock timeout: 99
----- probe hit report: 
kernel.trace("deactivate_task")!, (/usr/share/doc/systemtap/examples/profiling/latencytap.stp:47:1), hits: 254, cycles: 680min/43327avg/2248467max, from: kernel.trace("deactivate_task")
kernel.trace("activate_task")!, (/usr/share/doc/systemtap/examples/profiling/latencytap.stp:58:1), hits: 255, cycles: 890min/502549avg/2271568max, from: kernel.trace("activate_task")
kernel.function("finish_task_switch@kernel/sched.c:1969")?, (/usr/share/doc/systemtap/examples/profiling/latencytap.stp:78:7), hits: 509, cycles: 213min/1002207avg/5382852max, from: kernel.function("finish_task_switch") from: scheduler.cpu_on
begin, (/usr/share/doc/systemtap/examples/profiling/latencytap.stp:123:1), hits: 1, cycles: 1802min/1802avg/1802max, from: begin
begin, (/usr/share/doc/systemtap/examples/profiling/latencytap.stp:131:1), hits: 1, cycles: 227979min/227979avg/227979max, from: begin
Pass 5: run failed.  Try again with another '--vp 00001' option.
出错了！ 原因是lock timeout, 原来stap的全局变量是用锁保护的，现在超时了！知道原因好办，打个patch吧！

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
$ diff -up translate.cxx.orig  translate.cxx         
--- translate.cxx.orig     2011-03-22 21:26:52.000000000 +0800
+++ /translate.cxx     2011-03-29 20:31:28.000000000 +0800
@@ -5802,10 +5802,10 @@ translate_pass (systemtap_session& s)
       s.op->newline() << "#define MAXACTION_INTERRUPTIBLE (MAXACTION * 10)";
       s.op->newline() << "#endif";
       s.op->newline() << "#ifndef TRYLOCKDELAY";
-      s.op->newline() << "#define TRYLOCKDELAY 10 /* microseconds */";
+      s.op->newline() << "#define TRYLOCKDELAY 50 /* microseconds */";
       s.op->newline() << "#endif";
       s.op->newline() << "#ifndef MAXTRYLOCK";
-      s.op->newline() << "#define MAXTRYLOCK 100 /* 1 millisecond total */";
+      s.op->newline() << "#define MAXTRYLOCK 500 /* 1 millisecond total */";
       s.op->newline() << "#endif";
       s.op->newline() << "#ifndef MAXMAPENTRIES";
       s.op->newline() << "#define MAXMAPENTRIES 2048";
 
#编译安装后再来一次
$ sudo stap  --all-modules /usr/share/doc/systemtap/examples/profiling/latencytap.stp   
ERROR: probe overhead exceeded threshold
WARNING: Number of errors: 1, skipped probes: 0
Pass 5: run failed.  Try again with another '--vp 00001' option.
 
#又错了,这次原因是probe overhead exceeded threshold, 看下代码我们知道，脚本的开销太大了，超过正常的负载，通过查看代码可以用STP_NO_OVERLOAD来解除这个限制
 
#再来一次
$ sudo  stap -DSTP_NO_OVERLOAD --all-modules -DMAXSKIPPED=1024 /usr/share/doc/systemtap/examples/profiling/latencytap.stp 
 
Reason                                  Count  Average(us)  Maximum(us) Percent%
Userspace lock contention                 345     16409195     83258717      45%
                                         1453       867513     60231852      10%
                                           95      7391754     33821926       5%
migration() kernel thread                1733       402701      3571412       5%
                                         7239        87993       401552       5%
Reading from a pipe                       212      2922207     52151180       4%
                                          142      2267850     17990214       2%
                                          108      2457247      7494331       2%
Waking ksoftirqd                           16     16082822     59266312       2%
Waiting for event (select)                 99      2113310     28510974       1%
kjournald() kernel thread                 148      1313447     13983084       1%
Application requested delay                94      1059898     10011409       0%
                                           41      2391993      7618788       0%
Waiting for event (select)                 38      2259444     29057362       0%
                                          719        92947       584944       0%
Waiting for event (poll)                    1     57582711     57582711       0%
Application requested delay                 3     19030709     36000553       0%
Waiting for event (select)                 39      1341880      5847683       0%
                                           34       936628      6649350       0%
                                            5      6163603     10008484       0%
...
这次看到结果了，哈哈，小高兴一把。但是在繁忙的系统上这个脚本的资源占用特别多，也是不爽的。 幸运的是这个脚本支持查看某个进程的延迟情况， 就是在 latencytap.stp 后面加个-x 参数。

这个脚本设计应该是支持进程ID, 但是结果写成了线程ID，属于bug！！！

动手改下吧：

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
$ diff -u latencytap.stp.orig  latencytap.stp  
---  latencytap.stp.orig    2011-02-17 22:02:40.000000000 +0800
+++ latencytap.stp     2011-03-29 20:43:51.000000000 +0800
@@ -15,7 +15,7 @@
 global this_sleep;
 global debug = 0;
  
-function log_event:long (p:long) { return (!traced_pid || traced_pid == p) }
+function log_event:long (p:long) { return (!traced_pid || traced_pid == task_pid(p)) }
  
 #func names from hex addresses
 function func_backtrace:string (ips:string)
@@ -50,14 +50,14 @@
   # check to see if task is in appropriate state:
   # TASK_INTERRUPTIBLE      1
   # TASK_UNINTERRUPTIBLE    2
-  if (log_event($p->pid) && (s & 3)) {
+  if (log_event($p) && (s & 3)) {
     dequeue[$p] = gettimeofday_us();
   }
 }
  
 probe kernel.trace("activate_task") !,
       kernel.function("activate_task") {
-  if (!log_event($p->pid)) next
+  if (!log_event($p)) next
  
   a = gettimeofday_us()
   d = dequeue[$p]
 
#再来一次
$ sudo stap  --all-modules /usr/share/doc/systemtap/examples/profiling/latencytap.stp -x $$
...
这下终于爽了，旧内核用systemtap版本的，新内核用内核版本的，世界和谐！

通过对线上MySQL的诊断发现大部分时间花在mutex锁的竞争上来，我说过了，我会收拾你的，等着瞧！

玩得开心！

latencytop systemtap
This entry was posted by 褚霸 on 2011年03月30日 at 11:07, and is filed under Linux开发, Performance. Follow any responses to this post through RSS 2.0. You can leave a response or trackback from your own site.
8 comments

Raymond (918 天)
绝对的好工具，我们也碰到过线程太多性能下降的问题，未分析这么深入，谢谢分享的如此详细。

 
ydzhang (912 天)
的确是个好东西，学习了，一直关注着淘宝核心系统团队博客，希望这次能顺利通过淘宝的实习生招聘，暑假去淘宝实习。

 
yegle (891 天)
加个语法高亮，或者至少用等宽字体显示啊…

Microsoft Office Home And Student 2010 (680 天)
Microsoft Office Home And Student 2010…

[...]淘宝核心系统团队博客 | latencytop深度了解你的Linux系统的延迟[...]…

Reply ↓

rinehart (304 天)
有oprofile为什么还需要这个呢

 
褚霸 (304 天)
oprofile测量的是CPU的消耗，而不是你的系统调用或者业务本身的时间消耗，比如说锁等待的时间。

麦子麦--DBWinds – Linux Tracing Tools — Soap opera? (138 天)
[...] latencytop深度了解你的Linux系统的延迟 [...]

Reply ↓

qwer (69 天)
推荐未来的主流工具perf

发表评论
电子邮件地址不会被公开。 必填项已用 * 标注

姓名 * 

电子邮件 * 

站点

评论

您可以使用这些 HTML 标签和属性： <a href="" title=""> <abbr title=""> <acronym title=""> <b> <blockquote cite=""> <cite> <code> <del datetime=""> <em> <i> <q cite=""> <strike> <strong>


标签
beanstalkd BugFix cache CDN CPU epoll flashcache gdb http InnoDB kvm L1 Linux memcached mysql OceanBase overview pstack qemu redis Sheepdog smp ssd systemtap Tair tcp TFS traffic server unix 主从同步 事务 代理 分布式架构 分析 多线程 夸父 对象 开发模式 开源 指南 算法 管理员 缓存 网络 虚拟化
分类目录
BugFix
Cassandra
CDN
Dynamo
hypertable
JVM
Linux开发
mysql
OceanBase
Performance
Tair
Tengine
TFS
优化
分布式架构
底层架构
开发模式
数据库
未分类
算法
功能
登录
文章 RSS
评论 RSS
WordPress.org
成员个人博客
丁奇个人博客
三百个人博客
伯松个人博客
千石个人博客
华庭个人博客
叔度个人博客
坤谷个人博客
撒迦个人博客
日照个人博客
李子个人博客
正祥个人博客
永攀个人博客
茂七个人博客
褚霸个人博客
雕梁个人博客
淘宝其他官方博客
淘宝DBA
淘宝JAVA中间件
淘宝UED
淘宝招聘
淘宝搜索技术博客
淘宝数据平台
淘宝质量保障
淘宝核心系统团队博客 © 2011 | Powered by WordPress and Mystique theme by digitalnature 
22 queries in 0.54 seconds (23.70M)
========== https://code.google.com/p/aviator/ ==========
========== http://linux.gov.cn/ ==========
Access forbidden!

You don't have permission to access the requested directory. There is either no index document or the directory is read-protected.

If you think this is a server error, please contact the webmaster.

Error 403

linux.gov.cn
Fri Oct 4 18:23:37 2013
Apache
========== http://wiki.ubuntu.org.cn/%E9%A6%96%E9%A1%B5 ==========
Ubuntu
Forum
Wiki
Linux
Blog
Paste
Chat
搜索     
页面
讨论
查看源代码
历史
简体
繁体
 

导航
首页
最近更改
随机页面
页面分类
帮助
编辑
编辑指南
沙盒
当前事件
字词处理
工具箱
链入页面
链出更改
所有特殊页面
个人工具
登录
首页
欢迎来到 wiki.ubuntu.org.cn——Ubuntu 中文 Wiki 
请尽量将你的文章编入“站点导航”中
本Wiki现在有2,125篇文章


关于Wiki|   关于 Ubuntu |   获取 Ubuntu |   社区行为准则 |   wiki页面分类 |   帮助＆支持 |   参与＆开发

热点条目
Ubuntu 10.04 速配指南
Ubuntu 技巧
中文输入法
Flash 乱码
软件推荐
Linux不是Windows
网站架设服务
Ubuntu VPS 指南 
热点排行榜...
站点导航
	入门指引	系统安装	速配指南	FC杂志	经典资讯	
	网络应用	影音图像	娱乐游戏	环境模拟	其它应用
	源列表	系统维护	硬件支持	中文支持	系统安全
	桌面美化	主流桌面	其他桌面	
	脚本语言	编程语言	编译打包	软件翻译	嵌入式
	基本服务	网站架设	后台数据	


Ubuntu 中文站点是关于 Ubuntu Linux 的中文支持站点，是 Ubuntu 官方所认可的社区之一，担负发行版中文翻译、开发、以及提供本地化支持的职能。
Ubuntu 中文 Wiki 是一个为 Ubuntu Linux 编写文档的 Wiki 站点。它属于非盈利性的，我们在这里创作、改进、收集和整理 Ubuntu 相关的中文文档。也可以参与我们的翻译，可以点击帮助了解相关信息。
假如必要与他人交流获得问题解答（请作为最后选项，既然您已经来了这里 :P），请参见建议的交流方法。
     wiki.ubuntu.org.cn  forum.ubuntu.org.cn
1个分类: 入门
此页面已被浏览过3,732,314次。
此页由atsivsucks于2013年4月23日 (星期二) 13:53的最后更改。 在cat650、qiii2006和s217049、Ubuntu中文用户Luojie-dune和其他的工作基础上。 关于Ubuntu中文	 免责声明

========== http://linux.chinaitlab.com/special/linuxcom/ ==========


　　Linux虽然是免费的，但它的确是一个非常优秀的操作系统，与MS－WINDOWS相比具有可靠、 稳定、速度快等优点,且拥有丰富的根据UNIX版本改进的强大功能。下面，作为一个典型的DOS 和WINDOWS用户，让我们一起来学习Linux的一些主要命令，希望大家能尽快进入到Linux的世界里，成为玩转Linux高手.....[电子版下载] 　<<编者：YOYO>>
温馨提示：按 Ctrl+F 快速查找
　
cat
chattr
chgrp
chmod
chown
cksum
cmp
diff
diffstat
file
find
git
gitview
indent
cut
ln
less
locate
isattr
mattrib
mc
mdel
mdir
mktemp
more
mmove
mread
mren
mtools
mtoolstest
mv
od
paste
patch
rcp
rm
slocate
split
tee
tmpwatch
touch
umask
which
cp
in
mcopy
mshowfat
rhmask
whereis
　
cd
df
dirs
du
edquota
eject
mcd
mdeltree
mdu
mkdir
mlabel
mmd
mrd
mzip
pwd
quota
mount
mmount
rmdir
rmt
stat
tree
umount
ls
quotacheck	quotaoff	lndir	repquota	quotaon	 
 	 	 	 	 	 
　
col
colrm
comm
csplit
ed
egrep
ex
fgrep
fmt
fold
grep
ispell
jed
joe
join
look
mtype
pico
rgrep
sed
sort
spell
tr
expr
uniq
wc
　
lprm
lpr
lpq
lpd
bye
ftp
uuto
uupick
uucp
uucico
tftp
ncftp
ftpshut	ftpwho	ftpcount	 	 	 
　
badblocks
cfdisk
dd
e2fsck
ext2ed
fsck
fsck
fsconf
fdformat
hdparm
mformat
mkbootdisk
mkdosfs
mke2fs
mkfs.ext2
mkfs.msdos
mkinitrd
mkisofts
mkswap
mpartition
swapon
symlinks
sync
mbadblocks
mkfs
fsck.ext2	fdisk	losetup	mkfs	sfdisk
swapoff
　
apachectl
arpwatch
dip
getty
mingetty
uux
telnet
uulog
uustat
ppp-off
netconfig
nc
httpd
ifconfig
minicom
mesg
dnsconf
wall
netstat
ping
pppstats
samba
setserial
talk
traceroute
tty
newaliases
uuname
netconf
write
statserial	efax	pppsetup	tcpdump	ytalk	cu
smbd
testparm
smbd
smbclient	
shapecfg
 
　
adduser	chfn	useradd	date	exit	finger
fwhois	sleep	suspend	groupdel	groupmod	halt
kill	last	lastb	login	logname	logout
ps	nice	procinfo	top	pstree	reboot
rlogin	rsh	sliplogin	screen	shutdown	rwho
sudo	gitps	swatch	tload	logrotate	kill
uname	chsh	userconf	userdel	usermod	vlock
who	whoami	whois	newgrp	renice	su
skill	w	id	free	 	 
　
reset	clear	alias	dircolors	aumix	bind
chroot	clock	crontab	declare	depmod	dmesg
enable	eval	export	pwunconv	grpconv	rpm
insmod	kbdconfig	lilo	liloconfig	lsmod	minfo
set	modprobe	ntsysv	moouseconfig	passwd	pwconv
rdate	resize	rmmod	grpunconv	modinfo	time
setup	sndconfig	setenv	setconsole	timeconfig	ulimit
unset	chkconfig	apmd	hwclock	mkkickstart	fbset
unalias	
SVGAText Mode	
　
ar	bunzip2	bzip2	bzip2recover	gunzip	unarj
compress	cpio	dump	uuencode	gzexe	gzip
lha	restore	tar	uudecode	unzip	zip
zipinfo	 	 	 	 	 
　
setleds	loadkeys	rdev	dumpkeys	MAKEDEV	 
 	 	 	 	 	 
 	 	 	 	 	 
 	 	 	 	 	 
　　精彩专题
　　　　 　　　



========== http://hi.baidu.com/edeed/blog/item/e3eba40f227021e6ab6457bf.html ==========

相册广场游戏登录注册关注此空间
骨骨学习笔记
Oracle,MySQL,NoSQL,Linux and Life
2010-03-02 13:06 Linux 下 strace 命令用法总结(一)
1 功能说明
strace 命令是一种强大的工具, 能够显示任何由用户空间程式发出的系统调用. strace 显示这些调用的参数并返回符号形式的值. strace 从内核接收信息, 而且无需以任何特别的方式来构建内核. strace 的每一行输出包括系统调用名称, 然后是参数和返回值.
下面记录几个常用option:
-f -F选项告诉strace同时跟踪fork和vfork出来的进程
-o xxx.txt 输出到某个文档. 
-e execve 只记录 execve 这类系统调用.

2 详细用法
usage: strace [-dffhiqrtttTvVxx] [-a column] [-e expr] ... [-o file]
              [-p pid] ... [-s strsize] [-u username] [-E var=val] ...
              [command [arg ...]]
   or: strace -c [-e expr] ... [-O overhead] [-S sortby] [-E var=val] ...
              [command [arg ...]]
-c -- count time, calls, and errors for each syscall and report summary
-f -- follow forks, -ff -- with output into separate files
-F -- attempt to follow vforks, -h -- print help message
-i -- print instruction pointer at time of syscall
-q -- suppress messages about attaching, detaching, etc.
-r -- print relative timestamp, -t -- absolute timestamp, -tt -- with usecs
-T -- print time spent in each syscall, -V -- print version
-v -- verbose mode: print unabbreviated argv, stat, termio[s], etc. args
-x -- print non-ascii strings in hex, -xx -- print all strings in hex
-a column -- alignment COLUMN for printing syscall results (default 40)
-e expr -- a qualifying expression: option=[!]all or option=[!]val1[,val2]...
   options: trace, abbrev, verbose, raw, signal, read, or write
-o file -- send trace output to FILE instead of stderr
-O overhead -- set overhead for tracing syscalls to OVERHEAD usecs
-p pid -- trace process with process id PID, may be repeated
-s strsize -- limit length of print strings to STRSIZE chars (default 32)
-S sortby -- sort syscall counts by: time, calls, name, nothing (default time)
-u username -- run command as username handling setuid and/or setgid
-E var=val -- put var=val in the environment for command
-E var -- remove var from the environment for command

3 参数说明
-c 统计每一系统调用的所执行的时间,次数和出错的次数等.
-d 输出strace关于标准错误的调试信息.
-f 跟踪由fork调用所产生的子进程.
-ff 如果提供-o filename,则所有进程的跟踪结果输出到相应的filename.pid中,pid是各进程的进程号.
-F 尝试跟踪vfork调用.在-f时,vfork不被跟踪.
-h 输出简要的帮助信息.
-i 输出系统调用的入口指针.
-q 禁止输出关于脱离的消息.
-r 打印出相对时间关于每一个系统调用.
-t 在输出中的每一行前加上时间信息.
-tt 在输出中的每一行前加上时间信息,微秒级.
-ttt 微秒级输出,以秒了表示时间.
-T 显示每一调用所耗的时间.
-v 输出所有的系统调用.一些调用关于环境变量,状态,输入输出等调用由于使用频繁,默认不输出.
-V 输出strace的版本信息.
-x 以十六进制形式输出非标准字符串.
-xx 所有字符串以十六进制形式输出.
-a column 设置返回值的输出位置.默认 为40.
-e expr 指定一个表达式,用来控制如何跟踪.格式如下:
[qualifier=][!]value1[,value2]...
qualifier只能是 trace,abbrev,verbose,raw,signal,read,write其中之一.value是用来限定的符号或数字.默认的 qualifier是 trace.感叹号是否定符号.例如-eopen等价于 -e trace=open,表示只跟踪open调用.而-etrace!=open表示跟踪除了open以外的其它调用.有两个特殊的符号 all 和 none. 注意有些shell使用!来执行历史记录里的命令,所以要使用\\.
-e trace=set 只跟踪指定的系统调用.例如:-e trace=open,close,rean,write表示只跟踪这四个系统调用.默认的为set=all.
-e trace=file 只跟踪有关文件操作的系统调用.
-e trace=process 只跟踪有关进程控制的系统调用.
-e trace=network 跟踪与网络有关的所有系统调用.
-e strace=signal 跟踪所有与系统信号有关的系统调用.
-e trace=ipc 跟踪所有与进程通讯有关的系统调用.
-e abbrev=set 设定strace输出的系统调用的结果集.-v 等与 abbrev=none.默认为abbrev=all.
-e raw=set 将指定的系统调用的参数以十六进制显示.
-e signal=set 指定跟踪的系统信号.默认为all.如 signal=!SIGIO(或者signal=!io),表示不跟踪SIGIO信号.
-e read=set 输出从指定文件中读出的数据.例如-e read=3,5
-e write=set 输出写入到指定文件中的数据.
-o filename 将strace的输出写入文件filename
-p pid 跟踪指定的进程pid.
-s strsize 指定输出的字符串的最大长度.默认为32.文件名一直全部输出.
-u username 以username 的UID和GID执行被跟踪的命令.

--End--
#Linux
分享到： 浏览(2482) 评论 转载
你可能也喜欢

 
Mansory 改装La Revoluzione
 
Hennessey 推出迈凯轮MP4-12C HPE700改装
 
1972 Bugazzi Custom Coupe
 
2013款本田CR-Z
 
Opel Monza 鸥翼概念车华丽亮相法兰克福
 
保时捷Panamera动力外观改装
 
Linux下很全面的监控工具dstat
本文最近访客

 
silverxinger
8月15日
 
wulujia
6月22日
 
sqxxr
6月9日
 
枫灵雪月
6月7日
 
jcx2bd
5月9日
 
biao060798
10月22日
评论

 发布 
帮助中心 | 空间客服 | 投诉中心 | 空间协议
©2013 Baidu

百度空间，让世界发现你
向世界展示自己，发布喜爱的图片、文字和音乐
简单注册登录

========== http://linux.sheup.com/ ==========
Linux教程网
首页基础知识Linux业界Linux系统Linux人物Linux文化Linux资讯Linux综合当前位置：Linux教程网 - linux安装教程，linux命令大全，linux使用教程 超准，2013年（蛇年）流年运势大师详批！ Linux教程网 

 
linux常用命令大全
linux教程网收集整理了部分linux常用命令编撰成这一部linux命令大全，我们通常使用的linux 关机命令、linux 重启命令、linux 删除命令、linux ftp 命令、linux 压缩命令、linux 复制命令 在这里都可以找到。键入ctrl+f即可快速搜索Linux命令。 linux常用命令：bzip2linux常用命令：bunzip2linux常用命令：arlinu
分类：指令大全 查阅全文
linux命令：bzip2
bzip2 功能说明：.bz2文件的压缩程序。语　　法：bzip2 [-cdfhkLstvVz][--repetitive-best][--repetitive-fast][- 压缩等级][要压缩的文件]补充说明：bzip2采用新的压缩演算法，压缩效果比传统的LZ77/LZ78压缩演算法来得好。若没有加上任何参数，bz
分类：指令大全 查阅全文
linux命令：bunzip2
bunzip2 功能说明：.bz2文件的解压缩程序。语　　法：bunzip2 [-fkLsvV][.bz2压缩文件]补充说明：bunzip2可解压缩.bz2格式的压缩文件。bunzip2实际上是bzip2的符号连接，执行bunzip2与bzip2 -d的效果相同。参　　数：　-f或--force 　解压缩时，
分类：指令大全 查阅全文
linux命令：ar
ar 功能说明：建立或修改备存文件，或是从备存文件中抽取文件。语　　法：ar[-dmpqrtx][cfosSuvV][a<成员文件>][b<成员文件>][i<成员文件>][备存文件][成员文件]补充说明：ar可让您集合许多文件，成为单一的备存文件。在备存文件中，所有成员文件皆保有原来的属性与权限。参　　
分类：指令大全 查阅全文
linux命令：yes
1.命令说明输出回应的字符串。yes回应“y”字符，后者指定字符。 2.路径/usr/bin/yes 3.语法yes [--help] [--version] string 4.参数--help 显示帮助字符。 --version 显示版本信息 5.相关命令无 6.举例说明[root@bixuan/]#yes "OK" //回应“OK”字符串。命
分类：指令大全 查阅全文
linux命令：xlsfonts
xlsfonts 功能说明：列出X Server使用的字体。语　　法：xlsfonts [-1Clmou][-display<主机名称或IP地址>:<显示器编号>][-fn<范本样式>][-ll][-lll][-n<显示栏位数>][-w<每列字符数>]补充说明：执行xls
分类：指令大全 查阅全文
linux命令：xlsclients
xlsclients 功能说明：列出显示器中的客户端应用程序。语　　法：xlsclients [-al][-display<显示器编号>][-m<最大指令长度>]补充说明：执行xlsclients指令可列出某个显示器中，正在执行的客户端应用程序信息。参　　数：  -a  &nb
分类：指令大全 查阅全文
linux命令：xlsatoms
xlsatoms 功能说明：列出X Server定义的成分。语　　法：xlsatoms [-display<显示器编号>][-format<输出格式>][-name<成分名称>][-range<列表范围>]补充说明：执行xlsatoms指令会列出X Server内部所有定义
分类：指令大全 查阅全文
linux命令：XF86Setup
XF86Setup 功能说明：设置XFee86。语　　法：XF86Setup [-display<主机名称或IP地址>:<显示器编号>][-nodialog][-sync]补充说明：这是Linux系统用来设置XFee86的程序，它会进入图形模式，通过互动操作界面，让用户轻松完成XFee86环境的设置。参　
分类：指令大全 查阅全文
linux命令：Xconfigurator
 Xconfigurator 功能说明：设置XFree86。语　　法：Xconfigurator [--card<显卡型号>][--expert][--help][--hsync"<水平扫描频率>"][-kickstart][--monitor<显示器型号>][--server<
分类：指令大全 查阅全文
linux命令：startx(start X Window)
 startx(start X Window) 功能说明：启动X Window。语　　法：startx [程序][--服务器设置]补充说明：startx为启动X Window的script文件，实际上启动X Window的程序为xinit。参　　数：  
分类：指令大全 查阅全文
linux命令：reconfig
 reconfig 功能说明：转换配置文件。语　　法：reconfig [Xconfig] XF86Config补充说明：reconfig指令能将XFree86 3.1及以前的版本的配置文件，转成新的格式。现今的配置文件XF86Config，存放在/etc或/etc/X11目录下，它的格式包含了更多的
分类：指令大全 查阅全文
linux命令：pppsetup
 pppsetup 功能说明：设置PPP连线。语　　法：pppsetup补充说明：这是Slackware发行版内附程序，它具有互动式的问答界面，让用户轻易完成PPP的连线设置。
分类：指令大全 查阅全文
linux命令：smbclient(samba client)
 smbclient(samba client) 功能说明：可存取SMB/CIFS服务器的用户端程序。语　　法：smbclient [网络资源][密码][-EhLN][-B<IP地址>][-d<排错层级>][-i<范围>][-I<IP地址>][-l<记录文件
分类：指令大全 查阅全文
linux命令：apachectl
 apachectl(Apache control interface) 功能说明：可用来控制Apache HTTP服务器的程序。语　　法：apachectl [configtest][fullstatus][graceful][help][restart][start][status][s
分类：指令大全 查阅全文

姓名打分名字算命	
2013年蛇年星座运势	
免费生辰八字详批	
诸葛测字算命占吉凶
站点导航 Linux教程PhpLinux非技术类指令大全Shell安装启动XwindowKdeGnome输入法类美化汉化网络配置存储备份杂项工具编程技术网络安全内核技术速度优化ApacheEmailFtp服务Cvs服务代理服务Samba域名服务网络过滤其他服务NfsOracleDhcpMysqlLdapRedHat 

 精彩推荐
姓：  名：  
性别：  血型:  
生日：     年
 月   日

Copyright © 2004-2009 Linux教程网 （linux.sheup.com）All rights reserved 版权所有 Version 11.05.14
京ICP备05002479号
========== http://blog.csdn.net/tianlesoftware/article/details/6207380 ==========
您还未登录！|登录|注册|帮助首页业界移动云计算研发论坛博客下载
更多
David Dai -- Focus on Oracle
The important thing in life is to have a great aim ,and the determination to attain it！
目录视图摘要视图订阅
2014年1月微软MVP申请开始啦！      CSDN社区中秋晒福利活动正式开始啦！        专访钟声：Java程序员，上班那点事儿      独一无二的职位：开源社区经理      “说说家乡的互联网”主题有奖征文
 Linux netstat 命令详解
分类： Network 2011-02-25 13:13 2951人阅读 评论(0) 收藏 举报
linuxsocketstcpinternetunixstream
      
       Netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。
       在Internet RFC标准中，Netstat的定义是： Netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。
 
检查2222 端口的相关信息：
[root@singledb ~]# netstat -an |grep 2222
tcp        0      0 :::2222                     :::*                        LISTEN     
tcp        0      0 ::ffff:192.168.3.200:2222   ::ffff:192.168.3.115:53516  ESTABLISHED
      
 
该命令的帮助文档如下：
[root@singledb ~]# netstat -h
usage: netstat [-veenNcCF] [<Af>] -r         netstat {-V|--version|-h|--help}
       netstat [-vnNcaeol] [<Socket> ...]
       netstat { [-veenNac] -I[<Iface>] | [-veenNac] -i | [-cnNe] -M | -s } [delay]
 
        -r, --route                display routing table
        -I, --interfaces=[<Iface>] display interface table for <Iface>
        -i, --interfaces           display interface table
        -g, --groups               display multicast group memberships
        -s, --statistics           display networking statistics (like SNMP)
        -M, --masquerade           display masqueraded connections
        -v, --verbose              be verbose
        -n, --numeric              don't resolve names
        --numeric-hosts            don't resolve host names
        --numeric-ports            don't resolve port names
        --numeric-users            don't resolve user names
        -N, --symbolic             resolve hardware names
        -e, --extend               display other/more information
        -p, --programs             display PID/Program name for sockets
        -c, --continuous           continuous listing
        -l, --listening            display listening server sockets
        -a, --all, --listening     display all sockets (default: connected)
        -o, --timers               display timers
        -F, --fib            display Forwarding Information Base (default)
        -C, --cache                display routing cache instead of FIB
        -T, --notrim               stop trimming long addresses
        -Z, --context              display SELinux security context for sockets
 
  <Iface>: Name of interface to monitor/list.
  <Socket>={-t|--tcp} {-u|--udp} {-S|--sctp} {-w|--raw} {-x|--unix} --ax25 --ipx --netrom
  <AF>=Use '-A <af>' or '--<af>'; default: inet
  List of possible address families (which support routing):
    inet (DARPA Internet) inet6 (IPv6) ax25 (AMPR AX.25)
    netrom (AMPR NET/ROM) ipx (Novell IPX) ddp (Appletalk DDP)
    x25 (CCITT X.25)
      
       在上面的命令里讲了一个参数的意思。 如果想查看更详细的内容，可以使用man命令。 这个可以显示的更详细。
 
 
Netstat的一些常用选项 ：
       netstat -s: 按照各个协议分别显示其统计数据。
       netstat -r: 显示关于路由表的信息。
netstat -a: 显示一个所有的有效连接信息列表.
       netstat -n： 显示所有已建立的有效连接。
 
 
[root@singledb ~]# netstat -a
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address               Foreign Address             State     
tcp        0      0 localhost.localdomain:2208  *:*                         LISTEN        
tcp        0      0 192.168.122.1:domain        *:*                         LISTEN      
tcp        0      0 ::ffff:192.168.3.200:ssh    ::ffff:192.168.3.115:51710  ESTABLISHED
tcp        0      0 ::ffff:192.16:rockwell-csp2 ::ffff:192.168.3.115:53516  ESTABLISHED
udp        0      0 *:48902                     *:*                                    
udp        0      0 192.168.122.1:domain        *:*                                                                      
udp        0      0 *:mdns                      *:*                                    
Active UNIX domain sockets (servers and established)
Proto RefCnt Flags       Type       State         I-Node Path
unix  2      [ ACC ]     STREAM     LISTENING     6166   @ISCSIADM_ABSTRACT_NAMESPACE
unix  28     [ ]         DGRAM                    6709   /dev/log
unix  2      [ ACC ]     STREAM     LISTENING     9022   /dev/gpmctl
unix  2      [ ACC ]     STREAM     LISTENING     6702   /var/run/audispd_events
 
以其中一条做说明：
tcp        0      0 ::ffff:192.168.3.200:ssh    ::ffff:192.168.3.115:51710  ESTABLISHED
 
协议（Proto）：TCP，指是传输层通讯协议。
有关TCP, 可以参考Blog：
       网络七层协议 说明
       http://blog.csdn.net/tianlesoftware/archive/2010/11/16/6012976.aspx
 
Local  Address：::ffff:192.168.3.200:ssh，本地的IP地址，和用于连接的端口， 这里写成ssh了。 指的是SSH 端口。  
Foreign Address： ffff:192.168.3.115:51710， 远程机器的的IP地址和连接的端口。
State：ESTABLISHED。 连接状态。可有一下几种状态：
                     LISTEN  ：在监听状态中。  
                     ESTABLISHED：已建立联机的联机情况。
                     TIME_WAIT：该联机在目前已经是等待的状态。 
 
 
 [root@singledb ~]# netstat -n
Active Internet connections (w/o servers)
Proto Recv-Q Send-Q Local Address               Foreign Address             State     
tcp        0    132 ::ffff:192.168.3.200:22     ::ffff:192.168.3.115:51710  ESTABLISHED
tcp        0      0 ::ffff:192.168.3.200:2222   ::ffff:192.168.3.115:53516  ESTABLISHED
--刚才这里显示的SSH。 现在显示成对应的端口了。
Active UNIX domain sockets (w/o servers)
Proto RefCnt Flags       Type       State         I-Node Path
unix  28     [ ]         DGRAM                    6709   /dev/log
unix  2      [ ]         DGRAM                    1413   @/org/kernel/udev/udevd
unix  2      [ ]         DGRAM                    7379   @/org/freedesktop/hal/udev_event
unix  2      [ ]         DGRAM                    15309 
unix  2      [ ]         DGRAM                    13877 
unix  2      [ ]         DGRAM                    13005 
unix  3      [ ]         STREAM     CONNECTED     12935 
unix  3      [ ]         STREAM     CONNECTED     12934 
unix  2      [ ]         DGRAM                    12930 
 
 
 Netstat -n基本上是-a参数的数字形式，-a 和 －n 是最常用的两个，其中
       （1）-n 显示用数字化主机名，即IP地址
       （2）-n 只显示TCP连接
 
  
[root@singledb ~]# netstat -r
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
192.168.3.0     *               255.255.255.0   U         0 0          0 bond0
192.168.122.0   *               255.255.255.0   U         0 0          0 virbr0
169.254.0.0     *               255.255.0.0     U         0 0          0 bond0
default         192.168.3.1     0.0.0.0         UG        0 0          0 bond0   
 
 
[root@singledb ~]# netstat -s
Ip:
    63105 total packets received
    0 forwarded
    0 incoming packets discarded
    41834 incoming packets delivered
    33322 requests sent out
Icmp:
    1377 ICMP messages received
    0 input ICMP message failed.
    ICMP input histogram:
        destination unreachable: 1377
    1377 ICMP messages sent
    0 ICMP messages failed
    ICMP output histogram:
        destination unreachable: 1377
IcmpMsg:
        InType3: 1377
        OutType3: 1377
Tcp:
    147 active connections openings
    33 passive connection openings
    0 failed connection attempts
    0 connection resets received
    2 connections established
    31684 segments received
    31347 segments send out
    393 segments retransmited
    0 bad segments received.
    0 resets sent
Udp:
    132 packets received
    1 packets to unknown port received.
    0 packet receive errors
    201 packets sent
TcpExt:
    23 TCP sockets finished time wait in fast timer
    7032 delayed acks sent
    10 delayed acks further delayed because of locked socket
    Quick ack mode was activated 8137 times
    2 packets directly queued to recvmsg prequeue.
    2 packets directly received from prequeue
    3496 packets header predicted
    2325 acknowledgments not containing data received
    7805 predicted acknowledgments
    6 times recovered from packet loss due to SACK data
    TCPDSACKUndo: 3
    12 congestion windows recovered after partial ack
    3 TCP data loss events
    5 fast retransmits
    3 retransmits in slow start
    137 other TCP timeouts
    2 sack retransmits failed
    8137 DSACKs sent for old packets
    24 DSACKs received
IpExt:
    InMcastPkts: 36
    OutMcastPkts: 40
    InBcastPkts: 8617
[root@singledb ~]#
 
 
 
 
------------------------------------------------------------------------------
Blog： http://blog.csdn.net/tianlesoftware
网上资源： http://tianlesoftware.download.csdn.net
相关视频：http://blog.csdn.net/tianlesoftware/archive/2009/11/27/4886500.aspx
DBA1 群：62697716(满); DBA2 群：62697977(满)
DBA3 群：62697850   DBA 超级群：63306533;    
聊天 群：40132017
--加群需要在备注说明Oracle表空间和数据文件的关系，否则拒绝申请
分享到： 
上一篇：IP(Internet Protocal) 地址 说明
下一篇：Linux iptables 防火墙 添加删除 端口

 
查看评论

  暂无评论

您还没有登录,请[登录]或[注册]
* 以上用户言论只代表其个人观点，不代表CSDN网站的观点或立场

个人资料
  
Dave
 

访问：4602275次
积分：52114分
排名：第12名
原创：1012篇转载：96篇译文：1篇评论：1548条
文章搜索

Dave's Links
QQ:251097186
Email:tianlesoftware@gmail.com
Skype:tianlesoftware
My LinkedIn
My FaceBook
My Twitter
My Sina Weibo
My Tencent Weibo
LineZing
文章分类
Dave 随笔(40)
Oracle Troubleshooting(187)
My Blog Summary(14)
Tools & Scripts(11)
IBM AIX(35)
Linux(96)
Storage(19)
Network(9)
MySQL(14)
Oracle Exadata(0)
Oracle 12c(1)
Oracle ASM(85)
Oracle Data Guard(38)
Oracle Golden Gate(21)
Oracle RAC(110)
Oracle RMAN(45)
Oracle Stream(2)
Oracle Timesten(0)
Oracle Basic Knowledge(223)
Oracle Advanced Knowledge(190)
Oracle Backup & Recovery(14)
Oracle Developer(22)
Oracle Certification(9)
Oracle Performance(87)
System Architecture(1)
文章存档
2013年09月(1)
2013年08月(6)
2013年07月(8)
2013年06月(5)
2013年05月(1)
展开
国外技术链接
ixora
dioncho
OraDBA
Gavin Soorma
oracle-base
oracle-developer
databasejournal
Julian Dyke
Jonathan Lewis(Oracle Core)
oracle-scripts
oaktable
官网链接
E-Delivery
Oracle Public-Yum
Oracle Documents
MySQL Documents
GG Documents
ORACLE CPU（Critical Patch Update）
Patchset Number Overview
Oracle 10g/11g 下载
Unix-Center
IBM Technical library
IBM 技术知识库
IBM AIX 认证专题
IBM DeveloperWorks
idevelopment
OCM 查询
国内技术链接
warehouse
dbsnake
eygle
冯大辉(Fenng)
HelloDBA
Kamus
骨骨
paul
Roger
Maclean
老 熊
Tomas Zhang
ixora
tianlesoftware
d.c.b.a
xifenfei
Ludatou
robinson1988
简朝阳
mysqlops
数据工人（boypoo）
Jerry Wu
文本时代
d-zero
道道
邓伟
最新评论
Oracle 11g Data Guard 使用duplicate from active database 创建 standby database
liuzhen2090: 不错
Oracle 数据库监听配置
huanghukun: 说的很详细,受教了,谢谢博主.
Dave Oracle 学习 手册 第一版 下载 说明
lhyaoo: Dave辛苦了，这么多的总结性文章花费了大量精力。文章质量相当的高。
Oracle 索引 详解
panchol: 谢谢楼主，好详细，辛苦了
Oracle 11g RAC ohasd failed to start at /u01/app/11.2.0/grid/crs/install/rootcrs.pl line 443 解决方法
Frank_zhao_sprint: @xyk008:在oracle的官方网站上可以下载
Oracle 11g RAC ohasd failed to start at /u01/app/11.2.0/grid/crs/install/rootcrs.pl line 443 解决方法
Frank_zhao_sprint: 非常感谢，采用你的方法我通过了。不过有点问题是虚拟机重启时，不能够自动启动crs，需要强制停止，然后...
RMAN Catalog 和 Nocatalog 的区别
yuefengh: 您好：与您反应一下，RMAN> connect target /;RMAN>register dat...
2013年5月22日 Dave 在深圳
zwl000906: dave，要多运动，约几个朋友一起去打球、跑步等，每周至少一次，且相互约，这样可以有一种驱动力，你就...
Oracle Buffer Cache 原理
yebai: 记录一下。
statspack安装使用 和 report 分析
yebai: 支持一下。
阅读排行
Oracle 字符集的查看和修改(129824)
Linux Crontab 定时任务 命令详解(127528)
Oracle 索引 详解(42633)
Linux awk 命令 说明(38164)
RMAN 备份与恢复 实例(30893)
有关 ORA-00604 错误的总结(30475)
Oracle 分区表 总结(28785)
Oracle AWR（Automatic Workload Repository） 说明(26722)
Redhat 5.4 + ASM + RAW+ Oracle 10g RAC 安装文档(26263)
Oracle ASM 详解(23170)
公司简介|招贤纳士|广告服务|银行汇款帐号|联系方式|版权声明|法律顾问|问题报告
QQ客服 微博客服 论坛反馈 联系邮箱：webmaster@csdn.net 服务热线：400-600-2320
京 ICP 证 070598 号
北京创新乐知信息技术有限公司 版权所有
世纪乐知(北京)网络技术有限公司 提供技术支持
江苏乐知网络技术有限公司 提供商务支持
Copyright © 1999-2012, CSDN.NET, All Rights Reserved 
   
========== http://www.linuxso.com/command/netstat.html ==========
========== http://www.linuxeden.com/ ==========

微信关注我们
随时获取最新开源资讯
	新闻 漫画 软件 论坛 商城 博客 人才 注册 广告 联系 投稿 手机版 RSS 微信  新手 管理 业界 安全 经验 编程 企业 DB 硬件 评论 人物 Unix 前沿 图库 嵌入 茶馆 介绍 团队
 

113年10月4日 星期五

企鹅看世界更多>>
已激活Android机型中有49%正运行果冻豆
硬件免费时代即将到来？
并不是只有三星，几乎所有安卓OEM都作过弊
消息称微软3家大股东施压董事会要盖茨辞职
iPhone5S 将让谷歌变成“更严厉的家长”
廉价镜头也能拍出高质量照片
8款iPhone速度测试 老设备关机更快
当纸媒恐龙领导坐上了App时代高铁
Twitter为何成为美NFL首个社交网络合作伙伴
移动应用分发市场竞争的逻辑
幸福和成功的十条诫律
要闻更多>>
Linux有后门？
[傲游证实：开发Linux版] [Ceylon发布1.0 beta]
[新OpenSUSE的树莓派镜像] [GNOME3.10初步支持Wayland]
开源美图 2013 10 04(04日)
SUSE支持Hyper-V 助力构建混合虚拟云(04日)
布局微服务器 英特尔新8核Atom抢攻DC(04日)
提升用户体验的最佳免费 jQuery 表单插件 (04日)
英特尔为Arduino项目提供Galileo x86芯片(04日)
惠普官员称开源SDN是个错误(03日)
每日文章精选 2013 10 03(03日)
开源美图 2013 10 03(03日)
让内存中的NoSQL数据存储适合企业级应用 (03日)
每日文章精选 2013 10 02(02日)
C++模板”>>”编译问题与词法消歧设(02日)
Ubuntu 13.10不默认使用Mir(02日)
2013 中国谷歌开发者节 去报名吧(02日)
开源美图 2013 10 02(02日)
Spark 配置(02日)
DevOps，你真的了解吗？(02日)
Chrome V31可告诉你网页文字使用的是啥字体(01日)
我的领域中有一位牛仔！(01日)
Symbian帝国兴衰史(01日)
  搜索
一周评分排行

现有的基于统计翻译的在线工具如巴比鱼和Google翻译，翻译的结果[详细]
傲游证实：开发Linux版浏览器覆盖全平
谷歌工程师将语言翻译变成向量空间数学
GNU诞生三十周年
Linux有后门？看Linus在LinuxCon上怎么
编程语言Ceylon发布1.0 beta
版本更新资讯
PrimeFaces 4.0 正式版发布
PyQt 5.1 发布，Qt 库的 Python 版本
TinyMCE 4.0.7 发布，可视化HTML编辑器
pride 1.4.8 发布，Android 开发脚本
phpMyAdmin 4.0.8-rc1 发布
IntelliJ IDEA 12.1.5 发布
Python 2.6.9 RC1 发布
Apache CloudStack 4.2.0 发布
Sencha Touch 2.3 - 触摸表格、新的主
Linux Kernel 3.11.3/3.10.14/3.4.64/3
红帽企业 Linux 发布 5.10 版本
新评	热顶	一周热点	当月热点

观点：对GNU/LINUX越来越失望
随着GNU/Linux的快速发展，各种各样的发行版越来超多，而在用户体验[详细]
开源美图 2013 10 02
Spark 配置
惠普官员称开源SDN是个错误
Ubuntu 13.10不默认使用Mir
硬件免费时代即将到来？
英特尔为Arduino项目提供Galileo x86芯片


Linux有后门？看Linus在LinuxCon上怎么
LinuxCon大会 是北美每年一度的Linux盛事，这里集合了开发者、系统管理员、架构师以及各个水平的技术天才，他们就Linux未来的发展共同商讨教育、合作以及问题的解决之道。 都有[详细]
Valve：游戏的未来必然属于Linux
深度游戏中心发布
Linux 3.12 代号 Suicidal Squirrel
英特尔和RH合作实现Gnome的Wayland支持
英特尔拒绝支持Ubuntu的XMir
技术文章更多>>
Ubuntu下使用PPA安装DPlayer深度影音播放器
Ubuntu下安装DMusic 的百度音乐插件
使用 Shutter 轻松做到网站截图
＂多才多艺”的命令行文件管理器 - CLEX
Ubuntu 下使用PPA 安装深度音乐播放器
Unity Tweak Tool: Ubuntu Unity 配置工具
通过PPA在Ubuntu上安装Appgrid
怎样选择你的最佳商用Linux服务器？
十个最好的ZSH技巧
WinUSB: 在Linux上创建一个Win的可引导的U盘
IT漫画 更多>>
漫画：浏览器战队
漫画：不同人眼中的IT男
漫画：开源世界地图
漫画：他们怎么看
漫画：美好的表象
漫画：大数据浪潮汹涌
漫画：高端程序员
漫画：程序员之歌
漫画：程序猿的理想与现实
漫画：Windows用户进化史
开源人才招聘与求职平台
高薪聘请网络安全工程师
UC研发平台诚邀各路精英
【北京】知名互联网\\电商平台诚聘linu
【广州捷游】诚招手游客户端、页游服务
Nutch:从搜索引擎到网络爬虫---分享公开
高薪聘请网络安全工程师
【广州捷游】诚招手游客户端（c++\\lua
聘请网络安全工程师
高薪聘请网络安全工程师
【广州捷游】广州捷游高薪诚聘erlang、
论坛导航
初级应用->新手入门 | 服务器应用 | 中文化 | 软件使用交流 | 硬件驱动 | 图片秀|茶馆
高级应用->数据库 | 系统安全 | 嵌入式应用
编程开发->C/C++(STL/boost) | 内核 | RAD|Perl/PHP/Python | JAVA/XML | Shell
发行版->Redhat和Fedora | Debian | Gentoo | Slackware/Suse | Mandrake/Mandriva
Unix ->FreeBSD | Solaris | 其他Unix讨论
论坛精华
如果再回到从前——Mandriva 2006
[转贴]菜鸟泡妞利器——打造双系统U盘(
GIMP资源
2010架构师大会（SACC）演讲PPT下载
iptables 高级使用研讨
FAQ系列 持续更新中
Admon第一个版本0.1发布
[原创]电驴下载利器　Mldonkey和sancho
论坛排行	论坛新贴	一周热帖	月度排行
落雨无声
长汀钢琴、声乐表演、舞蹈、主持演讲艺术培训-182
“盲”品特技
2013年10月工作记录（实时更新）
白葡萄酒怎么自制补水面膜？
红酒配绿茶，美味又健康
新焖大虾
linux下的图形界面
香港酒神黄雅历
男人怎样能长寿
精选排行

在Ubuntu 13.04和12.04下安装K
经过开发团队六个月的紧张工作后，KDE [详细]
在Ubuntu 13.04和12.04下安装KDE SC 4.11
ARM：技术平台比英特尔“先进数代”？
励志：陈欧侃的故事
Ansilove/PHP 1.10 发布，ANSi 到 PNG 转换
Python-SIP 4.14 发布
评论更多>>
为什么还有人雇佣糟糕的程序员？
请解决问题，而不是创造点子
鲍尔默最大错误：一味关注谷歌 忽略苹果
10个让你早起的技巧
产品经理如何赢得开发人员的尊重和支持？
挑战无处不在
智能手机专利世界大战：一场无休止的战争
网友观点---Linux困惑：价值观的混乱
Openbiz将引领PHP开源框架的革新
学写代码比学外语更流行？
企业应用更多>>
Coremail邮件系统满足国家科技部应用
Yupoo（又拍网）的系统架构
基于ARM-linux的智能监控系统设计
数据中心交换机的五种主要技术
Linux/Unix下pid文件作用浅析
应用解析：利用Linux和GFS打造集群存储
云计算时代的灾难恢复
Unix迁移Linux三大阶段 移植 升级 测试
新浪微博


PostgreSQL-大象

netbsd

清凉一夏

OpenBSD-安全的河豚

Super Linux
系统初探
新手入门
04日Linux常用命令大全
13日解决 UNetbootin 引导故障
23日初学者必看：Linux压缩那些事儿
31日学习Unix系统必须经过的一关编译内核
31日Linux初学者应该养成的七个使用习惯
21日Linux初学者最常遇到的五个问题
21日Linux系统管理入门必须经历的三步
19日Unix系统操作中命令知识学习之前准备

Node.js初体验

RedHat/CentOS利用iso
使用经验
29日Ubuntu下使用PPA安装DPlayer深度影音播放器
27日Ubuntu下安装DMusic 的百度音乐插件
26日使用 Shutter 轻松做到网站截图
25日＂多才多艺”的命令行文件管理器 - CLEX
25日Ubuntu 下使用PPA 安装深度音乐播放器
24日Ledger-复式记账的一个功能强大的命令行工具
23日Unity Tweak Tool: Ubuntu Unity 配置工具
23日通过PPA在Ubuntu上安装Appgrid

Ubuntu下使用PPA安装D

Ubuntu下安装DMusic
　系统管理
通过 ulimit 改善系统性能
系统自动化配置和管理工具
磁盘分区对齐的重要性
系统管理员需知：25个Linux
修改Linux内核启动图片
CentOS 6.4 中 Vsftpd 解决
Linux下的高精度时间获得与
Linux下定义Windows常用数
高效的使用 top 
Linux下用fdisk进行分区的
Linux SWAP 交换分区配置说
windows和linux双系统删除l
如何修改SuSE Linux的系统
Linux 操作系统PS命令详细
分析并解决Unix操作系统常
轻松的教你Linux磁盘配额配
Linux系统调优参数知多少 
由浅入深
编程开发
23日20个非常棒的扁平设计免费资源
22日函数式编程为何越来越受到重视
03日8个最佳PHP库
15日为什么计数应该从零开始？
14日Web 开发人员需知的 Web 缓存知识
08日DDNS 的工作原理及其在 Linux 上的实现
07日Linux和Windows上流行的脚本语言
31日JavaScript eval(＂050＂)的那些事

20个非常棒的扁平设计

函数式编程为何越来越
数据库类
17日用MYSQL为vsftpd服务器建立虚拟机用户
19日从小型网站到超大规模网站的MySQL参考架构
03日Mysql服务器的主辅数据同步 
14日mysql读写性能测试
10日Erlang+C+Lisp的大数据方案：BugSense
10日利用MySQL日志模拟恢复数据变化轨迹（上）
05日PostgreSQL建立索引如何避免写数据锁定
12日CouchDB是什么？为什么我们要关注它？

用MYSQL为vsftpd服务

从小型网站到超大规模
　系统安全
通过Backtrack Linux 来加
Ubuntu 13.04 用户安装 Mac
详解四种级别Linux服务器入
十大策略助你提升Linux系统
应用安全Linux的企业端口扫
关注认识Linux系统安全基础
Linux系统的病毒历史介绍
安全详解：如何清理Linux内
讲解Unix操作系统UUCP系统
Unix病毒、蠕虫和木马威胁
Unix病毒和蠕虫如何工作
Unix系统中的安全问题
Linux系统安全保护四要领
导致 SELinux 警告的四个常
[信息图]值得注意的 Androi
你可能不知道的 HTTP 协议
通用型安全操作系统解决方
开源世界
开源人物
03日索尼确认PS4将支持语音识别 
12日比尔·盖茨也卖萌
18日佩奇：老把竞争挂在嘴边是愚蠢的
25日李大维的创客文化：开放创新和新山寨
13日Google 拉里·佩奇（Larry Page）访谈录
06日马克·安德森：“精益创业”的三大误区
04日Eric Schmidt明年四月发新书《新数字时代》
28日科技界十大女强人：梅耶尔毫无悬念上榜

索尼确认PS4将支持语

比尔·盖茨也卖萌
Unix家族
02日简单的介绍Unix操作系统病毒机制
28日关于四大Unix操作系统功能简介
06日Unix操作系统怎么去轻松快速复制
06日Unix操作系统中UUCP知识详细讲解
06日Unix操作系统设备驱动程序的基本结构
16日InterNet上常见的Unix系统种类概述
16日深入分析3种Unix服务器的知识
15日学习Unix系统中设备驱动程序的方法

Opensolaris 内核编译

OpenBSD内核编译和优
　硬件相关
怎样在 ubuntu 上安装 Linu
Android开发教程：页面切换
Linux编译声卡驱动
Linux操作系统下安装显卡驱
在RHEL5系统下安装纯文本打
如何解决Linux操作系统找不
Linux kernel2.6.25 CS8900
在SUSE Linux系统下安装ADS
如何在Linux操作系统下配置
解决Intel HD Audio Contro
Redhat Linux系统下双网卡
Linux操作系统下安装声卡驱
在RHEL5服务器系统下双网卡
Linux通过ndiswrapper安装
Ubuntu下NVIDIA驱动安装及3
实用技巧：Linux2.6.18 SD
Linux系统下蓝牙立体声配置
合作媒体

串口服务器 鸿鹄网 KVM切换器 MOXA代理 酷勤网 MOXA FreeBSDChina Linux时代 LUPA开源社区 开源视窗 中国网管联盟 煎蛋网 添翼圈 ExtMail邮件服务器 更多链接
Linuxeden.com Linux伊甸园　　　欢迎批评指正　　　本站云服务由 UCloud提供
联系我们 | 会员注册 | 广告服务
CopyLeft © 1999 - 2011 Linuxeden.com , All Rights Reserved
浙ICP备05047359号 Linux伊甸园　版权所有
========== http://www.linuxcast.net/ ==========
课程
好友
问答
交流
登录 / 注册
全方位的专业 IT 学习、交流及问答平台 
所有视频课程永久免费
25,076 位用户 － 254 个免费视频课程 － 2,633 个技术问答

免费学习
Linux浏览全部 74 个课程

Linux基本操作
课程包含Linux图形界面下的日常操作维护及命令行...
7 个课程14092 人学习

Linux磁盘及文件系统管理
课程包括磁盘基本概念、文件系统的基本概念及分区、文...
4 个课程7250 人学习

Linux下获取帮助
课程包括图形界面及命令行界面下如何获取所使用命令工...
1 个课程4410 人学习

用户及权限基础
课程包括权限的概念及如何管理使用用户及权限系统对进...
3 个课程5124 人学习
数据库浏览全部 11 个课程

MySQL数据库基础
介绍MySQL数据库的安装和配置，SQL语法，My...
10 个课程3836 人学习

Oracle数据库入门基础
讲解Oracle数据库的常见知识、安装、管理及日常...
1 个课程2273 人学习
Web开发浏览全部 68 个课程

Web基本概念
讲解Web、HTTP及网络相关基本概念，已经网站相...
3 个课程934 人学习

HTML语言基础
讲解HTML的语法规则，以及常见HTML标签及其作用。
7 个课程611 人学习

CSS样式
讲解CSS层叠样式表的语法规则，以及如何使用CSS...
5 个课程477 人学习

HTML+Div+CSS 实战项目
综合HTML、CSS和Div布局的知识概念编写一个...
5 个课程642 人学习
移动开发浏览全部 9 个课程

iOS 软件开发入门
苹果iOS是由苹果公司开发的手持设备操作系统。应用...
9 个课程825 人学习

Android 开发基础
Android是一种基于Linux的自由及开放源代...
即将推出
Cisco浏览全部 41 个课程

CCNA - 网络基础
10 个课程987 人学习

CCNA - 路由基础
3 个课程412 人学习

CCNA - 动态路由协议
10 个课程248 人学习

CCNA - 策略及服务
5 个课程229 人学习
学习动态

zxl_kyo 1小时前 学习了：
OSI 七层模型 - 5

阿勇 3分钟前 学习了：
Web服务原理、HTTP协议

yhl 1小时前 学习了：
php-fpm 安装
今日热门问答

求ruby on rails 学习顺序，图书推荐
6小时前 - 1 个回答

centos wifi設置？
7小时前 - 1 个回答

如何搭建c编程环境
昨天00点56分 - 4 个回答

dd之后能进行数据恢复吗？
3小时前 - 1 个回答

linux因为修改了fstab文件启动不了了
6小时前 - 1 个回答

centos启动的时候进度条感觉不好看，怎么设置成默认不用进度条的？
9小时前 - 1 个回答

关于KeyID
4小时前 - 1 个回答
更多问题
「试想这样一幅场景，你可以在地铁上啃注册会计师，在公交车上学 Linux，在排队的间歇学学法律，是不是很美？」

 36氪 - Codecademy Linux 版诞生，国内 IT 培训师推出 Linux 免费在线视频学习及问答网
关于 意见反馈 职位 隐私声明 新浪微博
陕ICP备10204545号 © 2012 - 2013 IterCast，保留所有权利

========== http://www.commandlinefu.com/commands/browse ==========
Hide
What's this?
commandlinefu.com is the place to record those command-line gems that you return to again and again.
Delete that bloated snippets file you've been using and share your personal repository with the world. That way others can gain from your CLI wisdom and you from theirs too. All commands can be commented on, discussed and voted up or down.
If you have a new feature suggestion or find a bug, please get in touch via http://commandlinefu.uservoice.com/
Get involved!
You can sign-in using OpenID credentials, or register a traditional username and password.
OpenIDorSign inRegister
First-time OpenID users will be automatically assigned a username which can be changed after signing in.

 
Hide
Stay in the loop…
Follow the Tweets.

Every new command is wrapped in a tweet and posted to Twitter. Following the stream is a great way of staying abreast of the latest commands. For the more discerning, there are Twitter accounts for commands that get a minimum of 3 and 10 votes - that way only the great commands get tweeted.
» http://twitter.com/commandlinefu
» http://twitter.com/commandlinefu3
» http://twitter.com/commandlinefu10
Subscribe to the feeds.

Use your favourite RSS aggregator to stay in touch with the latest commands. There are feeds mirroring the 3 Twitter streams as well as for virtually every other subset (users, tags, functions,…):
Subscribe to the feed for:
» all commands
» commands with 3 up-votes (commandlinefu3)
» commands with 10 up-votes (commandlinefu10)
Hide
News
2011-03-12 - Confoo 2011 presentation
Slides are available from the commandlinefu presentation at Confoo 2011: http://presentations.codeinthehole.com/confoo2011/
2011-01-04 - Moderation now required for new commands
To try and put and end to the spamming, new commands require moderation before they will appear on the site.
2010-12-27 - Apologies for not banning the trolls sooner
Have been away from the interwebs over Christmas. Will be more vigilant henceforth.
2010-09-24 - OAuth and pagination problems fixed
Apologies for the delay in getting Twitter's OAuth supported. Annoying pagination gremlin also fixed.
Hide
Tags
!!$PATH,Date,NTP.bashrc.bash_profile.svn/dev/mem/dev/null/dev/random/dev/urandom/etc/passwd3232bit6464bit7z7zipa2zfaAccessaccesslogaccess_logackACLacpiactive directoryadbaddaddressaixalarmaliasaliasesalphaalsaAmazonamixeranagramanalysisandroidannoyatronannoyingansiapacheapache2apiaplayaproposaptapt-cacheapt-getapt-keyaptitudearch linuxarch.linuxarchivearchlinuxargumentaria2arithmeticArparp-scanarrayartasciiascii artashaskapacheaspellassemblyasteriskatatomattachmentaudioauthenticationautomaticallyautomationautosshavconvaverageaviawesomeawkawk grepawk, sortbackgroundbackupbandwidthbangbannerbase64basenamebashbash .svnbash String Manipulationsbash tricksbashrcbash_historybatchbatch renameBatch Utilitiesbatterybcbc -lbeautifulbeautifybeepbellbenchmarkbgbinarybinary clockbindBIOSblkidblockblockdevbluetoothBOFHbookmarksbootboxeebranchbranchesbreakbrewbrightboxbrightnessbroken linksbrowserbsdbufferbuildbuilt-inbuiltinbzip2bzip2, gzip, compression,C ProgrammingC/C++cachecalcalccalculationcalculatorcalibrecanoncapistranocapitalizecapslockcapturecasecatcczecdCDDAcdmacdrdaocdromcentoscertificatechangecharacterscheckchecksumcheck_diskchgrpchmodchownchromechromiumcifsciphercitrixcleancleaningclearcliclientsclipboardclockcloudcmdcmdlinecmpcobblercodecode pointscodeccolcolorcolordiffcolorizecolorscolortestcolumnCOLUMNScomiccommandcommandlinefucommandlinefu.comcommentcommitcomparecompilecompletioncompresscompressionconffilesconfigconnectionconnectionsconsolecontactscontentconversionconvertconvertercookiescopycopy pastecopy progresscorruptcountcountercowsaycpcpancpiocpucpu usagecpuinfocpulimitcrashcrimsonfucronjobcrontabcryptcshcssCSVcurlcutcvscwdcygpathcygwindaemondangerousdarwindashdata sinkdatabasedateDate manipulationdatesDB2dbusdbus-senddcddddosdebconfDebiandebugdecimaldeclarededuplicatedefaultdefunctdelaydeletedeleteddeliciousdevelopmentdevfsdevicedevicesdfdiagnosticdicewaredictionariesdictionarydictionary.comdiffdigdigitdirectoriesdirectorydirectory size,dudirnamediscogsdiskdisk quotadisk sizedisk spacedisk usagedisplaydistributiondistrodivxdmenudmgdmidecodednsdodockdomain namedonedosdotdotfilesdowndownloaddownvotesdpkgdpkg-querydrivedrivespacedropboxdsmemberutildudummy file, null file, test filedumpduplicateduplicate directoriesduplicate directorydvdeaster-eggebookebuildebuildsEC2echoeclipseededitegrepeixemacsemailemergeemptyemulatorencodingEncryptionEnglishenscriptentropyenvenvironenvironmenteolepochepuberrnoerrorescapeescape sequenceeselectespeakesxethtoolevalexcludeexclude binaryexeexecexecutableexecuteexifexiftooleximexitexpandexpansionexpirationexplorer.exeexportexprext3ext4extensionextensionsexternalexternal ipextglobextractfacebookfactorialFATfdfdiskfestivalfetchffmpegffmpeg2theorafgfield separatorfieldsfigletfilefile copfile descriptorfile formatfile renamefile sizefile sizesfile timefile transferfilenamefilepathfilesfilesizeFilesystemfilterfiltered stream feedfindfind textfinderfingerfirefoxfirewallfixfizzbuzzflacflashflipfloating pointflushflush dnsflvfocusfoldfolderfontsforfor loopfor-eachfork bombformatfortunefoundryfreeFreeBSDfriendfstabftpfumanchufunfunctionfunnyfusefuserfuturamaGamegatewaygawkgccgconftoolgdbgenerategeneratorGentoogeographical locationgeoipget website ipgetentgetfaclgettextghostscriptgifgitgithubglobglobalglobstargmailgnomegnome-open .GNU coreutilsGNU findGNU grepgnu screenGNU/Linuxgnuplotgooglegoogle apigoogle calendargoogle readergoogle shortenergoogleclgotoGPGgpsgpsbabelgraphgrepgrep,groupgroupsgrowlgrowlnotifygrubgs,gstreamergtkgtk2GUIgunzipgvimgziphackhalthard diskhard driveharddiskhardwarehashhashcathddhdiutilhdparmHEADhead,headershelphexhexdumphiddenhidehighlighthistogramhistoryhomebrewhomepagehosthostnamehostname to iphostshotkeyhp-uxhtmlhtml2texthtml5httphttpdhttp_codehumanhuman-readablehybridI/Oicmpiconsiconvid3identifyififconfigifconfig.meIFSimageimage galleryImage processingImageMagickimagesimportincrementindentinfoinkscapeinodeinotifyinotifywaitinstallinstalled packagesinstapaperintegerinteractiveinterfaceinternetioioniceiosiostatiotopIPip addressip rangeipadiphoneipodipsiptablesipv4ipv6ircirssiiscsiisoiso9660jarjavajavascriptjob controljobsjoinjokejotjpegjpgjsonjvmkalarmKDEkernelkeykey sequencekeyboard layoutkeyboard shortcutskeyringkillkill google chromekill pkill processkill processkillallknown_hostskookyookorn shellkshkubuntulabellamelanguagelanscanlaptoplast commandlast, modfiiedlatestlatexldapldapsearchlddlesslftplibrarylibreofficelimitlimits.conflineLINESlinklinksLinuxLinux UNIXlistlist of commandlistenliteralloadload averagelocatelogloggerloggingloginlogoutlogslooplosslesslsls globlshwlsmodLSO cookieslsoflspcilvmlynxlzmam3umacMAC , Wireless, hack, changemac addressmac os xmacosmacosxmacportsmailmailboxesMaildirMAILER-DAEMONmailqmailwatchermailxmakemaliciousmanmanagementmass downloadingmass movingmatchmatemathMATLABMatrixMatrix Stylemavenmd5md5deepmd5summdadmmediameminfomemorymemory usagemencodermercurialmergemerriam-webstermessagesmetametasploitmimeminutesmkdirmkfifomkpasswdmodification timemodifiedmodified filesmodinfomodprobemodulemodulesmogrifymonitormonitoringmontagemoremost-usedmotdmotherboardmountmount pointmousemouse trackingmovmovemoviemp3mp3gainmp3infomp4mpdmpegmpeg4mpg321mplayermplayer, videomsfmsgfiltermtimemulti-partmulticoremultilinemultipathmultiplemusicmuttmvmysqlmysqlbinlogmysqldumpmythtvnagiosnamenampnanonautilusnawkncncduncursesnetnetbiosnetcatnetcat ncnetshnetstatNetworknetwork cardnetwork managernetwork performancenetworkingnewest filenewlinenfsnginxnicenlnmapnodenohupnoisenon-printingnotifynotify-sendnslookupntfsnumbernumbersnumerateoauthoauth headeroauth keyoauth_headeroctalodoerniioggoggencold filesomploaderon-screenone lineonelineropenOpenOffice.orgopensshopensslopenvzoperatorsoptimizeoracleOs Xosxoutlookoutputp4packagepackage rememberpackagespackagingpacmanpacofpactlpagerparallelparameterparameter expansionparsingpartedpartitionpassphrasepassportpasswordpastepatchPATHpausepax-utilspbcopypbpastepcappcrepdfpdftkpentestpercentagePerforceperformanceperlpermissionspgrepphotophotographyphotosPHPpicasapicturePIDpidginPIMpingpipepipespiratepiratebaypkillplayplaylistPleskplotpngpopodcastpointspollpop3popdportport 80portagePOSIXPostfixPostGrespostgresqlpowerPowerShellprankprefixprepenprettifyprintprintenvprintfprintingprivacyprivilegeprocprocessprocess heirarchyProcess Managementprocessesprocessorprofileprofilingprogess meterProgrammingprogressprojectpromptPROMPT_COMMANDpronounceprotectprotocolprovisioningproxypsps grepps1ps2pdfpstreepublicpulseaudiopushdputtypvpwdpwgenpygmentizepygmentspythonpython-gdatapython3qemuqemu-imgqlistqpdfqrqrencodequickquotesqwertyradioraidrailsramrandomrangerapidshareraterawrdesktopRDPreadread textreadlinereadlinkRebootrecrecordrecoveryrecursiveredirectredirecting outputredirectionregexreleaseremindreminderremoteremoverenamerenicerepeatreplacerepositoryrequestsresetresizeresolutionrestoreresumerevreverserevertrevisedrevisionridiculousriprmrmdirrootrootkitrot13routerrpcrpmrsrsarssrsyncrsynchrubys3safesalt stacksambasavesayscanscannerscanningscheduleschtasksSCMscpscreenscreen shotscreencastscreensaverscreenshotscriptscrotsearchsearch and replacesearch,secureSecuritysedselectselinuxsendmailsensorsseqserialserverservicessessionsetsetfaclsfdiskshsha256sha256sumshadowsharesharepointshellShell programmingshell signalshellcodeshiftshoptshort urlshortcutshorturlshoutkeyshowshredshreddingshufShutdownsignalssimplesizeskypeslashdotsleepslurpsmbsmpsmtpsmwsmwcentral.netsnapshotssniffsnmpsocatsocketsolarissolaris10soma.fmsopcastsortsortingsoundsoundcardsourcesource codesources.listsoxsp-scspacespacessparsesparse filesspeakerspecial parametersspeechspeedspellcheckspellingsplitsplunksqlsqlitesqlite3squidssssdsshssh connect backssh tunnelssh tunnelingssh-agentssh-keygensshfssshpassSSH_TTYsslstatstationsstatisticsstatsstatusstderrstdinstdoutstoragestracestreamstream feedstreamingstringssttysusubfolderssubshellssubstitutionsubstringsubtitlessubtreesubversionsudosumsummationsunrisesuspendsvnsvn logswapswapoffswaponswitchsymbolic linksymbolssymlinkssyncsyntaxsysadminsysctlsysfssyslogsystemSystem Administrationsystem updatesystem_profilertabtab completiontabstagtailtail -ftartar.bz2tar.gztar.xztarballtcptcpdumptcshteetee,telnettemperaturetermtermcapterminalterminal titleterminfotesttest filetestingtextextText Processingtext to speechtext-to-speechtextfiletextmatetheorathepiratebaythrottlethroughputthumbnailsthunderbirdtidytimetimed outputtimeouttimertimestamptimezonetitletivotmuxtoilettokentokenizertomcattoptop processestorrenttorrentstouchtputtrtraceroutetranscodetranslatetraptrashtreetrickstrimtsharktsvttytune2fstunneltunnelingTVtweettwittertwitter stream feedtxt recordtypetypingUbuntuubuntu linux bash cli apt aptitudeudevudevadmudpuidulimitumountunameunarchiveundounicodeuniquniqueunixunlockunraruntilunzipUPCupcase, uppercase,updateupdatedbupgradeuploaduptimeupvotesurandomurlurl matchingurldecodurldecodeusageusbuserusernameusersutcutf8util-linuxuudecodeuuencodeuuidvalidationvarvariableVBoxHeadlessVBoxManagevcardVCSverboseversionversion controlvivideovideo editingvideo,Videosvimvirtualvirtual devicevirtualboxvirtualizationvirusvisavlcvmstatvmwarevncvolumevorbisVPNw3mwaitwajigwallpaperWarholwatchwatermarkwavwcweatherweb browserweb serverwebcamwebcomicweblogicwebmwebproxywebsiteweekwgetwhat-is-my-ipwhatthecommitwhichwhilewhile loopwhite spacewhitespacewhowhoamiwhoiswhowatchwifiwikipediawildcardwindowwindowswindows 7winewirelesswiresharkwmctrlwmicwordpressworking daywritewvgaWWWXX WindowX11x11grabx11vncxaxargsxclipxdg-openxdmcpxdotoolxexenxenserverXephyrxfcexkbxkcdxmlxml2xmllintxmlstarletxmms2xmodmapxmxxorgxpathxqueryxrandrxselxsetXSLTxtermxtracexvkbdxwindowsxwininfoxxdxzyamlyelpyesyoutubeyoutube-dlyumzcatzenityzeropadzfszgrepzipzombieZopezpoolzsh^M^Z
Hide
Functions
acpiadminaliasamixeraplayaproposaptararcharecordarpasatatqatrmaumixawkbadblocksbannerbasenamebashbatchbcbgbisonbreakbzgrepbzip2c++calcatcccdcdparanoiacdrdaocdrecordcflowchagechattrchgrpchkconfigchmodchownchshchvtclearcmpcolcolumncommcommandcpcpiocppcrontabcsplitctagscutcvsdatedddeltadfdiffdiff3digdirdirnamedisabledmesgdotdudumpdumpe2fse2fscke2labelechoedegrepejectemacsenableenvetagsevalexexecexitexpandexportexprfactorfalsefcfc-cachefc-listfdiskfetchmailfgfgrepfilefindfingerfmtfoldformailfreefsckftpfuserg++gawkgccgdbgetgetconfgetentgpggrepgroffgroupsgsgunzipgzexegziphalthashhdparmheadhexdumphosthostnamehwclockiconvidifconfiginfoinitinstallipcrmipcsiptablesiptables-restoreiptables-saveisoinfoispelljobsjoinkillkillallkudzulastlastbldconfiglddlesslftplinklnloadkeyslocalelocatelockfileloggerloginlognamelooklosetuplplpadminlprlpstatlslsattrlsmodlspcilsusbm4mailmailqmailxmakemanmanpathmcdmd5summergemformatmkdirmkdosfsmke2fsmkfifomkfsmkfs.ext3mkisofsmknodmkswapmktempmodinfomodprobemoremountmpg123mpg321mtmvnamednameinameifnetstatnewgrpnicenlnmnohupnslookupobjdumpodpasswdpastepatchpaxperlpidofpingpinkypmapprprintenvprintfpspwdpythonqstatquotardatereadreadelfreadlinkrenamereniceresetresize2fsrestorereturnrevrmrmdirrmmodrndcrouterpmrsyncscanimagescpscreenscriptsdiffsedsendmailsensorsseqsetsetledssettermsftpshsha1sumshiftshowkeyshredshutdownsizeskillsleepslocatesortsplitsshssh-addssh-keygensshdstatstracestringsstripsttysusudosumswapoffswaponsyncsysctltabstactailtailftartasksettcpdumpteetelnettesttimetimestloadtoptouchtputtrtraceroutetraptruettytune2fstypeulimitumountunaliasunameuniqunlinkunsetuptimeuseradduserdelusermodusersusleepuudecodeuuencodevivimvmstatwaitwallwatchwcwgetwhatiswhereiswhichwhowhoamiwhoiswritexargsyeszcatzdumpzgrepzless
Hide
Credits
Site by David Winterbottom (user root).
» http://codeinthehole.com
» http://twitter.com/codeinthehole
» root@commandlinefu.com

























Our braindumps is the best source to keep up with latest trends in IT. Spark up your IT expertise with VCP-410 dumps and 640-802 dumps.

========== https://code.google.com/p/parallel-ssh/ ==========
========== http://netkiller.sourceforge.net/centos/nginx.html ==========
========== http://www.lelelong.com/article-detail-1-id-35.html ==========
========== http://www.howtocn.org/nginx:nginx%E6%A8%A1%E5%9D%97%E5%8F%82%E8%80%83%E6%89%8B%E5%86%8C%E4%B8%AD%E6%96%87%E7%89%88 ==========
	
分享到...	
复制网址
邮件
QQ空间
新浪微博
腾讯微博
微信
人人网
开心网
网易微博
搜狐微博
QQ好友
淘江湖
飞信
豆瓣
一键分享
查看更多(124)
这是什么工具?JiaThis
[[Nginx模块参考手册中文版]] HowToCN
      
您的足迹: » Nginx模块参考手册中文版
首页
首页
网站服务器
Nginx How To
Apache How To
Nginx模块参考手册中文版
Nginx安装选项
Nginx指令索引
Nginx faq整理

监控
Ganglia

脚本分享
Shell

存储相关
Rsync

系统技巧
系统技巧

其它
联系站长
工作机会

目录
Nginx模块参考手册中文版
目录
1、编译Nginx（Compiling Nginx）
2、Nginx核心模块（Nginx Core Modules）
3、Nginx标准HTTP模块（Standard HTTP Modules）
4、Nginx可选HTTP模块（Optional HTTP Modules）
5、Nginx邮件模块（Mail modules）
6、第三方模块（3rd Party Modules）
7、nginx部分优化（哈希表与事件模型）（NginxOptimizations）
Discussion
Nginx模块参考手册中文版

原英文文档来源于Nginx维基，网页版会和维基同步更新，由于是第一次翻译英文文档，而且没有经过校对，错误在所难免，如果在阅读文档过程中发现翻译不当的地方，请点击这里与作者联系，谢谢！

Nginx完整指令索引请参考nginx指令索引

目录

1、编译Nginx（Compiling Nginx）

Nginx模块必须在编译的时候指定，完整的编译选项，可用的模块可以参考安装选项

下面是一个例子：

./configure \
  --prefix=/usr \
  --sbin-path=/usr/sbin/nginx \
  --conf-path=/etc/nginx/nginx.conf \
  --error-log-path=/var/log/nginx/error.log \
  --pid-path=/var/run/nginx/nginx.pid  \
  --lock-path=/var/lock/nginx.lock \
  --user=nginx \
  --group=nginx \
  --with-http_ssl_module \
  --with-http_flv_module \
  --with-http_gzip_static_module \
  --http-log-path=/var/log/nginx/access.log \
  --http-client-body-temp-path=/var/tmp/nginx/client/ \
  --http-proxy-temp-path=/var/tmp/nginx/proxy/ \
  --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ 
更多编译参数与可用的模块信息请运行./configure –help

2、Nginx核心模块（Nginx Core Modules）

这些模块对于Nginx是必须的。
2.1 主模块（Main Module）
2.2 事件模块（Events Module）
3、Nginx标准HTTP模块（Standard HTTP Modules）

这些模块默认会全部编译进Nginx，除非手工指定某个模块在configure时排除。
3.1 HTTP核心模块（HTTP Core）
3.2 HTTP负载均衡模块（HTTP Upstream）
3.3 HTTP访问控制模块（HTTP Access）
3.4 HTTP基本认证模块（HTTP Auth Basic）
3.5 HTTP目录清单生成模块（HTTP Auto Index）
3.6 浏览器相关模块（Browser）
3.7 字符集设置模块（Charset）
3.8 Empty GIF模块（Empty GIF）
3.9 FastCGI模块（FastCGI）
3.10 Geo模块（Geo）
3.11 Gzip压缩模块（Gzip）
3.12 HTTP头处理模块（HTTP Headers）
3.13 默认主页设置模块（Index）
3.14 HTTP Referer模块（HTTP Referer）
3.15 HTTP Limit Zone模块（HTTP Limit Zone）
3.16 HTTP Limit Requests模块（HTTP Limit Requests）
3.17 日志模块（Log）
3.18 Map模块（Map）
3.19 Memcached模块（Memcached）
3.20 HTTP代理模块（HTTP Proxy）
3.21 URL重写模块（Rewrite）
3.22 SSI模块（SSI）
3.23 User ID模块（User ID）
3.24 uWSGI模块（uWSGI）
3.25 Split Clients模块（Split Clients）
3.26 Scgi模块（Scgi）
4、Nginx可选HTTP模块（Optional HTTP Modules）

如果要使用这些模块，则必须在编译时指定相关的编译参数。
4.1 HTTP Addition模块（HTTP Addition）
4.2 嵌入式Perl模块（Embedded Perl）
4.3 FLV模块（FLV）
4.4 Gzip Precompression模块（Gzip Precompression）
4.5 Random Index模块（Random Index）
4.6 GeoIP模块（GeoIP）
4.7 Real IP模块（Real IP）
4.8 SSL模块（SSL）
4.9 Stub Status模块（Stub Status）
4.10 Substitution模块（Substitution）
4.11 WebDAV模块（WebDAV）
4.12 Google Perftools模块（Google Perftools）
4.13 XSLT模块（XSLT）
4.14 Secure Link模块（Secure Link）
4.15 Image Filter模块（Image Filter）
5、Nginx邮件模块（Mail modules）

5.1 邮件核心模块（Mail Core）
5.2 邮件认证模块（Mail Auth）
5.3 邮件代理模块（Mail Proxy）
5.4 邮件SSL认证模块（Mail SSL）
6、第三方模块（3rd Party Modules）

这些模块虽然没有正式被官方支持，但是可以帮助用户完成不少的功能。使用过程中请自行承担遇到的问题。 在nginx源代码目录中使用下列命令添加第三方模块：

./configure --add-module=/path/to/module1/source \
            --add-module=/path/to/module2/source
可以根据需求使用多个–add-module。 可能根据不同的模块需要一些其他的库，请根据模块自行安装。 Evan Miller编写了nginx模块开发指南，但是某些部分有些陈旧（这个指南已经有中文版，译者姚伟斌，请点击这里下载）。
7、nginx部分优化（哈希表与事件模型）（NginxOptimizations）

nginx部分优化（哈希表与事件模型）

留言

阿瞒, 2011/01/24 14:46
感谢分享

Egger, 2011/05/19 11:10
请问可不可以在windows下安装第三方模块，如何安装呢？

wanghongbin, 2011/05/19 11:13
这个我倒没有尝试过，不过既然是开源的东西，应该也是可以实现的，不过个人并不推荐在windows下使用nginx，因为nginx的高效主要来自于linux的epoll模型，所以在windows下nginx并不能发挥良好的性能

Egger, 2011/05/19 13:14
谢谢。我现在是nginx加上2个tomcat，当一个tomcat失效后，Nginx默认轮询的方式会有50%访问出错。我希望nginx可以自动切到另外一个上。

Egger, 2011/05/19 14:33
我已经通过设置proxy_next_upstream和proxy_connect_timeout让nginx自动切换到下一个后端服务器。谢谢

wanghongbin, 2011/05/19 15:10


nginx/nginx模块参考手册中文版.txt · 最后更改: 2011/07/06 15:07 由 wanghongbin
        
           

========== http://blog.csdn.net/poechant/article/details/7213546 ==========
您还未登录！|登录|注册|帮助首页业界移动云计算研发论坛博客下载
更多
@钟超Michael · 个人技术笔记
zhongchao.ustc#gmail.com
目录视图摘要视图订阅
2014年1月微软MVP申请开始啦！      CSDN社区中秋晒福利活动正式开始啦！        专访钟声：Java程序员，上班那点事儿      独一无二的职位：开源社区经理      “说说家乡的互联网”主题有奖征文
 服务器后端开发系列——《实战Nginx高性能Web服务器》
分类： Server - WebServer 2012-01-21 18:51 4261人阅读 评论(4) 收藏 举报
nginxweb服务服务器memcached测试负载均衡
1、高性能Web服务器Nginx的配置与部署研究（1）Nginx简介及入门示例
内容：概述Nginx的背景知识和简单的入门实例。

2、高性能Web服务器Nginx的配置与部署研究（2）Nginx入门级配置与部署及“Hello World”
内容：简述Nginx的基本配置项，并提供Nginx的基本部署方法和Hello World测试用例。

3、高性能Web服务器Nginx的配置与部署研究（3）Nginx的请求处理方式
内容：该文翻译自Nginx.org官网，为读者详述Nginx对HTTP请求的处理方式。

4、高性能Web服务器Nginx的配置与部署研究（4）Nginx常用命令
内容：Nginx部署中常用的命令，包括启动、测试、停止、发送信号等。

5、高性能Web服务器Nginx的配置与部署研究（5）Nginx配置符号
内容：这篇简短的博文，提供Nginx的配置文件中常出现的符号的用法。

6、高性能Web服务器Nginx的配置与部署研究（6）核心模块之主模块的测试常用指令
内容：详解Nginx的主模块中，测试时经常使用的指令。

7、高性能Web服务器Nginx的配置与部署研究（7）核心模块之主模块的非测试常用指令
内容：详解Nginx的主模块中，非测试常用指令的使用方式。

8、高性能Web服务器Nginx的配置与部署研究（8）核心模块之事件模块
内容：详解Nginx的事件模块中常用指令。

9、高性能Web服务器Nginx的配置与部署研究（9）核心模块之HTTP模块基本常用指令
内容：详解Nginx的HTTP模块中的常用指令。

10、高性能Web服务器Nginx的配置与部署研究（10）核心模块之HTTP模块Location相关指令
内容：单独将Nginx的HTTP模块中的Location相关指令提出，这是Nginx配置文件中的核心重点内容。该博文仍未完结，在不断更新中。

11、高性能Web服务器Nginx的配置与部署研究（11）应用模块之Memcached模块的两大应用场景
内容：以Nginx中的Memcached模块的使用的两大场景为例，展现Memcached模块的使用特点。

12、高性能Web服务器Nginx的配置与部署研究（12）应用模块之Memcached做文件缓存时压缩引起的问题
内容：续该系列博文中的第11篇，讲述Memcached使用时产生的问题，并分析原因所在。

13、高性能Web服务器Nginx的配置与部署研究（13）应用模块之Memcached模块+Proxy_Cache双层缓存模式
内容：讲述一种提供双层缓存抗穿透的HTTP服务缓存解决方案。

14、高性能Web服务器Nginx的配置与部署研究（14）平滑升级你的Nginx
内容：详述如何为Nginx平滑升级或新增编译模块。

15、高性能Web服务器Nginx的配置与部署研究（15）Upstream负载均衡模块
内容：讲述Nginx的HttpUpstreamModule如何实现对后端服务器的HTTP请求的负载均衡。

16、高性能Web服务器Nginx的配置与部署研究（16）小议location匹配模式优先级
内容：介绍 location 区段的模式匹配的几种基本方式（匹配符），以及优先级顺序，并提供实例分析。

该系列博文不断新增和更新中，欢迎对Nginx有兴趣的朋友关注并讨论。
-
分享到： 
上一篇：服务器后端开发系列——《实战FastDFS分布式文件系统》
下一篇：服务器后端开发系列——《实战Memcached内存缓存系统》
顶
10
踩
0

 
查看评论
3楼 tlg 2013-03-11 11:36发表 [回复]

最近一段时间根据的文档学习nginx，都能成功的部署。谢谢！
但在再做session黏贴时，在一些应用服务器(如tomcat)可以，在一些不行 , 不知道哪位能够交流一些
2楼 emlaiy 2012-06-20 16:18发表 [回复]

我是一名系统管理员，从您的文章中收获很多，感谢您的分享，谢谢。
1楼 qianguozheng 2012-02-11 09:18发表 [回复]

开始膜拜了，交个朋友吧，如果愿意的话Q601269358
Re: 钟超 2012-02-11 10:02发表 [回复]

回复qianguozheng：膜拜就免了，我也仍是在学习的道路上探索，对许多领域仍然无知的很。互相学习，共同进步吧。
您还没有登录,请[登录]或[注册]
* 以上用户言论只代表其个人观点，不代表CSDN网站的观点或立场

个人资料
  
钟超
 

访问：720428次
积分：11279分
排名：第239名
原创：336篇转载：11篇译文：14篇评论：438条
博客公告
谢谢大家的支持，由于工作繁忙，已无时间维护此博客。现本博客无限期停止更新。
博主简介：钟超Michael，现居北京，从事产品设计与研发。
博主拥有该Blog内全部原创文章的所有权利。欢迎以任何形式转载，但务必注明原文链接。任何个人、组织、网站、出版社不得在未经本人许可的情况下用于商业目的。
如果我的博文对你有所帮助，欢迎你评论留言，这是对我最大的鼓励。如果你发现我的博文有谬误，请你务必指正，这是对我和其他读者的莫大的帮助。 
柳大微博（钟超Michael）

博客专栏
	驾驭JVM
文章：3篇
阅读：15899
	实战FastDFS分布式文件系统
文章：8篇
阅读：31653
	实战Memcached缓存系统
文章：8篇
阅读：31191
	Nginx高性能Web服务器
文章：40篇
阅读：148846
文章搜索

文章分类
Lang. - C/C++(37)
Lang. - Java(41)
Lang. - PHP(1)
Lang. - Objective-C(4)
Lang. - Flash/Flex(6)
Lang. - Lisp(1)
Lang. - Erlang(1)
Lang. - Assembly(6)
Lang. - Node.js(2)
Web - JS/CSS(8)
Web - HTML/XHTML(1)
Server - WebServer(46)
Server - RealTime Media(26)
Server - Cache/DFS(23)
Server - Database(3)
Server - Logging(2)
Server - RPC/Protocol(4)
Server - ZooKeeper(3)
Server - Discuz(1)
System - Unix-like(10)
System - Windows(1)
System - Android(10)
Basic - Algo/DS(2)
Basic - Design Pattern(9)
Basic - Network(2)
Dev. Tools - Editor(13)
Dev. Tools - Compiler(2)
API - Commercial(11)
API - Java RMIIO(4)
API - YAML(3)
应用 - Windows(4)
应用 - Linux(17)
应用 - Discuz(5)
应用 - Mac OS(5)
试题 - C/C++/Java(0)
试题 - 算法/数据结构(4)
试题 - 逻辑推理(1)
基础 - 环境配置(8)
基础 - 系统安装(3)
基础 - 网站推荐(2)
外语 - 韩语(7)
编程艺术(1)
嬉笑怒骂(2)
软件Wiki(0)
音频编解码(2)
未分类(1)
应用 - 标记语言(1)
文章存档
2013年08月(1)
2013年01月(6)
2012年12月(7)
2012年10月(3)
2012年09月(12)
展开
阅读排行
Nginx源码完全注释（9）nginx.c: ngx_get_options(29388)
JVM 深入笔记（1）内存区域是如何划分的？(10419)
Nginx源码完全注释（8）ngx_errno.c(9224)
Makefile常见错误解析 - make: *** No rule to make target 'test1.o', needed by 'test2'. Stop(9008)
错误 330 (net::ERR_CONTENT_DECODING_FAILED)：未知错误解决办法(7094)
FastDFS的配置、部署与API使用解读（1）Get Started with FastDFS(7058)
Vim实战手册（8）Vimide——打造你自己的IDE（A）(6997)
Vim实战手册（9）Vimide——打造你自己的IDE（B）(6934)
Android开发之道（4）程序框架基础(6750)
实战Memcached缓存系统（1）Memcached基础及示例程序(6527)
最新评论
POCO库中文编程参考指南（10）如何使用TCPServer框架？
wgc7th: tcpserver好像只适合短连接的应用，TCPServerConnection处理完之后就退出并断...
FastDFS的配置、部署与API使用解读（1）Get Started with FastDFS
dangerous2440: 看完后，受益匪浅
C标准库参考指南系列译文（1）assert.h
heqinzao: go
JVM 深入笔记（1）内存区域是如何划分的？
ohyesurright: 复习
POCO库中文编程参考指南（10）如何使用TCPServer框架？
yand789: 你好，可发份代码我吗？yand789@126.com,多谢。我的tcpserver 运行，用你上面客...
C标准库参考指南系列译文（7）math.h
zhzht19861011: 3Q!
Vim实战手册（8）Vimide——打造你自己的IDE（A）
dinuoluoke: 点错了....对不起
真的，这份工作可能不适合你！
ywjava2009: 公司政治，没有比这个更讨厌的了，恨死了。。。。。。
使用 SCons 代替 Makefile 快速构建应用程序
infoworld: 约定要项目源码规则，做一个通用的makefile文件也可以呀。
使用 SCons 代替 Makefile 快速构建应用程序
infoworld: makefile在使用-j选项后依赖项不会生效，不知道scons是怎么解决这个问题的。没发现scon...
公司简介|招贤纳士|广告服务|银行汇款帐号|联系方式|版权声明|法律顾问|问题报告
QQ客服 微博客服 论坛反馈 联系邮箱：webmaster@csdn.net 服务热线：400-600-2320
京 ICP 证 070598 号
北京创新乐知信息技术有限公司 版权所有
世纪乐知(北京)网络技术有限公司 提供技术支持
江苏乐知网络技术有限公司 提供商务支持
Copyright © 1999-2012, CSDN.NET, All Rights Reserved 
   
========== http://www.bitscn.com/pdb/java/200605/23339.html ==========
========== http://liudeh-009.iteye.com/category/228212 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
问道江湖
博客微博相册收藏留言关于我
  
文章列表
长连接的几种实现方式

博客分类： TomcatJetty
Jetty Continuationservlet3长连接轮询 
       在日常项目中,大多的时候我们用的是短连接,一个请求过来,一个线程处理完该请求,线程被线程池回收,这个请求就关闭了.虽然这能满足很大部分的需求,但是也有些问题,比如说:如果客户端发的请求比较多,比较频繁,服务端就会忙于建立连接处理请求,由于服务端的线程数也有限,并发比较大的话有可能会造成服务端的崩溃.那有没有一种办法使连接少一些,让一个线程可以处理多个连接?长连接的出现就是为了解决上面的问题.        1.基于http协议的长连接          在HTTP1.0和HTTP1.1协议中都有对长连接的支持。其中HTTP1.0需要在request中增加”Connection ...
2012-10-14 17:22浏览 1402评论(0)分类:开源软件
从整体解读tomcat

博客分类： Tomcat
tomcat容器连接器组件整体架构
一. tomcat的容器组件      1.Engine,实现类StandardEngine      2.Host,实现类StandardHost      3.Context,实现类StandardContext      4.Wrapper,实现类StandardWrapper      容器类之间的关系如下:            容器的初始化顺序:     �� ...
2012-07-29 15:43浏览 877评论(0)分类:开源软件
Tomcat的Session过期处理策略

博客分类： Tomcat
tomcatsession过期策略
       tomcat容器实现类都继承了ContainerBase类,容器在启动的时候都会调用ContainerBase类的threadStart()方法,threadStart()方法如下:   protected void threadStart() { if (thread != null) return; if (backgroundProcessorDelay <= 0) return; threadDone = false; St ...
2012-07-11 11:18浏览 1133评论(2)分类:开源软件
解析Tomcat处理请求的类Connector<三>

博客分类： Tomcat
tomcataprconnector.Http11AprProtocol
      这次主要解析采用apr方式处理请求.apr用C实现，通过JNI调用,主要提升对静态资源（如HTML、图片、CSS、JS等）的访问性能.在tomcat下配置apr步骤:   1.下载本地库tcnative-1.dll,放在%jdk%\bin目录下(见附件).   2.在server.xml里配置listener,这个配置server.xml默认是有的       <Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" ...
2012-06-19 14:40浏览 576评论(0)分类:开源软件
解析Tomcat处理请求的类Connector<二>

博客分类： Tomcat
tomcatHttp11Protocolhttp/1.1io 
    这次主要解析采用IO方式处理请求.在Server.xml的配置如下: <Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" />         在tomcat启动的时候,会调用Connector类的Start()方法,根据以上配置,Connector的start()方法里会调用Http11Pro ...
2012-06-18 13:59浏览 682评论(0)分类:开源软件
解析Tomcat处理请求的类Connector<一>

博客分类： Tomcat
tomcatconnectorprotocolnio 
       Connector类的相关配置在Tomcat的安装目录conf下的Server.xml文件里,我这次主要解析采用NIO方式处理请求的情况.在Server.xml的配置如下:   <Connector port="8080" protocol="org.apache.coyote.http11.Http11NioProtocol" connectionTimeout="20000" redirectPort="8443" ...
2012-06-15 15:22浏览 946评论(0)分类:开源软件

liudeh_009
浏览: 39511 次
性别: 
来自: 杭州

最近访客 更多访客>>
dylinshi126sambadqhitlyx4world
文章分类
全部博客 (46)
JDK (13)
测试 (1)
Spring (2)
xml (1)
Httpclient (1)
open (1)
Https (2)
memcached (1)
Struts2 (1)
Spring MVC (2)
Python (1)
Web (3)
Hadoop (5)
window (1)
Tomcat (6)
Jetty (3)
程序人生 (2)
Ibatis (2)
jvm (1)
社区版块
我的资讯 (0)
我的论坛 (6)
我的问答 (0)
存档分类
2013-08 (1)
2013-06 (1)
2013-04 (4)
更多存档...
评论排行榜
BigDecimal在实际项目的应用及遇到的问题
最新评论
liudeh_009： besterzhao 写道冒昧问一句，processExpir ...
Tomcat的Session过期处理策略
besterzhao： 冒昧问一句，processExpires() 从哪里看出来“过 ...
Tomcat的Session过期处理策略
feijunvip： ..大神，能教我下怎么用么。。。看了半天，把那个包加到项目中？ ...
对新浪,腾讯微博常用接口的统一封装
hellostory： liudeh_009 写道hellostory 写道liude ...
BigDecimal在实际项目的应用及遇到的问题
liudeh_009： hellostory 写道liudeh_009 写道hello ...
BigDecimal在实际项目的应用及遇到的问题
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== http://wiki.apache.org/tomcat/MemoryLeakProtection ==========
   
Tomcat Wiki
Login
MemoryLeakProtection
FrontPageRecentChangesFindPageHelpContentsMemoryLeakProtection
Immutable PageInfoAttachments 
For some time Tomcat has had some means of protection against memory leaks when stopping or redeploying applications. This page tries to list them, and shows the situations where leaks can be detected and fixed.

Diagnose a classloader leak upon request

Starting with tomcat 6.0.25, the manager webapp has a new "Find Leaks" button. When triggered, it displays a list of webapps (their context path) that have been stopped (this includes undeployed and redeployed ones) but whose classloader failed to be GCed.

If a leaking webapp is redeployed several times, it will appear as many times as it actually leaked.

Caution: This diagnosis calls System.gc() which may not be desirable in production environments.

Different types of leaks that Tomcat can detect (or not)

When a webapp execution is stopped (this encompassed redeploy and undeploy), tomcat tries to detect and fix leaks.

Starting with tomcat 6.0.24, messages are logged to indicate the kind of leak that was detected.

Summary matrix

Leak cause
Detected by tomcat
Fixed by tomcat
Possible enhancements
Custom ThreadLocal class
>=6.0.24
>= 7.0.6
Webapp class instance as ThreadLocal value
>=6.0.24
>= 7.0.6
Webapp class instance indirectly held through a ThreadLocal value
no
>= 7.0.6
ThreadLocal pseudo-leak
>=6.0.24
>= 7.0.6
ContextClassLoader / Threads spawned by webapps
>=6.0.24
In 6.0.24-6.0.26 TimerThread are stopped but it may lead to problems. Optional from 6.0.27 with the clearReferencesStopTimerThreads flag. Other threads may be stopped with the clearReferencesStopThreads flag, but it's unsafe.
Fix the application to stop the thread when the application is stopped
ContextClassLoader / Threads spawned by classes loaded by the common classloader
>=6.0.24
In 6.0.24-6.0.26 TimerThread are stopped but it may lead to problems. Optional from 6.0.27 with the clearReferencesStopTimerThreads flag. Other threads may be stopped with the clearReferencesStopThreads flag, but it's unsafe.
Fix the offending code (set the correct CCL when spawning the thread)
ContextClassLoader / Threads spawned by JRE classes
no
>=6.0.24 pre-spawns some known offenders
static class variables
no
> 6.0.? . Disabled by default with tomcat 7
LogFactory
> 6.0.?
JDBC driver registration
> 6.0.?
> 6.0.?
RMI Target
> 6.0.?

ThreadLocal leaks

Classloader leaks because of uncleaned ThreadLocal variables are quite common. Depending on the use cases, they can be detected or not.


Custom ThreadLocal class

Suppose we have the following 3 classes in our webapp :


public class MyCounter {
        private int count = 0;

        public void increment() {
                count++;
        }

        public int getCount() {
                return count;
        }
}

public class MyThreadLocal extends ThreadLocal<MyCounter> {
}

public class LeakingServlet extends HttpServlet {
        private static MyThreadLocal myThreadLocal = new MyThreadLocal();

        protected void doGet(HttpServletRequest request,
                        HttpServletResponse response) throws ServletException, IOException {

                MyCounter counter = myThreadLocal.get();
                if (counter == null) {
                        counter = new MyCounter();
                        myThreadLocal.set(counter);
                }

                response.getWriter().println(
                                "The current thread served this servlet " + counter.getCount()
                                                + " times");
                counter.increment();
        }
}
If the LeakingServlet is invoked at least once and the Thread that served it is not stopped, then we created a classloader leak !

The leak is caused because we have a custom class for the ThreadLocal instance, and also a custom class for the value bound to the Thread. Actually the important thing is that both classes were loaded by the webapp classloader.

Hopefully tomcat 6.0.24 can detect the leak when the application is stopped: each Thread in the JVM is examined, and the internal structures of the Thread and ThreadLocal classes are introspected to see if either the ThreadLocal instance or the value bound to it were loaded by the WebAppClassLoader of the application being stopped.

In this particular case, the leak is detected and a message is logged. Tomcat 6.0.24 to 6.0.26 modify internal structures of the JDK (ThreadLocalMap) to remove the reference to the ThreadLocal instance, but this is unsafe (see #48895) so that it became optional and disabled by default from 6.0.27. Starting with Tomcat 7.0.6, the threads of the pool are renewed so that the leak is safely fixed.


Mar 16, 2010 11:47:24 PM org.apache.catalina.loader.WebappClassLoader clearThreadLocalMap
SEVERE: A web application created a ThreadLocal with key of type [test.MyThreadLocal] (value [test.MyThreadLocal@4dbb9a58]) and a value of type [test.MyCounter] (value [test.MyCounter@57922f46]) but failed to remove it when the web application was stopped. To prevent a memory leak, the ThreadLocal has been forcibly removed.
Note: this particular leak was actually already cured by previous versions of tomcat 6, because static references of classes loaded by the webappclassloader are nullified (see later).


Webapp class instance as ThreadLocal value

Suppose that we have the following class in the common classpath (for instance in a jar in tomcat/lib) :

public class ThreadScopedHolder {
        private final static ThreadLocal<Object> threadLocal = new ThreadLocal<Object>();

        public static void saveInHolder(Object o) {
                threadLocal.set(o);
        }

        public static Object getFromHolder() {
                return threadLocal.get();
        }
}
And those 2 classes in the webapp :

public class MyCounter {
        private int count = 0;

        public void increment() {
                count++;
        }

        public int getCount() {
                return count;
        }
}
public class LeakingServlet extends HttpServlet {

        protected void doGet(HttpServletRequest request,
                        HttpServletResponse response) throws ServletException, IOException {

                MyCounter counter = (MyCounter)ThreadScopedHolder.getFromHolder();
                if (counter == null) {
                        counter = new MyCounter();
                        ThreadScopedHolder.saveInHolder(counter);
                }

                response.getWriter().println(
                                "The current thread served this servlet " + counter.getCount()
                                                + " times");
                counter.increment();
        }
}
If the servlet is invoked at least once, the webapp classloader would not be GCed when the app is stopped: since the classloader of ThreadScopedHolder is the common classloader, it remains forever which is as expected. But its ThreadLocal instance has a value bound to it (for the non-terminated thread(s) that served the sevlet), which is an instance of a class loaded by the webapp classloader...

Here again, tomcat >=6.0.24 will detect the leak :

Mar 17, 2010 10:23:13 PM org.apache.catalina.loader.WebappClassLoader clearThreadLocalMap
SEVERE: A web application created a ThreadLocal with key of type [java.lang.ThreadLocal] (value [java.lang.ThreadLocal@44676e3f]) and a value of type [test.leak.threadlocal.value.MyCounter] (value [test.leak.threadlocal.value.MyCounter@62770d2e]) but failed to remove it when the web application was stopped. To prevent a memory leak, the ThreadLocal has been forcibly removed.

Webapp class instance indirectly held through a ThreadLocal value

Suppose we have the same ThreadScopedHolder class (in the common classloader) and MyCounter class in the webapp, but with the following servlet :

public class LeakingServlet extends HttpServlet {

        protected void doGet(HttpServletRequest request,
                        HttpServletResponse response) throws ServletException, IOException {

                List<MyCounter> counterList = (List<MyCounter>) ThreadScopedHolder
                                .getFromHolder();
                MyCounter counter;
                if (counterList == null) {
                        counter = new MyCounter();
                        ThreadScopedHolder.saveInHolder(Arrays.asList(counter));
                } else {
                        counter = counterList.get(0);
                }

                response.getWriter().println(
                                "The current thread served this servlet " + counter.getCount()
                                                + " times");
                counter.increment();
        }
}
We have more or less the same kind of leak as the previous one, but this time tomcat does not detect the leak when stopping the application. The problem is that when it inspects the entries of ThreadLocalMap, it checks whether either the key or the value is an instance of a class loaded by the webapp classloader. Here the key is an instance of ThreadLocal, and the value is an instance of java.util.ArrayList.

The "Find leaks" button in tomcat manager will report the leak when asked :

The following web applications were stopped (reloaded, undeployed), but their
classes from previous runs are still loaded in memory, thus causing a memory
leak (use a profiler to confirm):
/testWeb
But it does not give any clue about what caused the leak, we would need to make a heapdump and analyse it with some tool like Eclipse MAT.

Tomcat 7.0.6 and later fix this leak by renewing threads in the pool.


ThreadLocal pseudo-leak

Suppose we have the same MyCounter class as above (in the webapp) and the following servlet :

public class LeakingServlet extends HttpServlet {
        private ThreadLocal<MyCounter> myThreadLocal = new ThreadLocal<MyCounter>();

        protected void doGet(HttpServletRequest request,
                        HttpServletResponse response) throws ServletException, IOException {

                MyCounter counter = myThreadLocal.get();
                if (counter == null) {
                        counter = new MyCounter();
                        myThreadLocal.set(counter);
                }

                response.getWriter().println(
                                "The current thread served this servlet " + counter.getCount()
                                                + " times");
                counter.increment();
        }

        @Override
        public void destroy() {
                super.destroy();
                // normally not needed, just to make my point
                myThreadLocal = null;
        }
}
Notice that the ThreadLocal instance is referenced through an instance variable, not a static one.

Sun's implementation of ThreadLocal (and WeakHashMap) too is such that ThreadLocalMap entries whose key is GCed are not immediately removed. (The key is a weak reference to the ThreadLocal instance, see java.lang.ThreadLocal.ThreadLocalMap.Entry<T> in JDK 5/6. And there's no daemon thread waiting on a ReferenceQueue). Instead, it's only during subsequent uses of ThreadLocal features that each Thread removes the abandoned ThreadLocalMap.Entry entries (see ThreadLocalMap.expungeStaleEntries().

If many threads were used to serve our leaking webapp, but after we stop it only a couple of threads are enough to serve other webapps, one could have some threads that are no longer used, waiting for some work. Since those threads are blocked, they have no interaction with their ThreadLocalMap (i.e. there's no ThreadLocal value bound to them or removed), so that there's no opportunity to expungeStaleEntries().

Tomcat 6.0.24-6.0.26 "speeds up" the removal of stale entries (and thus fixes the pseudo-leak), by calling expungeStaleEntries() for each thread that has some stale entries. Since it's not thread-safe, it has been made optional and disabled by default from 6.0.27.

Tomcat 7.0.6 and later fix the problem by renewing threads in the pool.

Threads ContextClassLoader


Threads spawned by webapps

If a webapp creates a thread, by default its context classloader is set to the one of the parent thread (the thread that created the new thread). In a webapp, this parent thread is one of tomcat worker threads, whose context classloader is set to the webapp classloader when it executes webapp code.

Furthermore, the spawned thread may be executing (or blocked in) some code that involves classes loaded by the webapp, thus preventing the webapp classloader from being collected.

So, if the spawned thread is not properly terminated when the application is stopped, the webapp classloader will leak because of the strong reference held by the spawned thread.

Example :

public class LeakingServlet extends HttpServlet {
        private Thread leakingThread;

        protected void doGet(HttpServletRequest request,
                        HttpServletResponse response) throws ServletException, IOException {

                if (leakingThread == null) {
                        synchronized (this) {
                                if (leakingThread == null) {
                                        leakingThread = new Thread("leakingThread") {

                                                @Override
                                                public void run() {
                                                        synchronized (this) {
                                                                try {
                                                                        this.wait();
                                                                } catch (InterruptedException e) {
                                                                        e.printStackTrace();
                                                                }
                                                        }
                                                }
                                        };
                                        leakingThread.setDaemon(true);
                                        //leakingThread.setContextClassLoader(null);
                                        leakingThread.start();
                                }
                        }
                }
                response.getWriter().println("Hello world!");
        }
}
Here, when the app is stopped, the webapp classloader is still referenced by the spawned thread both through its context classloader and its current call stack (the anonymous Thread subclass is loaded by the webapp classloader).

When stopping an application, tomcat checks the context classloader of every Thread, and if it is the same as the app being stopped, it logs the following message :

Mar 18, 2010 11:13:07 PM org.apache.catalina.core.ApplicationContext log
INFO: HTMLManager: stop: Stopping web application at '/testWeb'
Mar 18, 2010 11:13:07 PM org.apache.catalina.loader.WebappClassLoader clearReferencesThreads
SEVERE: A web application appears to have started a thread named [leakingThread] but has failed to stop it. This is very likely to create a memory leak.
Now, if we uncomment the line leakingThread.setContextClassLoader(null); in the above example, tomcat (6.0.24) no longer detect the leak when the application is stopped because the spawned thread context classloader is no longer the webapp's. (the "Find leaks" feature in the manager will report it though)


Threads spawned by classes loaded by the common classloader

Suppose, we have the Commons Pool library in the classpath of the server (e.g. the jar is in tomcat/lib), and the following servlet :

public class LeakingServlet extends HttpServlet {
        private GenericObjectPool objectPool;

        protected void doGet(HttpServletRequest request,
                        HttpServletResponse response) throws ServletException, IOException {
                response.getWriter().println("Number of idle objects in the pool :"+objectPool.getNumIdle());
        }

        @Override
        public void init() throws ServletException {
                objectPool = new GenericObjectPool();
                objectPool.setFactory(new BasePoolableObjectFactory() {
                        private AtomicInteger counter = new AtomicInteger(0);

                        @Override
                        public Object makeObject() throws Exception {
                                String str = "Object #" + counter.incrementAndGet();
                                System.out.println("Creating "+str);
                                return str;
                        }

                        @Override
                        public void destroyObject(Object obj) throws Exception {
                                System.out.println("Destroying "+obj);
                        }
                });
                objectPool.setMinIdle(3);
                objectPool.setTimeBetweenEvictionRunsMillis(1000);
        }

        @Override
        public void destroy() {
                try {
                        objectPool.close();
                } catch (Exception e) {
                        e.printStackTrace();
                }
        }
}
The call to GenericObjectPool.setTimeBetweenEvictionRunsMillis) actually starts or reuses a java.lang.Timer shared between all GenericObjectPool instances. As long as a pool is running and at least one pool is using the timer eviction feature, the Timer lives.

If there's no other webapp using commons-pool, there's no leak : when we stop the webapp, the servlet is stopped and the pool is closed. If it was the only pool in use, the Timer thread is also stopped and there's no leak.

Now, imagine that there are 2 webapps using commons-pool with the timer eviction feature (imagine the above servlet is deployed in 2 webapps A and B). Suppose webapp A is deployed, then B. Since the commons-pool jar is shared between both webapps, only one Timer thread is spawned, with 2 TimerTask, one for each webapp, to handle the eviction of each pool instance.

Then, if we stop webapp A, boom it's leaking! the Timer thread has its context classloader set to the WebAppClassLoader of webapp A. This is somehow a bug of commons-pool, but tomcat 6.0.24 tries to help :


INFO: HTMLManager: stop: Stopping web application at '/testWeb'
Destroying Object #3
Destroying Object #2
Destroying Object #1
Mar 21, 2010 9:26:36 PM org.apache.catalina.loader.WebappClassLoader clearReferencesStopTimerThread
SEVERE: A web application appears to have started a TimerThread named [Timer-0] via the java.util.Timer API but has failed to stop it. To prevent a memory leak, the timer (and hence the associated thread) has been forcibly cancelled. 
So the leak is fixed, but unfortunately there's a side effect : it broke webapp B eviction timer. That's why stopping TimerThread has been made optional from 6.0.27.


Threads spawned by JRE classes

Just like third-party libraries may spawn threads that provoke leaks, some JRE classes also spawn threads that inherit from the current class loader and thus provoke leaks.

Instead of trying to stop such threads, tomcat prefers to force the creation of such threads when the container is started, before webapps are started. The JreMemoryLeakPreventionListener does it for a few known offenders in the JRE.


static class variables

When an app is stopped, Tomcat (even before 6.0.24) nullifies the value of all static class variables of classes loaded by the WebAppClassLoader. In some cases, it may fix a classloader leak (for example because of a custom ThreadLocal class, see above), but even if we still have a leak, it may decrease the amount of memory lost:

Imagine a class with the following variable :

private final static byte[] BUFFER = new byte[1024*1024]; //1MB buffer
Normally, the 1MB buffer should be freed when the app is stopped, but only if the classloader itself can be garbage-collected. Since there are still possibilities to have a leak of the classloader, clearing the BUFFER variable allows to recover 1MB of memory.


LogFactory

to be completed

JavaBean Introspector cache

Tomcat calls java.beans.Introspector.flushCaches(); when an app is stoppped.


JDBC driver registration

If a webapp contains a JDBC driver (e.g. in WEB-INF/lib), the driver will be registered with the DriverManager when it is first used. When the application is stopped, the driver should be deregistered with DriverManager to avoid a classloader leak. Since applications usually forget this, tomcat helps by deregistering the driver.


RMI target

to be completed


References

Mark Thomas interview on DZone
Eclipse Memory Analysis Tool
Related issues

49159 - Improve ThreadLocal memory leak clean-up
Sun bug 4957990 - In some cases the Server JVM fails to collect classloaders. According to this page it should have been fixed with java 6u16 but actually it was not. It seems to be fixed with 6u21 (documented here and verified by the author of this wiki page).
Sun bug 6916498 - An exception can keep a classloader in memory if the stack trace that was recorded when it was created contains a reference to one of its classes. Fixes were done in Tomcat for its own classes that had this issue (see BZ 50460), but some library or JRE code may still create a leak that is undetected by tools because of this JVM bug. See also BZ 53936 for a workaround that you can implement if you are unable to fix a buggy library.
CategoryFAQ

MemoryLeakProtection (last edited 2012-09-30 23:45:07 by KonstantinKolinko)
Immutable PageInfoAttachments 
MoinMoin PoweredPython PoweredGPL licensedValid HTML 4.01
========== http://blog.csdn.net/wangchengsi/article/details/2973012 ==========
您还未登录！|登录|注册|帮助首页业界移动云计算研发论坛博客下载
更多
王程斯的专栏静心做事
目录视图摘要视图订阅
2014年1月微软MVP申请开始啦！      CSDN社区中秋晒福利活动正式开始啦！        专访钟声：Java程序员，上班那点事儿      独一无二的职位：开源社区经理      “说说家乡的互联网”主题有奖征文
 Tomcat连接器：Coyote框架
分类： 开源 2008-09-24 06:16 4341人阅读 评论(1) 收藏 举报
tomcat框架sockethttp服务器servlet设计模式
目录(?)[+]
不论Tomcat的容器设计得如何精妙，本质上Tomcat就是个http服务器，需要从socket中获得HTTP数据流；另一方面，容器只能处理封装好的org.apache.coyote.Request （这个类的具体用途下面会讲到），从socket到Request之间需要有个转换过程。因此，连接socket和容器之间的重任就交给了Coyote

Coyote简介
coyote(北美的一种狼、山狗)

coyote是tomcat的Connector框架的名字，简单说就是coyote来处理底层的socket，并将http请求、响应等字节流层面的东西，包装成Request和Response两个类（这两个类是tomcat定义的，而非servlet中的ServletRequest和ServletResponse），供容器使用；同时，为了能让我们编写的servlet能够得到ServletRequest，tomcat使用了facade模式，将比较底层、低级的Request包装成为ServletRequest（这一过程通常发生在Wrapper容器一级），这也是为很多人津津乐道的tomcat对设计模式的一个巧妙的运用，具体过程将会在以后讨论。

所以，coyote本质上是为tomcat的容器提供了对底层socket连接数据的封装，以Request类的形式，让容器能够访问到底层的数据。

而关于连接池、线程池等直接和socket打交道的事情，tomcat交给了org.apache.tomcat.util.net包的类去完成，这里暂且不表

http://www.webweavertech.com/costin/archives/000421.html 
这个网页很好的描述了coyote的作用和设计思想，并介绍了其中几个影响性能的核心类

org.apache.coyote
这个包里面的主要是coyote框架的接口

Adapter
“适配器”在这里的意思，是指“凡是使用coyote连接器的容器，都要实现这个接口，以便从coyote连接器接收请求和响应数据”，当然这里的请求和响应是org.apache.coyote.Request和Response

ProtocolHandler
每个ProtocolHandler，代表着对一种协议的支持，比如tomcat默认支持的协议有http1.1和ajp。根据支持的协议，ProtocolHandler里面通常包含了一个实现对应协议的Handler接口的处理类，用于接收socket对象，再交给对应协议的Processor类（然而这个Processor类没有实现Processor接口，而是实现了ActionHook接口），最后由Processor类交给实现了Adapter接口的容器（准确的说是该容器的Pipeline的第一个Valve）

Processor
这个接口已经废弃了，通常tomcat的Processor实现类实现的接口是ActionHook。你会看到许多名为“XXXProcessor”的类，但其实他们实现的接口却是ActionHook

ActionHook
本接口代替了Processor接口，成为所有Processor实现类的标准接口。其方法只有一个：public void action( ActionCode actionCode, Object param); 
ActionCode是一个静态类，说白了是一堆常量（估计以后会改成enum），即对应不同的ActionCode，ActionHook要作出不同的动作，至于param是用于传递一些信息的，通常会把调用者“this”传递进去

InputBuffer和OutputBuffer
两个接口都只有一个方法，分别是doread和dowrite，就是把数据从ByteChunk参数读出或者写入ByteChunk。然而“数据”从何而来、怎样写进ByteChunk，还得看不同的类实现

Request，Response
鉴于其重要性，下面专文讲述

Request和Response
Request这个类可谓tomcat的一大核心，几乎所有connector和容器都要用到它

Request类实现了对底层http字节流的封装，因为http本质上是从网络过来的一串字节流，并且从逻辑上根据http协议，分成了头和体，其中头部又有很多字段（包括MIME字段）。而Request的作用就是把这些字节封装成对应的字段，并且达到处理效率的最优

因此，Request里面大部分方法是字段的get方法（set方法不多，因为大部分字段是不可改变的），此外还有提供给容器使用的方法，如recycle、inputbuffer等等。但最关键的是，Request是如何提高处理效率的

对于底层的、和字节流打交道的DO（data object），性能瓶颈在于对内存的使用上（因为字节都是放在一块块的内存中），如果能有效的使用内存，就能有效地提高DO的性能。

如果让我们来实现这个Request类，估计大部分人第一反应就是用String来表示每个http头字段，然而String的效率之低下是绝对无法胜任服务器的性能要求的

Request的注释告诉我们，它的大部分字段是“GC free”的，即很少、甚至不会被垃圾回收。杜绝了java中最大的一个性能瓶颈，Request自然性能得到大幅提升

此外，其字段的一些耗时操作都会延迟到用户代码一级，也就是说，tomcat内部在使用Request时，都会尽量保证它的字段处于原始的字节状态（而不是图方便到处使用String），直到用户代码（也就是我们写的servlet）需要时才进行转换，如果用不到（其实http请求的大部分字段在我们编程时都用不到），就不作转换。这样又进一步挖掘出更多的性能潜力，其思想和“延迟加载”的设计模式如出一辙。

当然，tomcat的程序员也是人也喜欢偷懒，谁都不乐意直接操纵字节数组，那样出错的风险也大。因此，tomcat的org.apache.tomcat.util包定义了许多底层的工具类，用于操作和维护字节数组。Request的字段们的类型为MessageBytes就是其中的一种

而关于Response，原理和Request类似，但是Response简单了很多，最明显的是里面的字段不像Request那样为效率绞尽脑汁，而是直接用了String，也许是Response对整体效率影响不大，亦或者当前版本的tomcat还未对其进行改造

分享到： 
上一篇：Tomcat源码学习
下一篇：Coyote for Http11: org.apache.coyote.http11

 
查看评论
1楼 kenshino 2008-12-02 14:32发表 [回复]

了解~
您还没有登录,请[登录]或[注册]
* 以上用户言论只代表其个人观点，不代表CSDN网站的观点或立场

个人资料
  
wangchengsi
 
访问：218485次
积分：3141分
排名：第2225名
原创：89篇转载：6篇译文：11篇评论：237条
文章搜索

文章分类
Eclipse技巧(1)
IBM产品(11)
J2SE(12)
Java EE(20)
多线程(1)
开源(14)
手机研究(1)
生活杂谈(35)
电脑技巧(7)
软件工程&amp;测试(5)
文章存档
2010年10月(1)
2010年09月(1)
2010年06月(2)
2010年03月(1)
2009年10月(1)
展开
阅读排行
第一次刷机——Motorola ME501刷机心得(31839)
Tomcat源码学习(12628)
推荐一本好书《How Tomcat Works》(12040)
招商银行软件中心（融博）面经(10684)
Coyote for Http11: org.apache.coyote.http11(7960)
启动框架 org.apache.catalina.startup(6834)
MQ集群(5556)
Java自动化测试（二）(4835)
用JMX监测JVM的运行参数(4767)
使用Jpcap进行java平台下的ipv6网络抓包(4540)
评论排行
IBM Message Broker笔记系列（三）(19)
使用Jpcap进行java平台下的ipv6网络抓包(14)
IBM Message Broker笔记系列（九）(12)
舞动精灵(12)
准备做个好学生(9)
IBM MessageBroker笔记系列（一）(8)
毕业旅行·厦门·金门之旅(8)
推荐一本好书《How Tomcat Works》(7)
MB与MQ简介(7)
IBM Message Broker笔记系列（六）(6)
推荐文章

最新评论
《How Tomcat Works》读书笔记（四）：容器初探
yishunliy: 能问个问题么？我也在看这个书，但是对于Valve又回调了ValveContext的invokeNex...
IBM Message Broker笔记系列（九）
chenlm2007: 专家你好，我在开发WMB的时候遇到一个问题，输入的是一个XML 1 2 3DECLARE a1 CH...
启动框架 org.apache.catalina.startup
小锋哥: 支持一个. 看的晕晕乎乎的
J2EE集群原理（二）
q1w2ok11: 谢谢了 己拜读
《How Tomcat Works》读书笔记（三）:Tomcat default connector
miliermili: 楼主讲的不错，对源码理解的很清晰！！！
招商银行软件中心（融博）面经
wuyuhua1981: 三天就拿到了offer，我面试说是1-2周
珠海紧急二日游
大公: 珠海挺漂亮的~！
推荐一本好书《How Tomcat Works》
大公: LZ是什么大学的，学生时期就这么懂的学习，懂得这么多东西！
招商银行软件中心（融博）面经
linux_java_80386: 没正装啊 这年头买不起
招商银行软件中心（融博）面经
kavensu: 明天就要去面试了，请问楼主现在招行软件怎么样？我现在有个中国航信的offer，那个比较好？
CSDN好友
kgn28
同学
宿舍好友的blog，文笔细腻，访问量非常大，很受低年级MM欢迎
班上头号才女，特别是英语好得让外语学院的都惭愧
宿舍另一才子，琴棋书画样样精通。如今考研成功，前往上财泡MM去了
博士师兄的blog
大米师兄的博客，主题是吃喝玩乐^_^
公司简介|招贤纳士|广告服务|银行汇款帐号|联系方式|版权声明|法律顾问|问题报告
QQ客服 微博客服 论坛反馈 联系邮箱：webmaster@csdn.net 服务热线：400-600-2320
京 ICP 证 070598 号
北京创新乐知信息技术有限公司 版权所有
世纪乐知(北京)网络技术有限公司 提供技术支持
江苏乐知网络技术有限公司 提供商务支持
Copyright © 1999-2012, CSDN.NET, All Rights Reserved 
  
========== http://smartvessel.iteye.com/category/115059 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
smartvessel
博客微博相册收藏留言关于我
  
文章列表
tomcat 7 源码分析-14 tomcat的container设计

博客分类： Tomcat 7源码分析
TomcatServletExcelSocket.net
                 实现 container←-----containerBase     ↑                          ↑     |继承                    |继承     |                          |     |         实现       ...
2010-08-05 14:52浏览 470评论(0)分类:企业架构
tomcat 7 源码分析-13 处理request的Valve和Valve的链表Pipeline

博客分类： Tomcat 7源码分析
TomcatCC++C#数据结构
tomcat打开endpoint的监听对通过某种协议，通常下是http的信息进行解析，组装成request，接着给Http11Protocol（ProtocolHandler）和Http11Processor处理。 adapter.service(request, response);   connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);  最终选择具体的Valve类处理request并生成response。 Valve和Pipeline的关系：Pipeli ...
2010-08-05 11:01浏览 518评论(0)分类:企业架构
tomcat 7 源码分析-12 Enumeration枚举

博客分类： Tomcat 7源码分析
Tomcat算法J#
Enumeration枚举，就是要把内容没有重复的遍历，而且不破坏原有的存储空间。在http headers的实现中，tomcat实现了一些枚举类。 Enumerate the distinct header names. Each nextElement() is O(n)   class NamesEnumerator implements Enumeration<String> { ...
2010-07-29 15:02浏览 279评论(0)分类:企业架构
tomcat 7 源码分析-11 tomcat对http协议的实现

博客分类： Tomcat 7源码分析
TomcatSocket浏览器
Implementation of InputBuffer which provides HTTP request header parsing as well as transfer decoding   socket能获得客户端发来的http协议，tomcat需要对http协议(传输的是byte流)进行解析，例如获得http的method,protocol,URI等信息. 既然是对byte流进行处理，tomcat封装了InternalInputBuffer。 public class InternalInputBuffer extends AbstractInputBuffer   ...
2010-07-28 11:11浏览 889评论(0)分类:企业架构
tomcat 7 源码分析-10 线程池ThreadPoolExecutor

博客分类： Tomcat 7源码分析
TomcatSocketApache工作
tomcat开启socket的accept线程后，其实要做的主要工作是交给worker线程去完成的，这其中使用了线程池的技术。 如： try { SocketWrapper<Socket> wrapper = new SocketWrapper<Socket>(socket); wrapper.setKeepAliveLeft(getMaxKeepAliveRequests()); getExecutor().execute(new SocketProcessor(wrapper)); ...
2010-07-26 14:55浏览 1423评论(0)分类:企业架构
tomcat 7 源码分析-9 tomcat对ServerSocket的封装和使用

博客分类： Tomcat 7源码分析
TomcatSocket.netthread浏览器
tomcat中ServerSocket线程监听是否有socket连接，如果有就转而处理。这个过程类似于你向tomcat发送一个URL请求，实质这个请求转换成http协议，通过socket发出来。 先看ServerSocket的封装主要为 public abstract class ServerSocketFactory implements Cloneable   class DefaultServerSocketFactory extends ServerSocketFactory { DefaultServerSocketFactory () { /* ...
2010-07-26 09:48浏览 776评论(0)分类:企业架构
tomcat 7 源码分析-8 生命周期lifecycle和监听listener

博客分类： Tomcat 7源码分析
TomcatJ#
每个应用都有生命周期lifecycle，可能包括init,start,stop,destroy等更多。针对生命周期的变化，如何做变化作出反应，tomcat在设计的时候，把时间监听listener结合起来，所以listener取的名字是lifecyclelistener，对lifecycle进行监听。 总的最底层的来自两个interface的设计Lifecycle和LifecycleListener。 lifecycle这个接口定义了除本身生命周期的函数，另外还定义了整个生命周期阶段的事件类型(这个肯定是为lifecyclelistener准备的)，同时还对LifecycleListener有 ...
2010-07-22 14:36浏览 597评论(0)分类:企业架构
tomcat 7 源码分析-7 server初始化中的JMX(DynamicMBean)再续

博客分类： Tomcat 7源码分析
TomcatApachethread
这里说下tomcat对DynamicMBean的实现和封装。利用tomcat包，可以轻松实现将自己的对象注册为MBeans。 看个例子就明白了。 package com.MBean.test; import org.apache.tomcat.util.modeler.BaseNotificationBroadcaster; public class DyMBeanObj extends BaseNotificationBroadcaster{ public int getConnectionNumber() { return this.conNum ...
2010-07-21 14:42浏览 464评论(0)分类:企业架构
tomcat 7 源码分析-6 server初始化中的JMX(DynamicMBean)续

博客分类： Tomcat 7源码分析
TomcatWindowsthread
先说JMX，The JMX technology provides a simple, standard way of managing resources such as applications, devices, and services. JMX是为了管理资源产生的，这个资源包括应用、设备和服务等。取个例子，如果你写了一个应用，初始化了20个的数据连接数，当你的应用还在跑的时候，发觉这个连接数少了，你要增加这个参数。JMX提供不需要停机，动态的管理连接数的方法。 先从简单的Standard MBeans看起。 通常我们先定义interface 第一步：MBean Interf ...
2010-07-20 18:01浏览 559评论(0)分类:企业架构
tomcat 7 源码分析-5 server初始化中的JMX(DynamicMBean)

博客分类： Tomcat 7源码分析
TomcatBeanCacheJVM
Server的中的初始化基本核心在StandardServer中，下面的代码 protected void initInternal() throws LifecycleException { super.initInternal(); // Register global String cache // Note although the cache is global, if there are multiple Servers // present in the JVM (may ha ...
2010-07-20 17:27浏览 561评论(0)分类:企业架构
tomcat 7 源码分析-4 server初始化背后getServer().init()

博客分类： Tomcat 7源码分析
TomcatUMLApacheJVM
getServer().init()其实就是调用server的init函数，但是server是个interface，还要看其在new的时候，这个就是多态。   digester.addObjectCreate("Server", "org.apache.catalina.core.StandardServer", "className"); digester.add ...
2010-07-19 22:52浏览 556评论(0)分类:企业架构
tomcat 7 源码分析-3 使用Digester读取xml文件实例化server

博客分类： Tomcat 7源码分析
XMLTomcatApache
接下来tomcat要load了，看下面一些程序片段 public void load() { long t1 = System.nanoTime(); initDirs(); initNaming(); Digester digester = createStartDigester(); ........ digester.push(this); digester.parse(inputSource); ........ get ...
2010-07-19 14:19浏览 593评论(1)分类:企业架构
tomcat 7 源码分析-2 类加载ClassLoader

博客分类： Tomcat 7源码分析
TomcatApacheJ#thread
tomcat在启动的时候使用了三个类加载器 private void initClassLoaders() { try { commonLoader = createClassLoader("common", null); if( commonLoader == null ) { // no config file, default to this loader - we might be in a 'single' env. ...
2010-07-17 18:39浏览 648评论(0)分类:企业架构
tomcat 7 源码分析-1 关于读取properties及注册系统properties

博客分类： Tomcat 7源码分析
TomcatApache
Tomact的启动开始于Bootstrap.java，在其init()中，首先要做的就是 setCatalinaHome(); setCatalinaBase(); initClassLoaders();  目的就是将tomcat启动的环境设置好，在进行classloader。 private void setCatalinaHome() { if (System.getProperty("catalina.home") != null) return; ...
2010-07-16 15:32浏览 856评论(0)分类:企业架构

smartvessel
浏览: 24396 次
性别: 
来自: 北京

最近访客 更多访客>>
dylinshi126ITspasguozhen_168stormhouse
文章分类
全部博客 (26)
Java基础 (4)
JEE (0)
随风的文字 (0)
Oracle基础及应用 (3)
Boost (4)
C++ (1)
Tomcat 7源码分析 (14)
社区版块
我的资讯 (0)
我的论坛 (5)
我的问答 (0)
存档分类
2010-08 (4)
2010-07 (13)
2009-12 (1)
更多存档...
最新评论
jieyuan_cg： 呃，这个不就是castor做的事情么？
tomcat 7 源码分析-3 使用Digester读取xml文件实例化server
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== http://oss.org.cn/ossdocs/apache/tomcat/heavyz/Bootstrap.java.html ==========
class Bootstrap

package org.apache.catalina.startup
2003-03-24

package org.apache.catalina.startup;


// JDKÀà¿â

import java.io.File;
import java.io.IOException;
import java.lang.reflect.Method;
import java.net.MalformedURLException;
import java.net.URL;
import java.util.ArrayList;


// apache×Ô¼ºµÄÀà¿â

import org.apache.catalina.loader.Extension;
import org.apache.catalina.loader.StandardClassLoader;



/**
 * Boostrap loader for Catalina.  This application constructs a class loader
 * for use in loading the Catalina internal classes (by accumulating all of the
 * JAR files found in the "server" directory under "catalina.home"), and
 * starts the regular execution of the container.  The purpose of this
 * roundabout approach is to keep the Catalina internal classes (and any
 * other classes they depend on, such as an XML parser) out of the system
 * class path and therefore not visible to application level classes.
 *
 * @author Craig R. McClanahan
 * @version $Revision: 1.36 $ $Date: 2002/04/01 19:51:31 $
 */



/**
 * ¸ÃÀàµÄmain·½·¨µÄÖ÷ÒªÈÎÎñ£º
 * --------------------------
 *
 * 1£¬´´½¨TOMCAT×Ô¼ºµÄÀàÔØÈëÆ÷(ClassLoader)
 *      +---------------------------+
 *      |         Bootstrap         |
 *      |             |             |
 *      |          System           |
 *      |             |             |
 *      |          Common           |
 *      |         /      \          |
 *      |     Catalina  Shared      |
 *      +---------------------------+
 *    ÆäÖÐ£º
 *    - Bootstrap - ÔØÈëJVM×Ô´øµÄÀàºÍ$JAVA_HOME/jre/lib/ext/*.jar
 *    - System    - ÔØÈë$CLASSPATH/*.class
 *    - Common    - ÔØÈë$CATALINA_HOME/common/...£¬ËüÃÇ¶ÔTOMCATºÍËùÓÐµÄWEB APP¶¼¿É¼û
 *    - Catalina  - ÔØÈë$CATALINA_HOME/server/...£¬ËüÃÇ½ö¶ÔTOMCAT¿É¼û£¬¶ÔËùÓÐµÄWEB APP¶¼²»¿É¼û
 *    - Shared    - ÔØÈë$CATALINA_HOME/shared/...£¬ËüÃÇ½ö¶ÔËùÓÐWEB APP¿É¼û£¬¶ÔTOMCAT²»¿É¼û£¨Ò²²»±Ø¼û£©
 *    ×¢Òâ£ºµ±Ò»¸öClassLoader±»ÇëÇóÔØÈëÒ»¸öÀàÊ±£¬ËüÊ×ÏÈÇëÇóÆä¸¸ClassLoaderÍê³ÉÔØÈë£¬
 *    ½öµ±Æä¸¸ClassLoaderÎÞ·¨ÔØÈë¸ÃÀàÊ±£¬²ÅÊÔÍ¼×Ô¼ºÔØÈë¸ÃÀà
 * 2£¬¸Ä±ä±¾ÉíÏß³ÌµÄÄ¬ÈÏClassLoader£¨±¾Ïß³Ì¾ÍÊÇTomcat ServerÏß³Ì£¬ÀàÔØÈëÆ÷ÊÇcatalinaLoader£©
 * 3£¬ÈÃcatalinaLoaderÔØÈëÒ»Ð©Àà£¬ÀàµÄÎ»ÖÃÔÚ$CATALINA_HOME/server/lib/catalina.jarÖÐ
 * 4£¬´´½¨org.apache.catalina.startup.CatalinaÀàµÄÒ»¸öÊµÀýstartupInstance£¬²¢ÎªÆäµ÷ÓÃ·½·¨£º
 *    startupInstance.setParentClassLoader(sharedLoader);
 *    startupInstance.process(args);
 *
 *
 * ÓÐ¹ØClassLoaderµÄËµÃ÷£º
 * -----------------------
 *
 * Ã¿¸ö±»DEPLOYµÄWEB APP¶¼»á±»´´½¨Ò»¸öClassLoader£¬ÓÃÀ´ÔØÈë¸ÃWEB APP×Ô¼ºµÄÀà
 * ÕâÐ©ÀàµÄÎ»ÖÃÊÇwebappX/WEB-INF/classes/*.classºÍwebappX/WEB-INF/lib/*.jar
 *
 * ClassLoaderµÄ¹¤×÷Á÷³ÌÊÇ£º
 * 1) ÊÕµ½Ò»¸öÔØÈëÀàµÄµÄÇëÇó
 * 2) ÇëÇóÆä¸¸ClassLoaderÀ´Íê³É¸ÃÀàµÄÔØÈë
 * 3) Èç¹û¸¸ClassLoaderÎÞ·¨ÔØÈë£¬Ôò×Ô¼ºÊÔÍ¼Íê³É¸ÃÀàµÄÔØÈë
 *
 * ÌØ±ð×¢ÒâWEB APP×Ô¼ºµÄClassLoaderµÄÊµÏÖÓëÖÚ²»Í¬£º
 * ËüÏÈÊÔÍ¼´ÓWEB APP×Ô¼ºµÄÄ¿Â¼ÀïÔØÈë£¬Èç¹ûÊ§°ÜÔòÇëÇó¸¸ClassLoaderµÄ´úÀí
 * ÕâÑù¿ÉÒÔÈÃ²»Í¬µÄWEB APPÖ®¼äµÄÀàÔØÈë»¥²»¸ÉÈÅ
 *
 * WEB APPµÄClassLoaderµÄ²ã´Î½á¹¹ÊÇ£º
 *     +----------------------------+
 *     |       Shared               |
 *     |      /      \ ...          |
 *     |   Webapp1  Webapp2  ...    |
 *     +----------------------------+
 * ¹Ê¶ÔÓÚÒ»¸öWEB APP£¬ÆäÀàÔØÈëµÄÓÅÏÈË³ÐòÈçÏÂ£º
 * - /WEB-INF/classes/*.class ºÍ /WEB-INF/lib/*.jar
 * - Bootstrap classes of JVM
 * - System class loader classes
 * - $CATALINA_HOME/common/...
 * - $CATALINA_HOME/shared/...
 *
 *
 * Ð¡½á£º
 * ------
 *
 * ×ÛÉÏ·ÖÎö
 * - Tomcat ServerÏß³ÌÊ¹ÓÃµÄclassLoaderÊÇCatalina
 * - Ã¿¸öWEB APPÏß³ÌÊ¹ÓÃµÄclassloaderÊÇWebapp?
 *
 */


public final class Bootstrap {



    /**
     * DEBUG¼¶±ð
     */

    private static int debug = 0;



    /**
     * ½Å±¾Ö´ÐÐ¸Ã³ÌÐòÊ±£¬Ìá¹©ÒÔÏÂµÄÏµÍ³ÊôÐÔ£º
     * java.endorsed.dirs="$JAVA_ENDORSED_DIRS" -classpath "$CLASSPATH" \
     * java.security.manager \
     * java.security.policy=="$CATALINA_BASE"/conf/catalina.policy \
     * catalina.base="$CATALINA_BASE" \
     * catalina.home="$CATALINA_HOME" \
     * java.io.tmpdir="$CATALINA_TMPDIR" \
     *
     * @param args Command line arguments to be processed
     */

    public static void main(String args[]) {


        // ÉèÖÃdebug

        for (int i = 0; i < args.length; i++)  {
            if ("-debug".equals(args[i]))
                debug = 1;
        }


        // ÉèÖÃºÃÏµÍ³ÊôÐÔcatalina.base£¬¼´±£Ö¤ÆäÓÐÖµ

        if (System.getProperty("catalina.base") == null)
            System.setProperty("catalina.base", getCatalinaHome());


        // ´´½¨Èý¸öClassLoader
        // ÕâÈý¸ö¶ÔÏóÊÇÍ¨¹ýClassLoaderFactoryµÄ¾²Ì¬·½·¨´´½¨µÄ
        // ÆäÊµ¼ÊÀàÐÍÊÇStandardClassLoader£¬Íê³Étomcat×Ô¶¨ÒåµÄÀàÔØÈë
        // ÕâÐ©Àà¶Ô·Çtomcat¼°ÆäÉÏµÄwebappµÄÆäËüjava³ÌÐò²»¿É¼û£¬¹ÊÓÃ×Ô¼ºµÄClassloaderÔØÈë

        ClassLoader commonLoader = null;
        ClassLoader catalinaLoader = null;
        ClassLoader sharedLoader = null;
        try {

            File unpacked[] = new File[1];
            File packed[] = new File[1];
            File packed2[] = new File[2];
            
            ClassLoaderFactory.setDebug(debug);


            // $CATALINA_HOME/common/classes/*.class - Î´Ñ¹ËõµÄÀà
            // $CATALINA_HOME/common/endorsed/*.jar - Ñ¹ËõµÄÀà£¨endorse£ºÖ§³Ö£©
            // $CATALINA_HOME/common/lib/*.jar - Ñ¹ËõµÄÀà
            // ÕâÐ©ÀàÊÇ±»tomcat serverÒÔ¼°ËùÓÐµÄwebappËù¹²ÏíµÄÀà£¬ÓÉcommonLoader¸ºÔðÔØÈë

            unpacked[0] = new File(getCatalinaHome(),
                                   "common" + File.separator + "classes");
            packed2[0] = new File(getCatalinaHome(),
                                  "common" + File.separator + "endorsed");
            packed2[1] = new File(getCatalinaHome(),
                                  "common" + File.separator + "lib");
            commonLoader =
                ClassLoaderFactory.createClassLoader(unpacked, packed2, null);



            // $CATALINA_HOME/server/classes/*.class
            // $CATALINA_HOME/server/lib/*.jar
            // ÕâÐ©ÀàÊÇ½ö±»tomcat serverÊ¹ÓÃ¶ø¶Ôwebapp²»¿É¼ûµÄÀà£¬ÓÉcatalinaLoader¸ºÔðÔØÈë

            unpacked[0] = new File(getCatalinaHome(),
                                   "server" + File.separator + "classes");
            packed[0] = new File(getCatalinaHome(),
                                 "server" + File.separator + "lib");
            catalinaLoader =
                ClassLoaderFactory.createClassLoader(unpacked, packed,
                                                     commonLoader);



            // $CATALINA_BASE/shared/classes/*.class
            // $CATALINA_BASE/shared/lib/*.jar
            // ÕâÐ©ÀàÊÇ½ö±»tomcatµÄwebappÊ¹ÓÃµÄÀà£¬ÓÉsharedLoader¸ºÔðÔØÈë

            unpacked[0] = new File(getCatalinaBase(),
                                   "shared" + File.separator + "classes");
            packed[0] = new File(getCatalinaBase(),
                                 "shared" + File.separator + "lib");
            sharedLoader =
                ClassLoaderFactory.createClassLoader(unpacked, packed,
                                                     commonLoader);
                                                     

            // ×¢ÒâÈý¸ö×Ô¼º¶¨ÖÃµÄClassLoaderµÄ²ã´Î¹ØÏµ£º
            // systemClassLoader (root)
            //   +--- commonLoader
            //          +--- catalinaLoader
            //          +--- sharedLoader

        } catch (Throwable t) {
            log("Class loader creation threw exception", t);
            System.exit(1);

        }


        // Îªµ±Ç°µÄÏß³Ì¸ü¸ÄÆäcontextClassLoader
        // Ò»°ãµÄÏß³ÌÄ¬ÈÏµÄcontextClassLoaderÊÇÏµÍ³µÄClassLoader£¨ËùÓÐÆäËü×Ô¶¨ÒåClassLoaderµÄ¸¸Ç×£©
        // µ±¸ÃÏß³ÌÐèÒªÔØÈëÀàÊ±£¬½«Ê¹ÓÃ×Ô¼ºµÄcontextClassLoaderÀ´Ñ°ÕÒ²¢ÔØÈëÀà
        // ¸ü¸ÄcontextClassLoader¿ÉÒÔ¸ü¸Ä¸ÃÏß³ÌµÄÑ°ÕÒºÍÔØÈëÀàµÄÐÐÎª£¬µ«²»Ó°Ïìµ½ÆäËüÏß³Ì
        // ×¢Òâ£¡Tomcat ServerÏß³ÌÊ¹ÓÃµÄÊÇcatalinaLoader

        Thread.currentThread().setContextClassLoader(catalinaLoader);



        // Load our startup class and call its process() method

        try {


            // Ô¤ÔØÈëcatalinalLoaderµÄÒ»Ð©Àà

            SecurityClassLoad.securityClassLoad(catalinaLoader);


            // »ñµÃtomcatµÄÆô¶¯Àà£ºorg.apache.catalina.startup.Catalina£¬²¢´´½¨¸ÃÀàµÄÒ»¸öÊµÀý

            if (debug >= 1)
                log("Loading startup class");
            Class startupClass =
                catalinaLoader.loadClass
                ("org.apache.catalina.startup.Catalina");
            Object startupInstance = startupClass.newInstance();


            // ÉèÖÃstartupInstanceµÄ¸¸ClassLoader£¬Ïàµ±ÓÚÖ´ÐÐ£º
            // Catalina startupInstance = new Catailina();
            // startupInstance.setParentClassLoader(sharedLoader);
            // ÏêÇé²Î¿¼Ààorg.apache.catalina.startup.Catalina

            if (debug >= 1)
                log("Setting startup class properties");
            String methodName = "setParentClassLoader";
            Class paramTypes[] = new Class[1];
            paramTypes[0] = Class.forName("java.lang.ClassLoader");
            Object paramValues[] = new Object[1];
            paramValues[0] = sharedLoader;
            Method method =
                startupInstance.getClass().getMethod(methodName, paramTypes);
            method.invoke(startupInstance, paramValues);


            // Ê¹ÓÃmain·½·¨»ñµÃµÄ²ÎÊýargsÀ´Ö´ÐÐprocess·½·¨£¬Ïàµ±ÓÚ£º
            // startupInstance.process(args);
            // ÏêÇé²Î¿¼Ààorg.apache.catalina.startup.Catalina

            if (debug >= 1)
                log("Calling startup class process() method");
            methodName = "process";
            paramTypes = new Class[1];
            paramTypes[0] = args.getClass();
            paramValues = new Object[1];
            paramValues[0] = args;
            method =
                startupInstance.getClass().getMethod(methodName, paramTypes);
            method.invoke(startupInstance, paramValues);

        } catch (Exception e) {
            System.out.println("Exception during startup processing");
            e.printStackTrace(System.out);
            System.exit(2);
        }

    }



    /**
     * ·µ»Ø$CATALINA_HOME±äÁ¿¡£Èç¹û¸Ã±äÁ¿Ã»ÓÐ¶¨Òå£¬Ôò½«Ö®¸³ÖµÎªÓÃ»§µÄµ±Ç°¹¤×÷Ä¿Â¼¡£
     */

    private static String getCatalinaHome() {
        return System.getProperty("catalina.home",
                                  System.getProperty("user.dir"));
    }



    /**
     * ·µ»Ø$CATALINA_BASE±äÁ¿¡£Èç¹û¸Ã±äÁ¿Ã»ÓÐ¶¨Òå£¬Ôò½«Ö®¸³ÖµÎª$CATALINA_HOME¡£
     */

    private static String getCatalinaBase() {
        return System.getProperty("catalina.base", getCatalinaHome());
    }



    /**
     * Êä³öLOGÐÅÏ¢¡£
     */

    private static void log(String message) {

        System.out.print("Bootstrap: ");
        System.out.println(message);

    }



    /**
     * Êä³öÓÉÒì³£ÒýÆðµÄLOGÐÅÏ¢¡£
     */

    private static void log(String message, Throwable exception) {

        log(message);
        exception.printStackTrace(System.out);

    }


}

========== http://www.dunsh.org/2006/08/02/robotstxt/ ==========
点石互动
公益性搜索引擎优化(SEO)站点，搜索引擎营销和SEO技术的交流平台。
首页 点石论坛 我们是谁？ 版权声明
切换搜索引擎
首页 > SEO技术	 > 如何写robots.txt？
如何写robots.txt？
作者：robin 时间：2006年8月2日
在国内，网站管理者似乎对robots.txt并没有引起多大重视，应一些朋友之请求，今天想通过这篇文章来简单谈一下robots.txt的写作。


robots.txt基本介绍

robots.txt是一个纯文本文件，在这个文件中网站管理者可以声明该网站中不想被robots访问的部分，或者指定搜索引擎只收录指定的内容。

当一个搜索机器人（有的叫搜索蜘蛛）访问一个站点时，它会首先检查该站点根目录下是否存在robots.txt，如果存在，搜索机器人就会按照该文件中的内容来确定访问的范围；如果该文件不存在，那么搜索机器人就沿着链接抓取。

另外，robots.txt必须放置在一个站点的根目录下，而且文件名必须全部小写。

robots.txt写作语法

首先，我们来看一个robots.txt范例：http://www.seovip.cn/robots.txt

访问以上具体地址，我们可以看到robots.txt的具体内容如下：

# Robots.txt file from http://www.seovip.cn
# All robots will spider the domain

User-agent: *
Disallow:

以上文本表达的意思是允许所有的搜索机器人访问www.seovip.cn站点下的所有文件。

具体语法分析：其中#后面文字为说明信息；User-agent:后面为搜索机器人的名称，后面如果是*，则泛指所有的搜索机器人；Disallow:后面为不允许访问的文件目录。

下面，我将列举一些robots.txt的具体用法：

允许所有的robot访问

User-agent: *
Disallow:

或者也可以建一个空文件 "/robots.txt" file

禁止所有搜索引擎访问网站的任何部分

User-agent: *
Disallow: /

禁止所有搜索引擎访问网站的几个部分（下例中的01、02、03目录）

User-agent: *
Disallow: /01/
Disallow: /02/
Disallow: /03/

禁止某个搜索引擎的访问（下例中的BadBot）

User-agent: BadBot
Disallow: /

只允许某个搜索引擎的访问（下例中的Crawler）

User-agent: Crawler
Disallow:

User-agent: *
Disallow: /

另外，我觉得有必要进行拓展说明，对robots meta进行一些介绍：

Robots META标签则主要是针对一个个具体的页面。和其他的META标签（如使用的语言、页面的描述、关键词等）一样，Robots META标签也是放在页面的＜head＞＜/head＞中，专门用来告诉搜索引擎ROBOTS如何抓取该页的内容。

Robots META标签的写法：

Robots META标签中没有大小写之分，name=”Robots”表示所有的搜索引擎，可以针对某个具体搜索引擎写为name=”BaiduSpider”。 content部分有四个指令选项：index、noindex、follow、nofollow，指令间以“,”分隔。

INDEX 指令告诉搜索机器人抓取该页面；

FOLLOW 指令表示搜索机器人可以沿着该页面上的链接继续抓取下去；

Robots Meta标签的缺省值是INDEX和FOLLOW，只有inktomi除外，对于它，缺省值是INDEX,NOFOLLOW。

这样，一共有四种组合：

＜META NAME="ROBOTS" CONTENT="INDEX,FOLLOW"＞
＜META NAME="ROBOTS" CONTENT="NOINDEX,FOLLOW"＞
＜META NAME="ROBOTS" CONTENT="INDEX,NOFOLLOW"＞
＜META NAME="ROBOTS" CONTENT="NOINDEX,NOFOLLOW"＞

其中

＜META NAME="ROBOTS" CONTENT="INDEX,FOLLOW"＞可以写成＜META NAME="ROBOTS" CONTENT="ALL"＞；

＜META NAME="ROBOTS" CONTENT="NOINDEX,NOFOLLOW"＞可以写成＜META NAME="ROBOTS" CONTENT="NONE"＞

目前看来，绝大多数的搜索引擎机器人都遵守robots.txt的规则，而对于Robots META标签，目前支持的并不多，但是正在逐渐增加，如著名搜索引擎GOOGLE就完全支持，而且GOOGLE还增加了一个指令“archive”，可以限制GOOGLE是否保留网页快照。例如：

＜META NAME="googlebot" CONTENT="index,follow,noarchive"＞

表示抓取该站点中页面并沿着页面中链接抓取，但是不在GOOLGE上保留该页面的网页快照。

特别说明，本文章的写作参考了一些网络信息，robin只是按照自己的思路对信息进行整理。

robin的其他文章：
2009年点石大会：并不只是SEO可以吸引你！ - 2009-11-03
点石邀你共聚南大探讨海外营销 - 2009-06-04
Robin主持：你问我答002期 - 2009-01-11
大部分网址导航站内页PR恢复 - 2009-01-06
庆元旦活动：2009年你的计划是什么？ - 2008-12-31
SEO技术
评论 (45)Trackbacks (3)

风中紫蝴蝶
2007年4月22日19:38	 | #1 回复 | 引用
写得太好了..请问作者怎么联系呀?

visc
2007年5月13日20:06	 | #2 回复 | 引用
谢谢robin，我收藏了

mao
2007年5月14日19:22	 | #3 回复 | 引用
附带一句就是
robots.txt 好像是可以作用于某个目录的。也就是放在
/test/ 下的robots.txt 只作用于 /test/ 目录

ohyee
2007年5月24日09:49	 | #4 回复 | 引用
收下。

use
2007年6月27日17:10	 | #5 回复 | 引用
已经转载,谢谢>
http://www.ititgo.cn/html/2007/6/805.htm

非主流
2007年8月12日04:09	 | #6 回复 | 引用
谢谢你啊。我正在测试:www.fzl.in

bluepig
2007年8月20日13:12	 | #7 回复 | 引用
写的很好 ，能不能转载你的文章啊，我会著名出处。

郑州人才网
2007年9月8日13:13	 | #8 回复 | 引用
不错，这个很经典，收藏学习。

郑州人才网
2007年9月8日14:37	 | #9 回复 | 引用
可是如何保护这个robots.txt 不被竞争对手看到呢？如果看到了 修改就完了，请告诉我，好吗，急！！job371@163.com

NAOMI
2007年9月19日10:17	 | #10 回复 | 引用
请问我的网站site:www.kjzcw.com时会出现8383端口的访问，能通过robot编写禁止访问吗

p268
2007年9月24日08:20	 | #11 回复 | 引用
谢谢robin，学习了，我收藏。

韩杨
2007年10月18日09:37	 | #12 回复 | 引用
果然是篇实用美文，站长们都很关注这些信息。

吕仕华
2007年10月27日09:51	 | #13 回复 | 引用
我想问一下,要是我是静态网页需要限制其他吗?急急!!!!!!

时尚衣衣
2007年11月3日22:11	 | #14 回复 | 引用
学习了，多谢分享！

幼峰
2007年11月14日11:06	 | #15 回复 | 引用
我对这个“或者也可以建一个空文件 “/robots.txt” file”不是很明白 能详细说说说么？

rzwince
2007年11月21日11:18	 | #16 回复 | 引用
我是新手站长,向您学习了,谢谢!

非主流
2007年11月22日14:08	 | #17 回复 | 引用
说的不错　谢谢！

商都租车网
2007年11月27日11:32	 | #18 回复 | 引用
http://www.sdzcw.com
看看我们写的对不对?

seoguy
2007年12月4日12:11	 | #19 回复 | 引用
写的不错。

非主流宝贝
2007年12月13日13:25	 | #20 回复 | 引用
..学习了.

美文欣赏
2007年12月17日17:39	 | #21 回复 | 引用
没用过这个...学习...

帝国
2007年12月24日10:15	 | #22 回复 | 引用
恩 谢谢 学习中 ... 收藏也！

学习
2007年12月25日08:14	 | #23 回复 | 引用
谢谢,懂了,写了一个
http://www.rajyfq.com

善良是罪
2008年1月2日13:25	 | #24 回复 | 引用
我想问的是，如果在根目录下，文件名也必须一致，那么直接把这个文件下载了，里面的内容不就全部泄露了？？？

聊城导航
2008年1月5日10:48	 | #25 回复 | 引用
高手就是高手啊，分析的很全也很透彻啊。好容易看！多多学习以后。

ygw
2008年1月6日15:49	 | #26 回复 | 引用
呵呵，很不错，辛苦了，顺便给你补上出处就更完整了
http://www.robotstxt.org/orig.html
http://www.robotstxt.org/meta.html
第一次来这里，顺便看了下贵站法大研究生的个人站点，可能的话希望能和她（他）联系，有机会也可以交流下知产问题

小姚
2008年1月14日15:50	 | #27 回复 | 引用
说得很详细哦，谢谢

紫雨莹霜
2008年1月18日09:18	 | #28 回复 | 引用
呵呵，受益了，谢谢

王德智
2008年3月10日10:59	 | #29 回复 | 引用
写的太好了，受益匪浅！

招聘会
2008年3月12日08:47	 | #30 回复 | 引用
经典....收藏之...


tudou
2008年3月31日11:33	 | #31 回复 | 引用
如果要禁止某个搜索引擎(如baiduspider)的访问是应该写在*的前面还是后面,另外如果*里面已经禁止了访问某个目录,baiduspider还需要写一遍吗?我的网站是http://www.tudouju.cn帮我看看是否正确?

8e
2008年3月31日13:27	 | #32 回复 | 引用
到现在我还没搞明白如果没有不让搜索引擎看的东西，那ROBOTS还有写的必要吗？

亮亮
2008年5月23日21:24	 | #33 回复 | 引用
我不是IT人士，只是对搜索引擎的运作有些好奇，来到这里，我的问题有了详细的答案，
感谢站长！

伊人网
2008年6月6日03:54	 | #34 回复 | 引用
很全面也很实用呀.感谢!

卡其博客
2008年6月7日20:26	 | #35 回复 | 引用
写的不错 知识慢慢学
欢迎访问卡其博客www.kaqi123.cn

ahcqren
2008年6月23日16:11	 | #36 回复 | 引用
我们我的设置过后,百度却还是把我的禁止的页面抓取了,并且还全部是抓区的这样的页面www.suzhiwang.com 大家帮我看看

ocean
2008年6月24日13:21	 | #37 回复 | 引用
写得很好，谢谢robin

richwelder
2008年7月1日16:05	 | #38 回复 | 引用
正在给自己的网站写rebots.txt呢..学习中...

伊人网
2008年9月13日14:20	 | #39 回复 | 引用
很好`很详细.谢谢分享

防伪
2008年9月20日21:39	 | #40 回复 | 引用
我想请问下，如何让搜索引擎把默认的主打域名改掉，我现在是两个域名，一个NET，一个COM，GG和百度默认的是NET的，但是我要的是COM的效果，请问怎么用robots达到这种效果，或者有其他办法不？

tomheng
2008年10月24日17:18	 | #41 回复 | 引用
谢谢作者的简介。受益匪浅啊！！

fezz
2008年11月11日17:25	 | #42 回复 | 引用
谢谢,按你的方法做了,不知行不行,好用再回来,顶顶,呵呵

闯
2008年11月28日09:49	 | #43 回复 | 引用
谢谢，非常有帮助。

lzhang
2008年11月29日14:28	 | #44 回复 | 引用
好东西，我的robots指定sitemap以前把语法整错了。不过META NAME如何应用还是不知道

提梦寻心
2009年1月16日19:20	 | #45 回复 | 引用
写的不错，我收录了，谢谢！
本文的评论功能被关闭了.
企业需要什么样的网络营销顾问 搜索引擎营销的一些策略
RSS 订阅
最新文章
2011年SEO人才分析报告--SEO人才网
《Google SEO 入门教程》更新
谷歌称自己多项产品SEO方面表现不佳
国内搜索引擎优化的发展趋势
Google个性化搜索和对SEO的影响
百度今日将全面启用凤巢系统替代竞价排名
2009年点石大会：并不只是SEO可以吸引你！
PR值正在更新
乐思蜀：我们不做网络民工
周志忠：传统行业搜索营销案例分享
关注博客和网站
Google黑板报
SEO论坛
搜索引擎营销观察
谷歌中文网站管理员博客
点石合作伙伴
杭州思亿欧
西安欧派
点石服务台
点石论坛
存档页
2011年08月
2010年11月
2010年03月
2010年01月
2009年12月
2009年11月
2009年10月
2009年09月
2009年08月
2009年06月
2009年04月
2009年03月
2009年02月
2009年01月
2008年12月
2008年11月
2008年10月
2008年09月
2008年07月
2008年06月
2008年05月
2008年04月
2008年03月
2008年02月
2008年01月
2007年12月
2007年11月
2007年10月
2007年09月
2007年08月
2007年07月
2007年06月
2007年05月
2007年04月
2007年03月
2007年02月
2007年01月
2006年12月
2006年11月
2006年10月
2006年09月
2006年08月
2006年07月
分类
Baidu专题
Blog营销
Google专题
MSN专题
SEO in China
SEO博文推荐
SEO技术
SEO月刊
SEO行业新闻
SEO论点
Yahoo专题
团队记事
国际SEO视点
市场营销
搜索引擎营销
播客营销
杂谈随笔
海外营销
点石人物专访
点石摘要
点石观察
点石视频
网络营销
置顶WordPress
版权所有 © 2006-2011	 点石互动
主题由 MG12 提供, 通过 XHTML 1.1 和 CSS 3 验证.
========== http://netkiller.sourceforge.net/centos/nginx.html ==========
========== http://netkiller.sourceforge.net/centos/nginx.html ==========
========== http://lustlost.blog.51cto.com/2600869/929915 ==========
========== http://netkiller.sourceforge.net/centos/nginx.html ==========
========== http://linvar.iteye.com/blog/672191 ==========

========== http://www.ibm.com/developerworks/cn/java/j-lo-spring25-mvc/ ==========
跳转到主要内容
登录 (或注册) 日本語 IBM

技术主题
软件下载
社区
技术讲座
搜索 developerWorks  
developerWorks 中国Java technology文档库
使用 Spring 2.5 基于注解驱动的 Spring MVC
陈 雄华 (quickselect@163.com), 技术总监, 宝宝淘网络科技有限公司
简介： 基于注解的配置有越来越流行的趋势，Spring 2.5 顺应这种趋势，为 Spring MVC 提供了完全基于注解的配置。本文将介绍 Spring 2.5 新增的 Sping MVC 注解功能，讲述如何使用注解配置替换传统的基于 XML 的 Spring MVC 配置。
发布日期： 2008 年 3 月 14 日 
级别： 初级 
访问情况 ： 70757 次浏览 
评论：  (查看 | 添加评论 - 登录)
 平均分 (224个评分)
为本文评分

概述
继 Spring 2.0 对 Spring MVC 进行重大升级后，Spring 2.5 又为 Spring MVC 引入了注解驱动功能。现在你无须让 Controller 继承任何接口，无需在 XML 配置文件中定义请求和 Controller 的映射关系，仅仅使用注解就可以让一个 POJO 具有 Controller 的绝大部分功能 —— Spring MVC 框架的易用性得到了进一步的增强.在框架灵活性、易用性和扩展性上，Spring MVC 已经全面超越了其它的 MVC 框架，伴随着 Spring 一路高唱猛进，可以预见 Spring MVC 在 MVC 市场上的吸引力将越来越不可抗拒。
本文将介绍 Spring 2.5 新增的 Sping MVC 注解功能，讲述如何使用注解配置替换传统的基于 XML 的 Spring MVC 配置。
回页首
一个简单的基于注解的 Controller
使用过低版本 Spring MVC 的读者都知道：当创建一个 Controller 时，我们需要直接或间接地实现 org.springframework.web.servlet.mvc.Controller 接口。一般情况下，我们是通过继承 SimpleFormController 或 MultiActionController 来定义自己的 Controller 的。在定义 Controller 后，一个重要的事件是在 Spring MVC 的配置文件中通过 HandlerMapping 定义请求和控制器的映射关系，以便将两者关联起来。
来看一下基于注解的 Controller 是如何定义做到这一点的，下面是使用注解的 BbtForumController：

清单 1. BbtForumController.java
                
package com.baobaotao.web;

import com.baobaotao.service.BbtForumService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.ModelAttribute;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestMethod;

import java.util.Collection;

@Controller                   //<——①
@RequestMapping("/forum.do")
public class BbtForumController {

    @Autowired
    private BbtForumService bbtForumService;

    @RequestMapping //<——②
    public String listAllBoard() {
        bbtForumService.getAllBoard();
        System.out.println("call listAllBoard method.");
        return "listBoard";
    }
}

从上面代码中，我们可以看出 BbtForumController 和一般的类并没有区别，它没有实现任何特殊的接口，因而是一个地道的 POJO。让这个 POJO 与众不同的魔棒就是 Spring MVC 的注解！
在 ① 处使用了两个注解，分别是 @Controller 和 @RequestMapping。在“使用 Spring 2.5 基于注解驱动的 IoC”这篇文章里，笔者曾经指出过 @Controller、@Service 以及 @Repository 和 @Component 注解的作用是等价的：将一个类成为 Spring 容器的 Bean。由于 Spring MVC 的 Controller 必须事先是一个 Bean，所以 @Controller 注解是不可缺少的。
真正让 BbtForumController 具备 Spring MVC Controller 功能的是 @RequestMapping 这个注解。@RequestMapping 可以标注在类定义处，将 Controller 和特定请求关联起来；还可以标注在方法签名处，以便进一步对请求进行分流。在 ① 处，我们让 BbtForumController 关联“/forum.do”的请求，而 ② 处，我们具体地指定 listAllBoard() 方法来处理请求。所以在类声明处标注的 @RequestMapping 相当于让 POJO 实现了 Controller 接口，而在方法定义处的 @RequestMapping 相当于让 POJO 扩展 Spring 预定义的 Controller（如 SimpleFormController 等）。
为了让基于注解的 Spring MVC 真正工作起来，需要在 Spring MVC 对应的 xxx-servlet.xml 配置文件中做一些手脚。在此之前，还是先来看一下 web.xml 的配置吧：

清单 2. web.xml：启用 Spring 容器和 Spring MVC 框架
                
<?xml version="1.0" encoding="UTF-8"?>
<web-app xmlns="http://java.sun.com/xml/ns/javaee"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://java.sun.com/xml/ns/javaee
    http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" version="2.5">
    <display-name>Spring Annotation MVC Sample</display-name>
    <!--  Spring 服务层的配置文件 -->
    <context-param>
        <param-name>contextConfigLocation</param-name>
        <param-value>classpath:applicationContext.xml</param-value>
    </context-param>
     
    <!--  Spring 容器启动监听器 -->
    <listener>
        <listener-class>org.springframework.web.context.ContextLoaderListener
        </listener-class>
    </listener>

    <!--  Spring MVC 的Servlet，它将加载WEB-INF/annomvc-servlet.xml 的
    配置文件，以启动Spring MVC模块-->
    <servlet>
        <servlet-name>annomvc</servlet-name>
        <servlet-class>org.springframework.web.servlet.DispatcherServlet
        </servlet-class>
        <load-on-startup>2</load-on-startup>
    </servlet>

    <servlet-mapping>
        <servlet-name>annomvc</servlet-name>
        <url-pattern>*.do</url-pattern>
    </servlet-mapping>
</web-app>

web.xml 中定义了一个名为 annomvc 的 Spring MVC 模块，按照 Spring MVC 的契约，需要在 WEB-INF/annomvc-servlet.xml 配置文件中定义 Spring MVC 模块的具体配置。annomvc-servlet.xml 的配置内容如下所示：
清单 3. annomvc-servlet.xml
                
<?xml version="1.0" encoding="UTF-8"?>
<beans 
    xmlns="http://www.springframework.org/schema/beans" 
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:p="http://www.springframework.org/schema/p" 
    xmlns:context="http://www.springframework.org/schema/context"
    xsi:schemaLocation="http://www.springframework.org/schema/beans 
    http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
    http://www.springframework.org/schema/context 
    http://www.springframework.org/schema/context/spring-context-2.5.xsd">
     
    <!-- ①：对web包中的所有类进行扫描，以完成Bean创建和自动依赖注入的功能 -->
    <context:component-scan base-package="com.baobaotao.web"/>

    <!-- ②：启动Spring MVC的注解功能，完成请求和注解POJO的映射 -->
    <bean class="org.springframework.web.servlet.mvc.annotation.
        AnnotationMethodHandlerAdapter"/>

    <!--  ③：对模型视图名称的解析，即在模型视图名称添加前后缀 -->
    <bean class="org.springframework.web.servlet.view.InternalResourceViewResolver" 
        p:prefix="/WEB-INF/jsp/" p:suffix=".jsp"/>
</beans>

因为 Spring 所有功能都在 Bean 的基础上演化而来，所以必须事先将 Controller 变成 Bean，这是通过在类中标注 @Controller 并在 annomvc-servlet.xml 中启用组件扫描机制来完成的，如 ① 所示。
在 ② 处，配置了一个 AnnotationMethodHandlerAdapter，它负责根据 Bean 中的 Spring MVC 注解对 Bean 进行加工处理，使这些 Bean 变成控制器并映射特定的 URL 请求。
而 ③ 处的工作是定义模型视图名称的解析规则，这里我们使用了 Spring 2.5 的特殊命名空间，即 p 命名空间，它将原先需要通过 <property> 元素配置的内容转化为 <bean> 属性配置，在一定程度上简化了 <bean> 的配置。
启动 Tomcat，发送 http://localhost/forum.do URL 请求，BbtForumController 的 listAllBoard() 方法将响应这个请求，并转向 WEB-INF/jsp/listBoard.jsp 的视图页面。
回页首
让一个 Controller 处理多个 URL 请求
在低版本的 Spring MVC 中，我们可以通过继承 MultiActionController 让一个 Controller 处理多个 URL 请求。使用 @RequestMapping 注解后，这个功能更加容易实现了。请看下面的代码：
清单 3. 每个请求处理参数对应一个 URL
                
package com.baobaotao.web;

import com.baobaotao.service.BbtForumService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.RequestMapping;

@Controller
public class BbtForumController {
    @Autowired
    private BbtForumService bbtForumService;

    @RequestMapping("/listAllBoard.do") // <—— ①
    public String listAllBoard() {
        bbtForumService.getAllBoard();
        System.out.println("call listAllBoard method.");
        return "listBoard";
    }

    @RequestMapping("/listBoardTopic.do") // <—— ②
    public String listBoardTopic(int topicId) {
        bbtForumService.getBoardTopics(topicId);
        System.out.println("call listBoardTopic method.");
        return "listTopic";
    }
}

在这里，我们分别在 ① 和 ② 处为 listAllBoard() 和 listBoardTopic() 方法标注了 @RequestMapping 注解，分别指定这两个方法处理的 URL 请求，这相当于将 BbtForumController 改造为 MultiActionController。这样 /listAllBoard.do 的 URL 请求将由 listAllBoard() 负责处理，而 /listBoardTopic.do?topicId=1 的 URL 请求则由 listBoardTopic() 方法处理。
对于处理多个 URL 请求的 Controller 来说，我们倾向于通过一个 URL 参数指定 Controller 处理方法的名称（如 method=listAllBoard），而非直接通过不同的 URL 指定 Controller 的处理方法。使用 @RequestMapping 注解很容易实现这个常用的需求。来看下面的代码：

清单 4. 一个 Controller 对应一个 URL，由请求参数决定请求处理方法
                
package com.baobaotao.web;

import com.baobaotao.service.BbtForumService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.RequestMapping;

@Controller
@RequestMapping("/bbtForum.do")  // <—— ① 指定控制器对应URL请求
public class BbtForumController {

    @Autowired
    private BbtForumService bbtForumService;

    // <—— ② 如果URL请求中包括"method=listAllBoard"的参数，由本方法进行处理
    @RequestMapping(params = "method=listAllBoard") 
    public String listAllBoard() {
        bbtForumService.getAllBoard();
        System.out.println("call listAllBoard method.");
        return "listBoard";
    }

    // <—— ③ 如果URL请求中包括"method=listBoardTopic"的参数，由本方法进行处理
    @RequestMapping(params = "method=listBoardTopic")
    public String listBoardTopic(int topicId) {
        bbtForumService.getBoardTopics(topicId);
        System.out.println("call listBoardTopic method.");
        return "listTopic";
    }
}

在类定义处标注的 @RequestMapping 让 BbtForumController 处理所有包含 /bbtForum.do 的 URL 请求，而 BbtForumController 中的请求处理方法对 URL 请求的分流规则在 ② 和 ③ 处定义分流规则按照 URL 的 method 请求参数确定。所以分别在类定义处和方法定义处使用 @RequestMapping 注解，就可以很容易通过 URL 参数指定 Controller 的处理方法了。
@RequestMapping 注解中除了 params 属性外，还有一个常用的属性是 method，它可以让 Controller 方法处理特定 HTTP 请求方式的请求，如让一个方法处理 HTTP GET 请求，而另一个方法处理 HTTP POST 请求，如下所示：

清单 4. 让请求处理方法处理特定的 HTTP 请求方法
                
package com.baobaotao.web;

import com.baobaotao.service.BbtForumService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestMethod;

@Controller
@RequestMapping("/bbtForum.do")  
public class BbtForumController {

    @RequestMapping(params = "method=createTopic",method = RequestMethod.POST)
    public String createTopic(){
        System.out.println("call createTopic method.");
        return "createTopic";
    }
}

这样只有当 /bbtForum.do?method=createTopic 请求以 HTTP POST 方式提交时，createTopic() 方法才会进行处理。
回页首
处理方法入参如何绑定 URL 参数
按契约绑定
Controller 的方法标注了 @RequestMapping 注解后，它就能处理特定的 URL 请求。我们不禁要问：请求处理方法入参是如何绑定 URL 参数的呢？在回答这个问题之前先来看下面的代码：
清单 5. 按参数名匹配进行绑定
                
    @RequestMapping(params = "method=listBoardTopic")
    //<—— ① topicId入参是如何绑定URL请求参数的？
    public String listBoardTopic(int topicId) { 
        bbtForumService.getBoardTopics(topicId);
        System.out.println("call listBoardTopic method.");
        return "listTopic";
    }

当我们发送 http://localhost//bbtForum.do?method=listBoardTopic&topicId=10 的 URL 请求时，Spring 不但让 listBoardTopic() 方法处理这个请求，而且还将 topicId 请求参数在类型转换后绑定到 listBoardTopic() 方法的 topicId 入参上。而 listBoardTopic() 方法的返回类型是 String，它将被解析为逻辑视图的名称。也就是说 Spring 在如何给处理方法入参自动赋值以及如何将处理方法返回值转化为 ModelAndView 中的过程中存在一套潜在的规则，不熟悉这个规则就不可能很好地开发基于注解的请求处理方法，因此了解这个潜在规则无疑成为理解 Spring MVC 框架基于注解功能的核心问题。
我们不妨从最常见的开始说起：请求处理方法入参的类型可以是 Java 基本数据类型或 String 类型，这时方法入参按参数名匹配的原则绑定到 URL 请求参数，同时还自动完成 String 类型的 URL 请求参数到请求处理方法参数类型的转换。下面给出几个例子：
listBoardTopic(int topicId)：和 topicId URL 请求参数绑定；
listBoardTopic(int topicId,String boardName)：分别和 topicId、boardName URL 请求参数绑定；

特别的，如果入参是基本数据类型（如 int、long、float 等），URL 请求参数中一定要有对应的参数，否则将抛出 TypeMismatchException 异常，提示无法将 null 转换为基本数据类型。
另外，请求处理方法的入参也可以一个 JavaBean，如下面的 User 对象就可以作为一个入参：

清单 6. User.java：一个 JavaBean
                
package com.baobaotao.web;

public class User {
    private int userId;
    private String userName;
    //省略get/setter方法
    public String toString(){
        return this.userName +","+this.userId;
    }
}

下面是将 User 作为 listBoardTopic() 请求处理方法的入参：

清单 7. 使用 JavaBean 作为请求处理方法的入参
                
    @RequestMapping(params = "method=listBoardTopic")
    public String listBoardTopic(int topicId,User user) {
        bbtForumService.getBoardTopics(topicId);
        System.out.println("topicId:"+topicId);
        System.out.println("user:"+user);
        System.out.println("call listBoardTopic method.");
        return "listTopic";
    }

这时，如果我们使用以下的 URL 请求：http://localhost/bbtForum.do?method=listBoardTopic&topicId=1&userId=10&userName=tom
topicId URL 参数将绑定到 topicId 入参上，而 userId 和 userName URL 参数将绑定到 user 对象的 userId 和 userName 属性中。和 URL 请求中不允许没有 topicId 参数不同，虽然 User 的 userId 属性的类型是基本数据类型，但如果 URL 中不存在 userId 参数，Spring 也不会报错，此时 user.userId 值为 0。如果 User 对象拥有一个 dept.deptId 的级联属性，那么它将和 dept.deptId URL 参数绑定。
通过注解指定绑定的 URL 参数
如果我们想改变这种默认的按名称匹配的策略，比如让 listBoardTopic(int topicId,User user) 中的 topicId 绑定到 id 这个 URL 参数，那么可以通过对入参使用 @RequestParam 注解来达到目的：
清单 8. 通过 @RequestParam 注解指定
                
package com.baobaotao.web;

import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;

…

@Controller
@RequestMapping("/bbtForum.do")
public class BbtForumController {
 
    @RequestMapping(params = "method=listBoardTopic")
    public String listBoardTopic(@RequestParam("id") int topicId,User user) {
        bbtForumService.getBoardTopics(topicId);
        System.out.println("topicId:"+topicId);
        System.out.println("user:"+user);
        System.out.println("call listBoardTopic method.");
        return "listTopic";
    }
…
}

这里，对 listBoardTopic() 请求处理方法的 topicId 入参标注了 @RequestParam("id") 注解，所以它将和 id 的 URL 参数绑定。
绑定模型对象中某个属性
Spring 2.0 定义了一个 org.springframework.ui.ModelMap 类，它作为通用的模型数据承载对象，传递数据供视图所用。我们可以在请求处理方法中声明一个 ModelMap 类型的入参，Spring 会将本次请求模型对象引用通过该入参传递进来，这样就可以在请求处理方法内部访问模型对象了。来看下面的例子：

清单 9. 使用 ModelMap 访问请示对应的隐含模型对象
                
@RequestMapping(params = "method=listBoardTopic")
 public String listBoardTopic(@RequestParam("id")int topicId,
 User user,ModelMap model) {
     bbtForumService.getBoardTopics(topicId);
     System.out.println("topicId:" + topicId);
     System.out.println("user:" + user);
     //① 将user对象以currUser为键放入到model中
     model.addAttribute("currUser",user); 
     return "listTopic";
 }

对于当次请求所对应的模型对象来说，其所有属性都将存放到 request 的属性列表中。象上面的例子，ModelMap 中的 currUser 属性将放到 request 的属性列表中，所以可以在 JSP 视图页面中通过 request.getAttribute(“currUser”) 或者通过 ${currUser} EL 表达式访问模型对象中的 user 对象。从这个角度上看， ModelMap 相当于是一个向 request 属性列表中添加对象的一条管道，借由 ModelMap 对象的支持，我们可以在一个不依赖 Servlet API 的 Controller 中向 request 中添加属性。
在默认情况下，ModelMap 中的属性作用域是 request 级别是，也就是说，当本次请求结束后，ModelMap 中的属性将销毁。如果希望在多个请求中共享 ModelMap 中的属性，必须将其属性转存到 session 中，这样 ModelMap 的属性才可以被跨请求访问。
Spring 允许我们有选择地指定 ModelMap 中的哪些属性需要转存到 session 中，以便下一个请求属对应的 ModelMap 的属性列表中还能访问到这些属性。这一功能是通过类定义处标注 @SessionAttributes 注解来实现的。请看下面的代码：

清单 10. 使模型对象的特定属性具有 Session 范围的作用域
                
package com.baobaotao.web;

…
import org.springframework.ui.ModelMap;
import org.springframework.web.bind.annotation.SessionAttributes;

@Controller
@RequestMapping("/bbtForum.do")
@SessionAttributes("currUser") //①将ModelMap中属性名为currUser的属性
//放到Session属性列表中，以便这个属性可以跨请求访问
public class BbtForumController {
…
    @RequestMapping(params = "method=listBoardTopic")
    public String listBoardTopic(@RequestParam("id")int topicId, User user,
ModelMap model) {
        bbtForumService.getBoardTopics(topicId);
        System.out.println("topicId:" + topicId);
        System.out.println("user:" + user);
        model.addAttribute("currUser",user); //②向ModelMap中添加一个属性
        return "listTopic";
    }

}

我们在 ② 处添加了一个 ModelMap 属性，其属性名为 currUser，而 ① 处通过 @SessionAttributes 注解将 ModelMap 中名为 currUser 的属性放置到 Session 中，所以我们不但可以在 listBoardTopic() 请求所对应的 JSP 视图页面中通过 request.getAttribute(“currUser”) 和 session.getAttribute(“currUser”) 获取 user 对象，还可以在下一个请求所对应的 JSP 视图页面中通过 session.getAttribute(“currUser”) 或 ModelMap#get(“currUser”) 访问到这个属性。
这里我们仅将一个 ModelMap 的属性放入 Session 中，其实 @SessionAttributes 允许指定多个属性。你可以通过字符串数组的方式指定多个属性，如 @SessionAttributes({“attr1”,”attr2”})。此外，@SessionAttributes 还可以通过属性类型指定要 session 化的 ModelMap 属性，如 @SessionAttributes(types = User.class)，当然也可以指定多个类，如 @SessionAttributes(types = {User.class,Dept.class})，还可以联合使用属性名和属性类型指定：@SessionAttributes(types = {User.class,Dept.class},value={“attr1”,”attr2”})。
上面讲述了如何往ModelMap中放置属性以及如何使ModelMap中的属性拥有Session域的作用范围。除了在JSP视图页面中通过传统的方法访问ModelMap中的属性外，读者朋友可能会问：是否可以将ModelMap中的属性绑定到请求处理方法的入参中呢？答案是肯定的。Spring为此提供了一个@ModelAttribute的注解，下面是使用@ModelAttribute注解的例子：
清单 11. 使模型对象的特定属性具有 Session 范围的作用域
                
package com.baobaotao.web;

import com.baobaotao.service.BbtForumService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.ui.ModelMap;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.SessionAttributes;
import org.springframework.web.bind.annotation.ModelAttribute;

import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpSession;

@Controller
@RequestMapping("/bbtForum.do")
@SessionAttributes("currUser") //①让ModelMap的currUser属性拥有session级作用域
public class BbtForumController {

    @Autowired
private BbtForumService bbtForumService;

    @RequestMapping(params = "method=listBoardTopic")
    public String listBoardTopic(@RequestParam("id")int topicId, User user,
ModelMap model) {
        bbtForumService.getBoardTopics(topicId);
        System.out.println("topicId:" + topicId);
        System.out.println("user:" + user);
        model.addAttribute("currUser",user); //②向ModelMap中添加一个属性
        return "listTopic";
    }


    @RequestMapping(params = "method=listAllBoard")
   //③将ModelMap中的
public String listAllBoard(@ModelAttribute("currUser") User user) { 
//currUser属性绑定到user入参中。
        bbtForumService.getAllBoard();
        System.out.println("user:"+user);
        return "listBoard";
    }
}

在 ② 处，我们向 ModelMap 中添加一个名为 currUser 的属性，而 ① 外的注解使这个 currUser 属性拥有了 session 级的作用域。所以，我们可以在 ③ 处通过 @ModelAttribute 注解将 ModelMap 中的 currUser 属性绑定以请求处理方法的 user 入参中。
所以当我们先调用以下 URL 请求： http://localhost/bbtForum.do?method=listBoardTopic&id=1&userName=tom&dept.deptId=12
以执行listBoardTopic()请求处理方法，然后再访问以下URL： http://localhost/sample/bbtForum.do?method=listAllBoard
你将可以看到 listAllBoard() 的 user 入参已经成功绑定到 listBoardTopic() 中注册的 session 级的 currUser 属性上了。
回页首
请求处理方法的签名规约
方法入参
我们知道标注了 @RequestMapping 注解的 Controller 方法就成为了请求处理方法，Spring MVC 允许极其灵活的请求处理方法签名方式。对于方法入参来说，它允许多种类型的入参，通过下表进行说明：
请求处理方法入参的可选类型	说明
Java 基本数据类型和 String	默认情况下将按名称匹配的方式绑定到 URL 参数上，可以通过 @RequestParam 注解改变默认的绑定规则
request/response/session	既可以是 Servlet API 的也可以是 Portlet API 对应的对象，Spring 会将它们绑定到 Servlet 和 Portlet 容器的相应对象上
org.springframework.web.context.request.WebRequest	内部包含了 request 对象
java.util.Locale	绑定到 request 对应的 Locale 对象上
java.io.InputStream/java.io.Reader	可以借此访问 request 的内容
java.io.OutputStream / java.io.Writer	可以借此操作 response 的内容
任何标注了 @RequestParam 注解的入参	被标注 @RequestParam 注解的入参将绑定到特定的 request 参数上。
java.util.Map / org.springframework.ui.ModelMap	它绑定 Spring MVC 框架中每个请求所创建的潜在的模型对象，它们可以被 Web 视图对象访问（如 JSP）
命令/表单对象（注：一般称绑定使用 HTTP GET 发送的 URL 参数的对象为命令对象，而称绑定使用 HTTP POST 发送的 URL 参数的对象为表单对象）	它们的属性将以名称匹配的规则绑定到 URL 参数上，同时完成类型的转换。而类型转换的规则可以通过 @InitBinder 注解或通过 HandlerAdapter 的配置进行调整
org.springframework.validation.Errors / org.springframework.validation.BindingResult	为属性列表中的命令/表单对象的校验结果，注意检验结果参数必须紧跟在命令/表单对象的后面
rg.springframework.web.bind.support.SessionStatus	可以通过该类型 status 对象显式结束表单的处理，这相当于触发 session 清除其中的通过 @SessionAttributes 定义的属性
Spring MVC 框架的易用之处在于，你可以按任意顺序定义请求处理方法的入参（除了 Errors 和 BindingResult 必须紧跟在命令对象/表单参数后面以外），Spring MVC 会根据反射机制自动将对应的对象通过入参传递给请求处理方法。这种机制让开发者完全可以不依赖 Servlet API 开发控制层的程序，当请求处理方法需要特定的对象时，仅仅需要在参数列表中声明入参即可，不需要考虑如何获取这些对象，Spring MVC 框架就象一个大管家一样“不辞辛苦”地为我们准备好了所需的一切。下面演示一下使用 SessionStatus 的例子：

清单 12. 使用 SessionStatus 控制 Session 级别的模型属性
                
@RequestMapping(method = RequestMethod.POST)
public String processSubmit(@ModelAttribute Owner owner, 
BindingResult result, SessionStatus status) {//<——①
    new OwnerValidator().validate(owner, result);
    if (result.hasErrors()) {
        return "ownerForm";
    }
    else {
        this.clinic.storeOwner(owner);
        status.setComplete();//<——②
        return "redirect:owner.do?ownerId=" + owner.getId();
    }
}

processSubmit() 方法中的 owner 表单对象将绑定到 ModelMap 的“owner”属性中，result 参数用于存放检验 owner 结果的对象，而 status 用于控制表单处理的状态。在 ② 处，我们通过调用 status.setComplete() 方法，该 Controller 所有放在 session 级别的模型属性数据将从 session 中清空。
方法返回参数
在低版本的 Spring MVC 中，请求处理方法的返回值类型都必须是 ModelAndView。而在 Spring 2.5 中，你拥有多种灵活的选择。通过下表进行说明：
请求处理方法入参的可选类型	说明
void	
此时逻辑视图名由请求处理方法对应的 URL 确定，如以下的方法：
@RequestMapping("/welcome.do")
public void welcomeHandler() {
}

对应的逻辑视图名为“welcome”
String	
此时逻辑视图名为返回的字符，如以下的方法：
@RequestMapping(method = RequestMethod.GET)
public String setupForm(@RequestParam("ownerId") int ownerId, ModelMap model) {
	Owner owner = this.clinic.loadOwner(ownerId);
	model.addAttribute(owner);
	return "ownerForm";
}

对应的逻辑视图名为“ownerForm”
org.springframework.ui.ModelMap	
和返回类型为 void 一样，逻辑视图名取决于对应请求的 URL，如下面的例子：
@RequestMapping("/vets.do")
public ModelMap vetsHandler() {
	return new ModelMap(this.clinic.getVets());
}

对应的逻辑视图名为“vets”，返回的 ModelMap 将被作为请求对应的模型对象，可以在 JSP 视图页面中访问到。
ModelAndView	当然还可以是传统的 ModelAndView。
应该说使用 String 作为请求处理方法的返回值类型是比较通用的方法，这样返回的逻辑视图名不会和请求 URL 绑定，具有很大的灵活性，而模型数据又可以通过 ModelMap 控制。当然直接使用传统的 ModelAndView 也不失为一个好的选择。
回页首
注册自己的属性编辑器
Spring MVC 有一套常用的属性编辑器，这包括基本数据类型及其包裹类的属性编辑器、String 属性编辑器、JavaBean 的属性编辑器等。但有时我们还需要向 Spring MVC 框架注册一些自定义的属性编辑器，如特定时间格式的属性编辑器就是其中一例。
Spring MVC 允许向整个 Spring 框架注册属性编辑器，它们对所有 Controller 都有影响。当然 Spring MVC 也允许仅向某个 Controller 注册属性编辑器，对其它的 Controller 没有影响。前者可以通过 AnnotationMethodHandlerAdapter 的配置做到，而后者则可以通过 @InitBinder 注解实现。
下面先看向整个 Spring MVC 框架注册的自定义编辑器：

清单 13. 注册框架级的自定义属性编辑器
                
>bean class="org.springframework.web.servlet.mvc.annotation.
AnnotationMethodHandlerAdapter"<
    >property name="webBindingInitializer"<
        >bean class="com.baobaotao.web.MyBindingInitializer"/<
    >/property<
>/bean<

MyBindingInitializer 实现了 WebBindingInitializer 接口，在接口方法中通过 binder 注册多个自定义的属性编辑器，其代码如下所示：

清单 14.自定义属性编辑器
                
package org.springframework.samples.petclinic.web;

import java.text.SimpleDateFormat;
import java.util.Date;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.propertyeditors.CustomDateEditor;
import org.springframework.beans.propertyeditors.StringTrimmerEditor;
import org.springframework.samples.petclinic.Clinic;
import org.springframework.samples.petclinic.PetType;
import org.springframework.web.bind.WebDataBinder;
import org.springframework.web.bind.support.WebBindingInitializer;
import org.springframework.web.context.request.WebRequest;

public class MyBindingInitializer implements WebBindingInitializer {

    public void initBinder(WebDataBinder binder, WebRequest request) {
        SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd");
        dateFormat.setLenient(false);
        binder.registerCustomEditor(Date.class, 
            new CustomDateEditor(dateFormat, false));
        binder.registerCustomEditor(String.class, new StringTrimmerEditor(false));
    }
}

如果希望某个属性编辑器仅作用于特定的 Controller，可以在 Controller 中定义一个标注 @InitBinder 注解的方法，可以在该方法中向 Controller 了注册若干个属性编辑器，来看下面的代码：

清单 15. 注册 Controller 级的自定义属性编辑器
                
@Controller
public class MyFormController {

    @InitBinder
    public void initBinder(WebDataBinder binder) {
        SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd");
        dateFormat.setLenient(false);
        binder.registerCustomEditor(Date.class, new CustomDateEditor(dateFormat, false));
    }
    …
}

注意被标注 @InitBinder 注解的方法必须拥有一个 WebDataBinder 类型的入参，以便 Spring MVC 框架将注册属性编辑器的 WebDataBinder 对象传递进来。
回页首
如何准备数据
在编写 Controller 时，常常需要在真正进入请求处理方法前准备一些数据，以便请求处理或视图渲染时使用。在传统的 SimpleFormController 里，是通过复写其 referenceData() 方法来准备引用数据的。在 Spring 2.5 时，可以将任何一个拥有返回值的方法标注上 @ModelAttribute，使其返回值将会进入到模型对象的属性列表中。来看下面的例子：

清单 16. 定义为处理请求准备数据的方法
                
package com.baobaotao.web;

import com.baobaotao.service.BbtForumService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Controller;
import org.springframework.ui.ModelMap;
import org.springframework.web.bind.annotation.ModelAttribute;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.SessionAttributes;

import java.util.ArrayList;
import java.util.List;
import java.util.Set;

@Controller
@RequestMapping("/bbtForum.do")
public class BbtForumController {

    @Autowired
    private BbtForumService bbtForumService;

    @ModelAttribute("items")//<——①向模型对象中添加一个名为items的属性
    public List<String> populateItems() {
        List<String> lists = new ArrayList<String>();
        lists.add("item1");
        lists.add("item2");
        return lists;
    }

    @RequestMapping(params = "method=listAllBoard")
    public String listAllBoard(@ModelAttribute("currUser")User user, ModelMap model) {
        bbtForumService.getAllBoard();
        //<——②在此访问模型中的items属性
        System.out.println("model.items:" + ((List<String>)model.get("items")).size());
        return "listBoard";
    }
}

在 ① 处，通过使用 @ModelAttribute 注解，populateItem() 方法将在任何请求处理方法执行前调用，Spring MVC 会将该方法返回值以“items”为名放入到隐含的模型对象属性列表中。
所以在 ② 处，我们就可以通过 ModelMap 入参访问到 items 属性，当执行 listAllBoard() 请求处理方法时，② 处将在控制台打印出“model.items:2”的信息。当然我们也可以在请求的视图中访问到模型对象中的 items 属性。
回页首
小结
Spring 2.5 对 Spring MVC 进行了很大增强，现在我们几乎完全可以使用基于注解的 Spring MVC 完全替换掉原来基于接口 Spring MVC 程序。基于注解的 Spring MVC 比之于基于接口的 Spring MVC 拥有以下几点好处：
方便请求和控制器的映射；
方便请求处理方法入参绑定URL参数；
Controller 不必继承任何接口，它仅是一个简单的 POJO。
但是基于注解的 Spring MVC 并不完美，还存在优化的空间，因为在某些配置上它比基于 XML 的配置更繁琐。比如对于处理多个请求的 Controller 来说，假设我们使用一个 URL 参数指定调用的处理方法（如 xxx.do?method=listBoardTopic），当使用注解时，每个请求处理方法都必须使用 @RequestMapping() 注解指定对应的 URL 参数（如 @RequestMapping(params = "method=listBoardTopic")），而在 XML 配置中我们仅需要配置一个 ParameterMethodNameResolver 就可以了。

参考资料
学习
Spring 系列：Spring 框架简介：优秀的 Spring 框架入门系列，了解 Spring 框架的基本概念。

轻量级开发的成功秘诀，第 3 部分: Spring 露出水面：介绍了在 Spring 框架的轻量级 Ioc 容器。

Spring Framework 和 IBM WebSphere Application Server：Interface21 的首席执行官 Rod Johnson 和 IBM 的 WebSphere Open Source 主管 Paul Buck 讨论了 Spring Framework 通过 IBM WebSphere Application Server 认证对 Spring 和 WebSphere 产品系列的开发人员和客户有何重要意义。

Tiger 中的注释，第 1 部分: 向 Java 代码中添加元数据：解释了元数据如此有用的原因，向您介绍了 Java 语言中的注释，并研究了 Tiger 的内置注释。

Tiger 中的注释，第 2 部分: 定制注释：说明了如何创建定制注释，如何用自己的注释注解文档，并进一步定制代码。

获得产品和技术
Springframework 网站：下载 Spring 框架。

关于作者

陈雄华，2002 年毕业于厦门大学计算机与信息工程学院，获硕士学位。是宝宝淘科技有限公司的创始人之一（http://www.baobaotao.com），这是一个服务于全国母婴用户的综合性网站，作者负责网站整体框架设计以及核心代码开发的工作。技术开发之余，常将经验所得行诸于文字，作者是国内多个著名技术网站的专栏作者，在各大技术网站、报刊杂志发表过数十篇技术文章，广受读者好评。于 2005 年出版《精通 JBuilder 2005》，于2007年出版《精通 Spring 2.x--企业应用开发详解》，其新作《EXT 2.x开发详解――AJAX和Web页面布局王者至尊》即将出版。
为本文评分
 平均分 (224个评分)
1 星1 星
2 星2 星
3 星3 星
4 星4 星
5 星5 星

评论
添加评论:
请 登录 或 注册 后发表评论。
注意：评论中不支持 HTML 语法

有新评论时提醒我剩余 1000 字符



 显示： 
很多疑问都清晰了 非常谢谢！
由 zhouxin515 于 16 April 2013 报告滥用
相当不错
由 sldehao 于 21 March 2013 报告滥用
很好
由 chenbf 于 25 February 2013 报告滥用
又解决了我在这块的一些疑问，O(∩_∩)O谢谢
由 dingbowell 于 22 February 2012 报告滥用
很不错,讲解得很好..
由 csjsjls 于 08 December 2011 报告滥用
回页首
内容

概述
一个简单的基于注解的 Controller
清单 3. annomvc-servlet.xml
让一个 Controller 处理多个 URL 请求
清单 3. 每个请求处理参数对应一个 URL
处理方法入参如何绑定 URL 参数
清单 5. 按参数名匹配进行绑定
清单 8. 通过 @RequestParam 注解指定
清单 11. 使模型对象的特定属性具有 Session 范围的作用域
请求处理方法的签名规约
注册自己的属性编辑器
如何准备数据
小结
参考资料
关于作者
建议
打印此页面
分享此页面关注 developerWorks
帮助
联系编辑
提交内容
网站导航
订阅源
在线浏览每周时事通讯
报告滥用
使用条款
隐私条约
浏览辅助
IBM 教育学院教育培养计划
IBM 创业企业全球扶持计划
ISV 资源 (英语)


========== http://starscream.iteye.com/blog/1066711 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
starscream
博客微博相册收藏留言关于我
  
Spring MVC 学习笔记 六 Handler Method的可用参数

博客分类： spring mvc
SpringMVCJavaBeanUI
 
使用@requesMapping标注的处理函数包括的可选参数，除了HttpServletRequest, HttpServletResponse, HttpSession这些web应用中常见的参数及之前提到过的@PathVariable外，还可以包括以下可选的参数，其中大部分参数的顺序没有特殊要求的。
 
java.util.Locale
当前请求所属的区域设置。
 
java.io.InputStream或java.io.Reader
用来读取request content，相当于  request.getInputStream()或request.getReader();
 
java.io.OutputStream或java.io.Writer
用来生成reponse content，相当于response.getOutputStream()或response.getWriter()。
 
java.security.Principal
当前认证了的用户
 
WebRequest或NativeWebRequest
Spring 对request,response,session等web元素封装后的对象
 
java.util.Map 或 org.springframework.ui.Model或org.springframework.ui.ModelMap
用来存放domain model的map结构。
 
HttpEntity<?>
可用来读取http请求的header和 body内容，注意因为httpentity,@RequestBody，Reader这三种类型的参数都是通过inputstram来读取httpbody的数据的，而inputstream流不能反复读取，因此这三种类型的参数不能放在一起使用。而且在没有设置content-type或没有设置相应的messageconverter的情况下，都会报错。
 
Command 或 form objects
通过spring 的databinding机制将request请求中的参数自动转换为对应的java bean实例。
 
Errors或BindingResult
对command或form objects值的校验结果。此参数必须紧跟在需校验的command或form object参数后面。因为databinding可以允许将输入参数和多个java bean 进行绑定(也就是说我们可以把输入request param转换成为多个java 对象)。
 
SessionStatus
Session的状态。当使用@SessionAttributes来标注请求需要session中对应的值时,在处理结束时，使用SessionStatus. setComplete()来将session设置为时效。
 
@RequestParam
将request参数和handler method参数做绑定。例如
@RequestParam(value="username",defaultValue="winzip",required=false) String name
表示将request中的username参数和handler method中的name参数绑定，缺省值为”winzip”,request请求中可以不传递此参数
 
@RequestHeader
将handler method中的参数与request header中的值绑定，例如
@RequestHeader(required=false,value="User-Agent") String ua
表示将header中的"User-Agent"与ua这个入参绑定。
 
@RequestBody
将handler method中的参数与request context body中的值绑定
例如
@RequestBody String u
表示将request body中的内容与u这个入参绑定。
 
@CookieValue
将handler method中的参数与cookie中的值绑定
例如
@CookieValue(value="JSESSIONID",required=false) String jssionid
 
@ModelAttribute
将handler method中的参数与对应的类型绑定，名称缺省为类名(首字母小写)，如果ModelAttribute指定了值则以该值作为model attribute name。
例如
@ModelAttribute("ooxx") User u
则在modelmap中创建了一个键值为ooxx的model attribute。
@ModelAttribute User u 或 User u
在modelmap中创建了一个键值为user的model attribute
 
 

1 
顶0 
踩 分享到：    
Spring MVC 学习笔记 七 controller中其 ... | Spring MVC 学习笔记 五 controller与re ...
2011-05-31 22:24浏览 3238评论(1)分类:企业架构相关推荐
评论
1 楼 linvar 2011-09-17  
不错
发表评论
  您还没有登录,请您登录后再发表评论

starscream
浏览: 90389 次
性别: 
来自: 上海

最近访客 更多访客>>
yanchen2066wxx19910319chenzhendongaslijiasheng
文章分类
全部博客 (16)
spring mvc (16)
移动开发 (0)
spring security (0)
社区版块
我的资讯 (0)
我的论坛 (0)
我的问答 (0)
存档分类
2011-06 (9)
2011-05 (7)
更多存档...
最新评论
xuguiyi1000： 有这个是工程实例的吗？
Spring MVC 学习笔记 十三 xml格式输入输出
太阳神喻： 不顶不行啊
Spring MVC 学习笔记 十五 what's new in spring mvc 3.1
风间苍月： wddgfzs 写道使用JSR-303 Validation进 ...
Spring MVC 学习笔记 十 使用jsr 303进行校验
estn_h： 4L 正解哦
Spring MVC 学习笔记 九 json格式的输入和输出
finallygo： Content-Type 不是response中的么?
Spring MVC 学习笔记 十五 what's new in spring mvc 3.1
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== http://blog.csdn.net/fengsezhengtu/article/details/6975982 ==========
========== http://wenku.baidu.com/view/7b48526127d3240c8447ef47.html ==========
百度文库首页|下载客户端|百度首页|登录注册

新闻网页贴吧知道音乐图片视频地图百科文库
 帮助
全部DOCPPTTXTPDFXLS
百度文库专业资料IT/计算机
上传文档
支持以下设备:扫二维码下载
AndroidiPhoneiPad
文档信息举报文档
fatcat132006贡献于2011-12-17
4.4
(82人评价)
我要评价
大家印象：有用(5)
1/2相关文档推荐
eclipse下mahout的配置与使...
1页1财富值
Apache Mahout 使用简介
暂无评价12页5财富值
使用入门
24页2财富值
使用入门
暂无评价47页免费
闪光灯使用入门
14页免费
喜欢此文档的还喜欢
mahout简介
20页免费
mahout in action 中文版
19页2财富值
Data Mining using Mahout
26页免费
Mahout安装图文版
9页1财富值
如要投诉违规内容，请到百度文库投诉中心；如要提出功能问题或意见建议，请点击此处进行反馈。
 
mahout使用入门4658人阅读
©2013 Baidu 使用百度前必读 | 文库协议
========== http://wenku.baidu.com/view/7d9b9b728e9951e79b8927e9.html ==========
========== http://hadoop.hadoopor.com/forum-58-1.html ==========
 注册 登录
论坛导航RSS
Hadoop技术论坛 » Mahout
关闭边栏
Mahout[ 44 主题 / 152 回复 ]RSS
版块介绍: Mahout是一个基于Hadoop实现各种机器学习与数据挖掘算法库。
版主: jiji879, andrew.wang, neilchen
12下一页返回首页
发帖
 类型	
主题:全部精华|时间:一天两天周月季|热门	作者/时间	回复 查看	
最后发表
 	  	 怎样查看mahout源代码？	
kawen33
2013-7-30	2/590	
摩西莫西
2013-8-3 23:47
 	  	 k-means的clusterdump問題	
gn667226
2013-5-16	1/611	
fansy
2013-7-31 19:13
 	  	 mahout下载安装和简单使用	
摩西莫西
2010-3-31	19/20987	
yangyun0312
2013-7-11 11:05
 	  	 mahout 和 hadoop的区别	
ck59505
2013-5-28	2/825	
ck59505
2013-5-28 20:54
 	  	 mahout in action 中文版	
winston
2011-3-3	16/12385	
haoyue
2013-5-24 20:03
 	  	 真心求一起研究mahout的朋友！论坛好冷清啊  ...2	
jiji879
2010-12-26	20/13946	
aries
2013-3-14 13:17
 	  	 有并行的遗传算法么？	
炽天使
2013-1-10	0/962	
炽天使
2013-1-10 22:10
 	  	 Kmeans	
giswt
2013-1-9	0/1186	
giswt
2013-1-9 16:08
 	  	 mahout下将文本文件转成sequencefile文件	
y948448714
2013-1-8	0/936	
y948448714
2013-1-8 16:28
 	  	 求救：mahout如何使用kmeans	
tjsdxh
2011-9-20	2/6940	
fansy
2012-12-5 17:07
 	  	 mahout中的fpgrowth算法有错吗？	
987293233
2012-7-18	1/1880	
eagle1098
2012-11-30 11:10
 		 mahout 输入数据问题	
soberchallen
2012-11-23	1/1726	
eagle1098
2012-11-30 10:58
 	  	 新手上路 请教如何跑mahout in action中的小例子	
sandylovechina
2012-3-12	1/2289	
糖糖_julia
2012-10-31 16:28
 		 Mahout学习资料 	
neuro220
2011-2-28	19/15328	
eagle1098
2012-9-2 23:08
 	  	 文本文件转成SequenceFile文件	
sxufesc706
2011-11-3	3/4710	
白面馒头
2012-6-13 10:47
 	  	 mahout里的logistic regresion是单机版的？	
superyc1984
2012-4-6	1/2003	
白面馒头
2012-6-12 18:01
 	  	 如何在Hadoop平台上实现SVM（支持向量机）？	
_fairyjocelyn1
2012-3-29	2/2776	
_fairyjocelyn1
2012-6-4 16:09
 	  	 自己修改mahout里的kmeans时缺某些jar包的问题 	
584164572
2012-4-16	3/3370	
winnie1985
2012-5-30 16:13
 		 在Hadoop集群里安装mahout	
whxiyi100829
2012-5-24	1/2051	
winnie1985
2012-5-30 16:11
 	  	 Mahout技术讨论群	
Loogn
2012-5-28	1/1870	
Loogn
2012-5-28 16:58
 	  	 最新版里面是有是SVM	
爱萌
2011-9-7	5/4466	
_fairyjocelyn1
2012-3-29 17:11
 	  	 求助mahout运行决策树异常。 	
ww165385778
2011-9-18	1/3336	
delavieri
2012-3-2 17:53
 	  	 Mahout 贝叶斯分类 如何处理CSV数据	
patrick
2011-12-9	1/4200	
sxufesc706
2012-2-15 23:32
 	  	 mahout中的mean shift算法	
hahacamel
2012-2-3	0/2197	
hahacamel
2012-2-3 17:24
 	  	 在mahou中出错了，请大家帮忙看看	
爱萌
2011-9-22	1/3183	
爱萌
2011-9-23 10:23
 	  	 Mahout的kmeans问题	
cc19860606
2010-11-22	4/5875	
boyaxxx
2011-9-18 14:23
 	  	 求助！！ mahout 0.5 源码安装失败	
vivounicorn
2011-9-16	0/3163	
vivounicorn
2011-9-16 12:42
 	  	 如何将eclipse中的程序打包到HADOOP上跑	
dreamhunter_lan
2011-8-23	2/4039	
pingpingdong
2011-9-9 15:00
 	  	 mvn install出错	
sxufesc706
2010-11-1	3/5055	
神魔天龙
2011-7-29 04:49
 	  	 mahout-0.3分类准备数据出错，求救！	
sxufesc706
2011-7-17	1/3365	
sxufesc706
2011-7-28 21:57
12下一页返回首页
发帖
     搜索
日 | 周 | 月 热门主题
Hadoop 1.2.1 ChainMa
到底有没有《HBase权威
最新主题
到底有没有《HBase权威
Hadoop 1.2.1 ChainMa
hadoop新资料
MapReduce如何才能不设
HBase和Hadoop安装问题
最新回复
到底有没有《HBase权威
Hadoop入门手册
Hadoop 1.2.1 ChainMa
reduce卡住停滞不前
那个daemon负责做chec
Hadoop技术论坛 ( 湘ICP备09027949号)|联系我们 |Archiver|WAP| 站长统计
GMT+8, 2013-10-4 18:59, Processed in 0.031551 second(s), 3 queries.
Powered by Discuz! 7.2
© 2001-2010 Comsenz Inc.
========== https://cwiki.apache.org/confluence/display/Hive/Home ==========

Browse
Pages
Blog
Labels
Attachments
Bookmarks
Mail
Advanced
What’s New
Space Directory
Keyboard Shortcuts
Confluence Gadgets
Log InSign Up
Dashboard
Apache Hive
Home
Tools
Attachments (0)
Page History
Restrictions
Info
Link to this Page…
View in Hierarchy
View Wiki Markup
 Home
Added by Confluence Administrator, last edited by Lefty Leverenz on Oct 01, 2013  (view change) show comment
Apache Hive
The Apache HiveTM data warehouse software facilitates querying and managing large datasets residing in distributed storage. Built on top of Apache HadoopTM , it provides

Tools to enable easy data extract/transform/load (ETL)
A mechanism to impose structure on a variety of data formats
Access to files stored either directly in Apache HDFSTM or in other data storage systems such as Apache HBaseTM
Query execution via MapReduce
Hive defines a simple SQL-like query language, called QL, that enables users familiar with SQL to query the data. At the same time, this language also allows programmers who are familiar with the MapReduce framework to be able to plug in their custom mappers and reducers to perform more sophisticated analysis that may not be supported by the built-in capabilities of the language. QL can also be extended with custom scalar functions (UDF's), aggregations (UDAF's), and table functions (UDTF's).

Hive does not mandate read or written data be in the "Hive format"---there is no such thing. Hive works equally well on Thrift, control delimited, or your specialized data formats. Please see File Format and SerDe in the Developer Guide for details.

Hive is not designed for OLTP workloads and does not offer real-time queries or row-level updates. It is best used for batch jobs over large sets of append-only data (like web logs). What Hive values most are scalability (scale out with more machines added dynamically to the Hadoop cluster), extensibility (with MapReduce framework and UDF/UDAF/UDTF), fault-tolerance, and loose-coupling with its input formats.

General Information about Hive
Getting Started
Presentations and Papers about Hive
A List of Sites and Applications Powered by Hive
FAQ
hive-users Mailing List
Hive IRC Channel: #hive on irc.freenode.net
About This Wiki
User Documentation
Hive Tutorial
HiveQL Language Manual (Queries, DML, DDL, CLI, etc.)
Hive Operators and Functions
Hive Web Interface
Hive Client (JDBC, ODBC, Thrift, etc.)
HiveServer2 Client
Hive Change Log
Avro SerDe
Administrator Documentation
Installing Hive
Configuring Hive
Setting Up Metastore
Setting Up Hive Web Interface
Setting Up Hive Server (JDBC, ODBC, Thrift, HiveServer2)
Hive on Amazon Web Services
Hive on Amazon Elastic MapReduce
HCatalog and WebHCat Documentation
HCatalog
WebHCat (Templeton)
Resources for Contributors
Hive Developer FAQ
How to Contribute
Hive Contributors Meetings
Hive Developer Guide
Plugin Developer Kit
Unit Test Parallel Execution
Hive PTest2 Infrastructure
Hive PreCommit Patch Testing
Hive Performance
Hive Architecture Overview
Hive Design Docs
Roadmap/Call to Add More Features
Full-Text Search over All Hive Resources
How to edit the website
Becoming a Committer
How to Commit
How to Release
Build Status on Jenkins (Formerly Hudson)
Project Bylaws
For more information, please see the official Hive website.

Apache Hive, Apache Hadoop, Apache HBase, Apache HDFS, Apache, the Apache feather logo, and the Apache Hive project logo are trademarks of The Apache Software Foundation.

Labels:
None
17 Child Pages Reorder Pages
Page: AboutThisWiki
Page: AvroSerDe
Page: Bylaws
Page: Dependent Tables
Page: Fix Hive Unit Tests on Hadoop 2 - HIVE-3949
Page: Hadoop-compatible Input-Output Format for Hive
Page: HiveAmazonElasticMapReduce
Page: HiveAwsEmr
Page: HiveChangeLog
Page: HiveDeveloperFAQ
Page: Hive PreCommit Patch Testing
Page: Hive PTest2 Infrastructure
Page: HiveServer2 Clients
Page: How to edit the website
Page: OperatorsAndFunctions
Page: PluginDeveloperKit
Page: RCFileCat

Powered by a free Atlassian Confluence Open Source Project License granted to Apache Software Foundation. Evaluate Confluence today.
This Confluence installation runs a Free Gliffy License - Evaluate the Gliffy Confluence Plugin for your Wiki!
Powered by Atlassian Confluence 3.5.17, the Enterprise Wiki   |  Report a bug  |  Atlassian News

========== http://blog.csdn.net/aidayei/article/category/807174 ==========
您还未登录！|登录|注册|帮助首页业界移动云计算研发论坛博客下载
更多
aidayei的专栏
目录视图摘要视图订阅
2014年1月微软MVP申请开始啦！      CSDN社区中秋晒福利活动正式开始啦！        专访钟声：Java程序员，上班那点事儿      独一无二的职位：开源社区经理      “说说家乡的互联网”主题有奖征文
 海量文献管理系统概述
很长一段时间不写博客了，因为最近要弄论文，但看到我的博客上被CSDN加了个“恒”的小图标，要求是每个月发四篇日志以上，以鼓励大家多把东西拿出来分享。这一点其实挺好的，很多程序员擅长于编码，但并不一定讲解的很好或清晰的写出来。一个技术牛人曾说过：技术人员能把一项技术完成，仅能得及格分，如果能把操作过程写下来，能得70分，而如果能做好、能写出来，并且清晰的讲给大家听，那才可以得满分。      开源...
2011-11-23 22:49 阅读(440) 评论(0)
 Mahout聚类中相似度计算
7.3 Hello World：运行一个简单的聚类实例(这个内容，我在前面博文“mahout中的kmeans简单实例”中已介绍过) 7.4 Exploring distance measures(距离度量扩展) 在上面的简单聚类示例中，我们用的是EuclideanDistanceMeasure(欧式距离)来计算点之间的距离。虽然它在我们上节的聚类实例中被证明是有效的度量方法，但在Mahout包...
2011-11-22 18:52 阅读(1544) 评论(1)
 将聚类结果展示在网页上
Nutch中自带对搜索结果的聚类，使用开源的Carrot2，以插件形式被调用，大概看了一下nutch关于clustering这一块的搜索源码，它会显示出URL和title，可是用mahout做文本聚类的话，最后的聚类结果中，只有向量， 当然自己可以将URL加进去，但如何显示标题呢...
2011-08-31 22:17 阅读(947) 评论(2)
 mahout之canopy算法简介
K 均值聚类算法的最大的优点是：原理简单，实现起来也相对简单，同时执行效率和对于大数据量的可伸缩性还是较强的。然而缺点也是很明确的，首先它需要用户在执行聚类之前就有明确的聚类个数K的设置，这一点是用户在处理大部分问题时都不太可能事先知道的，一般需要通过多次试验找出一个最优的 K...
2011-08-12 15:34 阅读(2481) 评论(0)
 mahout应用kmeans进行文本聚类2之——实例分析
在Mahout_in_Action这本书中，给了一个文本的聚类实例，并提供了原始输入数据，下面结合例子说明 作为聚类算法的主要应用场景 - 文本分类，对文本信息的建模也是一个常见的问题。在信息检索研究领域已经有很好的建模方式，就是信息检索领域中最常用的向量空间模型 词频 -...
2011-08-09 22:49 阅读(3954) 评论(2)
 mahout应用kmeans进行文本聚类1之——输入输出分析
输入分析： mahout下处理的文件必须是SequenceFile格式的，所以需要把txtfile转换成sequenceFile，而聚类必须是向量格式的，mahout提供下面两个命令来将文本转成向量形式 1.mahout seqdirectory：将文本文件转成Sequenc...
2011-08-09 22:45 阅读(3998) 评论(3)
 mahout中的kmeans结果分析
运行官网上的mahout kmeas示例，结果文件夹有clusteredPoints，clusters-N，data，用命令mahout seqdumper仔细看了一下结果文件 clusteredPoints：存放的是最后聚类的结果，将cluster-id和documents-...
2011-08-06 17:41 阅读(3459) 评论(2)
 编译mahout源码并导到eclipse中
为什么要编译源码呢?其实直接用二进制包更省事，只是为了方便读取源码和修改源码 1.直接在mahout安装目录下使用mvn install，这样mahout目录下的所有文件就都编译并打包安装，可以在各模块下的target目录中看到class目录和生成的jar包 2.如果只想编译部分，例如编译core：更换到core目录下，mvn compile，此时没有生成jar包，只生成了.class文件，之...
2011-08-05 22:54 阅读(3614) 评论(4)
 mahout seq2sparse源文件解析
mahout seq2sparse对应的源文件是SparseVectorsFromSequenceFiles.java 首先用DocumentProcessor.tokenizeDocuments方法，将(Text，Text)变成(Text，StringTuple) Stri...
2011-08-03 16:11 阅读(852) 评论(0)
 mahout读取nutch抓取数据后的文件
1.mahout seqdumper在读取data文件时，报少ParseText包，把这个包导进来后，就可以正确读取了 2.mahout seq2sparse转向量是关键，可这一步报类型转换错误，mahout中要的key-value是(Text,Text)类型...
2011-08-01 20:23 阅读(880) 评论(0)
 mahout中的kmeans简单实例
在Mahout_in_Action这本书中，有个kmeans的简单实例，可书中只给了源代码，而并没有指出要导入哪些包才能正确运行 这本书在前面提到书中所有代码都是基于mahout0.4版本的，可是我发现这个kmeans的例子，却是基于mahout0.3的，有几个函数0.4版中是...
2011-07-30 21:10 阅读(2038) 评论(1)
 将lucene索引转化成mahout输入向量
mahout lucene.vector --dir /home/test/test-in/index/ --output /home/test/test-in/outdex/part-out.vec --field body --dictOut /home/test/test-in/outdex/dict.out  问题1：版本问题( "Exception in thread "main" o...
2011-07-25 19:00 阅读(1623) 评论(2)
 Eclipse下mahout实现推荐的简单实例
环境：ubuntu下的eclipse 数据准备：test.txt 第一列为UserID ，第二列为ItemID，第三列为Preference Value 即评分 1,101,5 1,102,3 1,103,2.5 2,101,2 2,102,2.5 2,103,5...
2011-07-22 19:17 阅读(5821) 评论(4)
 mahout入门学习
因为要用到云计算下的数据挖掘，所以就简单看了一下mahout配置，mahout是一个基于Map/Reduce的机器学习算法库，运行在hadoop集群上 废话不多说，下面看配置过程 1.到mahout官网上下载mahout-distribution-0.4.tar.gz，这个是已经编译好的包，如果下的是源码包，则需要安装maven来编译 2.前面已经搭过hadoop，这里不再说，下面设置环境变...
2011-07-20 17:09 阅读(4769) 评论(3)
 k-means算法和层次聚类算法
将数据挖掘作业拿出来公析一下，作个记录...
2011-05-16 20:31 阅读(546) 评论(0)
 朴素贝叶斯算法和logistic回归算法
待有时间将机器学习课的作来拿出来分析和对比.......
2011-05-16 20:28 阅读(714) 评论(0)
个人资料
  
aidayei
 

访问：113961次
积分：1934分
排名：第4769名
原创：77篇转载：4篇译文：2篇评论：76条
文章搜索

文章分类
云计算与云存储(12)
搜索引擎(15)
机器学习与数据挖掘(16)
网站开发(10)
数据结构学习(16)
Linux学习(4)
恶意代码入侵检测(3)
图像处理(1)
设计模式学习(7)
心情日记(1)
文章存档
2012年08月(1)
2012年02月(4)
2011年12月(4)
2011年11月(5)
2011年10月(4)
展开
阅读排行
solr中文分词(6919)
hadoop集群搭建(5990)
Eclipse下mahout实现推荐的简单实例(5821)
mahout入门学习(4768)
Nutch爬取与Solr搜索结合(4544)
JSP/servlet实现文件上传下载和删除(4387)
mahout应用kmeans进行文本聚类1之——输入输出分析(3998)
mahout应用kmeans进行文本聚类2之——实例分析(3954)
编译mahout源码并导到eclipse中(3614)
solr索引如何存储(3572)
评论排行
JSP/servlet实现文件上传下载和删除(23)
solr读取word,pdf(14)
编译mahout源码并导到eclipse中(4)
Eclipse下mahout实现推荐的简单实例(4)
mahout入门学习(3)
mahout应用kmeans进行文本聚类1之——输入输出分析(3)
Nutch抓取数据分析(2)
Nutch爬取与Solr搜索结合(2)
将聚类结果展示在网页上(2)
mahout应用kmeans进行文本聚类2之——实例分析(2)
推荐文章

最新评论
mahout应用kmeans进行文本聚类2之——实例分析
源远流长: mahout clusterdump 查看聚类结果，但是抛出异常Exception in threa...
mahout中的kmeans结果分析
psnxtansini: “当设置了HADOOP_HOME后，用seqdumper去查看结果时，输入路径则是HDFS上的目录。...
nutch抓取数据后生成的文件格式
cvxiomin: lz nutch sequence files直接向量化作为mahout的输入最后搞定没？
HDFS文件读写
nationlity2003: 请问:c api 中 fileSize 是哪里得来的?
Eclipse下mahout实现推荐的简单实例
blhuang: 补充一下：在Mahout 0.7 版本中，没有了google-collection-1.0-rc2....
JSP/servlet实现文件上传下载和删除
小小Scott: 您好，我是一名在校大学生，正在做一个项目，也涉及文件的上传，下载，删除，浏览，连接数据库。在删除时，...
JSP/servlet实现文件上传下载和删除
hebutzhanghai: 我现在做的一个项目正好用到这块，希望能看一下的例子学习一下，谢谢啦。790754828@qq.com
Mahout聚类中相似度计算
chaojilei901008: 您好，我想问一下，我在运行Kmeans例子的时候默认是欧式距离是吧？那我在哪里修改，才能用其他的方式...
编译mahout源码并导到eclipse中
daylesslu: 你好 我是在win7下eclipse中导入mahout源码的，用的是mahout-distribut...
简单的背包问题
CSDN515: 学习了
公司简介|招贤纳士|广告服务|银行汇款帐号|联系方式|版权声明|法律顾问|问题报告
QQ客服 微博客服 论坛反馈 联系邮箱：webmaster@csdn.net 服务热线：400-600-2320
京 ICP 证 070598 号
北京创新乐知信息技术有限公司 版权所有
世纪乐知(北京)网络技术有限公司 提供技术支持
江苏乐知网络技术有限公司 提供商务支持
Copyright © 1999-2012, CSDN.NET, All Rights Reserved 
  
========== https://cwiki.apache.org/confluence/display/MAHOUT/Quickstart ==========

Browse
Pages
Blog
Labels
Attachments
Bookmarks
Mail
Advanced
What’s New
Space Directory
Keyboard Shortcuts
Confluence Gadgets
Log InSign Up
Dashboard
Apache Mahout
Mahout Wiki
Quickstart
Tools
Attachments (0)
Page History
Restrictions
Info
Link to this Page…
View in Hierarchy
View Wiki Markup
Export to PDF
Export to Word
Quickstart

Added by Grant Ingersoll, last edited by Jean-Loic Mauduy on Jul 03, 2013  (view change) show comment
Download and Installation
Download and installation
Running the Examples
Mahout runs on Apache Hadoop . So, to run these examples, install the latest compatible 1 2 Hadoop Common release .

1	 When using a release, see the release notes
2	 When using trunk, see parent/pom.xml
Clustering
Clustering of synthetic control data
Visualizing Sample Clusters
Clustering Seinfeld Episodes
Classification
Twenty Newsgroups
Wikipedia Bayes Example
Genetic Programming
Watchmaker
Decision Forest
Breiman Example
Partial Implementation
Recommendation mining
This package comes with four examples based on netflix data, bookcrossing, grouplens and jester data.

RecommendationExamples
Where to Go Next
If you are working with text, read more on Creating Vectors from Text
To learn more on grouping items by similarity and identifying clusters read more on Clustering your data
If you want to classify incoming items into predefinied categories read more on Classifying your data
To know how to Mine frequent patterns from your data read more on Parallel Frequent Pattern Mining
To read more on building recommendation engines have a look at the Recommender (Taste) documentation and Taste hadoop commandline
Go back to the Main Wiki Page for more information.

Labels:
None
Page: Mahout.GA.Tutorial
Page: BuildingMahout
Page: Twenty Newsgroups
Page: Class Discovery
Page: Traveling Salesman
Page: Clustering of synthetic control data
Page: ClusteringYourData
Page: Breiman Example
Page: ClassifyingYourData
Page: TasteCommandLine
Page: RecommendationExamples
Page: Viewing Results
Page: Partial Implementation
Page: Clustering Seinfeld Episodes
Page: Quick tour of text analysis using the Mahout command line
2 Comments comments.show.hide
Mar 08, 2012
Aneesha
Can any one help me to find out which algorithm is best for clustering LDA or K-means and why???

Permalink
 Apr 14, 2012
map_lixiupeng
do experiment,I do same work like you

Permalink

Powered by a free Atlassian Confluence Open Source Project License granted to Apache Software Foundation. Evaluate Confluence today.
This Confluence installation runs a Free Gliffy License - Evaluate the Gliffy Confluence Plugin for your Wiki!
Powered by Atlassian Confluence 3.5.17, the Enterprise Wiki   |  Report a bug  |  Atlassian News

========== http://running.iteye.com/category/144665 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
奔跑的羚羊
博客微博相册收藏留言关于我
  
文章列表
【译】mahout in action 3.3 内存中的DataModel

博客分类： Mahout in action
数据结构编程算法CC++
这是个抽象概念，在Mahout中，recommender的输入数据是DataModel。DataModel的实现为各种推荐器算法需要的数据提供了有效的使用。例如，一个DataModel可以在输入数据中，提供一个包括所有user IDs的列表，或提供与一个item相关联的所有�� ...
2011-03-14 10:04浏览 1668评论(1)分类:编程语言
【译】mahout in action 3.2 加速聚集

博客分类： Mahout in action
数据结构
非常高兴的是，Mahout已经重新创造了“java数组对象”。这只是万里长征的第一步。我们提及到规模是重要的吗？可能，你已经被说服，我们将会面对处理巨大数量的数据，和不寻常响应。 这个reduced的内存需求，由PreferenceArray和� ...
2011-03-13 20:51浏览 1304评论(0)分类:编程语言
【译】mahout in action 3.1 Preference对象

博客分类： Mahout in action
算法JVMOS
一个推荐引擎的输入数据是评分数据：它喜欢什么以及多少。所以，Mahout recommenders的输入数据是一组简单的“userID”,“itemID”,和“评分数据”元组，当然，这是一个大的集合。评分数据有时候会被省略。 3.1.1 Preference对象 Preference是一个最基础的概念，它表现一个单一的userID,itemID和一个评分数据。这个对象表现为一个用户对一个项目的打分。Preference是一个接口，通常使用的实现类为GenericPreference。例如：创建一条记录，user（123），对item（456）的打分是3.0： new GenericPrefere ...
2011-03-01 22:28浏览 1136评论(1)分类:编程语言
【译】mahout in action 3 数据展现

博客分类： Mahout in action
算法
这章主要讲述： 。Mahout如何展现recommender data 。DataModel的实现及其用法 。没有评分数据 Recommendations的质量主要是由数据的数量和质量决定的。“无用输出，无用输入” 在这里是最真实的。同样，推荐器算法都是集中数据，运行的性能主要受数据的数量和展现的影响。这一章 介绍Mahout的一些关键class，和访问推荐器相关的数据。
2011-03-01 22:17浏览 1274评论(0)分类:编程语言
【译】mahout in action 2.6 小结

博客分类： Mahout in action
在这章里，我们介绍了推荐引擎的概念。通过一个少量输入，创建一个简单的Mahout recommender，通过一个简单的计算来运行并解释了这个结果。
2011-03-01 22:05浏览 854评论(0)分类:编程语言
【译】mahout in action 2.5 评估GroupLens数据集合

博客分类： Mahout in action
算法Apache
用这些在进行中的工具，我们将可能不仅讨论速度，也讨论我们创造和修改的推荐引擎的质量。虽然大量真实数据的例子仍然要过几章才能讲到，我们将花一些时间在一个小型数据集合上去快速评估性能。 2.5.1 提取推荐器输入数据 GroupLens (http://grouplens.org/)是一个研究项目，它提供几个不同型号的数据集合，每一个都来自于真实的用户对电影的评分。这是几个有效的大型的真实世界的数据库中之一，在这本书中我们将会探究更多这种数据集合。从grouplens.org查找并下载“100K data set”，当前在 http://www.grouplens.org/node/73上可以得到。 ...
2011-03-01 22:02浏览 1486评论(0)分类:编程语言
【译】mahout in action 2.4 评估的精确和调用

博客分类： Mahout in action
搜索引擎
我们也可以得到一个关于recommender问题的更宽广的看法：对生产recommendations我们不用必须估计首选项值。没必要总是对用户提供估计的首选项值。在很多情况下，我们所想要的是一个recommendations的从最好到最差的排序列表。事实上，在有些情况下，我们不是很关心列表的精确排序：一组有点好的recommendations是好的。 用更一般的看法，我们也可以把经典的信息检索测量应用到评估recommenders:精度和调用。这些项目代表性的应用于像搜索引擎这样的程序，这为许多可能结果的查询返回一些最好的结果。
2011-03-01 21:33浏览 1326评论(1)分类:编程语言
【译】mahout in action 2.3 推荐器考核

博客分类： Mahout in action
单元测试算法工作
这是一个推荐引擎的工作，用来解释下面的问题：“对用户来说，怎么的推荐数据才是最好的”。在搞清楚这个的答案之前，我们首先应该解决这个问题。一个好的推荐数据精度指的是什么？我们需要知道产出一个怎么样的推荐� ...
2011-02-25 18:00浏览 1566评论(0)分类:编程语言
【译】mahout in action 2.2 运行首个推荐引擎

博客分类： Mahout in action
Apache算法生活IDE
Mahout包含一个推荐引擎的几种类型，事实上包含传统的基于用户（user-based），基于项目（item-based）推荐算法，也包括基于“slope-one”技术的实现（这一个新的有效的方法）。 你将根据实验，基于单机版的（SVD）初步实现。在下面的章节里，我们将会在Mahout的背景下和一些现实生活中的例子，来回顾上面的观察结果。我们将会考虑如何代表数据，如何进行有效的推荐算法，如何评估推荐器的效果，如何为一个特殊的问题调研和定制推荐器，最后考虑如何分布计算。 2.2.1 创建输入 我们将会以一个简单的例子，开始对Mahout中的推荐器认识。首先，我们需要给出推荐器的输入数据。在Maho ...
2011-02-25 16:51浏览 2229评论(0)分类:编程语言
【译】mahout in action 2.1 什么是推荐器？

博客分类： Mahout in action
浏览器算法出版框架
因为某种原因你从书架上取到这本书。也许你是在知道的其他书本，看到了这本书， 并觉的它有用。或者觉得书店把它放在这个位置，是因为喜欢这些书的人也喜欢这本书。也或许你在一个同事的书架上看到这本书，这位同事与 ...
2011-02-25 16:23浏览 1334评论(0)分类:编程语言
【译】mahout in action 2 推荐器介绍

博客分类： Mahout in action
设计模式
本章包括： 。介绍第一个Recommender 。推荐引擎的精确度评估 。评估一个引擎的准确度和召回 。在一个现实的例子Grouplens上评估一个Recommender 每天我们都形成对许多事情的看法，这些事情有我们喜欢的，不喜欢的，甚至不关心的。这是在不知不觉中发生的。当你在收音机上听到一首歌，你注意它，要么因为它引人注意，要么因为它听起来很糟糕，要么可能完全没有注意它。T恤，色拉，发型，滑雪场，容颜，电视节目都是相同的事情。 虽然大家的品味经常在变，但他们都遵循一定的模式。人们往往喜欢的事情，类似于他们喜欢的其他事情。因为我喜欢吃熏肉、生菜、番茄组成的三明治，你可以猜到我想吃总会三明治，它 ...
2011-02-25 15:48浏览 1487评论(0)分类:编程语言
【译】mahout in action 1.7 总结

博客分类： Mahout in action
Apache
Mahout是apache的一个年前的，开源的，研究机器学习项目。
2011-02-25 14:01浏览 1250评论(0)分类:编程语言
【译】mahout in action 1.6 安装Mahout

博客分类： Mahout in action
闲话少说，现在我们将一起来揭开Mahout的面纱。在这个过程中，你可能提前需要准备一些工具，来处理在本节即将介绍的一些代码。
2011-02-25 13:59浏览 1670评论(0)分类:编程语言
【译】mahout in action 1.4 扩展性Scaling up

博客分类： Mahout in action
UPMapreduceHadoop框架Apache
当提供大量的优良的输入数据时，这些技术中的那一个才可以最好的操作。有时候，这些技术不仅必须在大量的输入数据上操作，而且必须很快的产生结果。可扩展性，很快成为这些因素的一个主要问题。 根据粗略的估计，Picasa甚至在三年前可能已经服务器托管了5亿的图片。这意味着每日成千上万的新的图片必须被分析。通过它自己来分析一张图片没有很大的问题，虽然它重复成千上万次。但是，学习阶段需要同时地数以亿计的每张图片的信息，一定规模的计算对于单一的机器来说是显然是行不通的。 根据类似的分析，谷歌新闻中心每天查询大约3.5百万的新的新闻文章。虽然就其本身来说这不是很大的量，但考虑到这些文章必须与近来的文章一起被聚集， ...
2011-02-25 13:41浏览 1148评论(1)分类:编程语言
【译】mahout in action 1.4 分类Classification

博客分类： Mahout in action
AppleGoogle项目管理工作
分类技术决定一个东西是不是某个类型或种类的一部分，或者有没有某些属性。分类同样是普遍存在的，虽然这是更多的幕后工作。这种系统问题通常是通过对目录中的项目，很多例子的回顾来了解，从而推断出分类的规则。这里大致可以发现很多应用程序： 雅虎邮件，决定收到的消息是否是垃圾邮件，这基于用户之前的电子邮件和垃圾邮件报告，和电子邮件本身的特性一样。一些被分类为垃圾邮件的信息将会在图1.4中显示。 Picasa(http://picasa.google.com/)和其他一些相片管理应用程序，可以从一个图像中识别出一个人的脸部。 光学字符辨识软件，通过把小范围的已扫描的文本分割成若干个小单元格的个体，来分成单字。 ...
2011-02-25 13:31浏览 1477评论(0)分类:编程语言
【译】mahout in action 1.3 聚类Clustering

博客分类： Mahout in action
搜索引擎数据结构
聚类的出现不太出名，但同样是重要的内容。正如它的名字意味着聚类技术试图把大量的事情聚集起来形成群集以便来分享它们的相似点。这是一种在大型的或者很难理解的数据集合中发现层次结构和规则的方法，用这种方法可以揭示有趣的模式或形成易于理解的数据集合。 谷歌新闻中心为了使介绍的新闻需要按逻辑模式来分类，而不是按一个包含所有文章的未加工的列表。因此他们运用聚类技术，根据文章主题来分组各类新闻。图1.3将会在下面举例说明。 像clusty group这样的搜索引擎搜索类似的原因。 客户可能被这种技术聚类，有可能是根据如：收入状况，地点，购买习惯等属性分成几个片段。 图1.3一个来自于谷歌新闻中心的新闻分类样本 ...
2011-02-25 10:11浏览 1651评论(0)分类:编程语言
【译】mahout in action 1.2 推荐引擎Recommender Engines

博客分类： Mahout in action
影视Facebook
推荐引擎是当今使用中最直接的，可辨别的机器学习技术。我们已经都看到了，试图推荐基于我们过去行为的书本、影视或文章的服务或网站。它们努力推断出爱好和首选项，以及辨认有兴趣的未知项目： 。亚马逊网站在部署推荐上可能是最著名的商业网站。基于购买和用户浏览，亚马逊推荐可能有兴趣的书本或其他项目。看图 1.2. 。Netflix同样推荐可能有兴趣的DVD，而且它之所以著名，是因为提供1000000美元的奖励给那些能够提高他们推荐质量的研究人员。 。像Líbímseti(稍后讨论)这样的Dating网站甚至可以把人推荐给人。 。像Facebook这样的社交网络网站，把可变类型运用到推荐技术上来辨认人，这些人 ...
2011-02-25 09:57浏览 1818评论(1)分类:编程语言
【译】mahout in action 1.1 Mahout是否适合我

博客分类： Mahout in action
算法luceneHadoop搜索引擎项目管理
大家可能想知道，这个项目，这本身是否适合我？ 如果你想找一本机器学习的教科书，那就不适合你。本书不是用来完全解释理论，算法的各种来历和技术展现。熟悉这些机器学习的方法和相关的概念，如matrix and vector math，这�� ...
2011-02-25 09:46浏览 1831评论(0)分类:编程语言
【译】mahout in action 6.1从维基百科统计分析大量的数据

博客分类： Mahout in action
出版Web.net
维基百科(http://wikipedia.org)众所周知的在线百科全书，它的内容可以被用户编辑和维护。到2010年5月它的报导，仅仅用英语写的文章超过了3.2M。估计Freebase Wikipedia Extraction项目(http://download.freebase.com/wex/)的大小，仅仅英语文章超过4.2GB。作为web站点，维基百科的文章可以使用和被连接到另外的文章里面。有这么一篇文章，它里面有很多形同兴趣的文章连接。我们将认为这些文章为“users”，和文章的引用作为“items”，文章的来源为“likes” 幸运的，我们不在需要下载freebase百科的目录摘要和 ...
2011-02-24 18:15浏览 1370评论(0)分类:编程语言
【译】mahout in action 6 分布式计算推荐器（Distributing Recommendation Computations）

博客分类： Mahout in action
Hadoop算法Mapreduce
本章包括： 。从维基百科统计分析大量的数据 。编写在hadoop上使用的推荐器和分布式算法 。伪分布式存在非分布式的推荐器 我们越来越关注日益增长的数据，自从开始这本书：从10个选择，到100,000到1千万，和现在1.7千万。这里仍旧只有半成品在推荐领域。本章，我们将再次处理大量的数据，超过1.3亿的“偏好”在提交维基百科的文章到文章的连接选择。在这个数据集合，用户和项目都是条件约束，他们展示怎么推荐可以有效的实施针对较少的常见内容。 针对展示1.3亿“偏好”仍然是易于控制的大小，它是一个这样的刻度：换句话说我们过去看到的，对单机处理很麻烦的推荐器。我们将部署新的推荐算法，使用分布式计算着手处 ...
2011-02-24 17:41浏览 1722评论(0)分类:编程语言
【译】mahout in action 1 初识Mahout

博客分类： Mahout in action
Hadoop生活Apache算法数据结构
本章内容： .什么是mahout .初识推荐引擎，聚类，分类在现实生活 .建立mahout 你们可能已经从标题中猜出,这本书是关于一个特定的工具Mahout,在现实生活中使用。那么什么是mahout？ Mahout是一个Apache的开源机器学习项目。该算法属于广阔的 “机器学习”,或“集体智慧的伞形结构。这就可以代表很多东西,但此时此刻,我们关心Mahout的主要部分是：协同过滤（CF）/推荐引擎（recommender）,聚类（clustering）和分类（classification）。 它具有很强的扩展性。当被处理的非常巨大的数据量，对单个机器来说可能太巨大以至于无法完成时，Mahout ...
2011-02-22 11:50浏览 3022评论(2)分类:编程语言

奔跑的羚羊
浏览: 132488 次
性别: 
来自: 北京

最近访客 更多访客>>
dylinshi126haolebook523wanyinglong
文章分类
全部博客 (97)
java (12)
linux (12)
db (1)
hadoop (14)
hive (8)
Mahout in action (21)
mahout (7)
虚拟化 (11)
nginx (11)
社区版块
我的资讯 (0)
我的论坛 (28)
我的问答 (1)
存档分类
2013-09 (10)
2012-09 (1)
2012-06 (1)
更多存档...
最新评论
zenoh： 你好我搭建好了hive+ hbase的环境，hbase也能正常 ...
Hive HBase 整合
bin_1715575332： 为何不直接指定row format delimited fie ...
hive处理日志，自定义inputformat
chlhp： 跳过以下两个步骤，也是可以添加并运行成功的，为什么呢？2.修改 ...
Hadoop添加节点datanode
nitian123ok： 太好了，找到中文的了
【译】mahout in action 1.2 推荐引擎Recommender Engines
cooler1217： alter database hive character s ...
hive使用mysql保存metastore
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]

========== https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-BuiltinAggregateFunctions%28UDAF%29 ==========

Browse
Pages
Blog
Labels
Attachments
Bookmarks
Mail
Advanced
What’s New
Space Directory
Keyboard Shortcuts
Confluence Gadgets
Log InSign Up
Dashboard
Apache Hive
LanguageManual UDF
Tools
Attachments (0)
Page History
Restrictions
Info
Link to this Page…
View in Hierarchy
View Wiki Markup
 LanguageManual UDF
Added by Confluence Administrator, last edited by Lefty Leverenz on Sep 24, 2013  (view change) show comment
Hive Operators and User-Defined Functions (UDFs)
Hive Operators and User-Defined Functions (UDFs)
Built-in Operators
Relational Operators
Arithmetic Operators
Logical Operators
Complex Type Constructors
Operators on Complex Types
Built-in Functions
Mathematical Functions
Mathematical Functions and Operators for Decimal Datatypes
Collection Functions
Type Conversion Functions
Date Functions
Conditional Functions
String Functions
Misc. Functions
xpath
get_json_object
Built-in Aggregate Functions (UDAF)
Built-in Table-Generating Functions (UDTF)
explode
json_tuple
parse_url_tuple
GROUPing and SORTing on f(column)
UDF internals
	Case-insensitive
All Hive keywords are case-insensitive, including the names of Hive operators and functions.
In the CLI, use the commands below to show the latest documentation:

SHOW FUNCTIONS;
DESCRIBE FUNCTION <function_name>;
DESCRIBE FUNCTION EXTENDED <function_name>;
Built-in Operators
Relational Operators
The following operators compare the passed operands and generate a TRUE or FALSE value depending on whether the comparison between the operands holds.

Operator	Operand types	Description
A = B	 All primitive types	 TRUE if expression A is equal to expression B otherwise FALSE
A <=> B	 All primitive types	 Returns same result with EQUAL(=) operator for non-null operands, but returns TRUE if both are NULL, FALSE if one of the them is NULL (as of version 0.9.0)
A == B	None!	Fails because of invalid syntax. SQL uses =, not ==
A <> B	 All primitive types	 NULL if A or B is NULL, TRUE if expression A is NOT equal to expression B otherwise FALSE
A != B	 All primitive types	 a synonym for the <> operator
A < B	 All primitive types	 NULL if A or B is NULL, TRUE if expression A is less than expression B otherwise FALSE
A <= B	 All primitive types	 NULL if A or B is NULL, TRUE if expression A is less than or equal to expression B otherwise FALSE
A > B	 All primitive types	 NULL if A or B is NULL, TRUE if expression A is greater than expression B otherwise FALSE
A >= B	 All primitive types	 NULL if A or B is NULL, TRUE if expression A is greater than or equal to expression B otherwise FALSE
A [NOT] BETWEEN B AND C	 All primitive types	 NULL if A, B or C is NULL, TRUE if A is greater than or equal to B AND A less than or equal to C otherwise FALSE. This can be inverted by using the NOT keyword. (as of version 0.9.0)
A IS NULL	 all types	 TRUE if expression A evaluates to NULL otherwise FALSE
A IS NOT NULL	 All types	 FALSE if expression A evaluates to NULL otherwise TRUE
A [NOT] LIKE B	 strings	 NULL if A or B is NULL, TRUE if string A matches the SQL simple regular expression B, otherwise FALSE. The comparison is done character by character. The _ character in B matches any character in A (similar to . in posix regular expressions) while the % character in B matches an arbitrary number of characters in A (similar to .* in posix regular expressions) e.g. 'foobar' like 'foo' evaluates to FALSE where as 'foobar' like 'foo_ _ _' evaluates to TRUE and so does 'foobar' like 'foo%'
A RLIKE B	 strings	 NULL if A or B is NULL, TRUE if any (possibly empty) substring of A matches the Java regular expression B, otherwise FALSE. E.g. 'foobar' RLIKE 'foo' evaluates to TRUE and so does 'foobar' RLIKE '^f.*r$'.
A REGEXP B	 strings	 Same as RLIKE
Arithmetic Operators
The following operators support various common arithmetic operations on the operands. All return number types; if any of the operands are NULL, then the result is also NULL.

Operator	Operand types	Description
A + B	 All number types	 Gives the result of adding A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands. e.g. since every integer is a float, therefore float is a containing type of integer so the + operator on a float and an int will result in a float.
A - B	 All number types	 Gives the result of subtracting B from A. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.
A * B	 All number types	 Gives the result of multiplying A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands. Note that if the multiplication causing overflow, you will have to cast one of the operators to a type higher in the type hierarchy.
A / B	 All number types	 Gives the result of dividing B from A. The result is a double type.
A % B	 All number types	 Gives the reminder resulting from dividing A by B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.
A & B	 All number types	 Gives the result of bitwise AND of A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.
A | B	 All number types	 Gives the result of bitwise OR of A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.
A ^ B	 All number types	 Gives the result of bitwise XOR of A and B. The type of the result is the same as the common parent(in the type hierarchy) of the types of the operands.
~A	 All number types	 Gives the result of bitwise NOT of A. The type of the result is the same as the type of A.
Logical Operators
The following operators provide support for creating logical expressions. All of them return boolean TRUE, FALSE, or NULL depending upon the boolean values of the operands. NULL behaves as an "unknown" flag, so if the result depends on the state of an unknown, the result itself is unknown.

Operator	Operand types	Description
A AND B	 boolean	 TRUE if both A and B are TRUE, otherwise FALSE. NULL if A or B is NULL
A && B	 boolean	 Same as A AND B
A OR B	 boolean	 TRUE if either A or B or both are TRUE; FALSE OR NULL is NULL; otherwise FALSE
A || B	 boolean	 Same as A OR B
NOT A	 boolean	 TRUE if A is FALSE or NULL if A is NULL. Otherwise FALSE.
! A	 boolean	 Same as NOT A
A IN (val1, val2, ...)	 boolean	 TRUE if A is equal to any of the values
A NOT IN (val1, val2, ...)	 boolean	 TRUE if A is not equal to any of the values
Complex Type Constructors
The following functions construct instances of complex types.

Constructor Function	 Operands	 Description
map	 (key1, value1, key2, value2, ...)	 Creates a map with the given key/value pairs
struct	 (val1, val2, val3, ...)	 Creates a struct with the given field values. Struct field names will be col1, col2, ...
named_struct	 (name1, val1, name2, val2, ...)	 Creates a struct with the given field names and values. (as of Hive 0.8.0)
array	 (val1, val2, ...)	 Creates an array with the given elements
create_union	 (tag, val1, val2, ...)	 Creates a union type with the value that is being pointed to by the tag parameter
Operators on Complex Types
The following operators provide mechanisms to access elements in Complex Types

Operator	Operand types	Description
A[n]	 A is an Array and n is an int	 Returns the nth element in the array A. The first element has index 0 e.g. if A is an array comprising of ['foo', 'bar'] then A[0] returns 'foo' and A[1] returns 'bar'
M[key]	 M is a Map<K, V> and key has type K	 Returns the value corresponding to the key in the map e.g. if M is a map comprising of {'f' -> 'foo', 'b' -> 'bar', 'all' -> 'foobar'} then M['all'] returns 'foobar'
S.x	 S is a struct	 Returns the x field of S. e.g for struct foobar {int foo, int bar} foobar.foo returns the integer stored in the foo field of the struct.
Built-in Functions
Mathematical Functions
The following built-in mathematical functions are supported in hive; most return NULL when the argument(s) are NULL:

Return Type	Name (Signature)	Description
DOUBLE	 round(DOUBLE a)	 Returns the rounded BIGINT value of a
DOUBLE	 round(DOUBLE a, INT d)	 Returns a rounded to d decimal places
BIGINT	 floor(DOUBLE a)	 Returns the maximum BIGINT value that is equal or less than a
BIGINT	 ceil(DOUBLE a), ceiling(DOUBLE a)	 Returns the minimum BIGINT value that is equal or greater than a
DOUBLE	 rand(), rand(INT seed)	 Returns a random number (that changes from row to row) that is distributed uniformly from 0 to 1. Specifying the seed will make sure the generated random number sequence is deterministic.
DOUBLE	 exp(DOUBLE a)	 Returns ea where e is the base of the natural logarithm
DOUBLE	 ln(DOUBLE a)	 Returns the natural logarithm of the argument a
DOUBLE	 log10(DOUBLE a)	 Returns the base-10 logarithm of the argument a
DOUBLE	 log2(DOUBLE a)	 Returns the base-2 logarithm of the argument a
DOUBLE	 log(DOUBLE base, DOUBLE a)	 Return the base-base logarithm of the argument d
DOUBLE	 pow(DOUBLE a, DOUBLE p), power(DOUBLE a, DOUBLE p)	 Return ap
DOUBLE	 sqrt(DOUBLE a)	 Returns the square root of a
STRING	 bin(BIGINT a)	 Returns the number in binary format (see http://dev.mysql.com/doc/refman/5.0/en/string-functions.html#function_bin)
STRING	 hex(BIGINT a) hex(STRING a) hex(BINARY a)	 If the argument is an INT or binary hex returns the number as a STRING in hex format. Otherwise if the number is a STRING, it converts each character into its hex representation and returns the resulting STRING. (see http://dev.mysql.com/doc/refman/5.0/en/string-functions.html#function_hex, BINARY version as of Hive 0.12.0)
BINARY	 unhex(STRING a)	 Inverse of hex. Interprets each pair of characters as a hexadecimal number and converts to the byte representation of the number. (BINARY version as of Hive 0.12.0, used to return a string)
STRING	 conv(BIGINT num, INT from_base, INT to_base), conv(STRING num, INT from_base, INT to_base)	 Converts a number from a given base to another (see http://dev.mysql.com/doc/refman/5.0/en/mathematical-functions.html#function_conv)
DOUBLE	 abs(DOUBLE a)	 Returns the absolute value
INT or DOUBLE	 pmod(INT a, INT b), pmod(DOUBLE a, DOUBLE b)	 Returns the positive value of a mod b
DOUBLE	 sin(DOUBLE a)	 Returns the sine of a (a is in radians)
DOUBLE	 asin(DOUBLE a)	 Returns the arc sin of a if -1<=a<=1 or NULL otherwise
DOUBLE	 cos(DOUBLE a)	 Returns the cosine of a (a is in radians)
DOUBLE	 acos(DOUBLE a)	 Returns the arccosine of a if -1<=a<=1 or NULL otherwise
DOUBLE	 tan(DOUBLE a)	 Returns the tangent of a (a is in radians)
DOUBLE	 atan(DOUBLE a)	 Returns the arctangent of a
DOUBLE	 degrees(DOUBLE a)	 Converts value of a from radians to degrees
DOUBLE	 radians(DOUBLE a)	 Converts value of a from degrees to radians
INT or DOUBLE	 positive(INT a), positive(DOUBLE a)	 Returns a
INT or DOUBLE	 negative(INT a), negative(DOUBLE a)	 Returns -a
FLOUT	 sign(DOUBLE a)	 Returns the sign of a as '1.0' (if a is positive) or '-1.0' (if a is negative), '0.0' otherwise
DOUBLE	 e()	 Returns the value of e
DOUBLE	 pi()	 Returns the value of pi
Mathematical Functions and Operators for Decimal Datatypes
	Version
The decimal datatype was introduced in Hive 0.11.0 (HIVE-2693).
All regular arithmetic operators (such as +, -, *, /) and relevant mathematical UDFs (Floor, Ceil, Round, and many more) have been updated to handle decimal types. For a list of supported UDFs, see Mathematical UDFs in Hive Data Types.

Collection Functions
The following built-in collection functions are supported in hive:

Return Type	Name(Signature)	Description
int	 size(Map<K.V>)	 Returns the number of elements in the map type
int	 size(Array<T>)	 Returns the number of elements in the array type
array<K>	 map_keys(Map<K.V>)	 Returns an unordered array containing the keys of the input map
array<V>	 map_values(Map<K.V>)	 Returns an unordered array containing the values of the input map
boolean	 array_contains(Array<T>, value)	 Returns TRUE if the array contains value
array<t>	 sort_array(Array<T>)	 Sorts the input array in ascending order according to the natural ordering of the array elements and returns it (as of version 0.9.0)
Type Conversion Functions
The following type conversion functions are supported in hive:

Return Type	 Name(Signature)	 Description
binary	 binary(string|binary)	 Casts the parameter into a binary
Expected "=" to follow "type"	 cast(expr as <type>)	 Converts the results of the expression expr to <type> e.g. cast('1' as BIGINT) will convert the string '1' to it integral representation. A null is returned if the conversion does not succeed.
Date Functions
The following built-in date functions are supported in hive:

Return Type	Name(Signature)	Description
string	 from_unixtime(bigint unixtime[, string format])	 Converts the number of seconds from unix epoch (1970-01-01 00:00:00 UTC) to a string representing the timestamp of that moment in the current system time zone in the format of "1970-01-01 00:00:00"
bigint	 unix_timestamp()	 Gets current time stamp using the default time zone.
bigint	 unix_timestamp(string date)	 Converts time string in format yyyy-MM-dd HH:mm:ss to Unix time stamp, return 0 if fail: unix_timestamp('2009-03-20 11:30:01') = 1237573801
bigint	 unix_timestamp(string date, string pattern)	 Convert time string with given pattern (see [http://java.sun.com/j2se/1.4.2/docs/api/java/text/SimpleDateFormat.html]) to Unix time stamp, return 0 if fail: unix_timestamp('2009-03-20', 'yyyy-MM-dd') = 1237532400
string	 to_date(string timestamp)	 Returns the date part of a timestamp string: to_date("1970-01-01 00:00:00") = "1970-01-01"
int	 year(string date)	 Returns the year part of a date or a timestamp string: year("1970-01-01 00:00:00") = 1970, year("1970-01-01") = 1970
int	 month(string date)	 Returns the month part of a date or a timestamp string: month("1970-11-01 00:00:00") = 11, month("1970-11-01") = 11
int	 day(string date) dayofmonth(date)	 Return the day part of a date or a timestamp string: day("1970-11-01 00:00:00") = 1, day("1970-11-01") = 1
int	 hour(string date)	 Returns the hour of the timestamp: hour('2009-07-30 12:58:59') = 12, hour('12:58:59') = 12
int	 minute(string date)	 Returns the minute of the timestamp
int	 second(string date)	 Returns the second of the timestamp
int	 weekofyear(string date)	 Return the week number of a timestamp string: weekofyear("1970-11-01 00:00:00") = 44, weekofyear("1970-11-01") = 44
int	 datediff(string enddate, string startdate)	 Return the number of days from startdate to enddate: datediff('2009-03-01', '2009-02-27') = 2
string	 date_add(string startdate, int days)	 Add a number of days to startdate: date_add('2008-12-31', 1) = '2009-01-01'
string	 date_sub(string startdate, int days)	 Subtract a number of days to startdate: date_sub('2008-12-31', 1) = '2008-12-30'
timestamp	 from_utc_timestamp(timestamp, string timezone)	 Assumes given timestamp ist UTC and converts to given timezone (as of Hive 0.8.0)
timestamp	 to_utc_timestamp(timestamp, string timezone)	 Assumes given timestamp is in given timezone and converts to UTC (as of Hive 0.8.0)
Conditional Functions
Return Type	Name(Signature)	Description
T	 if(boolean testCondition, T valueTrue, T valueFalseOrNull)	 Return valueTrue when testCondition is true, returns valueFalseOrNull otherwise
T	 COALESCE(T v1, T v2, ...)	 Return the first v that is not NULL, or NULL if all v's are NULL
T	 CASE a WHEN b THEN c [WHEN d THEN e]* [ELSE f] END	 When a = b, returns c; when a = d, return e; else return f
T	 CASE WHEN a THEN b [WHEN c THEN d]* [ELSE e] END	 When a = true, returns b; when c = true, return d; else return e
String Functions
The following are built-in String functions are supported in hive:

Return Type	Name(Signature)	Description
int	 ascii(string str)	 Returns the numeric value of the first character of str
string	 base64(binary bin)	 Convert the argument from binary to a base 64 string (as of Hive 0.12.0)
string	 concat(string|binary A, string|binary B...)	 Returns the string or bytes resulting from concatenating the strings or bytes passed in as parameters in order. e.g. concat('foo', 'bar') results in 'foobar'. Note that this function can take any number of input strings.
array<struct<string,double>>	 context_ngrams(array<array<string>>, array<string>, int K, int pf)	 Returns the top-k contextual N-grams from a set of tokenized sentences, given a string of "context". See StatisticsAndDataMining for more information.
string	 concat_ws(string SEP, string A, string B...)	 Like concat() above, but with custom separator SEP.
string	 concat_ws(string SEP, array<string>)	 Like concat_ws() above, but taking an array of strings. (as of Hive 0.9.0)
string	 decode(binary bin, string charset)	 Decode the first argument into a String using the provided character set (one of 'US_ASCII', 'ISO-8859-1', 'UTF-8', 'UTF-16BE', 'UTF-16LE', 'UTF-16'). If either argument is null, the result will also be null. (as of Hive 0.12.0)
binary	 encode(string src, string charset)	 Encode the first argument into a BINARY using the provided character set (one of 'US_ASCII', 'ISO-8859-1', 'UTF-8', 'UTF-16BE', 'UTF-16LE', 'UTF-16'). If either argument is null, the result will also be null. (as of Hive 0.12.0)
int	 find_in_set(string str, string strList)	 Returns the first occurance of str in strList where strList is a comma-delimited string. Returns null if either argument is null. Returns 0 if the first argument contains any commas. e.g. find_in_set('ab', 'abc,b,ab,c,def') returns 3
string	 format_number(number x, int d)	 Formats the number X to a format like '#,###,###.##', rounded to D decimal places, and returns the result as a string. If D is 0, the result has no decimal point or fractional part. (as of Hive 0.10.0)
string	 get_json_object(string json_string, string path)	 Extract json object from a json string based on json path specified, and return json string of the extracted json object. It will return null if the input json string is invalid. NOTE: The json path can only have the characters [0-9a-z_], i.e., no upper-case or special characters. Also, the keys *cannot start with numbers.* This is due to restrictions on Hive column names.
boolean	 in_file(string str, string filename)	 Returns true if the string str appears as an entire line in filename.
int	 instr(string str, string substr)	 Returns the position of the first occurence of substr in str
int	 length(string A)	 Returns the length of the string
int	 locate(string substr, string str[, int pos])	 Returns the position of the first occurrence of substr in str after position pos
string	 lower(string A) lcase(string A)	 Returns the string resulting from converting all characters of B to lower case e.g. lower('fOoBaR') results in 'foobar'
string	 lpad(string str, int len, string pad)	 Returns str, left-padded with pad to a length of len
string	 ltrim(string A)	 Returns the string resulting from trimming spaces from the beginning(left hand side) of A e.g. ltrim(' foobar ') results in 'foobar '
array<struct<string,double>>	 ngrams(array<array<string>>, int N, int K, int pf)	 Returns the top-k N-grams from a set of tokenized sentences, such as those returned by the sentences() UDAF. See StatisticsAndDataMining for more information.
string	 parse_url(string urlString, string partToExtract [, string keyToExtract])	 Returns the specified part from the URL. Valid values for partToExtract include HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO. e.g. parse_url('http://facebook.com/path1/p.php?k1=v1&k2=v2#Ref1', 'HOST') returns 'facebook.com'. Also a value of a particular key in QUERY can be extracted by providing the key as the third argument, e.g. parse_url('http://facebook.com/path1/p.php?k1=v1&k2=v2#Ref1', 'QUERY', 'k1') returns 'v1'.
string	 printf(String format, Obj... args)	 Returns the input formatted according do printf-style format strings (as of Hive 0.9.0)
string	 regexp_extract(string subject, string pattern, int index)	 Returns the string extracted using the pattern. e.g. regexp_extract('foothebar', 'foo(.*?)(bar)', 2) returns 'bar.' Note that some care is necessary in using predefined character classes: using '\s' as the second argument will match the letter s; ' 
s' is necessary to match whitespace, etc. The 'index' parameter is the Java regex Matcher group() method index. See docs/api/java/util/regex/Matcher.html for more information on the 'index' or Java regex group() method.
string	 regexp_replace(string INITIAL_STRING, string PATTERN, string REPLACEMENT)	 Returns the string resulting from replacing all substrings in INITIAL_STRING that match the java regular expression syntax defined in PATTERN with instances of REPLACEMENT, e.g. regexp_replace("foobar", "oo|ar", "") returns 'fb.' Note that some care is necessary in using predefined character classes: using '\s' as the second argument will match the letter s; ' 
s' is necessary to match whitespace, etc.
string	 repeat(string str, int n)	 Repeat str n times
string	 reverse(string A)	 Returns the reversed string
string	 rpad(string str, int len, string pad)	 Returns str, right-padded with pad to a length of len
string	 rtrim(string A)	 Returns the string resulting from trimming spaces from the end(right hand side) of A e.g. rtrim(' foobar ') results in ' foobar'
array<array<string>>	 sentences(string str, string lang, string locale)	 Tokenizes a string of natural language text into words and sentences, where each sentence is broken at the appropriate sentence boundary and returned as an array of words. The 'lang' and 'locale' are optional arguments. e.g. sentences('Hello there! How are you?') returns ( ("Hello", "there"), ("How", "are", "you") )
string	 space(int n)	 Return a string of n spaces
array	 split(string str, string pat)	 Split str around pat (pat is a regular expression)
map<string,string>	 str_to_map(text[, delimiter1, delimiter2])	 Splits text into key-value pairs using two delimiters. Delimiter1 separates text into K-V pairs, and Delimiter2 splits each K-V pair. Default delimiters are ',' for delimiter1 and '=' for delimiter2.
string	 substr(string|binary A, int start) substring(string|binary A, int start)	 Returns the substring or slice of the byte array of A starting from start position till the end of string A e.g. substr('foobar', 4) results in 'bar' (see [http://dev.mysql.com/doc/refman/5.0/en/string-functions.html#function_substr])
string	 substr(string|binary A, int start, int len) substring(string|binary A, int start, int len)	 Returns the substring or slice of the byte array of A starting from start position with length len e.g. substr('foobar', 4, 1) results in 'b' (see [http://dev.mysql.com/doc/refman/5.0/en/string-functions.html#function_substr])
string	 translate(string input, string from, string to)	 Translates the input string by replacing the characters present in the from string with the corresponding characters in the to string. This is similar to the translate function in PostgreSQL. If any of the parameters to this UDF are NULL, the result is NULL as well (available as of Hive 0.10.0)
string	 trim(string A)	 Returns the string resulting from trimming spaces from both ends of A e.g. trim(' foobar ') results in 'foobar'
binary	 unbase64(string str)	 Convert the argument from a base 64 string to BINARY (as of Hive 0.12.0)
string	 upper(string A) ucase(string A)	 Returns the string resulting from converting all characters of A to upper case e.g. upper('fOoBaR') results in 'FOOBAR'
Misc. Functions
Return Type	Name(Signature)	Description
varies	 java_method(class, method[, arg1[, arg2..]])	 Synonym for reflect (as of Hive 0.9.0)
varies	 reflect(class, method[, arg1[, arg2..]])	 Use this UDF to call Java methods by matching the argument signature (uses reflection). (as of Hive 0.7.0)
int	 hash(a1[, a2...])	 Returns a hash value of the arguments (as of Hive 0.4)
xpath
The following functions are described in LanguageManual XPathUDF:

xpath, xpath_short, xpath_int, xpath_long, xpath_float, xpath_double, xpath_number, xpath_string
get_json_object
A limited version of JSONPath is supported:

$ : Root object
. : Child operator
[] : Subscript operator for array
* : Wildcard for []
Syntax not supported that's worth noticing:

: Zero length string as key
.. : Recursive descent
@ : Current object/element
() : Script expression
?() : Filter (script) expression.
[,] : Union operator
[start:end.step] : array slice operator
Example: src_json table is a single column (json), single row table:

+----+
                               json
+----+
{"store":
  {"fruit":\[{"weight":8,"type":"apple"},{"weight":9,"type":"pear"}],
   "bicycle":{"price":19.95,"color":"red"}
  },
 "email":"amy@only_for_json_udf_test.net",
 "owner":"amy"
}
+----+
The fields of the json object can be extracted using these queries:

hive> SELECT get_json_object(src_json.json, '$.owner') FROM src_json;
amy
 
hive> SELECT get_json_object(src_json.json, '$.store.fruit\[0]') FROM src_json;
{"weight":8,"type":"apple"}
 
hive> SELECT get_json_object(src_json.json, '$.non_exist_key') FROM src_json;
NULL
Built-in Aggregate Functions (UDAF)
The following are built-in aggregate functions are supported in Hive:

Return Type	Name(Signature)	Description
BIGINT	 count(*), count(expr), count(DISTINCT expr[, expr_.])	 count(*) - Returns the total number of retrieved rows, including rows containing NULL values; count(expr) - Returns the number of rows for which the supplied expression is non-NULL; count(DISTINCT expr[, expr]) - Returns the number of rows for which the supplied expression(s) are unique and non-NULL.
DOUBLE	 sum(col), sum(DISTINCT col)	 Returns the sum of the elements in the group or the sum of the distinct values of the column in the group
DOUBLE	 avg(col), avg(DISTINCT col)	 Returns the average of the elements in the group or the average of the distinct values of the column in the group
DOUBLE	 min(col)	 Returns the minimum of the column in the group
DOUBLE	 max(col)	 Returns the maximum value of the column in the group
DOUBLE	 variance(col), var_pop(col)	 Returns the variance of a numeric column in the group
DOUBLE	 var_samp(col)	 Returns the unbiased sample variance of a numeric column in the group
DOUBLE	 stddev_pop(col)	 Returns the standard deviation of a numeric column in the group
DOUBLE	 stddev_samp(col)	 Returns the unbiased sample standard deviation of a numeric column in the group
DOUBLE	 covar_pop(col1, col2)	 Returns the population covariance of a pair of numeric columns in the group
DOUBLE	 covar_samp(col1, col2)	 Returns the sample covariance of a pair of a numeric columns in the group
DOUBLE	 corr(col1, col2)	 Returns the Pearson coefficient of correlation of a pair of a numeric columns in the group
DOUBLE	 percentile(BIGINT col, p)	 Returns the exact pth percentile of a column in the group (does not work with floating point types). p must be between 0 and 1. NOTE: A true percentile can only be computed for integer values. Use PERCENTILE_APPROX if your input is non-integral.
array<double>	 percentile(BIGINT col, array(p1 [, p2]...))	 Returns the exact percentiles p1, p2, ... of a column in the group (does not work with floating point types). pi must be between 0 and 1. NOTE: A true percentile can only be computed for integer values. Use PERCENTILE_APPROX if your input is non-integral.
DOUBLE	 percentile_approx(DOUBLE col, p [, B])	 Returns an approximate pth percentile of a numeric column (including floating point types) in the group. The B parameter controls approximation accuracy at the cost of memory. Higher values yield better approximations, and the default is 10,000. When the number of distinct values in col is smaller than B, this gives an exact percentile value.
array<double>	 percentile_approx(DOUBLE col, array(p1 [, p2]...) [, B])	 Same as above, but accepts and returns an array of percentile values instead of a single one.
array<struct {'x','y'}>	 histogram_numeric(col, b)	 Computes a histogram of a numeric column in the group using b non-uniformly spaced bins. The output is an array of size b of double-valued (x,y) coordinates that represent the bin centers and heights
array	 collect_set(col)	 Returns a set of objects with duplicate elements eliminated
array	 collect_list(col)	 Returns a list of objects with duplicates (as of Hive 0.13.0)
Built-in Table-Generating Functions (UDTF)
Normal user-defined functions, such as concat(), take in a single input row and output a single output row. In contrast, table-generating functions transform a single input row to multiple output rows.

Return Type	Name(Signature)	Description
N rows	 explode(ARRAY)	 Returns one row for each element from the array
N rows	 explode(MAP)	 Returns one row for each key-value pair from the input map with two columns in each row: one for the key and another for the value. (as of Hive 0.8.0)
 	 inline(ARRAY<STRUCT[,STRUCT]>)	 Explodes an array of structs into a table (as of Hive 0.10)
Array Type	 explode(array<TYPE> a)	 For each element in a, explode() generates a row containing that element
tuple	 json_tuple(jsonStr, k1, k2, ...)	 It takes a set of names (keys) and a JSON string, and returns a tuple of values. This is a more efficient version of the get_json_object UDF because it can get multiple keys with just one call
tuple	 parse_url_tuple(url, p1, p2, ...)	 This is similar to the parse_url() UDF but can extract multiple parts at once out of a URL. Valid part names are: HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, USERINFO, QUERY:<KEY>.
 	 stack(INT n, v_1, v_2, ..., v_k)	 Breaks up v_1, ..., v_k into n rows. Each row will have k/n columns. n must be constant.
Using the syntax "SELECT udtf(col) AS colAlias..." has a few limitations:

No other expressions are allowed in SELECT
SELECT pageid, explode(adid_list) AS myCol... is not supported
UDTF's can't be nested
SELECT explode(explode(adid_list)) AS myCol... is not supported
GROUP BY / CLUSTER BY / DISTRIBUTE BY / SORT BY is not supported
SELECT explode(adid_list) AS myCol ... GROUP BY myCol is not supported
Please see LanguageManual LateralView for an alternative syntax that does not have these limitations.

explode
explode() takes in an array as an input and outputs the elements of the array as separate rows. UDTF's can be used in the SELECT expression list and as a part of LATERAL VIEW.

An example use of explode() in the SELECT expression list is as follows:

Consider a table named myTable that has a single column (myCol) and two rows:

Array<int> myCol
[1,2,3]
[4,5,6]
Then running the query:

SELECT explode(myCol) AS myNewCol FROM myTable;

Will produce:

(int) myNewCol
1
2
3
4
5
6
json_tuple
A new json_tuple() UDTF is introduced in hive 0.7. It takes a set of names (keys) and a JSON string, and returns a tuple of values using one function. This is much more efficient than calling GET_JSON_OBJECT to retrieve more than one key from a single JSON string. In any case where a single JSON string would be parsed more than once, your query will be more efficient if you parse it once, which is what JSON_TUPLE is for. As JSON_TUPLE is a UDTF, you will need to use the LATERAL VIEW syntax in order to achieve the same goal.

For example,

select a.timestamp, get_json_object(a.appevents, '$.eventid'), get_json_object(a.appenvets, '$.eventname') from log a;
should be changed to

select a.timestamp, b.*
from log a lateral view json_tuple(a.appevent, 'eventid', 'eventname') b as f1, f2;
parse_url_tuple
The parse_url_tuple() UDTF is similar to parse_url(), but can extract multiple parts of a given URL, returning the data in a tuple. Values for a particular key in QUERY can be extracted by appending a colon and the key to the partToExtract argument, e.g. parse_url_tuple('http://facebook.com/path1/p.php?k1=v1&k2=v2#Ref1', 'QUERY:k1', 'QUERY:k2') returns a tuple with values of 'v1','v2'. This is more efficient than calling parse_url() multiple times. All the input parameters and output column types are string.

SELECT b.*
FROM src LATERAL VIEW parse_url_tuple(fullurl, 'HOST', 'PATH', 'QUERY', 'QUERY:id') b as host, path, query, query_id LIMIT 1;
GROUPing and SORTing on f(column)
A typical OLAP pattern is that you have a timestamp column and you want to group by daily or other less granular date windows than by second. So you might want to select concat(year(dt),month(dt)) and then group on that concat(). But if you attempt to GROUP BY or SORT BY a column on which you've applied a function and alias, like this:

select f(col) as fc, count(*) from table_name group by fc;
You will get an error:

FAILED: Error in semantic analysis: line 1:69 Invalid Table Alias or Column Reference fc
Because you are not able to GROUP BY or SORT BY a column alias on which a function has been applied. There are two workarounds. First, you can reformulate this query with subqueries, which is somewhat complicated:

select sq.fc,col1,col2,...,colN,count(*) from
  (select f(col) as fc,col1,col2,...,colN from table_name) sq
 group by sq.fc,col1,col2,...,colN;
Or you can make sure not to use a column alias, which is simpler:

select f(col) as fc, count(*) from table_name group by f(col);
Contact Tim Ellis (tellis) at RiotGames dot com if you would like to discuss this in further detail.

UDF internals
The context of a UDF's evaluate method is one row at a time. A simple invocation of a UDF like

SELECT length(string_col) FROM table_name;
would evaluate the length of each of the string_col's values in the map portion of the job. The side effect of the UDF being evaluated on the map-side is that you can't control the order of rows which get sent to the mapper. It is the same order in which the file split sent to the mapper gets deserialized. Any reduce side operation (e.g. SORT BY, ORDER BY, regular JOIN, etc.) would apply to the UDFs output as if it is just another column of the table. This is fine since the context of the UDF's evaluate method is meant to be one row at a time.

If you would like to control which rows get sent to the same UDF (and possibly in what order), you will have the urge to make the UDF evaluate during the reduce phase. This is achievable by making use of DISTRIBUTE BY, DISTRIBUTE BY + SORT BY, CLUSTER BY. An example query would be:

SELECT reducer_udf(my_col, distribute_col, sort_col) FROM
(SELECT my_col, distribute_col, sort_col FROM table_name DISTRIBUTE BY distribute_col SORT BY distribute_col, sort_col) t
However, one could argue that the very premise of your requirement to control the set of rows sent to the same UDF is to do aggregation in that UDF. In such a case, using a User Defined Aggregate Function (UDAF) is a better choice. You can read more about writing a UDAF here. Alternatively, you can user a custom reduce script to accomplish the same using Hive's Transform functionality. Both of these options would do aggregations on the reduce side.

Labels:
None

Powered by a free Atlassian Confluence Open Source Project License granted to Apache Software Foundation. Evaluate Confluence today.
This Confluence installation runs a Free Gliffy License - Evaluate the Gliffy Confluence Plugin for your Wiki!
Powered by Atlassian Confluence 3.5.17, the Enterprise Wiki   |  Report a bug  |  Atlassian News

========== http://searchwiki.taobao.ali.com/index.php/Hadoop_streaming_%E9%80%9F%E6%88%90 ==========
Failed!!
========== http://twiki.corp.taobao.com/bin/view/%E5%B9%BF%E5%91%8A%E6%8A%80%E6%9C%AF%E9%83%A8/Taobao_Algo/AES/TechMeterial/PymredTutorial ==========
========== http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/ ==========
========== http://hadoop.apache.org/common/docs/r0.15.2/streaming.html#Hadoop+Streaming ==========
Not Found

The requested URL /docs/r0.15.2/streaming.html was not found on this server.

Apache/2.4.6 (Unix) mod_wsgi/3.4 Python/2.7.5 OpenSSL/1.0.1e Server at hadoop.apache.org Port 80
========== http://rdc.taobao.com/blog/cs/?p=160 ==========
淘宝核心系统团队博客
基础 极致 分享
HOME
招聘信息
淘宝核心系统团队介绍
« static const member initialize夸父驱动造成内核panic的解决手记 »
paxos算法介绍
    本介绍是 Paxos Made Simple 的中文说明。会摘录一些原来的段落讲解。如果大家发现有问题的地方，参照原文。说明中部分内容摘自维基百科。
    Paxos Made Simple 是因为最初的论文比较难懂，作者又写了这篇比较形象好懂的介绍。首先要明确的是 Paxos 算法，是为了解决分布式环境下一致性的问题而提出的算法。这里将牺牲一些严格性，采用比较好懂的具体例子对文章加以解读。

    注意：对这个说明进行理解的时候要先搞清这么一种思路：Paxos的目的是在分布式环境里解决一致性问题。文章先提出了两个约束(条件)。只要保证这两个约束就保证了问题解的正确性。但是, 因为开始的约束很难实现，于是对约束进行加强(满足了加强后的约束就一定满足原来的约束。比如, 我对自己提一个约束:明天的约会对象必须是个人，然后对这个约束做了一次加强，加强成明天的约会对象必须是个女人. 那么只要后一个得到满足, 则加强前的一个一定得到满足.)，最终找到一些更强的约束, 而这些约束可以实现,  于是也就找到了实现最初约束的办法. 下面按照这种思路, 我们来看看 Paxos Made Simple 是怎么解决分布式环境一致性的问题的.

    原文提出的问题是在分布式环境下如何选择一个值。我把这个问题形象化成一个更实际的问题，如何确定一把锁的归属。假设一个场景，一个唯一资源被一把锁保护着，现在又很多分布在不同主机上的进程开始争用这把锁。不妨让争用锁的进程分别是S1，S2，S3……。 锁名称L1. 那么回归到原文的例子上，就是对变量L1选择一个值，可能值为(S1,S2,S3….). 当然，最简单的办法是用一个单一进程来做为server，S1, S2, S3 …..向其申请锁，谁先到归谁。这样的结果是，系统产生了一个单点。如果这个唯一的server宕机, 则整个系统不可用. 为了提高其可用性, 我们考虑用一个小集群来代替这个唯一的server. 这个小集群有下面的特点：其中任何一台机器可能失效，但是这台机器恢复回来的时候，应该是有记忆的，就是说，能找到其失效前的一些必要数据。
    在介绍算法的过程中, 我们会遇到几种角色, 先来看我们马上要接触的两种，提案者和批准人。提案者是提出议案的，批准人进行批准。注意，本文只介绍这两者之间的交互关系，不介绍 其他角色的参与(learners)。角色代表了一定的权利和义务, 就是说能干什么以及必须干什么, 一个进程是可以身兼多种角色的。
    现在我们暂时先把那个替代唯一server的小集群看成一批批准人, 并且假设这个集群有5个节点, 也就是有5个批准人（A1-A5）。S系列的进程是提案者, 他们希望的提案就是自己占有锁资源。比如S1的提案是L1 = S1。 S2的提案是 L1 = S2 …… 。实际上就是大家都想获得锁资源. 锁只有一把, 显然，只有一个提案可以获得通过，那么5个批准人的集群如何确定那个提案获得通过呢？简单来说，少数服从多数。就是获得超过半数批准人支持的提案获胜。显然, 当每个批准人只能批准一个提案的时候, 不肯能出现两个都获得超过半数批准的提案. 我们称超过半数的一群批准者为一个多数派。所以只要我们约定，一个批准者只能批准一个提案, 只有获得多数派批准的提案才生效。有了这两个约定, 那么生效的提案一定是唯一的. 也就是说L1的取值唯一。当然, 如果只有一个提案者做出了提案, 则提案应该被接受。就是说，S系列进程只有一个进程要求得到锁资源，这个要求应该被满足。我们提出如下要求：
    P1 一个批准者必须接受他收到的第一个提案。
    这一个简单的要求能解决上面的问题吗? 显然不能. 当几个S进程一起要求锁的时候，可能每个批准者批准了一个。从而无法形成多数派。即便只有两个S进程提出锁要求，假设我们的5人集团当掉一个，剩下四个有两个同意S1，有两个同意S2，还是形不成多数派。为了解决此问题, 我们允许一个批准者可以批准超过一个的提案。可是如此一来，就会有多个提案获得多数派的批准了啊, 所以还要有限制, 为了方便，让我们把每个提案者提出的提案进行编号。每个提案者的编号不同，而且编号是偏序的(做到这一点很容易, 比如提案的时候, 把提案号带上主机的ip等)。在我们的例子里，就先用机器名加变量名S1_L1，S2_L1来作为提案的编号。当多数派批准一个提案比如S1_L1（提案S1_L1在我们的例子中应该是L1 = S1）的时候，值被选定，提案被通过（注意“通过”这个词，后续中，对于经过多数派批准的生效的提案，我用“通过”这个词）。我们允许多个提案被通过，只要他们提案的值是一样的。比如S1_L1提案（S1_L1:L1=S1）被通过之后，如果机器S2提出提案S2_L1，要求把锁给S1（S2_L1:L1=S1）那么这个提案应该也被通过。当然我们的例子里，S2是不会这么干的。我们把这个规则表述成如下的形式
    P2 一个值为V的提案被通过了，那么编号比这个提案大的提案通过的条件是提案的值是V。
    因为一个提案被通过，那么至少要被一个批准者批准。所以我们可以对P2做加强。
    p2a 一个值为V的提案被通过了，那么编号比这个提案大的提案被批准的条件是提案的值是V。
    请注意p2和p2a的区别，别糊涂了。(区别是通过和批准这两个词, 说p2a是p2的加强是因为保证了p2a就保证p2。)
    注意，这里又有一个问题，假设S1_L1提案被A1,A2,A3批准，从而获得了通过。现在S2提出提案S2_L2，提给了A5.A5跟据P1的要求，应该批准该提案，但是这是违反p2a的。我们再对p2a做一次加强
    p2b 一个值为V的提案被通过了，那么编号比这个提案大的提案的值应该是V。

    想想为什么p2b是p2a的加强, 应该很容易想明白吧.
    只有被提出的提案才可能被批准，我们规定了提出的提案的值应该是V，自然保证了被批准以及被通过的值。所以保证了p2b 就一定保证了 p2a, 就一定保证了p2.那我们的例子来说，一旦L1的值被确定了，后续的提案其值只能遵循已经通过的值。
    p2b 是难以实现的。这里我们引入另一个约束
    p2c 提出一个编号为n具有值v的提案的前提是：存在一个多数派，要么他们中没有人批准过编号小于n的任何提案，要么他们批准的提案中编号小于n的最大的提案值是v。
  下面通过数学归纳法证明p2c蕴含了p2b：
    假设具有值 v 的提案 m 获得通过，当 n=m+1 时，根据 P2c，由于任何一个多数派中至少有一个批准了 m，因此提案n具有值 v；若 (m+1)..(n-1) 所有提案都具有值v，根据 P2c，若反设新提案 n 不具有值v 则存在一个多数派，他们没有批准过 m..(n-1) 中的任何提案。但是我们知道，他们中至少有一个人批准了 m。于是我们导出了矛盾，获得了证明。也就是说，只要满足p2c，那么p2b就得到满足。
    以上这么啰嗦的一堆，其实是证明了，只要保证了p2c，我们就保证了p2， 保证了p2， 则选出的值一定是唯一值。那么下面看如何设计算法保证p2c。
    保证p2c的关键问题，其实是要批准者做出不批准某种类型提案的承诺。所以：提案者提出一个提案前，首先要和足以形成多数派的批准者进行通信，获得他们进行的最近一次批准活动的编号，并且得到他们不批准比当前提案编号小的提案的承诺（prepare 过程），之后根据回收的信息决定这次提案的 value，形成提案开始投票。当获得多数批准者批准后，提案获得通过。这个简略的过程经过进一步细化后就形成了 Paxos 算法。
    如果一个批准者在 prepare 过程中回答了一个编号为n的提案，但是在开始对 n 进行投票前，又批准另一个提案编号小于n的提案，如果两个提案具有不同的 value，这个批准就会违背 P2c。因此在 prepare 过程中，批准者对于”不再批准编号小于 n 的提案”的承诺是保证算法正确的基础。所以又有一个对 P1 的加强：

     P1a：当且仅当批准者没有收到编号大于 n 的提案请求时，批准者批准编号为 n 的提案。

现在已经可以提出完整的算法了。


通过一个决议分为两个阶段：

prepare 阶段：
提案者选择一个提案编号 n 并将 prepare 请求发送给批准者中的一个多数派；
批准者收到 prepare 消息后，如果提案的编号大于它已经回复的所有 prepare 消息，则批准者将自己上次的批准回复给提案者，并承诺不再批准小于 n 的提案；
批准阶段：
当一个提案者收到了多数批准者对 prepare 的回复后，就进入批准阶段。它要向回复 prepare 请求的批准者发送批准的请求，包括编号 n 和根据 P2c 决定的 value（如果根据 P2c 没有决定 value，那么它可以自由决定 value）。
在不违背自己向其他提案者的承诺的前提下，批准者收到批准请求后即批准这个请求。
    这个过程在任何时候中断都可以保证正确性。

    这个算法的正确性和完备性就是上面的证明。但是为了便于理解，我们可以用我们上面的例子来描述一个决议过程。这个描述仅仅是便于大家理解。描述中有一些在实际算法上不合适的地方，这里不考虑。

    批准者是A1-A5.申请者是S系列。提案是决定L1的取值。

    首先S2提出编号是0001S2的提案, 内容是L1=S2.我们采用 提案者:编号[值]这种记录方式记做 S2:0001S2[S2]。它要先进行prepare阶段，于是向A1，A2，A3，A4发送了请求。

    同时S1提出S1:0001S1[S1]，发给A1-A5.进行prepare。

    我们来看这5个A的回复：我们用 批准者[收到的提案：给出的回复]这个格式来描述一下A系列的行为。回复有三种1 ok表示做出承诺 （没有做出批准的时候）2 null表示没有给回复（提案编号比承诺过的编号小）3value表示做出承诺，同时给出value（已经做出过批准的时候）

     A1[0001S1:ok] [0001S2:ok]  A1先接到s1的prepare请求，做出了承诺，又接到s2的请求，做出了承诺 现在A1的承诺是不批准<0001S2 A1要记住他的承诺和值 记做 A1-(0001S2,null)

     A3[0001S2:ok] [0001S1:null]  A3-(0001S2,null)

     A2[0001S1:ok]                     A2-(0001S1,null)

     A5[0001S1:ok]                     A5-(0001S1,null)

    注意，到此时，S1已经收到了一个多数派的回复(A1,A2,A5) A3因为违反承诺，没有给S1回复。这时S1开始批准阶段的请求,其中提案的值是S1（因为prepare阶段没有批准者返回值）。请求顺序是A5，A4，A3，A2，A1（A3虽然没有给回复，但是是可以向它发批准请求的。算法优化的问题现在不讨论，只讲正确性）。那么这个时候的回复应该是什么样呢？

    A5[0001S1:ok] A5要记住当前的提案编号是0001S1 value是S1。记做 A5-(0001S1，S1)

    A4 我们假设A4由于网络原因，没有收到prepare阶段的请求，直接受到了批准阶段请求。按照规则，他应该做出批准，并且记住状态

    A4[0001S1:ok]       A4-(0001S1，S1)

    A3 已经做出承诺不能批准所以不回复

    A3[0001S1:null]     A3-(0001S2,null)

    A2[0001S1:ok]      A2-(0001S1,S1)

   已经达到多数派，提案通过，A1其实不会给出回复。不过没关系了。现在我们再看后来的提议者S2. S2向A1，A2，A3，A4发出请求，到目前为止，只有A1,A3收到了请求。我们继续推演后续的A收到请求的反应。

    假设现在A4收到请求 考虑A4的状态A4-(0001S1，S1)  因为新的提议编号更大，所以A4要回复给S2提议的值,状态不变

    A4[0001S2:S1]      A4-(0001S1，S1)

    A2[0001S2:S1]      A2-(0001S1，S1)

    这个时候S2妄图提出值为S2的提案的企图没能得到多数派的同意，不会进入批准阶段了。

————————————————————————–

    这个例子只是形象的看了一下算法是如何工作的。实际算法的正确性和完备性是上面的证明过程。这种举例只是为了帮助形象化理解，有兴趣的同学可以自己再推演一下其他情况，比如S2胜出，比如S1在得到多数派prepare ok后 只向两个A发出了批准请求然后挂掉等情况。

    真正在做算法实现的时候还是有一些注意的事情的，比如我们假设一个比较极端的情况，S1在prepare时候向A1-A5发申请，都得到了回复。然后S2也发了一遍申请，当然也都得到回复，这个时候S1发出提案，实际上是得不到回复的。现在假设S2突然挂掉。那么对于我们的例子，没人得到锁。如果是用来选master，到现在还没人是master。这个时候S1应该再做一次提案采用更大的一个编号（这就是为什么我的例子中，提案编号前面是几位的序号）。但是这样实现，又面临着S1，S2交替增大编号，谁也得不到批准的问题。这些问题都是需要注意的（实现的时候足够注意就可以解决）。这些不属于本文讨论内容，这里只是提醒一下。

 

算法
This entry was posted by 道安 on 2010年05月31日 at 17:45, and is filed under 算法. Follow any responses to this post through RSS 2.0. You can leave a response or trackback from your own site.
12 comments

learning (955 天)
想请教楼主一个问题：在fast paxos算法中，首先选出一个leader，然后由leader提案。我想不通的是选leader本身就是一个一致性问题，难道是先用其他一致性算法选出一个leader再进行paxos算法？

 
X (813 天)

learning:

想请教楼主一个问题：在fast paxos算法中，首先选出一个leader，然后由leader提案。我想不通的是选leader本身就是一个一致性问题，难道是先用其他一致性算法选出一个leader再进行paxos算法？

用“slow” paxos算法选出leader不就行了

 
ggzwtj (792 天)
leader已经是一致的了，那用leader直接选出value是不是就不存在不一致问题了？

我爱英格兰 » Paxos算法的一些理解细节 (740 天)
[...] 容易造成混淆, 增加了对核心思想的理解难度. 这篇写得挺不错, 但是读完还是没有完全理解. 后来读了原始论文Paxos Made [...]

Reply ↓

Carson (542 天)
建议看Wiki吧～～～这里解释得更复杂

 
BLueaerodone (541 天)
写的已经很清晰了，学习了～

 
long (466 天)
批准和通过的意思，与wiki上是相反的

 
dutianmin (459 天)
不懂装懂，乱抄袭！误导人！

 
Anson (275 天)
这个是我看到过介绍 paxos 算法最贴近实战的文章，顶！

 
袁璞 (226 天)
贴近实战，非常好！

 
萧筱亮 (175 天)
关于选取leader问题，leader怎么选？由于消息传递的不确定性，可能有多个 proposer 自认为自己已经成为 leader？

 
elmar (91 天)
每个成员的提案编号是怎么维护的？比如P1要提出一个提案，那他怎么确定自己的提案编号？是自己上次提出的提案号？上次自己接受的提案号？还是上次自己收到的提案号？

发表评论
电子邮件地址不会被公开。 必填项已用 * 标注

姓名 * 

电子邮件 * 

站点

评论

您可以使用这些 HTML 标签和属性： <a href="" title=""> <abbr title=""> <acronym title=""> <b> <blockquote cite=""> <cite> <code> <del datetime=""> <em> <i> <q cite=""> <strike> <strong>


标签
beanstalkd BugFix cache CDN CPU epoll flashcache gdb http InnoDB kvm L1 Linux memcached mysql OceanBase overview pstack qemu redis Sheepdog smp ssd systemtap Tair tcp TFS traffic server unix 主从同步 事务 代理 分布式架构 分析 多线程 夸父 对象 开发模式 开源 指南 算法 管理员 缓存 网络 虚拟化
分类目录
BugFix
Cassandra
CDN
Dynamo
hypertable
JVM
Linux开发
mysql
OceanBase
Performance
Tair
Tengine
TFS
优化
分布式架构
底层架构
开发模式
数据库
未分类
算法
功能
登录
文章 RSS
评论 RSS
WordPress.org
成员个人博客
丁奇个人博客
三百个人博客
伯松个人博客
千石个人博客
华庭个人博客
叔度个人博客
坤谷个人博客
撒迦个人博客
日照个人博客
李子个人博客
正祥个人博客
永攀个人博客
茂七个人博客
褚霸个人博客
雕梁个人博客
淘宝其他官方博客
淘宝DBA
淘宝JAVA中间件
淘宝UED
淘宝招聘
淘宝搜索技术博客
淘宝数据平台
淘宝质量保障
淘宝核心系统团队博客 © 2010 | Powered by WordPress and Mystique theme by digitalnature 
22 queries in 0.27 seconds (23.71M)
========== http://rdc.taobao.com/blog/cs/?p=162 ==========
淘宝核心系统团队博客
基础 极致 分享
HOME
招聘信息
淘宝核心系统团队介绍
« 夸父驱动造成内核panic的解决手记Cassandra测试结果 »
paxos 实现
本文主要介绍zookeeper中zookeeper Server leader的选举，zookeeper在选举leader的时候采用了paxos算法(主要是fast paxos)，这里主要介绍其中两种：LeaderElection 和FastLeaderElection.

我们先要清楚以下几点
一个Server是如何知道其它的Server

在zookeeper中,一个zookeeper集群有多少个Server是固定，每个Server用于选举的IP和PORT都在配置文件中

除了IP和PORT能标识一个Server外，还有没有别的方法
每一个Server都有一个数字编号，而且是唯一的，我们根据配置文件中的配置来对每一个Server进行编号，这一步在部署时需要人工去做，需要在存储数据文件的目录中创建一个文件叫myid的文件，并写入自己的编号,这个编号在处理我提交的value相同很有用

成为Leader的必要条件
获得n/2 + 1个Server同意(这里意思是n/2 + 1个Server要同意拥有zxid是所有Server最大的哪个Server)

zookeeper中选举采用UDP还是TCP
zookeeper中选举主要是采用UDP，也一种实现是采用TCP，在这里介绍的两种实现采用的是UDP

zookeeper中有哪几种状态
LOOKING 初始化状态

LEADING  领导者状态

FOLLOWING  跟随者状态

如果所有zxid都相同(例如: 刚初始化时),此时有可能不能形成n/2+1个Server，怎么办
zookeeper中每一个Server都有一个ID,这个ID是不重复的，而且按大小排序，如果遇到这样的情况时，zookeeper就推荐ID最大的哪个Server作为Leader

zookeeper中Leader怎么知道Fllower还存活，Fllower怎么知道Leader还存活
Leader定时向Fllower发ping消息，Fllower定时向Leader发ping消息，当发现Leader无法ping通时，就改变自己的状态(LOOKING)，发起新的一轮选举

名词解释
zookeeer Server： zookeeper中一个Server,以下简称Server

zxid(zookeeper transtion id)： zookeeper 事务id，他是选举过程中能否成为leader的关键因素，它决定当前Server要将自己这一票投给谁(也就是我在选举过程中的value,这只是其中一个,还有id)

myid/id(zookeeper server id)： zookeeper server id ，他也是能否成为leader的一个因素

epoch/logicalclock：他主要用于描述leader是否已经改变,每一个Server中启动都会有一个epoch,初始值为0,当 开始新的一次选举时epoch加1,选举完成时 epoch加1。

tag/sequencer：消息编号

xid：随机生成的一个数字，跟epoch功能相同

Fast Paxos消息流向图与Basic Paxos的对比
消息流向图
basic paxos 消息流向图
Client   Proposer      Acceptor     Learner
   |         |          |  |  |       |  |
   X-------->|          |  |  |       |  |  Request
   |         X--------->|->|->|       |  |  Prepare(N)//向所有Server提议
   |         |<---------X--X--X       |  |  Promise(N,{Va,Vb,Vc})//向提议人回复是否接受提议(如果不接受回到上一步)
   |         X--------->|->|->|       |  |  Accept!(N,Vn)//向所有人发送接受提议消息
   |         |<---------X--X--X------>|->|  Accepted(N,Vn)//向提议人回复自己已经接受提议)
   |<---------------------------------X--X  Response
   |         |          |  |  |       |  |
fast paxos消息流向图
没有冲突的选举过程

Client    Leader         Acceptor      Learner
   |         |          |  |  |  |       |  |
   |         X--------->|->|->|->|       |  |  Any(N,I,Recovery)
   |         |          |  |  |  |       |  |
   X------------------->|->|->|->|       |  |  Accept!(N,I,W)//向所有Server提议，所有Server收到消息后，接受提议
   |         |<---------X--X--X--X------>|->|  Accepted(N,I,W)//向提议人发送接受提议的消息
   |<------------------------------------X--X  Response(W)
   |         |          |  |  |  |       |  |
第一种实现: LeaderElection
LeaderElection是Fast paxos最简单的一种实现，每个Server启动以后都询问其它的Server它要投票给谁，收到所有Server回复以后，就计算出zxid最大的哪个Server，并将这个Server相关信息设置成下一次要投票的Server



每个Server都有一个response线程和选举线程,我们先看一下每个线程是做一些什么事情

response线程
它主要功能是被动的接受对方法的请求，并根据当前自己的状态作出相应的回复，每次回复都有自己的Id，以及xid，我们根据他的状态来看一看他都回复了哪些内容

LOOKING状态：

自己要推荐的Server相关信息(id,zxid)

LEADING状态

myid,上一次推荐的Server的id

FLLOWING状态:

当前Leader的id，以及上一次处理的事务ID(zxid)

选举线程
选举线程由当前Server发起选举的线程担任，他主要的功能对投票结果进行统计，并选出推荐的Server。选举线程首先向所有Server发起一次询问(包括自己)，被询问方，根据自己当前的状态作相应的回复，选举线程收到回复后，验证是否是自己发起的询问(验证 xid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些 信息存储到当次选举的投票记录表中，当向所有Server都询问完以后，对统计结果进行筛选并进行统计，计算出当次询问后获胜的是哪一个 Server，并将当前zxid最大的Server设置为当前Server要推荐的Server(有可能是自己，也有可以是其它的Server，根据投票 结果而定，但是每一个Server在第一次投票时都会投自己)，如果此时获胜的Server获得n/2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态。每一个Server都重复以上流程，直到选出 leader

了解每个线程的功能以后，我们来看一看选举过程

选举过程中，Server的加入
当一个Server启动时它都会发起一次选举，此时由选举线程发起相关流程，那么每个Server都会获得当前zxid最大的哪个Server是谁，如果当次最大的Server没有获得n/2+1个票数，那么下一次投票时，他将向zxid最大的Server投票，重复以上流程，最后一定能选举出一个Leader

选举过程中，Server的退出
只要保证n/2+1个Server存活就没有任何问题，如果少于n/2+1个Server存活就没办法选出Leader

选举过程中，Leader死亡
当选举出Leader以后，此时每个Server应该是什么状态(FLLOWING)都已经确定，此时由于Leader已经死亡我们就不管它，其它的Fllower按正常的流程继续下去，当完成这个流程以后，所有的Fllower都会向Leader发送Ping消息，如果无法ping通，就改变自己的状态为(FLLOWING ==> LOOKING)，发起新的一轮选举

选举完成以后，Leader死亡
这个过程的处理跟选举过程中Leader死亡处理方式一样，这里就不再描述

第二种实现: FastLeaderElection
fastLeaderElection是标准的fast paxos的实现，它首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息

数据结构
本地消息结构：

static public class Notification {
long leader;  //所推荐的Server id

long zxid;      //所推荐的Server的zxid(zookeeper transtion id)

long epoch;   //描述leader是否变化(每一个Server启动时都有一个logicalclock，初始值为0)

QuorumPeer.ServerState state;   //发送者当前的状态
InetSocketAddress addr;            //发送者的ip地址
}

网络消息结构：

static public class ToSend {

int type;        //消息类型
long leader;  //Server id
long zxid;     //Server的zxid
long epoch;  //Server的epoch
QuorumPeer.ServerState state; //Server的state
long tag;      //消息编号

InetSocketAddress addr;

}

Server具体的实现
每个Server都一个接收线程池(3个线程)和一个发送线程池 (3个线程),在没有发起选举时，这两个线程池处于阻塞状态，直到有消息到来时才解除阻塞并处理消息，同时每个Server都有一个选举线程(可以发起 选举的线程担任)；我们先看一下每个线程所做的事情，如下：

被动接收消息端(接收线程池)的处理:

notification： 首先检测当前Server上所被推荐的zxid,epoch是否合法(currentServer.epoch <= currentMsg.epoch && (currentMsg.zxid > currentServer.zxid || (currentMsg.zxid == currentServer.zxid && currentMsg.id > currentServer.id))) 如果不合法就用消息中的zxid,epoch,id更新当前Server所被推荐的值，此时将收到的消息转换成Notification消息放入接收队列中，将向对方发送ack消息

ack:   将消息编号放入ack队列中，检测对方的状态是否是LOOKING状态，如果不是说明此时已经有Leader已经被选出来，将接收到的消息转发成Notification消息放入接收对队列

主动发送消息端(发送线程池)的处理:

notification: 将要发送的消息由Notification消息转换成ToSend消息，然后发送对方，并等待对方的回复,如果在等待结束没有收到对方法回复，重做三次,如果重做次还是没有收到对方的回复时检测当前的选举(epoch)是否已经改变，如果没有改变，将消息再次放入发送队列中，一直重复直到有Leader选出或者收到对方回复为止

ack: 主要将自己相关信息发送给对方

主动发起选举端(选举线程)的处理:

首先自己的epoch 加1，然后生成notification消息,并将消息放入发送队列中，系统中配置有几个Server就生成几条消息，保证每个Server都能收到此消息,如果当前Server的状态是LOOKING就一直循环检查接收队列是否有消息，如果有消息，根据消息中对方的状态进行相应的处理。

LOOKING状态:

首先检测消息中epoch是否合法，是否比当前Server的大,如果比较当前Server的epoch大时，更新epoch，检测是消息中的zxid,id是否比当前推荐的Server大，如果是更新相关值，并新生成notification消息放入发关队列，清空投票统计表； 如果消息小的epoch则什么也不做； 如果相同检测消息中zxid,id是否合法,如果消息中的zxid，id大，那么更新当前Server相关信息，并新生成notification消息放入发送队列，将收到的消息的IP和投票结果放入统计表中，并计算统计结果，根据结果设置自己相应的状态

LEADING状态:

将收到的消息的IP和投票结果放入统计表中(这里的统计表是独立的)，并计算统计结果，根据结果设置自己相应的状态

FOLLOWING状态:

将收到的消息的IP和投票结果放入统计表中(这里的统计表是独立的)，并计算统计结果，根据结果设置自己相应的状态

了解每个线程的功能以后，我们来看一看选举过程,选举过程跟第一程一样

选举过程中，Server的加入
当一个Server启动时它都会发起一次选举，此时由选举线程发起相关流程，通过将自己的zxid和epoch告诉其它Server，最后每个Server都会得zxid值最大的哪个Server的相关信息，并且在下一次投票时就投zxid值最大的哪个Server，重复以上流程，最后一定能选举出一个Leader

选举过程中，Server的退出
只要保证n/2+1个Server存活就没有任何问题，如果少于n/2+1个Server存活就没办法选出Leader

选举过程中，Leader死亡
当选举出Leader以后，此时每个Server应该是什么状态 (FLLOWING)都已经确定，此时由于Leader已经死亡我们就不管它，其它的Fllower按正常的流程继续下去，当完成这个流程以后，所有的 Fllower都会向Leader发送Ping消息，如果无法ping通，就改变自己的状态为(FLLOWING ==> LOOKING)，发起新的一轮选举

选举完成以后，Leader死亡
这个过程的处理跟选举过 程中Leader死亡处理方式一样，这里就不再描述

算法
This entry was posted by 段飞 on 2010年06月2日 at 17:31, and is filed under 算法. Follow any responses to this post through RSS 2.0. You can leave a response or trackback from your own site.
29 comments

aoxiang_bin (1212 天)
很赞！有时间看看。o(∩_∩)o

Zookeeper全解析——Paxos的灵魂 | Trend Micro CDC SPN Team (1149 天)
[...] 又一个问题产生了，总统怎么选出来的？oh, my god! It’s a long story. 在淘宝核心系统团队的Blog上面有一篇文章是介绍如何选出总统的，有兴趣的可以去看看：http://rdc.taobao.com/blog/cs/?p=162 [...]

Reply ↓

昆仑 (1004 天)
在研究代码时发现了这篇文章,写的很到位,已经在自己的文章中引用了这篇文章,赞下

Zookeeper研究和应用 « 大象|森林 (1003 天)
[...] 介绍完了Paoxs算法, 分布式选举几乎是顺理成章的, 因为分布式选举不过是Paoxs算法的一次或者若干次执行, 所不同的只是proposal内容为:”谁是Leader”.下面这两个图解释了zookeeper集群在正常工作和选举时各个节点状态的异同: zookeeper采用org.apache.zookeeper.server.quorum.FastLeaderElection作为其缺省选举算法,关于这个算法的具体执行流程可以参考淘宝核心系统段飞同学的文章“paxos 实现”.或者也可以直接阅读源代码. zookeeper源代码量不大,结构清晰,注释充分,阅读体验超好~ 我就不在这里越俎代庖了. [...]

Reply ↓
Zookeeper研究和应用 - webguo的科技博客 (990 天)
[...] Zookeeper研究和应用 January 18th, 2011 发表评论 阅读评论 zookeeper简介zookeeper是一个开源分布式的服务,它提供了分布式协作,分布式同步,配置管理等功能. 其实现的功能与google的chubby基本一致.zookeeper的官方网站已经写了一篇非常经典的概述性文章,请大家参阅:ZooKeeper: A Distributed Coordination Service for Distributed Applications在此我仅花少量笔墨介绍下本文相关的内容。在zookeeper的集群中，各个节点共有下面3种角色和4种状态：角色：leader,follower,observer状态：leading,following,observing,looking除了observer和observing之外,其它的角色和状态与下面将要介绍的Paoxs算法中的角色与状态一一对应,我们将在下文中具体描述.observer是zookeeper-3.3版本新添加的一个角色,在这里有相关的介绍. 他们的引入是为了解决zookeeper集群扩大后,由于网络可靠性下降可能导致的拜占庭将军问题. observer的行为在大多数情况下与follower完全一致, 但是他们不参加选举和投票, 而仅仅接受(observing)选举和投票的结果.zookeeper实现了一个层次名字空间(hierarchal name space)的数据模型, 它特别象一个文件系统, 每个文件被称为znode, 一个znode除了自己包含一些数据外,还能拥有孩子节点.存在下述的3种类型znode:Persistent Nodes: 永久有效地节点,除非client显式的删除,否则一直存在Ephemeral Nodes: 临时节点,仅在创建该节点client保持连接期间有效,一旦连接丢失,zookeeper会自动删除该节点Sequence Nodes: 顺序节点,client申请创建该节点时,zk会自动在节点路径末尾添加递增序号,这种类型是实现分布式锁,分布式queue等特殊功能的关键Zookeeper Watch 定义如下:A watch event is one-time trigger, sent to the client that set the watch, which occurs when the data for which the watch was set changes.在我看来,watch可以理解为一个分布式的回调,当client关心的znodes发生变化时,zookeeper将会把消息传回到client,并导致client的消息处理函数得到调用.zk的任何一个读操作都能够设置watch,例如:getData(), getChildren(),and exists()可以watch的event包括如下的二种:KeeperState:Disconnected,SyncConnected,ExpiredEventType:None,NodeCreated,NodeDeleted,NodeDataChanged,NodeChildrenChanged这些状态是很容易理解的. watch的实现只言片语没法说清楚,后面我可能会专门写一篇文章讲述这个实现.Paoxs算法说到zookeeper,我们不得不提起Paoxs算法和Lesile Lamport.Paoxs算法是zookeeper的灵魂,这个算法是Leslie Lamport在1990年提出的一种基于消息传递的一致性算法.Paxos 算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。一个典型的场景就是:”在zookeeper cluster中谁是leader?”。该算法由Leslie于1990年在文章The Part-Time Parliament中首次提出,但是这篇文章相当的晦涩难懂(也有一些轶事,可以看文章链接中Leslie自己写的内容),于是,Lesilie在2001年写下了Paxos Made Simple.他对此解释道:At the PODC 2001 conference, I got tired of everyone saying how difficult it was to understand the Paxos algorithm, published in [122]. Although people got so hung up in the pseudo-Greek names that they found the paper hard to understand, the algorithm itself is very simple. So, I cornered a couple of people at the conference and explained the algorithm to them orally, with no paper. When I got home, I wrote down the explanation as a short note, which I later revised based on comments from Fred Schneider and Butler Lampson. The current version is 13 pages long, and contains no formula more complicated than n1 > n2.Paxos Made Simple的abstract只有一句话:The Paxos algorithm, when presented in plain English, is very simple.可见这位Lamport老兄是多么的有意思. 顺便说一句,这位老哥就是LaTex中的”La”.在上文中是这样描述Paoxs算法执行过程的:Phase 1.(a) A proposer selects a proposal number n and sends a prepare request with number n to a majority of acceptors.(b) If an acceptor receives a prepare request with number n greater than that of any prepare request to which it has already responded, then it responds to the request with a promise not to accept any more proposals numbered less than n and with the highest-numbered proposal (if any) that it has accepted.Phase 2.(a) If the proposer receives a response to its prepare requests (numbered n) from a majority of acceptors, then it sends an accept request to each of those acceptors for a proposal numbered n with a value v, where v is the value of the highest-numbered proposal among the responses, or is any value if the responses reported no proposals.(b) If an acceptor receives an accept request for a proposal numbered n, it accepts the proposal unless it has already responded to a prepare request having a number greater than n.这几乎就是Paxos的全部了.具体的执行过程举例可以在Zookeeper全解析——Paxos作为灵魂中找到,在此不再赘述.Zookeeper完全实现了Paoxs算法,zk cluster中每个节点都保持了一份完整的数据模型,当任何一个client通过某集群节点向集群发起读写请求时,该节点会向Leader节点发出投票请求,如果投票通过(超过一半节点同意)则该请求被执行,否则该请求被驳回. 通过paoxs算法,zookeeper的保持了数据模型的一致性,同时保持了任何操作的原子性.分布式选举介绍完了Paoxs算法, 分布式选举几乎是顺理成章的, 因为分布式选举不过是Paoxs算法的一次或者若干次执行, 所不同的只是proposal内容为:”谁是Leader”.下面这两个图解释了zookeeper集群在正常工作和选举时各个节点状态的异同:zookeeper状态示意图zookeeper采用org.apache.zookeeper.server.quorum.FastLeaderElection作为其缺省选举算法,关于这个算法的具体执行流程可以参考淘宝核心系统段飞同学的文章“paxos 实现”.或者也可以直接阅读源代码. zookeeper源代码量不大,结构清晰,注释充分,阅读体验超好~ 我就不在这里越俎代庖了.zookeeper应用拥有了zookeeper如此强大的分布式协作系统后,我们可以很容易的实现大量的分布式应用,包括了分布式锁,分布式队列,分布式Barrier,双阶段提交等等. 这些应用可以帮我们改进很多复杂系统的协作方式,将这些系统的实现变得更加优雅而高效.鉴于篇幅,本文仅介绍分布式锁的实现.利用了前文提到的sequence nodes可以非常容易的实现分布式锁. 实现分布式锁的基本步骤如下(这些步骤需要在所有需要锁的客户端执行):client调用create()创建名为”_locknode_/lock-”的节点,注意需要设置sequence和ephemeral属性client调用getChildren(“_locknode_”),注意不能设置watch,这样才能避免羊群效应如果步骤1中创建的节点序号最低,则该client获得锁,开始执行其它程序client对lock-xxx中序号仅次于自己创建节点的那个节点调用exists(),并设置watch如果exist()返回false(节点不存在)则回到步骤2,否则等待步骤4中的watch被触发并返回步骤2分布式锁在zookeeper的源代码中已经有实现,可以参考org.apache.zookeeper.recipes.lock下面是一个使用分布式锁的样例,这段程序摘自一个hadoop reduce的configure函数, 使用分布式锁的目的是确保一台机器上的所有reduce进程中,只有一个reduce进程会执行某些初始化代码. 同时其它reduce在总和初始化完成之前不会继续执行. class zkWatcher implements Watcher { //watch回调函数 public void process(WatchedEvent event) { if (event.getType() == EventType.NodeCreated) { if (event.getPath() == "balbalbal.init_done" //如果回调信息是节点创建,且创建的节点是init成功节点,则触发latch gcihInitLatch.countDown(); } else if (event.getState() == KeeperState.SyncConnected) { //server连接成功,触发连接成功latch zkConnectedLatch.countDown(); } } } public void configure(String conf) { try { //zookeeper服务器列表,节点间用,分隔 String keepers = "zk_server0:port,zk_server1:port,zk_server2:port"; String Init_Done = "/full-dump-gcih/" + InetAddress.getLocalHost().getHostName() + ".init_done"; String HostName = InetAddress.getLocalHost().getHostName(); // 初始化一个Watch zkWatcher zkw = new zkWatcher(); //异步创建连接, 并设置zkw为watch回调 ZooKeeper zk = new ZooKeeper(keepers, 5000, zkw); //等待zookeeper创建连接成功 zkConnectedLatch.await(); //创建分布式锁 WriteLock gcih_lock = new WriteLock(zk, "/full-dump-gcih/" + HostName, null); //检测初始化成功标识是否存在,并设置watch if (null == zk.exists(Init_Done, true)) { // if the init_done node not exists we try to init if (gcih_lock.lock()) { //获取锁成功,初始化数据 initializeData(conf); //创建初始化成功标识,注意这个标志是永久节点 zk.create(Init_Done, null, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); //工作完成,释放锁 gcih_lock.unlock(); } else { //未获取锁,说明已经有reduce在做初始化了,释放锁 gcih_lock.unlock(); if (!gcihInitLatch.await(30, TimeUnit.MINUTES)) throw new IOException( "Init UDP time out, critical error"); else { //latch成功返回,说明the one 初始化成功了 initializeData(null); } } } else {// if init_done exists we simply load data from gcih initializeData(null); } } catch (Exception e) { ….. } }多个reduce分别获取锁后,加锁节点的子节点信息如下所示[zk: localhost:2181(CONNECTED) 31] ls /full-dump-gcih/xxxxx.cm2[x-84692699318388014-0000000001, x-84692699318387993-0000000000]这些节点全部是Sequence+Ephemeral 属性的节点, 其中x-84692699318388014-000000000name-zk_session_id-sequence_number这个节点名称是org.apache.zookeeper.recipes.lock中使用的名称,可以根据需要自己重新实现相关代码,进而设计一个专用的锁.关于Zookeeper更多的应用请参阅ZooKeeper Recipes and Solutions 分类: 系统架构 标签: architecture  large-scale  相关文章 [...]

Reply ↓
Zookeeper研究和应用 « 搜索技术博客－淘宝 (984 天)
[...] zookeeper采用org.apache.zookeeper.server.quorum.FastLeaderElection作为其缺省选举算法,关于这个算法的具体执行流程可以参考淘宝核心系统段飞同学的文章“paxos 实现”.或者也可以直接阅读源代码. zookeeper源代码量不大,结构清晰,注释充分,阅读体验超好~ 我就不在这里越俎代庖了. [...]

Reply ↓

herry (954 天)
问题1：
xid：随机生成的一个数字，跟epoch功能相同
为什么需要xid和epoch才能确定leader是否发生了变化?
问题2：
当向所有Server都询问完以后，对统计结果进行筛选并进行统计，计算出当次询问后获胜的是哪一个 Server，并将当前zxid最大的Server设置为当前Server要推荐的Server(有可能是自己，也有可以是其它的Server，根据投票 结果而定，但是每一个Server在第一次投票时都会投自己)，如果此时获胜的Server获得n/2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态。每一个Server都重复以上流程，直到选出 leader

描述中zxid是如何生成的？
这里有点不太明白的是，是否获得n/2+1票数的Server一定是zxid最大的Server？另外最后一句，为什么每个Server都需要重复以上流程？

Zookeeper简介与安装 « 永无止境 (940 天)
[...] paxos 实现 [...]

Reply ↓

Roger (890 天)
博主,”第一种实现”中的”Response”线程中的”FOLLOWING状态”有错别字

 
Jacobs Wu (820 天)
调研代码受益于本文，感谢。我增加了FastLeaderElection分析和时序图，请参考我的博客：http://blog.sina.com.cn/u/1793692835

Zookeeper全解析——Paxos作为灵魂 | web开发 (798 天)
[...] 又一个问题产生了，总统怎么选出来的？oh, my god! It’s a long story. 在淘宝核心系统团队的Blog上面有一篇文章是介绍如何选出总统的，有兴趣的可以去看看：http://rdc.taobao.com/blog/cs/?p=162 [...]

Reply ↓

coffeeBearIT (767 天)
有个问题请教：fast paxos算法是有coordinator角色的，在fastLeaderElection本身就是选leader，这个coordinator的角色在代码中体现在哪里呢？
另外，一个关于paxos算法的问题，classic paxos用leader来防止活锁，但是到了fast paxos却允许proposer绕过leader直接提案，那么在fast paxos中活锁是怎么避免的呢？

 
holy (727 天)
配置了奇数个zk servers,但只有偶数个活的的zk servers,此时怎么选举出leader?

 
魏讲文 (704 天)
FastLeaderElection根本不是Paxos，也不是Fast Paxos的实现。
FastLeaderElection源码与Paxos的论文相去甚远。

Paxos与 FastPaxos算法中也有一个leader选举的问题。

FastLeaderElection对于zookeeper来讲，只是相当于Paxos中的leader选举。

如果我说的不清楚，欢迎发邮件到我的邮箱讨论！

webguo在路上 » Zookeeper研究和应用 (637 天)
[...] zookeeper采用org.apache.zookeeper.server.quorum.FastLeaderElection作为其缺省选举算法,关于这个算法的具体执行流程可以参考淘宝核心系统段飞同学的文章“paxos 实现”.或者也可以直接阅读源代码. zookeeper源代码量不大,结构清晰,注释充分,阅读体验超好~ 我就不在这里越俎代庖了. [...]

Reply ↓

sunday (599 天)
博主，你好，看了下选举代码，有个问题：totalOrderPredicate中self.getQuorumVerifier().getWeight(newId)这个判断是什么意思呢？

 
fding (535 天)
QuorumVerifier是用来即是验证“投票通过”的接口，目前zk中有两种verifier,即QuorumMaj和QuorumHierarchical, 其中QuorumHierarchical对服务器分组加权，以实现权值过半才能算通过，而不是QuorumMaj中的机器数过半算通过。
权值为0的节点是不能成为leader的。

Zookeeper全解析——Paxos作为灵魂 | 火牛●博 (523 天)
[...] 又一个问题产生了，总统怎么选出来的？oh, my god! It’s a long story. 在淘宝核心系统团队的Blog上面有一篇文章是介绍如何选出总统的，有兴趣的可以去看看：http://rdc.taobao.com/blog/cs/?p=162 [...]

Reply ↓

魏讲文 (473 天)
org.apache.zookeeper.server.quorum.FastLeaderElection 里面并不是Paxos算法。详细的论证请看：https://dl.dropbox.com/u/64148846/Thoughts%20On%20Zookeeper.pdf

 
pingyuyue (465 天)
关于：“ Fllower怎么知道Leader还存活 ?

回答：当发现Leader无法ping通时，就改变自己的状态(LOOKING)，发起新的一轮选举”

假如是这种情况呢，Leader还存活着，只是Fllower与Leader之间的通信出了问题，那么这个Fllower便发起选举？这样不太合适

另外，其它的Fllower 都还可以ping通 leader 是否他们就可以 不响应这次选举？

 
gavin (383 天)
博主： zookeeper中选举采用UDP还是TCP

zookeeper中选举主要是采用UDP，也一种实现是采用TCP，在这里介绍的两种实现采用的是UDP

对你的这个说法有疑问，你写的这个应该3.4以前的版本，现在3.4.3默认都是TCP了，

 
repls (382 天)
请教一个问题：在文章中你说“但是每一个Server在第一次投票时都会投自己”，那么当在第二次（包括第二次）以后的投票中，每一个Server是根据一个什么算法进行投票呢？也就是说用一个什么理由来决定我需要将这票投给你。
帮忙解答一下这个疑惑，谢谢

 
段飞 (381 天)
使用TCP还是UDP可以根据自己的需要进行配置

zookeeper election 选举 (373 天)
[...] 这块从：http://rdc.taobao.com/blog/cs/?p=162抄过来的： [...]

Reply ↓

Scott (248 天)
你的邮箱是多少？

 
scsldb (247 天)
发给你了

 
metaboy (247 天)
刚好正在弄Zookeeper,学习了….

» Zookeeper研究和应用 大象的森林 (163 天)
[...] zookeeper采用org.apache.zookeeper.server.quorum.FastLeaderElection作为其缺省选举算法,关于这个算法的具体执行流程可以参考淘宝核心系统段飞同学的文章“paxos 实现”.或者也可以直接阅读源代码. zookeeper源代码量不大,结构清晰,注释充分,阅读体验超好~ 我就不在这里越俎代庖了. [...]

Reply ↓
Zookeeper全解析——Paxos作为灵魂 | 奚学斌的园地 (153 天)
[...] 又一个问题产生了，总统怎么选出来的？oh, my god! It’s a long story. 在淘宝核心系统团队的Blog上面有一篇文章是介绍如何选出总统的，有兴趣的可以去看看：http://rdc.taobao.com/blog/cs/?p=162 [...]

Reply ↓
发表评论
电子邮件地址不会被公开。 必填项已用 * 标注

姓名 * 

电子邮件 * 

站点

评论

您可以使用这些 HTML 标签和属性： <a href="" title=""> <abbr title=""> <acronym title=""> <b> <blockquote cite=""> <cite> <code> <del datetime=""> <em> <i> <q cite=""> <strike> <strong>


标签
beanstalkd BugFix cache CDN CPU epoll flashcache gdb http InnoDB kvm L1 Linux memcached mysql OceanBase overview pstack qemu redis Sheepdog smp ssd systemtap Tair tcp TFS traffic server unix 主从同步 事务 代理 分布式架构 分析 多线程 夸父 对象 开发模式 开源 指南 算法 管理员 缓存 网络 虚拟化
分类目录
BugFix
Cassandra
CDN
Dynamo
hypertable
JVM
Linux开发
mysql
OceanBase
Performance
Tair
Tengine
TFS
优化
分布式架构
底层架构
开发模式
数据库
未分类
算法
功能
登录
文章 RSS
评论 RSS
WordPress.org
成员个人博客
丁奇个人博客
三百个人博客
伯松个人博客
千石个人博客
华庭个人博客
叔度个人博客
坤谷个人博客
撒迦个人博客
日照个人博客
李子个人博客
正祥个人博客
永攀个人博客
茂七个人博客
褚霸个人博客
雕梁个人博客
淘宝其他官方博客
淘宝DBA
淘宝JAVA中间件
淘宝UED
淘宝招聘
淘宝搜索技术博客
淘宝数据平台
淘宝质量保障
淘宝核心系统团队博客 © 2010 | Powered by WordPress and Mystique theme by digitalnature 
22 queries in 0.30 seconds (23.81M)
========== http://rdc.taobao.com/blog/cs/?p=261 ==========
淘宝核心系统团队博客
基础 极致 分享
HOME
招聘信息
淘宝核心系统团队介绍
« 使用sendfile淘宝开源平台正式上线 »
paxos算法介绍续
    有兄弟说上一篇关于 paxos 算法的文章不够清楚, 于是我从 fast paxos 这篇文章中, 把对 basic paxos的介绍的章节选择性翻译出来, 放到这里给大家做参考.

    下面的内容都集中关注于算法的有效性证明, 至于算法的具体实现, 优化等, 都不做介绍.
    所有的基本概念, 基本定义这里不再重复, 默认大家已经了解了算法的总体的目的, 主要的角色.
    括号中的内容是我加的一些解释, –基本都是多余的—, 其他的都可以在 fast paxos 这篇文章的 2.2 章节找到. 
 
    算法会执行很多个 round. 每个 round 都使用一个正整数进行编号. round 并不需要按照它们编号的次序去执行,  一个 round 不必须被完整的执行, round 可以被直接跳过, 不同的 round 可以同时并行的执行. 一个 round 可能选择一个 value.  一个 round 中, 一个 acceptor 可以投票给某个 value 或者不投票(不可以投票给不同的value).  
    
    为了达到一致性, 不能让两个不同的 value 被投票通过. 因为一个 round 里, 任何一个 acceptor 只能给一个 value 投票. 那么任何一个 round 中, 经过一个多数派批准的 value 一定是单一的, 不可能出现在一个 round 中, 两个不同的 value 都得到多数派的批准的情况. 但是一个 acceptor 在不同的 round 中可以投票给不同的 value, 所以保持一致性的关键在于在不同的 round 中, 要保证不会有不同的 value 被选出.
    每个 acceptor a 需要记住下面这些信息:
    rnd[a]  a 参与的所有 round 中编号最大的那个. 初始值为0。 0不是一个 round 的编号, 0表示没参与任何round
    vrnd[a] a 投过票的所有 round 中编号最大的那个 round, 初始值为0。 vrnd[a] <= rnd[a] 总是成立的.
    vval[a] a 在 vrnd[a] 这个 round 中, 投票批准的 value 值. 初始值, 也就是当 vrnd[a] = 0 时的值, 无意义.
    任何一个 round i 都具有一个被预先指派好的 coordinator(leader). coordinator 负责选出本 round 大家要投票的 value. coordinator c 需要保持以下信息:
    
    crnd c 启动的所有 round 里编号最大的那个, 初始值为0。
    
    cval c 在 round crnd 中, 所挑选的用于投票的 value. 如果 c 在 round crnd 中还没有挑选 value 则为 none. 初始值无意义.
    这里要求每个 round 中有一个事先指派好的 coordinator. 如何确定这个 coordinator 不在这里讨论, 有很多方式在绝大多数情况下可以很好的选出唯一的一个 coordinator. 而且即便选择 coordinator 的算法在特殊情况下失败, 导致系统中有不止一个 coordinator 确信自己是唯一的 coordinator, 也不影响下面描述的一致性算法的正确性.
    
    round i 按照下面的阶段进行, 其中 c 是本 round 的 coordinator.
    1  (a) 如果 crnd < i 则 c 设置 crnd 为 i, 从而开始 round i. 先把 cval 设置成 none, 然后给所有的 acceptor 发请求, 要求它们加入到 round i中来.
        (b) 如果一个 acceptor a 收到了要求加入 round i 的请求, 并且 i > rnd[a],  那么 a 把 rnd[a] 置成 i, 然后向 coordinator c 发送一个消息. 消息包含了 round 的编号 i, 以及 a 的两个当前值 vrnd[a] 和 vval[a].
             如果i <= rnd[a], 这说明, a 已经开始了 round i, 或者是开始了一个编号更高的 round. 那么 a 就简单的忽略该请求.
    2 (a) 当 c 收到1b 消息的时候, 因为消息中有 round 的编号, 不妨设为i, 如果 crnd = i, 那么说明 c 没有开始一个更高编号的 round. cval = none 说明 c 在本round 没有执行2a阶段的操作. 这个时候, 如果c 从一个 acceptor 的多数派中收到本 round 的1b 阶段的消息, c 可以根据一定的规则选择一个 value v, 设置 cval 为 v, 并且向所有的 acceptor 发请求, 要求它们在 round i 投票给 v.  选择 v 的规则后面详述.

       
       (b) 如果一个 acceptor a 收到了一个请求, 要求它在 round i 投票给 value v, 并且 i >= rnd[a] and vrnd[a] <> i; 那么 a 在 round i 投票给 v, 并且设置 vrnd[a] 和 rnd[a] 为 i, 设置 vval[a] 为 v, 然后发消息给所有的 learner, 宣布它的 round i 的投票结果.
            如果 i < rnd[a] 或者 vrnd[a] = i, 说明 a已经开始一个编号更高的round 或者在round i中 已经投过票了, 那么 a 忽略该请求.
    learner 如果在 round i 中, 收到acceptor 中一个多数派的 2b 消息, 都宣称它们已经投票给 value v, 那么 learner 可以确认 v 获得了通过.
    
    一个 coordinator 可以在任何时候开始一个新的 round 并且开始执行 1a 阶段的动作. 只要这个 round 的编号不低于它已经开始执行了的 round的编号. 不同的 round 可以同时执行, 但是, 一个 acceptor 如果收到了编号更高的 round 的消息, 它必须停止参与当前的 round. 阶段 2a 是允许在不同的round 里发送不同的 value 的. 但是在一个特定的 round 中, 不会出现不同的 value 被发送.
    算法的核心部分在于如何在阶段2a中挑选一个合适的value v. 为了保证一致性, 这个 v 应该有什么样的属性呢?
    
    CP. 对于任意 round i 和 j , j < i, 如果一个 value v 在round j 已经被批准通过, 或者有可能被批准通过, 那么, 在 round i, 没有 acceptor 可以批准 v 以外的值.
    CP.的一个等价的表述是: 对于任意的 round i 和 j , j < i, 如果一个 acceptor 在 round i 批准了 v, 那么在 round j 被批准通过, 或有可能在 round j 被批准通过的值只有v.
    
    我们前面已经说过, 在同一个 round 中, 不可能有两个不同的 value 被批准通过(因为批准通过需要一个多数派, 按照我们的规则, 不可能有两个不同的 value 在同一个 round 中都得到了多数派的批准), 而 CP 实际上保证了在不同的 round 中, 不会有不同的 value 被批准通过. 所以 CP 保证了一致性.
    算法只有保持属性 CP 就能保证一致性, 因为 round i 中的 v 是 coordinator 在阶段 2a 中挑选出来的， 所以我们只需要确定 v 满足如下的属性：
        CP(v,i)  对于任何的 round j, 其中 j < i. 除了 v , 其他的 value 都不可能被批准通过.
    先看在 round j 中 v 被批准通过或者有可能被批准通过的条件. 当且仅当, 存在一个多数派Q, Q 中的每一个 acceptor 要么在 round j 中投票给了 v, 要么在 round j 中还没有投票. 我们注意到, 一个 acceptor a从来不会减小 rnd[a] 的值, 并且, 在 round j 中, 如果 j < rnd[a] 它就会忽略 round j的投票请求, 所以我们有:
    Observation 1  一个 value v 在 round j 被批准通过, 或者可能被批准通过的条件是, 有一个多数派Q, 其中 Q 中的每一个 acceptor a, 要么在 round j 投票给 v, 要么满足 rnd[a] <= j(还没有在round j 投票).
    因为任何两个多数派, 最少有一个公共成员, 所以 observation 1 暗示了下面两个 observation.
    observation 2 如果有一个多数派 Q, 其中 Q 中的每一个 acceptor a 满足rnd[a] > j 并且, 在round j 没有投票, 那么 round j 不可能批准任何值.

    observation 3 如果存在一个多数派Q和一个 value v, Q 中的每一个 acceptor a 满足 rnd[a] > j, 并且 a 要么在 round j 投票给 v, 要么在 round j没投票. 那么round j不可能批准除 v 之外的任何 value.
    
    假设 coordinator 从一个多数派Q收到了 round i的阶段1b的消息. 因为一个acceptor a 在发送了1b消息的时候会设置 rnd[a] 为 i, 并且 acceptor 从来不会减低rnd[a] 的值, 所以对于Q中的所有 acceptor 来说, 均满足 rnd[a] >= i. 用 vr(a) 和 vv(a) 来表示 acceptor 在消息 1b 中汇报的值 vrnd[a] 和 vval[a]. 让k取得Q中vr(a)的最大值, 我们考虑两种情况:
    
    K1 k=0
    K2 k>0
    在情形K1， 因为Q中的每个 acceptor a, 都有vrnd[a] = 0, 所以对于任何 round j, j < i, Q中的acceptor 都没有投票批准任何的 value. 根据 observation 2， 我们知道在任何 round j, j<i, 不可能有任何的value被批准, 或者有可能被批准. 这种情况下, coordinator 选择任何vaule v, 都可以满足CP(v,i), 这个时候, coordinator 只需要在被提议的 value 中选择一个就可以了.
    在情形K2， 至少一个acceptor 汇报说在 round k 投过票, 没有 acceptor 在round j ,j>k, 中投过票. 我们让 a0 为Q 中在round k投过票的 acceptor, 于是有 vr(a0) =k. 在阶段2a, coordinator 要选出的 value 就是 vv(a0). 为了证明这种选择满足CP(v,i), 我们必须证明, 对于任意的 round j, j <i, 除了 value v外, 不可能有其他的value 被选出或者可能被选出. 因为 vrnd[a] <= rnd[a] 并且 acceptor a 只有在 i > rnd[a] 的时候才会回复 round i的消息, 所以 k < i. 我们将证明分为下面三种情况.
    当 k < j < i, 用 a 表示 Q 中的任意一个 acceptor, vr(a) 是a投过票的 round 中编号最大的那个, 所以 vr(a) <=k < j, 所以在那个时候 a 还没有在round j进行投票. 因为它回复 round i的消息的时候会把rnd[a] 设置成i, 并且保证不会对编号小于i的round 投票, 所以 Q 中的acceptor 都不会在 round j中进行投票, 通过 observation 2 我们知道, 在round j 不会有任何value 被选出, 或者有可能被选出.
    当 j=k, acceptor a0 在 round k中投票批准了value v, 那么它设置 srnd[a0] 为k, vval[a0] 为v. 因为acceptor 只能对 coordinator 提议的 value 投票, 所以, 每一个acceptor 要么在round k中投票给了v, 要么没参与投票.(这里我来解释一下, 虽然系统中可能有多个 coordinator 相信自己是唯一的 coordinator, 但是他们开始在一个round里提出value之前, 必须得到一个多数派的加入该round的回应. 这保证了即便选择coordinator的算法失败, 系统中有多个coordinator, 被提出开始投票的 value 仍旧是唯一的).  因为Q中的任意 acceptor a, 都满足rnd[a] >= i >k. 通过 observation 3， 我们知道, 除了 value v以外, 不可能有其他的 value 在round j被批准或者可能被批准.

    当j<k, 通过归纳法, 我们可以假定 CP 一直保持着, 当 acceptor a0 在 round k 投票给 v 就说明了在round j 不可能有 v 以外的 value 被批准.
    至此, 我们证明了在同一个round 中, 不会有超过一个的value 被批准, 又证明了, 在不同的 round 中, 也不会有超过一个value 被批准, 所以一致性得到了保证.
    下面是选择value的具体方法:
    设Q是在round i中 发送了消息 1b 的任一多数派.
    vr(a) 和 vv(a) 是 Q 中 acceptor a在消息1b中汇报的 vrnd[a] 和 vval[a].
    k 是 Q 中的 a 所汇报所有的 vr(a) 中最大的那个
    V 是Q 中当vr(a) =k 时, vv(a) 的集合.
    如果 k=0 , 则 v 可以是任何被提议的 value.
    否则 V应该只包含一个元素, 选择该元素为 value.
算法
This entry was posted by 道安 on 2010年06月24日 at 16:10, and is filed under 算法. Follow any responses to this post through RSS 2.0. You can leave a response or trackback from your own site.
4 comments

编码小书童 (1079 天)
paxos 算法最主要的优点在于数据同步的一致性保证,以及容错冗余条件下的数据提交保证,以及消息传输可异步性这三点.Leader选举只是分布式算法中一个很普遍的问题,主要考虑消息的复杂度.paxos用于这个问题很显然不是很合适.如何优化paxos的消息复杂度才是有意义的工作.希望淘宝将其应用在数据同步方面,并性能有所提高.

 
ggzwtj (793 天)
我说一个我的理解：如果有20个value，Acceptor要从其中选出1个，但是总共只有11个Acceptor，一个多数派只有6个，所以最多只有6个value会在一个选举过程中出现。

Paxos 概要之二 ：场景， wiki 有误！？ | 时光流连却忘返 (627 天)
[...] http://blog.csdn.net/chen77716/article/details/6166675 http://rdc.taobao.com/blog/cs/?p=261 此条目由 huliang 发表在 分布式 分类目录，并贴了 paxos [...]

Reply ↓
3个帮 » Apache Zookeeper入门 (559 天)
[...] ZooKeeper 顾名思义 动物园管理员，他是拿来管大象(Hadoop) 、 蜜蜂(Hive) 、 小猪(Pig)  的管理员， Apache Hbase和 Apache Solr 以及LinkedIn sensei  等项目中都采用到了 Zookeeper。ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，ZooKeeper是以Fast Paxos算法为基础，实现同步服务，配置维护和命名服务等分布式应用。 ZooKeeper 如何工作？ [...]

Reply ↓
发表评论
电子邮件地址不会被公开。 必填项已用 * 标注

姓名 * 

电子邮件 * 

站点

评论

您可以使用这些 HTML 标签和属性： <a href="" title=""> <abbr title=""> <acronym title=""> <b> <blockquote cite=""> <cite> <code> <del datetime=""> <em> <i> <q cite=""> <strike> <strong>


标签
beanstalkd BugFix cache CDN CPU epoll flashcache gdb http InnoDB kvm L1 Linux memcached mysql OceanBase overview pstack qemu redis Sheepdog smp ssd systemtap Tair tcp TFS traffic server unix 主从同步 事务 代理 分布式架构 分析 多线程 夸父 对象 开发模式 开源 指南 算法 管理员 缓存 网络 虚拟化
分类目录
BugFix
Cassandra
CDN
Dynamo
hypertable
JVM
Linux开发
mysql
OceanBase
Performance
Tair
Tengine
TFS
优化
分布式架构
底层架构
开发模式
数据库
未分类
算法
功能
登录
文章 RSS
评论 RSS
WordPress.org
成员个人博客
丁奇个人博客
三百个人博客
伯松个人博客
千石个人博客
华庭个人博客
叔度个人博客
坤谷个人博客
撒迦个人博客
日照个人博客
李子个人博客
正祥个人博客
永攀个人博客
茂七个人博客
褚霸个人博客
雕梁个人博客
淘宝其他官方博客
淘宝DBA
淘宝JAVA中间件
淘宝UED
淘宝招聘
淘宝搜索技术博客
淘宝数据平台
淘宝质量保障
淘宝核心系统团队博客 © 2010 | Powered by WordPress and Mystique theme by digitalnature 
22 queries in 0.25 seconds (23.65M)
========== http://my.oschina.net/cmffire/blog/11280 ==========
开源中国社区开源项目发现、使用和交流平台
项目讨论代码资讯翻译博客Android招聘
当前访客身份： 游客 [ 登录 | 加入开源中国 ] 你有0新留言

软件


风林火山
  关注此人
关注(14) 粉丝(23) 积分(46)
这个人很懒，啥也没写
.
发送留言
.
请教问题
博客分类
数据库(2)
Linux(17)
算法(4)
java(8)
杂项(16)
分布式(5)
各种协议(2)
golang(10)
流媒体(12)
日常记录(1)
阅读排行
1. Zookeeper分布式安装手册
2. UML中数据流图，用例图，类图，对象图，角色图，活动图，序列图详细讲述保存供参考
3. Apache Zookeeper入门1
4. 分布式服务框架 Zookeeper -- 管理分布式环境中的数据
5. 摄像头视频采集压缩及传输
6. Apache ZooKeeper入门2
7. 最近仔细研究了一下Java的NIO以及线程并发，搞清了点思路，特作笔记如下（NIO篇）
8. 140个Google的面试题
最新评论
@风林火山：引用来自“Hily”的评论 ./go.sh 不会起作用，应... 查看»
@Hily：./go.sh 不会起作用，应该用 source /etc/profil... 查看»
@whee：192.168.3.131 namenode 192.168.3.132 datanode... 查看»
@whee：192.168.3.131 namenode 192.168.3.132 datanode... 查看»
@whee：echo ruok | nc 求教 是什么意思 查看»
@Digerl：ANDROID的设计者，这样的人全美国只有一个。这样... 查看»
@Digerl：照你这个分法，到100层仍然是废物。 查看»
@生日：俺也自认为是个程序员吧 查看»
@亦夕：对于严肃的问题，幽一把默也是不错的。 查看»
@刘永奎：这是一个严肃的问题，一楼为什么要调侃呢？ 查看»
访客统计
今日访问：8
昨日访问：10
本周访问：56
本月访问：42
所有访问：30212
空间 » 博客	 » 分布式 » 博客正文
 Apache Zookeeper入门1
7人收藏此文章, 我要收藏 发表于2年前(2010-12-18 16:34) , 已有3294次阅读 ，共2个评论
作者: H.E. | 您可以转载, 但必须以超链接形式标明文章原始出处和作者信息及版权声明 
网址: http://www.javabloger.com/article/apache-zookeeper-hadoop.html
口水:Zookeeper是我目前接触过Apache开源系统中比较复杂的一个产品，要搞清楚这个东东里面的运作关系还真不是一时半会可以搞定的事，本人目前只略知皮毛之术。

ZooKeeper 是什么？

  ZooKeeper 顾名思义 动物园管理员，他是拿来管大象(Hadoop) 、 蜜蜂(Hive) 、 小猪(Pig)  的管理员， Apache Hbase和 Apache Solr 以及LinkedIn sensei  等项目中都采用到了 Zookeeper。ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，ZooKeeper是以Fast Paxos算法为基础，实现同步服务，配置维护和命名服务等分布式应用。
 

ZooKeeper 如何工作？

  ZooKeeper是作为分布式应用建立更高层次的同步(synchronization)、配置管理 (configuration maintenance)、群组(groups)以及名称服务(naming)。在编程上，ZooKeeper设计很简单，所使用的数据模型风格很像文件系统的目录树结构，简单来说，有点类似windows中注册表的结构，有名称，有树节点，有Key(键)/Value(值)对的关系，可以看做一个树形结构的数据库，分布在不同的机器上做名称管理。

   Zookeeper分为2个部分：服务器端和客户端，客户端只连接到整个ZooKeeper服务的某个服务器上。客户端使用并维护一个TCP连接，通过这个连接发送请求、接受响应、获取观察的事件以及发送心跳。如果这个TCP连接中断，客户端将尝试连接到另外的ZooKeeper服务器。客户端第一次连接到ZooKeeper服务时，接受这个连接的 ZooKeeper服务器会为这个客户端建立一个会话。当这个客户端连接到另外的服务器时，这个会话会被新的服务器重新建立。

   启动Zookeeper服务器集群环境后，多个Zookeeper服务器在工作前会选举出一个Leader，在接下来的工作中这个被选举出来的Leader死了，而剩下的Zookeeper服务器会知道这个Leader死掉了，在活着的Zookeeper集群中会继续选出一个Leader，选举出leader的目的是为了可以在分布式的环境中保证数据的一致性。如图所示：


  另外，ZooKeeper 支持watch(观察)的概念。客户端可以在每个znode结点上设置一个观察。如果被观察服务端的znode结点有变更，那么watch就会被触发，这个watch所属的客户端将接收到一个通知包被告知结点已经发生变化。若客户端和所连接的ZooKeeper服务器断开连接时，其他客户端也会收到一个通知，也就说一个Zookeeper服务器端可以对于多个客户端，当然也可以多个Zookeeper服务器端可以对于多个客户端，如图所示：


你还可以通过命令查看出，当前那个Zookeeper服务端的节点是Leader，哪个是Follower，如图所示：


我通过试验观察到 Zookeeper的集群环境最好有3台以上的节点，如果只有2台，那么2台当中不管那台机器down掉，将只会剩下一个leader，那么如果有再有客户端连接上来，将无法工作，并且剩下的leader服务器会不断的抛出异常。内容如下：
java.net.ConnectException: Connection refused
        at sun.nio.ch.Net.connect(Native Method)
        at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:507)
        at java.nio.channels.SocketChannel.open(SocketChannel.java:146)
        at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:347)
        at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectAll(QuorumCnxManager.java:381)
        at org.apache.zookeeper.server.quorum.FastLeaderElection.lookForLeader(FastLeaderElection.java:674)
        at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:611)
2010-11-15 00:31:52,031 – INFO  [QuorumPeer:/0:0:0:0:0:0:0:0:2181:FastLeaderElection@683] – Notification time out: 12800

并且客户端连接时还会抛出这样的异常，说明连接被拒绝，并且等待一个socket连接新的连接，这里socket新的连接指的是zookeeper中的一个Follower。
org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1000) Opening socket connection to server 192.168.50.211/192.168.50.211:2181  
org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:908) Socket connection established to 192.168.50.211/192.168.50.211:2181, initiating session  
org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1118) Unable to read additional data from server sessionid 0×0, likely server has closed socket, closing socket connection and attempting reconnect  
org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1000) Opening socket connection to server localhost/127.0.0.1:2181  
 2010-11-15 13:31:56,626 WARN   org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1120) Session 0×0 for server null, unexpected error, closing socket connection and attempting reconnect  
 

 先写到这里，全面了解Zookeeper不太容易，光看Apache Zookeeper官方的wiki和文档还不能对其有深入的了解，想阅读Zookeeper中的部分源代码。另外，本人目前正在学习和了解ing，欢迎大家与我交流，谢谢。


 
关键字： zookeeper 分布式
原文地址：http://www.javabloger.com/article/apache-zookeeper-hadoop.html
Apache ZooKeeper入门2 »
开源中国-程序员在线工具：API文档大全(120+) JS在线编辑演示 二维码 更多>>
分享到： 顶已有 0人顶
共有 2 条网友评论
	
1楼：filebat 发表于 2011-08-23 17:50 回复此评论
事件变化侦听的实现是不是可以理解成: client主动报告的push方式＋server定期主动查询的pull方式？（呵呵， 没有毅力去看代码确认）
- 客户端定期向选取的leader发送状态信息
- 当客户端fail多时， master会判断该结点最近更新时间是否过久。如果过久， 那么将该结点标记成不可访问。

- Denny(markfilebat@126.com)
	
2楼：小杨阿哥哥 发表于 2012-04-10 21:59 回复此评论
支持下，呵呵，加油
 
 文明上网，理性发言
回到页首 | 回到评论列表
关闭相关文章阅读
2010/12/18分布式服务框架 Zookeeper -- 管理分...
2010/12/18 Zookeeper分布式安装手册
2013/09/06基于ZooKeeper的分布式Session实现...
2012/03/19分布式设计与开发（三）------高一致...
2013/06/05使用zookeeper实现分布式共享锁...
© 开源中国(OsChina.NET) | 关于我们 | 广告联系 | @新浪微博 | 开源中国手机版 | 粤ICP备12009483号-3	开源中国手机客户端：AndroidiPhoneWP7
========== http://www.cnblogs.com/vamei/archive/2012/05/28/2521650.html ==========

Vamei
技术推动进步，分享促进社区。
博客园
首页
博问
闪存
联系
订阅
管理
随笔-155  文章-0  评论-1389 
Python基础01 Hello World!

作者：Vamei 出处：http://www.cnblogs.com/vamei 欢迎转载，也请保留这段声明。谢谢！

 

简单的‘Hello World!’

 

1. 直接运行python

假设你已经安装好了python, 那么在Linux命令行输入:

$python

将直接进入python。然后在命令行提示符>>>后面输入:

>>>print 'Hello World!'

可以看到，python随后在屏幕上输出:


Hello World!

print是一个常用的python关键字(keyword)，其功能就是输出。

（在Python 3.x中，print的语法会有所变化，作为一个函数使用， 所以上面应写成print('Hello World!')，以此类推 ）

 

2. 写一段小程序

另一个使用Python的方法，用文本编辑器写一个.py结尾的文件，比如说hello.py

在hello.py中写入如下，并保存:


print 'Hello World!'

退出文本编辑器，然后在命令行输入:

$python hello.py

来运行hello.py。可以看到python随后输出


Hello World!

 

总结：

print

命令行模式: 运行python，在命令行输入命令并执行。

程序模式: 写一段python程序并运行。

如果你喜欢这篇文章，欢迎推荐。
如果你认为这篇文章值得更多人阅读，欢迎使用右侧的“分享”功能。
技术推动进步，分享促进社区。
标签: Python
绿色通道： 好文要顶 关注我 收藏该文与我联系 
Vamei
关注 - 30
粉丝 - 1081
荣誉：推荐博客
+加关注
3 0
(请您对文章做出评价)
« 上一篇：Python快速教程 (手册)
» 下一篇：Python基础02 基本数据类型
posted @ 2012-05-28 17:23 Vamei 阅读(9549) 评论(8) 编辑 收藏
评论列表
   #1楼 2012-12-10 21:00 john23.net  
感谢分享
支持(0)反对(0)
   #2楼 2013-01-22 08:59 韵味  
hi，博主，想问下您，通常都用什么工具编写python，Vim或IDIE或Eclipse 还是其他的，那个方便点。
支持(0)反对(0)
   #3楼[楼主] 2013-01-22 09:14 Vamei  
@韵味
我用过vim和idle，现在主要是vim。
我觉得vim就挺方便的，用多了的原因。
支持(0)反对(0)
   #4楼 2013-05-22 15:20 nsdont  
博主，你用vim写python时， 有用到什么插件没，求推荐，求指导
支持(0)反对(0)
   #5楼[楼主] 2013-05-22 16:37 Vamei  
@nsdont
没有…… vim有Python高亮，这就够了。
支持(0)反对(0)
   #6楼 2013-05-22 16:52 nsdont  
@Vamei
嗯，这就足以了，是我贪多了
支持(0)反对(0)
   #7楼[楼主] 2013-05-22 18:10 Vamei  
@nsdont
我有点懒，总觉得够用就行。你可以探索一下插件。
支持(0)反对(0)
   #8楼 2013-05-24 09:30 whthomas  
@nsdont
ipython
支持(0)反对(0)
刷新评论刷新页面返回顶部
注册用户登录后才能发表评论，请 登录 或 注册，访问网站首页。
博客园首页博问新闻闪存程序员招聘知识库

最新IT新闻:
· 谷歌未来全球增长面临的10大挑战
· Twitter创始人谈如何创造财富
· 花旗因证券研究违规被罚款3000万美元
· IE漏洞或被集成到开源工具 可引发大规模攻击
· 评论：微软之死
» 更多新闻...
最新知识库文章:
· 语法规范：BNF与ABNF
· 程序员的样子
· Hadoop之父Doug Cutting
· 从头到尾彻底解析Hash表算法
· Socket网络编程常用的结构及函数小结
» 更多知识库文章...
公告
从这里开始 
Python/Java/Linux/协议/算法/数据科学系列文章，按照正序排列，提高阅读体验。

我的微博  

我的豆瓣
	
推荐阅读
昵称：Vamei
园龄：1年4个月
荣誉：推荐博客
粉丝：1081
关注：30
+加关注
我的标签
Python(50)
Java(25)
Linux(15)
网络(15)
大数据(14)
算法(13)
系列索引(6)
心理学(5)
开发工具(4)
散装(4)
更多
推荐博客
苍痕
新加坡IT创业
酷壳
综合技术博客，很有深度。
小坦克
网络协议，理论与应用。
系列文章
Java快速教程
Linux的概念与体系
Python快速教程
数据科学
协议森林
纸上谈兵: 算法与数据结构
积分与排名
积分 -	301814
排名 -	267
最新评论
1. Re:Python简史
楼主的介绍十分翔实啊！
--Jason Luo
2. Re:博客一年: 心理之旅
支持Vamei，我读了你很多篇文章，不仅把以前的知识巩固下来了，还学到了一些新东西，继续加油！
--linzo
3. Re:Python标准库02 时间与日期 (time, datetime包)
楼主是好人
--互相学习
4. Re:Java进阶04 RTTI
感谢楼主写了这么多通俗易懂的好文，赞！
--linzo
5. Re:Python小题目 针对快速教程
精简到5行：
data = [i.strip().split(',') for i in open('old.txt') if not (i.startswith('#') or i=='\n')]
[i[0] for i in data if int(i[2])<60]
[i[0] for i in data if i[0].startswith('L')]
sum([int(i[2]) for...
--noback
6. Re:Python网络01 原始Python服务器
楼主的文章写的浅显易懂还到位，特别是一些细节地方的备注对我这类基础很少的人来说特别有用，以前好多不懂的疑惑一下子就解开了，感谢！
--开心星
7. Re:Python深入01 特殊方法与多范式
更优雅的办法应该是 lambda x: x+5, list的写法吧
--miqingren
8. Re:Python深入03 对象的属性
class bird(object): feather = True class chicken(bird): fly = False def __init__(self, age): self.age = age def __getattr__(self,name): if name=='adult': if self.age > 1.0:...
--lwkjob
9. Re:协议森林08 不放弃 (TCP协议与流通信)
楼主强人啊，通俗易懂，清晰明白
--太阳小子
10. Re:协议森林15 先生，要点单吗? (HTTP协议概览)
感谢lz通俗易懂的好文,为什么教科书不能讲得这么明白呢?
--ptrees
11. Re:Java基础04 封装与接口
呵呵
--冰天百华
12. Re:Java基础04 封装与接口
挺好的
--冰天百华
13. Re:纸上谈兵: 树, 二叉树, 二叉搜索树
3楼说的对。
--Unity3D之轨迹
14. Re:Python标准库10 多进程初步 (multiprocessing包)
vamei，你好看了你的博客有一段时间的了。抱着不求甚解的态度看到了这一段（我觉得我学不来编程，也许这只是自己给自己的借口吧。没什么东西是不需要积累的，但是我觉得看不到什么进步）我学习python主要是用作主机的日常维护。但是看到多进程这一步的时候，我到我们服务器上做测试。结果发现python 2.4竟然没有multiprocess这个模块。网上找了下python升级的资料，都挺复杂的。还不能把原...
--天楚
15. Re:协议森林11 涅槃 (TCP重新发送)
@Vamei，楼主有个问题，你的文章中说
TCP片段头部的checksum会校验包括IP头部、TCP头部和TCP数据在内的整个序列
这个checksum校验怎么还有IP头部呢？不是只有TCP的头部和数据吗？
--脐橙君
推荐排行榜
1. 协议森林01 邮差与邮局 (网络协议概观)(55)
2. 为什么要写技术博(50)
3. 博客一年: 心理之旅(35)
4. 协议森林08 不放弃 (TCP协议与流通信)(35)
5. 协议森林02 小喇叭开始广播 (以太网与WiFi协议)(24)
6. 版本管理三国志 (CVS, Subversion, git)(24)
7. 协议森林09 爱的传声筒 (TCP连接)(20)
8. Python快速教程(20)
9. Python简史(17)
10. 协议森林11 涅槃 (TCP重新发送)(17)
11. 协议森林10 魔鬼细节 (TCP滑窗管理)(17)
12. 协议森林(15)
13. 协议森林03 IP接力赛 (IP, ARP, RIP和BGP协议)(14)
14. C编译: 使用gdb调试(14)
15. Java快速教程(13)

========== http://woodpecker.org.cn/abyteofpython_cn/chinese/ ==========
简明 Python 教程
下一页
简明 Python 教程
Swaroop, C. H. 著
沈洁元  译
www.byteofpython.info

版本：1.20

A Byte of Python
Copyright © 2003-2005 Swaroop C H
简明 Python 教程
《简明 Python 教程》为 "A Byte of Python" 的唯一指定简体中文译本，版权 © 2005 沈洁元
本书依照 创作公用约定（署名-非派生作品-非商业用途） 发布。

概要

无论您刚接触电脑还是一个有经验的程序员，本书都将有助您学习使用Python语言。

目录表

前言
本书的读者
本书的由来
本书目前的状况
官方网站
约定条款
欢迎给我反馈
值得思考的一些东西
1. 介绍
简介
Python的特色
     概括
为什么不使用Perl？
程序员的话
2. 安装Python
Linux和BSD用户
Windows®用户
概括
3. 最初的步骤
简介
使用带提示符的解释器
挑选一个编辑器
使用源文件
     输出
     它如何工作
可执行的Python程序
获取帮助
概括
4. 基本概念
字面意义上的常量
数
字符串
变量
标识符的命名
数据类型
对象
     输出
     它如何工作
逻辑行与物理行
缩进
概括
5. 运算符与表达式
简介
运算符
运算符优先级
     计算顺序
     结合规律
表达式
     使用表达式
概括
6. 控制流
简介
if语句
     使用if语句
     它如何工作
while语句
     使用while语句
for循环
     使用for语句
break语句
     使用break语句
continue语句
     使用continue语句
概括
7. 函数
简介
     定义函数
函数形参
     使用函数形参
局部变量
     使用局部变量
     使用global语句
默认参数值
     使用默认参数值
关键参数
     使用关键参数
return语句
     使用字面意义上的语句
DocStrings
     使用DocStrings
概括
8. 模块
简介
     使用sys模块
字节编译的.pyc文件
from..import语句
模块的__name__
     使用模块的__name__
制造你自己的模块
     创建你自己的模块
     from..import
dir()函数
     使用dir函数
概括
9. 数据结构
简介
列表
     对象与类的快速入门
     使用列表
元组
     使用元组
     元组与打印语句
字典
     使用字典
序列
     使用序列
参考
     对象与参考
更多字符串的内容
     字符串的方法
概括
10. 解决问题——编写一个Python脚本
问题
解决方案
     版本一
     版本二
     版本三
     版本四
     进一步优化
软件开发过程
概括
11. 面向对象的编程
简介
self
类
     创建一个类
对象的方法
     使用对象的方法
__init__方法
     使用__init__方法
类与对象的变量
     使用类与对象的变量
继承
     使用继承
概括
12. 输入/输出
文件
     使用文件
储存器
     储存与取储存
概括
13. 异常
错误
try..except
     处理异常
引发异常
     如何引发异常
try..finally
     使用finally
概括
14. Python标准库
简介
sys模块
     命令行参数
     更多sys的内容
os模块
概括
15. 更多Python的内容
特殊的方法
单语句块
列表综合
     使用列表综合
在函数中接收元组和列表
lambda形式
     使用lambda形式
exec和eval语句
assert语句
repr函数
概括
16. 接下来学习什么？
图形软件
     GUI工具概括
探索更多内容
概括
A. 自由/开放源码软件（FLOSS）
B. 关于本书
后记
关于作者
关于译者
关于简体中文译本
C. 修订记录
时间表
术语表
表格

5.1 运算符与它们的用法
5.2 运算符优先级
15.1 一些特殊的方法
例子

3.1 使用带提示符的Python解释器
3.2 使用源文件
4.1 使用变量和字面意义上的常量
5.1 使用表达式
6.1 使用if语句
6.2 使用while语句
6.3 使用for语句
6.4 使用break语句
6.5 使用continue语句
7.1 定义函数
7.2 使用函数形参
7.3 使用局部变量
7.4 使用global语句
7.5 使用默认参数值
7.6 使用关键参数
7.7 使用字面意义上的语句
7.8 使用DocStrings
8.1 使用sys模块
8.2 使用模块的__name__
8.3 如何创建你自己的模块
8.4 使用dir函数
9.1 使用列表
9.2 使用元组
9.3 使用元组输出
9.4 使用字典
9.5 使用序列
9.6 对象与参考
10.1 备份脚本——版本一
10.2 备份脚本——版本二
10.3 备份脚本——版本三（不工作！）
10.4 备份脚本——版本四
11.1 创建一个类
11.2 使用对象的方法
11.3 使用__init__方法
11.4 使用类与对象的变量
11.5 使用继承
12.1 使用文件
12.2 储存与取储存
13.1 处理异常
13.2 如何引发异常
14.1 使用sys.argv
15.1 使用列表综合
15.2 使用lambda形式
下一页
前言
========== http://en.wikipedia.org/wiki/HTTP_persistent_connection ==========
========== http://en.wikipedia.org/wiki/Keepalive#TCP_keepalive ==========
========== http://www.cnxct.com/use-get-for-ajax-requests-why/ ==========
返回顶部猜你喜欢
Home
About
Pecker Scanner
 
莿鸟栖草堂凯风自南，吹彼棘心。棘心夭夭，母氏劬劳。凯风自南，吹彼棘薪。母氏圣善，我无令人。
RSS Feed
YSLOW法则中，为什么yahoo推荐用GET代替POST？
Posted by CFC4N on 2011/08/07 发表评论14条评论  
背景：
上上周五，公司前端工程师培训，提到前端优化的一些技巧，当然不能少了yahoo yslow的优化法则。其中有这么一条“Use GET for AJAX Requests”，这些法则从最开始的14条，到现在的35条，一直都时刻关注的。可这么一条的原因我却一点都不清楚。在提问的环节里，我对yahoo WEB前端优化法则推荐AJAX中，使用GET代替POST的原因有疑问，便请教前端工程师。我们的工程师说GET的话，浏览器发送一个包，POST会发两个等等。我对这个解释仍带有疑问，甚至怀疑。培训结束后，我随便搜索了一下，并没有得到理想的结果，可能很少人对Yahoo这么有权威的组织提出的优化法则产生怀疑，也很少人想知道为什么建议这么做，更多的人会唯命是从，墨守成规。之后，我又看了遍优化法则，看到一条是推荐开发者使用AJAX缓存的，这时，一个“伟大”的想法在我脑袋中一闪，莫非是GET请求可以缓存，而POST不可以？接着，我把我这个“伟大”的猜测告诉我的同事们，当初已经是下班时间，好多同事都离开公司，我也匆忙收拾东西下班了，没有仔细查找答案。

周末期间，脑袋中频繁的闪现这个问题，仍对我的想法有怀疑，Yahoo前端这么牛X的团队的想法，岂是我这样的菜鸟能这么容易的猜测推断到的？我对我当初的推测的怀疑就像“小时候就怀疑小JJ绝对不是只用来撒尿那么简单”一样坚定。但向我这么懒惰的同学，实在找不出一点时间来验证我这个想法，空闲的时间宁愿多打几盘CS。一直拖到现在，台风来了，在家宅两天，头都睡扁了，也找不出不写这篇文章的理由。

验证Yahoo推荐的理由：
验证XHR请求中yahoo推荐用GET代替POST做法的理由

POST is implemented in the browsers as a two-step process: sending the headers first, then sending data. So it’s best to use GET
POST请求分两步：发送http headers，再发送http data

HTML+JS代码：

01
<body>
02
<script src="jquery.1.3.2.js"></script>
03
<form method="post" action="">
04
<select name="option" id="option">
05
  <option value="POST" name="POST">POST</option>
06
  <option value="GET" name="GET">GET</option>
07
</select>
08
  <input  id="button"  type="button" value="POST提交">
09
</form>
10
<script language="JavaScript">
11
<!--
12
$('#button').click(function(){
13
  var option = $('#option').val();
14
  $.ajax({
15
    type: option,
16
    url:"cc.php",
17
    data: "name=cfc4n&option="+option,
18
    success: function(msg){
19
      alert(msg);
20
    }
21
  });
22
});
23
//-->
24
</script>
25
 </body>
抓包工具：wireshark
提示：wireshark(1.2.5版)在抓http包的时候，会默认合并packet reassembly选项，记得全部去掉。如下图(edit–>Preferences)

wireshark去掉 packet reassembly选项
我分别发了一个GET、一个POST的XHR(XMLHttpRequest)请求，其数据包如下：

XHR HTTP请求中GET与POST发送的数据包详情

如上图，GET请求发送的数据包为第一个红框内的结果；POST请求发送的数据包为第二个红框内结果，但多了一个第12条数据包(粉红色框内)，从10.0.0.108(我的PC)发往98.126.129.106(www.cnxct.com的服务器IP,也就是表单提交的目标服务器IP)，wireshark给出的信息是“Continuation or non-HTTP traffic”，这个提示就是说，本次数据包是接着上一次的HTTP请求发的，没有HTTP header，只有http data。
详情如下图
XHR HTTP POST请求的header部分数据：

XHR HTTP POST请求的header部分数据
XHR HTTP POST 请求的DATA部分：

XHR HTTP POST 请求的DATA部分
结论?：
果然，如伟大的YAhoo前端团队所说，XHR HTTP的POST请求会分为两步，先发HTTP HEADER，再发HTTP DATA部分。

然而，新的疑问又来了。为什么要分为两部？谁(例如W3C这种机构)规定的？每个浏览器都是这样的么？分两次比一次的的效率更高吗？

继续：
带这我新的疑问，又进行了如下尝试：先分浏览器，IE8、Firefox5.0、Chrome13分别发送XHR GET 、XHR POST请求，抓包对比结果。


我惊奇的发现(细心的同学会注意到第三张图中，有椭圆形的框标出那些结果的浏览器是Chrome13)，Firefox5发送POST的数据包确是没有像yahoo前端优化法则中提到的那样，分为两次，两个包发送，而是一次完成http headers和 http data的发送。如下图：

firefox5在发送XHR POST请求时的数据包

大家可以从图中看到line-based text data:application/x-www-from-urlcoded下面就是POST的数据。
这时，又有很多疑问产生了，其他浏览器呢？IE的所有版本都会分两次发么？Firefox的其他版本呢？
当我想一个一个尝试抓包对比的同时，幸运的搜到了关于我这个疑问的PDF(Analysis_of_browser_specific_characteristics.pdf)
其中，提到firefox大部分版本在XP、WIN7、UBUNTU、MAC OS等系统上都是以1个包来实现的，其他常见浏览器都是分为两个包。
相比大家很清楚的知道，HTTP(TCP)完成一次事务，通讯次数越多，越有可能出现故障(网络延迟等因素)，开销越大，浏览器(客户端)、服务端都要再进行一次TCP通讯，而且，需要一定的时间。对于我们追求更高的用户体验，需要HTTP通讯都避免到这些缺点，而各大浏览器开发商为何仍这么做呢？firefox的做法是最好的吗？

上面的PDF里，模拟了各种网络环境，比如网络延迟、网络丢包等情况，分别来对比POST请求的1次包和2次包的优缺点。得出的结论是：当网络环境好的情况下，1次包跟2次包的在时间上差别基本可以无视。而在网络环境差的情况下，(2次包)TCP的验证数据包完整性上，有非常大的优点，客户端先告诉服务端即将发送的数据包大小，MD5等标识，当服务端告诉客户端收到(ACK包)的时候，客户端再次向服务端发送POST 的DATA。假如网络环境不好，网络延迟、丢包的时候，服务端会等待(延迟时)，客户端重发POST的DATA数据到服务单，来确保本次请求的完整性。

撰写这个PDF的作者在他的博客里详细的描述了写这个博客的起因，以及结果，还有一些关于与yahoo yslow前端团队的一些沟通过程，大家可以在这里阅读下(yahoo 的前端团队好像不太友好，哈)。

结论：
通过参考这个PDF，以及我自己做的抓包测试，让我了解Yahoo YSLOW前端团队的这个推荐(他们没详细的说为啥这么推荐，只是简单的提了下GET请求产生TCP一个包；POST请求，产生2个TCP包。甚至都没告诉我们Firefox的多数版本[可能是所有版本]都是发一个TCP包的。更详细、更深层原因也没说，这里还得感谢下http://loadimpact.com的作者)。

备注：
这里提供下我抓包测试时候的数据包(截图用到的数据包中包含我的一些cookie，没上传。这里的是我新抓的，各位见谅)，各位可以参考下，如果我的文字、方向有错，欢迎指出。
IE8、FF5、Chrome13发起XHR请求数据包

当你读到这里时，我承认，我骗了你，文章的内容不光是标题中所写的，为何推荐使用POST代替GET，更多的是抓去TCP、HTTP通讯包来验证各个浏览器是否如YSLOW所述的那样分2次包的过程，以及2次包与1次包的优缺点(PDF中)。希望你看到最后的时候，忘记标题讲的是什么。

猜你喜欢:

HTTP请求欺骗
AJAX技术 vs 传统的ASP无刷新技术
在vc中如何用post方法提交表单！
最令PHPer头痛的十四个问题
好东西共享出来 JGsoft RegexBuddy v3.1.0 零售版 (破解版)
所谓技术ajax, http, tcp, wireshark, xhr, XMLHttpRequest, yahoo, yslow, 前端, 浏览器
← 《正则表达式》PPT共享(公司内部培训)WEB开发安全与运维安全浅见 →
最新最早最热
14256

CC
V5
2011年8月8日回复顶转发举报

Giko
很棒，很少看到这么有砂锅精神的人类了。
2011年8月8日回复顶转发举报

yuen
相比大家很清楚的知道，HTTP(TCP)完成一次事物，

事务
2011年8月9日回复顶转发举报

CFC4N
回复 yuen: 哈哈，是的，打字错了。谢谢。
2011年8月9日回复顶转发举报

橙子
其实那个错别字我早看出来了，就看你改不改哈哈。 
2011年8月10日回复顶转发举报

牌探007
代码 看不懂啊
2011年8月27日回复顶转发举报

cccc
GET请求可以缓存，而POST不可以
这个问题还没有解答......
2012年1月15日回复顶转发举报

CFC4N
回复 cccc: 抱歉，刚看到。GET可以被缓存，POST不会被浏览器缓存，这是RFC2616规定的，呵呵，除非浏览器不遵照标准。
2012年1月18日回复顶转发举报

someone
网络条件很差的情况下，get如果发送失败应该也会重发吧，这是TCP层来保证的。是这样吗？
2012年5月5日回复顶转发举报

超
哥.文章不错,精神可嘉.
就是这打灰机的上帝之手,能不能少一些错别字呢...
2012年7月5日回复顶转发举报

alex
好文章啊。学到了很多。
xhr get或post的使用仅仅是从是否明文传递方面来区分的。。肤浅啊。
2012年8月16日回复顶转发举报

盛溪游子
我们目前在做应用系统的时候,为了安全性,都使用post作为提交方式.get方式的表单提交会被认为是不安全不被处理.一些链接也会被包装为post进行提交.
1月12日回复顶转发举报

盛溪游子
推荐以后ajax的例子都去使用 www.geonames.org 找一个服务进行示例代码的编写  
1月12日回复顶转发举报

lee
如果我告诉你，不管你发一个还是两个，NGINX 会收到一个完整的 HTTP Message ，才处理下一步呢？见RFC2616和NGINX代码
1月12日回复顶转发举报
社交帐号登录:
微博
QQ
人人
豆瓣
更多»


发布
多说
Categories

我的微博

最新文章
基于语法分析的PHP webshell扫描工具–Pecker Scanner
为什么不能在字符组中使用反向引用
PHP API中，MYSQL与MYSQLI的持久连接区别
Nginx模块fastcgi_cache的几个注意点
手机通讯录，或许可以增加QQ、微信之类IM用户黏度
再读《Rework重来》
google play购买Nexus 4手机小记
2012壬辰年总结
php与mysql通讯那点事
webgame中Mysql Deadlock ERROR 1213 (40001)错误的排查历程
随机博文
nginx、php-fpm默认配置与性能–TCP socket还是unix domain socket
网站总算又重见天日了,
朝三暮四，还是朝四暮三？
UBUNTU用ADSL拨号有问题啦!
2012壬辰年总结
wordpress博客永久地址的二次重写
终止进程的内幕
看清程序员
小试P3P协议
七条对于软件专业同学一些建议
Search by Tags!
apache beryl block codeigniter discuz hook libmysql Linux mysql mysqli mysqlnd nexus 4 nginx pecker scanner PHP php-fpm php webshell PHP木马 PHP解密 python rewrite ssdt strace tcp ubuntu url rewrite webshell xgl xoops 产品 反向引用 回溯 手机 招聘 插件 朝花夕拾 木马 正则 正则表达式 浮躁 精通正则表达式 老爷机 贪婪 零宽断言 非贪婪
博文归档

Meta
登录
署名协议

莿鸟栖草堂 由 CFC4N 创作，采用 知识共享 署名-非商业性使用-相同方式共享 3.0 未本地化版本 许可协议进行许可。
基于http://www.cnxct.com上的作品创作。
Copyright © 2013 莿鸟栖草堂  | Powered by WordPress  | Theme zBench 赣ICP备06006420号 站长统计
Δ Top
========== http://www.cnxct.com/wp-content/uploads/2011/08/Analysis_of_browser_specific_characteristics.pdf ==========
Failed!!
========== http://www.oncoding.cn/2009/ajax-get-post/ ==========
幼学笔记
OnCoding...
追寻简单生活
文章/ARTICLES ·前端 ·地图 ·PHP ·扯淡 关于/ABOUT  
2009
30/12月
分类：
前端
TAGS：
ajax
get
post
评论(4)
寻根究底：Ajax请求的GET与POST方式比较 原
YSlow里有一条规则叫Use GET for AJAX requests，即“使用GET方式请求AJAX”，YSlow中的解释如下：

When using the XMLHttpRequest object, the browser implements POST in two steps: (1) send the headers, and (2) send the data. It is better to use GET instead of POST since GET sends the headers and the data together (unless there are many cookies). IE’s maximum URL length is 2 KB, so if you are sending more than this amount of data you may not be able to use GET.

翻译：

当使用XMLHttpRequest对象时，浏览器通过两个步骤实现POST：(1)发送请求头；(2)发送数据。而GET的请求头和数据是一起发送的(除非包含很多cookie)，所以使用GET方式更好些。IE支持的最大URL长度是2KB，所以你的数据很长的话就不能用GET了。

这段话蜻蜓点水，只说了GET和POST的这两个差别，而实际使用中会是这么简单吗？

寻根：GET与POST的差别


RFC2616中详细定义和解释了GET和POST，简单来说，GET和POST的根本区别如下：

GET通过URL传递参数(以本文的动态地址 http://www.oncoding.cn/?p=480 为例)，同时发送请求头，从服务器取得数据：

GET /?p=480 HTTP/1.1

Host: www.oncoding.cn

Mozilla/5.0

….

POST也需要URL和请求头，同时需要额外发送数据到服务器，然后取得服务器响应，其数据格式如下：

POST /wp-login.php HTTP/1.1

Host: www.oncoding.cn

User-Agent: Mozilla/5.0

….

userid=admin&password=asdfg

GET和POST为什么有速度的差异？

如YSlow所说，POST比GET多出了一个发送数据的步骤，我们可以通过MIDP实现GET和POST的程序代码来理解这一个过程：

帮助
01
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
17
18
// MIDP实现GET的过程(变量定义省略)：
conn = (HttpConnection) Connector.open( url ); //建立连接
conn.setRequestProperty( "User-Agent", agent ); //设置请求头
 
int rc = conn.getResponseCode(); //取得响应
// ....
// MIDP实现POST的过程(encodedData为post数据)：
conn = (HttpConnection) Connector.open( url ); //建立连接
conn.setRequestMethod( HttpConnection.POST ); //设置请求头
conn.setRequestProperty( "User-Agent", agent );
conn.setRequestProperty( "Content-Type", type );
conn.setRequestProperty( "Content-Length", 
                encodedData.length() );
 
OutputStream os = conn.openOutputStream(); //发送数据
os.write( encodedData.getBytes() );
 
int rc = conn.getResponseCode(); //取得响应
以上程序摘自HTTP POST Basics。

分析可见，速度的差别确实出在这一个发送数据的环节上，这一环节究竟耗时多少，我们一会儿来测一下。

何时用GET，何时用POST

这个问题不该在我们话题的讨论之列。关于使用场合的差别，无非有两个因素：

1. POST比GET更安全。因为GET数据可以缓存，url可以被人轻松的得到，而Ajax中不存在这个问题；

2. IE支持url最长为2KB，所以参数过长不能用GET，这条是Ajax需要考虑的地方。

究底：Ajax的GET与POST在速度上有多少差别

刚刚有老外写的一篇GET and POST Requests in AJAX，比较GET和POST在Ajax中的速度问题，写的洋洋洒洒，但通篇没有一点数据和理论，各浏览器的测试结果居然只有”Very slow”和”Fast”。。。

我们干脆自己写程序来测试一下，通过发送Ajax请求前和接收到Ajax数据后的时间差，来测试其速度的差异。使用了纯Javascript和jquery两种方式作比较。

测试DEMO在这里 | 下载测试程序包(请根据网速，酌情修改请求时间间隔，否则会引起混乱)

手头的几个浏览器测试了一下，PHP程序放在美国Dreamhost服务器上，通过山东电信网络测试结果如下：

Firefox 3.5





Chrome 4.0.266 Beta





IE8





虚拟机中的IE6：





虚拟机中的Firefox 2.0：





通过对这几个流行的浏览器的测试，发现POST确实比GET要慢，而慢的这个时间基本等于服务器的响应时间(Ping值)。浏览器之间的差距不大，Firefox3.5和Chrome4速度比IE要快一点。通过jQuery进行Ajax调用比纯JavaScript稍快(是jQuery做了优化还是我JS程序写的不好？)。

其他浏览器有时间再测试一下，也欢迎有条件的朋友帮忙测试。

后记

为什么要寻根究底研究这个东西呢？

源于同事开发中遇到的一个问题——使用beforeunload事件，在用户关闭浏览器时通过Ajax向服务器发送数据，使用的POST方式。

在分析数据时，发现有一种情况，得到了请求头信息，却没有得到Ajax数据。虽然这部分数据很少，但引起了我的兴趣，同时把心里一直不明白的这个问题搞清楚了。通过这通分析知，这种情况的原因可能是浏览器在得到服务器响应之前，就关闭了连接，而Ajax的异步调用方式，致使beforeunload不会等待Ajax返回，导致POST数据未能发送。解决方法，可以将数据发送改为同步方式。(这个设想不成立，因为发送请求不是异步的，所以原因可能在别的地方。)

幼学笔记原创内容，根据CC协议发布，欢迎具名转载。

« 教程：编写放在收藏夹里的网页划词翻译工具使用框架的最高境界是忘掉框架，而不是依赖甚至依附框架 »
4 个评论：

 benjamin huangPosted 2010年09月13日 at 8:11 上午 | Permalink
写得一篇很好的文章
我也遇到过你后记里的问题 原因是有一个结束tag没写好 导致后面的数据全没了(ie only) 不知道跟你遇到的问题相不相关呢 
 olivesPosted 2011年04月13日 at 3:22 下午 | Permalink
总结的很好，转载了
 JasonPosted 2011年09月4日 at 10:38 上午 | Permalink
哈哈学习了啊
 chajian8Posted 2012年05月13日 at 11:29 上午 | Permalink
好文章啊，，，学习啦。。。
发表评论

Name *

Email *

Website

Comment

文明评论，共同进步

推荐阅读
小记JavaScript享元模式
再探JavaScript单元测试
使用OpenCV开发iOS图像处理应用(To be continued..)
“最被误解的语言”正焕发全新活力
可以在前端实现的几个地理位置小功能
JavaScript单元测试工具 — QUnit
使用框架的最高境界是忘掉框架，而不是依赖甚至依附框架
寻根究底：Ajax请求的GET与POST方式比较
教程：编写放在收藏夹里的网页划词翻译工具
抑制气候变化，每个人的责任，刻不容缓
哥写的不是程序，是寂寞
JavaScript程序执行顺序问题总结
JavaScript中使用JSON
“查看全文(Read more)”设计教程与欣赏
Google Maps Api介绍与基础操作
提高网站可用性的10个小技巧
使用整洁的代码标记构建页面
解密CSS Sprites：技巧、工具和教程
Google Maps经纬度编码算法的JavaScript及PHP实现
© 幼学笔记 Oncoding.cn Powered by WordPress, Theme by Oncoding.cn
除非特别注明，幼学笔记上的内容均采用Creative Commons 姓名标示－非商业性－相同方式分享2.5 授权条款授权。

========== http://blog.csdn.net/zkx928/article/details/8307605 ==========
您还未登录！|登录|注册|帮助首页业界移动云计算研发论坛博客下载
更多
有梦，有追求
一点一点的积累。一步一步的前进
目录视图摘要视图订阅
2014年1月微软MVP申请开始啦！      CSDN社区中秋晒福利活动正式开始啦！        专访钟声：Java程序员，上班那点事儿      独一无二的职位：开源社区经理      “说说家乡的互联网”主题有奖征文
 TCP客户端 长连接策略
分类： C/C++ 网络编程 2012-12-17 15:32 306人阅读 评论(0) 收藏 举报
目录(?)[+]
不久前，我的 Socket Client 程序遇到了一个非常尴尬的错误。它本来应该在一个 socket 长连接上持续不断地向服务器发送数据，如果 socket 连接断开，那么程序会自动不断地重试建立连接。
有一天发现程序在不断尝试建立连接，但是总是失败。用 netstat 查看，这个程序竟然有上千个 socket 连接处于 CLOSE_WAIT 状态，以至于达到了上限，所以无法建立新的 socket 连接了。
为什么会这样呢？
它们为什么会都处在 CLOSE_WAIT 状态呢？
CLOSE_WAIT状态的生成原因
首先我们知道，如果我们的 Client 程序处于 CLOSE_WAIT 状态的话，说明套接字是被动关闭 的！
因为如果是 Server 端主动断掉当前连接的话，那么双方关闭这个 TCP 连接共需要四个 packet ：
       Server ---> FIN ---> Client
       Server <--- ACK <--- Client
    这 时候 Server 端处于 FIN_WAIT_2 状态；而我们的程序处于 CLOSE_WAIT 状态。
       Server <--- FIN <--- Client
这 时 Client 发送 FIN 给 Server ， Client 就置为 LAST_ACK 状 态。
        Server ---> ACK ---> Client
Server 回应了 ACK ，那么 Client 的套接字才会真正置为 CLOSED 状态。




 
我们的程序处于 CLOSE_WAIT 状态，而不是 LAST_ACK 状 态 ，说明还没有发 FIN 给 Server ，那么可能是在关闭连接之前还有许多数据要发送或者其他事要做，导致没有发这个 FIN packet 。
 
原因知道了，那么为什么不发 FIN 包呢，难道会在关闭己方连接前有那么多事情要做吗？
还有一个问题，为什么有数千个连接都处于这个状态呢？难道那段时间内，服务器端总是主动拆除我们的连接吗？
 
不管怎么样，我们必须防止类似情况再度发生！
首先，我们要防止不断开辟新的 端口 ，这可以通过设置 SO_REUSEADDR 套接字选项做到：
重用本地地址和端口
以前我总是一个端口不行，就换一个新的使用，所以导致让数千个端口进入 CLOSE_WAIT 状态。如果下次还发生这种尴尬状况，我希望加一个限定，只是当前这个端口处于 CLOSE_WAIT 状态！
在调用
sockConnected = socket(AF_INET, SOCK_STREAM, 0);
之后，我们要设置该套接字的选项来重用：
/// 允许重用本地地址和端口:
/// 这样的好处是，即使socket断了，调用前面的socket函数也不会占用另一个，而是始终就是一个端口
/// 这样防止socket始终连接不上，那么按照原来的做法，会不断地换端口。
int nREUSEADDR = 1;
setsockopt(sockConnected,
              SOL_SOCKET,
              SO_REUSEADDR,
              (const char *)&nREUSEADDR,
              sizeof (int ));
教科书上是这么说的：这样，假如服务器关闭或者退出，造成本地地址和端口都处于 TIME_WAIT 状态，那么 SO_REUSEADDR 就显得非常有用。
也许我们无法避免被冻结在 CLOSE_WAIT 状态永远不出现，但起码可以保证不会占用新的端口。
其次，我们要设置 SO_LINGER 套接字选项：
从容关闭还是强行关闭？
LINGER 是“拖延”的意思。
默认情况下 (Win2k) ， SO_DONTLINGER 套接字选项的是 1 ； SO_LINGER 选项是， linger 为 {l_onoff ： 0 ， l_linger ： 0} 。
如果在发送数据的过程中 (send() 没有完成，还有数据没发送 ) 而调用了 closesocket() ，以前我们一般采取的措施是“从容关闭 ”：
因为在退出服务或者每次重新建立 socket 之前，我都会先调用
/// 先将双向的通讯关闭
     shutdown(sockConnected, SD_BOTH);
     /// 安全起见，每次建立Socket连接前，先把这个旧连接关闭
closesocket(sockConnected);
 
我们这次要这么做：
设置 SO_LINGER 为零（亦即 linger 结构中的 l_onoff 域设为非零，但 l_linger 为 0 ） ，便不用担心 closesocket 调用进入“锁定”状态（等待完成），不论是否有排队数据未发送或未被确认。这种关闭方式称为“强行关闭”，因为套接字的虚电路立即被复位，尚未发出的所有数据都会丢失。在远端的 recv() 调用都会失败，并返回 WSAECONNRESET 错误。
在 connect 成功建立连接之后设置该选项：
linger m_sLinger;
m_sLinger.l_onoff = 1;  // ( 在closesocket()调用,但是还有数据没发送完毕的时候容许逗留)
m_sLinger.l_linger = 0; // ( 容许逗留的时间为0秒)
setsockopt(sockConnected,
         SOL_SOCKET,
         SO_LINGER,
         (const char *)&m_sLinger,
         sizeof (linger));
 
总结
也许我们避免不了 CLOSE_WAIT 状态冻结的再次出现，但我们会使影响降到最小，希望那个重用套接字选项能够使得下一次重新建立连接时可以把 CLOSE_WAIT 状态踢掉。
Feedback
# 回复：[Socket]尴尬的CLOSE_WAIT状态以及应对策略 2005-01-30 3:41 PM yun.zheng 
回复人： elssann(臭屁虫和他的开心果) ( ) 信誉：51 2005-01-30 14:00:00 得分: 0

我的意思是：当一方关闭连接后，另外一方没有检测到，就导致了CLOSE_WAIT的出现，上次我的一个朋友也是这样，他写了一个客户端和 APACHE连接，当APACHE把连接断掉后，他没检测到，出现了CLOSE_WAIT，后来我叫他检测了这个地方，他添加了调用 closesocket的代码后，这个问题就消除了。 
如果你在关闭连接前还是出现CLOSE_WAIT,建议你取消shutdown的调用，直接两边closesocket试试。

另外一个问题:
比如这样的一个例子： 
当客户端登录上服务器后，发送身份验证的请求，服务器收到了数据，对客户端身份进行验证，发现密码错误，这时候服务器的一般做法应该是先发送一个密码错误的信息给客户端，然后把连接断掉。
如果把 
m_sLinger.l_onoff = 1; 
m_sLinger.l_linger = 0; 
这样设置后，很多情况下，客户端根本就收不到密码错误的消息，连接就被断了。
 
# 回复：[Socket]尴尬的CLOSE_WAIT状态以及应对策略 2005-01-30 3:41 PM yun.zheng 
elssann(臭屁虫和他的开心果) ( ) 信誉：51 2005-01-30 13:24:00 得分: 0

出现CLOSE_WAIT的原因很简单，就是某一方在网络连接断开后，没有检测到这个错误，没有执行closesocket，导致了这个状态的实现，这在TCP/IP协议的状态变迁图上可以清楚看到。同时和这个相对应的还有一种叫TIME_WAIT的。
另外，把SOCKET的SO_LINGER设置为0秒拖延（也就是立即关闭）在很多时候是有害处的。 
还有，把端口设置为可复用是一种不安全的网络编程方法。
 

# 回复：[Socket]尴尬的CLOSE_WAIT状态以及应对策略 2005-01-30 3:42 PM yun.zheng 
elssann(臭屁虫和他的开心果) ( ) 信誉：51 2005-01-30 14:48:00 得分: 0

能不能解释请看这里 
http://blog.csdn.net/cqq/archive/2005/01/26/269160.aspx
 
再看这个图：
http://tech.ccidnet.com/pub/attachment/2004/8/322252.png
断开连接的时候， 
当发起主动关闭的左边这方发送一个FIN过去后，右边被动关闭的这方要回应一个ACK，这个ACK是TCP回应的，而不是应用程序发送的，此时，被动关闭的一方就处于CLOSE_WAIT状态了。如果此时被动关闭的这一方不再继续调用closesocket,那么他就不会发送接下来的FIN，导致自己老是处于CLOSE_WAIT。只有被动关闭的这一方调用了closesocket,才会发送一个FIN给主动关闭的这一方，同时也使得自己的状态变迁为LAST_ACK。
 

# 回复：[Socket]尴尬的CLOSE_WAIT状态以及应对策略 2005-01-30 3:54 PM yun.zheng 
elssann(臭屁虫和他的开心果) ( ) 信誉：51 2005-01-30 15:39:00 得分: 0

比如被动关闭的是客户端。。。
当对方调用closesocket的时候，你的程序正在
int nRet = recv(s,....); 
if (nRet == SOCKET_ERROR) 
{ 
// closesocket(s); 
return FALSE; 
}
很多人就是忘记了那句closesocket，这种代码太常见了。
我的理解，当主动关闭的一方发送FIN到被动关闭这边后，被动关闭这边的TCP马上回应一个ACK过去，同时向上面应用程序提交一个ERROR，导致上面的SOCKET的send或者recv返回SOCKET_ERROR，正常情况下，如果上面在返回SOCKET_ERROR后调用了 closesocket,那么被动关闭的者一方的TCP就会发送一个FIN过去，自己的状态就变迁到LAST_ACK.
 

# 回复：[Socket]尴尬的CLOSE_WAIT状态以及应对策略 2005-01-30 4:17 PM yun.zheng 
int nRecvBufLength = 
recv(sockConnected, 
szRecvBuffer, 
sizeof(szRecvBuffer), 
0); 
/// zhengyun 20050130: 
/// elssann举例说，当对方调用closesocket的时候，我的程序正在 
/// recv，这时候有可能对方发送的FIN包我没有收到，而是由TCP代回了 
/// 一个ACK包，所以我这边程序进入CLOSE_WAIT状态。 
/// 所以他建议在这里判断是否已出错，是就主动closesocket。 
/// 因为前面我们已经设置了recv超时时间为30秒，那么如果真的是超时了， 
/// 这里收到的错误应该是WSAETIMEDOUT，这种情况下也可以关闭连接的 
if (nRecvBufLength == SOCKET_ERROR) 
{ 
TRACE_INFO(_T("=用recv接收发生Socket错误=")); 
closesocket(sockConnected); 
continue; 
}
这样可以吗？ 
网络连接无法释放—— CLOSE_WAIT
关键字： TCP ，CLOSE_WAIT, Java, SocketChannel
 
问题描述： 最近性能测试碰到的一个问题。客户端使用NIO，服务器还是一般的Socket连接。当测试进行一段时间以后，发现服务器端的系统出现大量未释放的网络连接。用netstat -na查看，连接状态为CLOSE_WAIT。这就奇怪了，为什么Socket已经关闭而连接依然未释放。
 
解决： Google了半天，发现关于CLOSE_WAIT的问题一般是C的，Java似乎碰到这个问题的不多（这有一篇 不错的，也是解决CLOSE_WAIT的，但是好像没有根本解决，而是选择了一个折中的办法）。接着找，由于使用了NIO，所以怀疑可能是这方面的问题，结果找到了这篇 。顺着帖子翻下去，其中有几个人说到了一个问题—— 一端的Socket调用close后，另一端的Socket没有调用close .于是查了一下代码，果然发现Server端在某些异常情况时，没有关闭Socket。改正后问题解决。
时间基本上花在Google上了，不过也学到不少东西。下面为一张TCP连接的状态转换图：
 



 
说明：虚线和实线分别对应服务器端(被连接端)和客户端端(主动连接端)。
结合上图使用netstat -na命令即可知道到当前的TCP连接状态。一般LISTEN、ESTABLISHED、TIME_WAIT是比较常见。
 
分析：
上面我碰到的这个问题主要因为TCP的结束流程未走完，造成连接未释放。现设客户端主动断开连接，流程如下
 
       Client                            消息                                    Server
         close()
                                      ------ FIN ------->
        FIN_WAIT1                                                         CLOSE_WAIT
                                      <----- ACK -------
        FIN_WAIT2 
                                                                                  close()
                                       <------ FIN ------                     
        TIME_WAIT                                                       LAST_ACK      
                                      ------ ACK ------->  
                                                                                   CLOSED
           CLOSED
 
如上图所示，由于Server的Socket在客户端已经关闭时而没有调用关闭，造成服务器端的连接处在“挂起”状态，而客户端则处在等待应答的状态上。此问题的典型特征是：一端处于FIN_WAIT2 ，而另一端处于CLOSE_WAIT . 不过，根本问题还是程序写的不好，有待提高。

TIME_WAIT状态
根据TCP协议，主动发起关闭的一方，会进入TIME_WAIT状态，持续2*MSL(Max Segment Lifetime)，缺省为240秒，在这个post 中简洁的介绍了为什么需要这个状态。
值得一说的是，对于基于TCP的HTTP协议，关闭TCP连接的是Server端，这样，Server端会进入TIME_WAIT状态，可想而知，对于访问量大的Web Server，会存在大量的TIME_WAIT状态，假如server一秒钟接收1000个请求，那么就会积压240*1000=240，000个 TIME_WAIT的记录，维护这些状态给Server带来负担。当然现代操作系统都会用快速的查找算法来管理这些TIME_WAIT，所以对于新的 TCP连接请求，判断是否hit中一个TIME_WAIT不会太费时间，但是有这么多状态要维护总是不好。
HTTP协议1.1版规定default行为是Keep-Alive，也就是会重用TCP连接传输多个 request/response，一个主要原因就是发现了这个问题。还有一个方法减缓TIME_WAIT压力就是把系统的2*MSL时间减少，因为 240秒的时间实在是忒长了点，对于Windows，修改注册表，在HKEY_LOCAL_MACHINE/ SYSTEM/CurrentControlSet/Services/ Tcpip/Parameters上添加一个DWORD类型的值TcpTimedWaitDelay，一般认为不要少于60，不然可能会有麻烦。
对于大型的服务，一台server搞不定，需要一个LB(Load Balancer)把流量分配到若干后端服务器上，如果这个LB是以NAT方式工作的话，可能会带来问题。假如所有从LB到后端Server的IP包的 source address都是一样的(LB的对内地址），那么LB到后端Server的TCP连接会受限制，因为频繁的TCP连接建立和关闭，会在server上留下TIME_WAIT状态，而且这些状态对应的remote address都是LB的，LB的source port撑死也就60000多个(2^16=65536,1~1023是保留端口，还有一些其他端口缺省也不会用），每个LB上的端口一旦进入 Server的TIME_WAIT黑名单，就有240秒不能再用来建立和Server的连接，这样LB和Server最多也就能支持300个左右的连接。如果没有LB，不会有这个问题，因为这样server看到的remote address是internet上广阔无垠的集合，对每个address，60000多个port实在是够用了。
一开始我觉得用上LB会很大程度上限制TCP的连接数，但是实验表明没这回事，LB后面的一台Windows Server 2003每秒处理请求数照样达到了600个，难道TIME_WAIT状态没起作用？用Net Monitor和netstat观察后发现，Server和LB的XXXX端口之间的连接进入TIME_WAIT状态后，再来一个LB的XXXX端口的 SYN包，Server照样接收处理了，而是想像的那样被drop掉了。翻书，从书堆里面找出覆满尘土的大学时代买的《UNIX Network Programming, Volume 1, Second Edition: Networking APIs: Sockets and XTI》，中间提到一句，对于BSD-derived实现，只要SYN的sequence number比上一次关闭时的最大sequence number还要大，那么TIME_WAIT状态一样接受这个SYN，难不成Windows也算BSD-derived?有了这点线索和关键字 (BSD)，找到这个post ，在NT4.0的时候，还是和BSD-derived不一样的，不过Windows Server 2003已经是NT5.2了，也许有点差别了。
做个试验，用Socket API编一个Client端，每次都Bind到本地一个端口比如2345，重复的建立TCP连接往一个Server发送Keep-Alive=false 的HTTP请求，Windows的实现让sequence number不断的增长，所以虽然Server对于Client的2345端口连接保持TIME_WAIT状态，但是总是能够接受新的请求，不会拒绝。那如果SYN的Sequence Number变小会怎么样呢？同样用Socket API，不过这次用Raw IP，发送一个小sequence number的SYN包过去，Net Monitor里面看到，这个SYN被Server接收后如泥牛如海，一点反应没有，被drop掉了。
按照书上的说法，BSD-derived和Windows Server 2003的做法有安全隐患，不过至少这样至少不会出现TIME_WAIT阻止TCP请求的问题，当然，客户端要配合，保证不同TCP连接的sequence number要上涨不要下降。
分享到： 
上一篇：诡异：bind()函数出现WSAEFAULT（10014） 错误
下一篇：Top 10 Programming Fonts

 
查看评论

  暂无评论

您还没有登录,请[登录]或[注册]
* 以上用户言论只代表其个人观点，不代表CSDN网站的观点或立场

个人资料
  
zkx928
 

访问：3993次
积分：238分
排名：千里之外
原创：15篇转载：34篇译文：0篇评论：1条
文章搜索

文章分类
wince(1)
WTL 库(1)
C/C++(26)
STL(1)
c++ 库(1)
网络编程(8)
编程(9)
算法(1)
数据库(0)
其他(5)
Windows Process(0)
Windows c(0)
Windows Process Communication(2)
Win(0)
Windows(13)
MFC(2)
shlapi(1)
调试(2)
linux(2)
设计模式(2)
UML(0)
金山开源学习(1)
备用(0)
文章存档
2013年09月(5)
2013年08月(18)
2013年07月(6)
2012年12月(13)
2012年11月(5)
展开
阅读排行
关于wince 网口的远程桌面(327)
TCP客户端 长连接策略(306)
转VC各种问题(178)
Windows线程生灭 (一)(152)
初识WTL(151)
C/C++网络编程中的TCP保活(147)
诡异：bind()函数出现WSAEFAULT（10014） 错误(116)
系统托盘编程完全指南（二）(111)
Top 10 Programming Fonts(110)
系统托盘编程完全指南（一）(103)
评论排行
关于wince 网口的远程桌面(1)
动态库导出类-----practice(0)
线程间数据交换算法，有效避免锁竞争 -- TwoQueues(0)
CSDN six code search engine(0)
调试过程所遇问题汇集(0)
socket 五种模型理解之一---------select模型(0)
动态库两种调用(0)
经验随手记录(0)
类的设计原则--OOD(0)
linux kernel note(0)
推荐文章

最新评论
关于wince 网口的远程桌面
zkx928: 有个缺点就是，连接时间长了。wince 工控版莫名的给断网了。求解中...
公司简介|招贤纳士|广告服务|银行汇款帐号|联系方式|版权声明|法律顾问|问题报告
QQ客服 微博客服 论坛反馈 联系邮箱：webmaster@csdn.net 服务热线：400-600-2320
京 ICP 证 070598 号
北京创新乐知信息技术有限公司 版权所有
世纪乐知(北京)网络技术有限公司 提供技术支持
江苏乐知网络技术有限公司 提供商务支持
Copyright © 1999-2012, CSDN.NET, All Rights Reserved 
  
========== http://blog.enjoydiy.com/2011/10/464.html ==========
========== http://zh.wikipedia.org/wiki/Wikipedia:%E9%A6%96%E9%A1%B5 ==========
========== http://www.talaland.com/ ==========
========== http://blog.zephyrleaves.net/ ==========
装逼程序员
Coding For Fun
首页 关于我 给我留言

如何做Xcode工程的工程化管理
2013年9月9日淘宝文通3条评论
有感于我厂某iOS项目的开发管理混乱,所以这里说一下我这边对Xcode工程的一些管理经验

如果开发人数很多,且负责不同的部分和组件的话,可以用子Project的方式或者Workspace+多个Project的方式来分割功能和组件
由于project.pbxproj这个文件很容易发生冲突(比如新增文件,删除文件,改变Build Setting等都会改变这个文件),且很难合并冲突,那么采用多Project的方式可以降低project.pbxproj冲突的机会,而一些公用的代码或组件也可以放在一个Project中,然后其他Project来依赖这个公用的Project就可以搞定了

使用CocoaPods管理第三方的组件和类库
至于什么是CocoaPods,可以看这篇文章 http://blog.zephyrleaves.net/?p=712

使用CocoaPods可以极大减少对依赖包的管理成本,现在AppCode 2.5已经开始原生支持CocoaPods了,Xcode上也有对CocosPods的支持插件 https://github.com/ricobeck/KFCocoaPodsPlugin

对于需要打出不同渠道或不同测试环境的包,可以通过Build Configuration来进行区分
在Xcode项目->Project->Info->Configurations下面可以点+号添加自定义的Build Configuration(默认只有Release和Debug),然后针对不同的渠道和环境配置不同的Build Setting,当然一些渠道的配置也可以走XCCONFIG的方式进行配置,不过我还是建议走Build Configuration,因为这样很容易配置Scheme

用Scheme来配置打包对应的Build Configuration 以及 执行 对应的 Build Configuration
由于不同渠道和环境通过Build Configuration来进行区分配置,那么执行和打包的入口就需要由Scheme来进行管理,特别是在使用CocoaPods管理的情况下,整个工程是用workspace来进行管理的 ,这个时候使用xcodebuild的时候就必须指定Scheme了

在Manage Schemes下面,可以创建多个Scheme(默认应该有一个对应Target的一个Scheme),在Edit Scheme里面可以设置不同Action(Run/Test/Profile/Analyze/Archive)对应的Build Configuration是啥,我这边是一个Build Configuration对于一个Scheme,这样很方便

由于Scheme都是放在个人的userdata下面的,所以在Manage Schemes下面对Scheme选中Shared,那么这些Scheme就可以被共享给团队的其他成员看到并使用了

使用xcodebuild命令打包
由于一般情况下可能需要对多个渠道打出多个app包,如果对每个渠道都先clean在archive需要多个操作,实际上如上有配置对应渠道的Scheme后,可以用xcodebuild命令一次打出过个包来,比如:

xcodebuild -workspace XXX.xcworkspace -scheme XXX clean archive 
xcodebuild -workspace XXX.xcworkspace -scheme XXX_91 clean archive
写这样一个shell,就可以一次打出2个archive了

OK,上面这些都是我管理Xcode工程的一些经验,如果大家有更好的一些实践的话,都可以来告诉我哦

分类: 技术标签: CocoaPods, iOS, Objective-C, Xcode, 无线
使用CocoaPods进行Xcode的项目依赖管理
2013年7月17日淘宝文通暂无评论
什么是CocoaPods
CocoaPods是Xcode上的一个依赖管理工具

CocoaPods有点像Java领域的Maven.当然它并不是作为构建工具存在的,构建还是由Xcode来负责,CocoaPods主要负责了各个类库的依赖管理,而且强大的是它还有自己的资源库..而且对比Maven它的依赖管理更加灵活,可以直接依赖本地的库或者自定义依赖一个git上的库.这点和Gradle很像

阅读全文…

分类: 技术标签: CocoaPods, Objective-C, Xcode, 无线
利用dwarfdump分析线上iOS Crash Log
2013年5月3日淘宝文通1条评论
线上的CrashLog利用UserTrack的搜集的话一般都无法识别,比如

3   XXX                          0x00126adf XXX + 1006303
4   XXX                          0x0005ff49 XXX + 192329
5   Foundation                          0x33a864a1 <redacted> + 460
6   CoreFoundation                      0x331438f7 <redacted> + 14
7   CoreFoundation                      0x331431f3 <redacted> + 362
那么怎么去识别这种CrashLog呢?

Mac提供了一个dwarfdump的小工具来解析这种CrashLog,需要dSYM的配合

利用dwarfdump --lookup=ADDRESS DSYMFILE 的方式查找crash出错的地址在DSYM文件中的代码段

我这里提供一个Python的小工具,直接输入address offset(就是上面的堆栈里+号后面的那个数字),生成一个可读的堆栈

#!/usr/bin/python
# wentong@taobao.com
# 13-5-3
#
import optparse
import os

DSYM = ""


def map_hex(x):
    return """dwarfdump --lookup=%s %s|grep -E "start_addr:|Line table file:";echo -------------------; """ % (
        hex(0x00001000 + int(x)), DSYM)


def add(x, y):
    return x + y


if __name__ == '__main__':
    parser = optparse.OptionParser()
    parser.add_option("-l", "--list", dest="list",
                      help="addresses of the backtrace")

    parser.add_option("-d", "--dsym", dest="dsym",
                      help="the file of dSYM")

    (options, args) = parser.parse_args()
    if options.list is not None and options.dsym is not None:
        DSYM = options.dsym
        alist = map(map_hex, options.list.split(','))
        command = reduce(add, alist)
        # print command
        os.system(command)
        pass
    else:
        parser.print_help()
使用方法就是

iOSCrashAnalyza.py
-l1067213,1006303,192329,11307 -d/Users/zephyrleaves/crash/XXX.app.dSYM
其中l后面就是跟 3 XXX 0x00126adf XXX + 1006303 这行中的1006303 这个数字

直接输出

Line table file: 'XXXX.m' line 74, column 56 with start address 0x00000000001058bc
    start_addr: 0x0010581c YYYY
-------------------
Line table file: 'AAAA.m' line 182, column 5 with start address 0x00000000000f6aae
    start_addr: 0x000f659c -[AAAA BBBB:]
-------------------
Line table file: 'CCCC.m' line 2028, column 2 with start address 0x000000000002ff48
    start_addr: 0x0002fef8 -[CCCC DDDD]
-------------------
Line table file: 'main.m' line 16, column 51 with start address 0x0000000000003bf6
    start_addr: 0x00003be4 main
-------------------
这样的可读的堆栈了

分类: 技术标签: Objective-C, Python, 无线
TDH_Socket近期的一些更新
2013年3月1日淘宝文通暂无评论
更新了连接分配算法,能使连接平均的分配到io线程上,让io线程发挥最大效果
支持了Between操作
优化了 show processlists的输出 能看到当前执行线程 正在执行那个ip的客户端发过来的 多少id的请求
支持 TC Malloc
修复了一些bug
大家可以在https://github.com/alibaba/TDH_Socket 下载试用

最近更新的功能还在develop分支上哦,别看错了

分类: 技术标签: C/C++,
========== http://blog.pluskid.org/ ==========
Loading [MathJax]/jax/element/mml/jax.js
HOME
ABOUT
ARCHIVES
LINKS
Free Mind
We are drowning in information and starving for knowledge.
CommentsPosts

 
  
 
All My Blogs
New Blog (since 2012)
Old Blog (before 2009)
Categories
Bugs (10)
Develop (14)
Life (41)
Machine Learning (30)
Mathematics (4)
Tool (27)
Calendar
October 2013
M	T	W	T	F	S	S
« Jun
 	 
 	1	2	3	4	5	6
7	8	9	10	11	12	13
14	15	16	17	18	19	20
21	22	23	24	25	26	27
28	29	30	31	 
Tags
Active Learning AutoHotkey Book Bug Clustering Computer Vision Drawing Emacs Erlang Fun Game Google GreaseMonkey Information Retrieval Javascript Kernel Language Model LaTeX Learning Theory Life Linux Manifold Math Matlab MSTC Multiclass Learning Network Open Source Optimization Photo Probability Python Ruby Supervised Learning Support Vector Machine Thinkpad Thought Tip Tool Translate Unsupervised Learning Vim Wordpress YASnippet zju
Yet Another New Blog
 by pluskid, on 2012-06-11, in Life     6 comments
记得最开始写的那个 blog 也是在大概两年之后换的，就是现在这个 blog 。不过当时之所以换是因为原来帮我 host blog 的朋友他们的主机要停止使用了，在 DH 新搭了 blog 但是懒得从旧版本的 wordpress 费力导入新版本，于是就分开了两个 blog ，旧的不发新帖，只供访问。

现在一晃又两年，正好又搭了一个新 blog ：http://freemind.pluskid.org ，测试了几天，目前已经有几篇文章了。是用 Static Blog Generator 搭建起来的，所以 comments 之类的都是用的外部服务。Static Blogging 有好处也有坏处，所以我现在也还没有决定是否直接切换过去。这个 blog 我会继续维护，但是暂时可能不会在这里发新文章了，如果我用了一段时间 static blogging 感觉没法用下去的话，可能又会切换回这里。如果有带来不便请见谅！^_^目前已经切换到那边了，当然这个 blog 也会继续开放中，只是不会在这里发布新文章了。

Tags: Blog
Multiclass Learning with ECOC
 by pluskid, on 2012-05-24, in Machine Learning     12 comments
ECOC 是 Error-Correcting Output Codes 的缩写。上一篇文章中提到 ECOC 可以用来将 Multiclass Learning 问题转化为 Binary Classification 问题，本文中我们将对这个方法进行介绍。

要了解 ECOC ，可以从 One-vs-Rest 的 Multiclass Learning 策略出发。回忆一下，对于一个 K 类的分类问题，One-vs-Rest 策略为每一个类 都训练一个 binary classifier ，用于区分“类别 i” 和“非类别 i”两类。对于这个策略，可以用下面这样一个图来表示（假设我们有四个类）：

这个表中，每一行代表一个类，而每一列代表一个 binary classifier ，其中表格内的元素表示该列所对应的 binary 问题中，该行所对应的类别的数据被当作正例还是负例。例如，第一列表示该 binary classifier 是通过把第一类当作正类 (+1) ，剩余的第二、三、四类当作负类 (-1) 而训练出来的。如此类推。

现在我们将这个表格称作 ECOC codebook ，而把表格的列数称作是 ECOC 的 code length L ，并且不再要求 L 和类别数 K 相等。在 codebook 中，每个类别会对应一个长度为 L 的 code 。例如，在刚才的例子中，第一类所对应的 code 为 +1-1-1-1 ，第四类所对应的 code 为 -1-1-1+1 。

» Continue reading Multiclass Learning with ECOC

Tags: Multiclass Learning, Supervised Learning
Google 代码之夏，Multiclass Learning
 by pluskid, on 2012-05-14, in Machine Learning     27 comments
虽然各种大小事情和死线依旧是蜂拥而来，但是我想这个假期我“Officially”应该是主要在做 Google Summer of Code 。因为难得的很长的假期，以后又更少有机会回家了，所以理所当然的要呆在家里，但是为了避免一个假期过后荒废得最后连数字都不会数了，我又一直苦恼在家里应该做些什么事情——必须要是有外力来强制进度的事情，否则毫无疑问地会慢慢荒废掉，因为家里本就是一个适合休息堕落的环境呀。最后想到 GSoC 的时候突然眼睛一亮：这不就是为我这种情况量身定做的吗？！

将军 (Shogun) 是众多项目中我比较感兴趣的一个。因为肯定是希望做跟机器学习相关的项目呀，所以实际上 shogun 是项目列表里最相关的一个了。简单地来说就是用 C++ 写的一个机器学习算法库，里面实现了各种常用的算法，并且把许多著名的算法（像 LibSVM、LibLinear、Vowpal Wabbit 等）也都统一的包装起来，然后再提供了各种语言像 Matlab、Python、R 等下面的接口供方便调用。

不过虽然我以前也见到过 Shogun ，但是却并没有实际用过。以前见到这个名字的时候还以为是日本人写的库（因为 Shogun 是日语单词“将军”呀），后来了解了一下才发现实际上是有德国的 Max Planck Institute (MPI) 里的一个组发起的项目（这个 MPI 里有好多机器学习非常强的组呢！），而这个略奇怪的名字实际上是由最初的两个作者 Soeren Sonnenburg 和 Gunnar Raetsch 的名字的开头 So 和 Gun 拼起来再变化得到的。但是究竟是如何查到这个日语单词的呢？嗯，也许是 Google 了一下看到 wikipedia 的页面了吧……不过，Soeren 说你可以给 Shogun 画个好看点的 logo 的……许多年前参加 GSoC 的时候也被叫给当时的项目画了个 Logo ，不过这次就真的完全没有想法了啊，其实我觉得就这样用汉字做 logo 也挺不错的。

» Continue reading Google 代码之夏，Multiclass Learning

Tags: Multiclass Learning, Open Source, Supervised Learning
关于留学申请的一些注意事项
 by pluskid, on 2012-03-23, in Life     52 comments
据说先报一下申请结果可以提高点击率：

Offer：MIT (2.10, CSAIL), UW (1.30)
AD: OSU (3.15, funding to be decided)
Withdraw：Cornell, UCLA, GaTech, TTIC, UCSD, Rutgers, UAlberta, WUSL, OSU, UToronto, UMich
Reject：Stanford (2.11), CMU (2.4 Stat SML, 2.11 CSD, 2.14 MLD), Princeton (2.18), UToronto (2.25), UC Berkeley (3.7), UCLA (2.22, 3.8), Cornell (3.12), UPenn (3.22)
背景大致是这样的：ZJU CS 本硕(本科 GPA 3.7)，G 1390+3.5, T 110(口语 23), 无交流无实习，有 top 会议和期刊论文(但是没有一作)，导师 strongly recommend ，申请方向是机器学习和学习理论。

这里对自己的申请过程做一些总结，希望对后来的同学有一些帮助。但是自己一直不是很喜欢所谓的“经验之谈”，因为大部分情况下一个人把一件事情做好了这其实只是一个非常个例的情况，他自己总结出来的东西并不一定是导致他所取得的成果所必需的，或者甚至是起相反作用的；而且即使别人总结的有道理，也并不一定可以照搬，许多时候只有自己摸索出来的路才是真正适合自己的。所以我在这里说的东西，除了一些客观的事实（例如关于 TOEFL 两年有效期的问题等），其他的都请各位仅供参考。 

» Continue reading 关于留学申请的一些注意事项

Tags: Tip
留学申请注意事项：英语考试
 by pluskid, on 2012-03-23, in Life     One comment


GT 其实没有太多可说的，我个人一直觉得 GT 属于比较鸡肋的条件：只要过了一定的线以后就变得不那么重要了。我参加的是老 G （就是那次 ETS 搞的万恶的 11G），一年只有两次，所以报名上时间也要计划好，但是现在新 G 貌似一年有很多次，所以时间上应该也问题不大了。我是先考 T 再考 G 的，这个感觉怎么都无所谓，看自己喜欢了。总之“不那么重要”并不是说不重要，认真考出好成绩总是没有坏处的，复习过程可能会有些漫长，特别是背 GRE 的单词，虽然有点痛苦，但是并不是百无一用，取决于你以后要过什么样的生活，实际上我个人觉得 GRE 中的大部分单词其实还是非常常用的，例如在英美的报刊杂志新闻之类的地方。当然有一个不得不承认的事实就是：在考完试之后大部分单词会被迅速遗忘掉。TOEFL 的话，复习用 Official Guide + TPO 吧！关于 GT 考试两个很好的论坛就是太傻和寄托家园。上面还有许多其他有用的资料，例如《太傻十日谈》是一本很有意思的书（虽然我没看完…… -.-），还有可以找到各大学校的《飞跃手册》之类的都是对整个申请过程有非常大的参考价值的（目前比较新且内容比较全的应该是《北大飞跃手册第二版》和《上交飞跃手册 2010~2011 版》吧），不过也要选择性吸收，例如许多飞跃手册上关于 GT 送分还是讲的电话甚至寄信给 ETS 的送分方式，实际上现在在网上送分已经非常方便了。

关于 TOEFL 要多说几句的是它的过期时间是两年。然而就像一兆可以是 1000000 也可以是 1048576 一样，这个“两年”的解释上也有各种“猫腻”。主要的分歧在于从何时开始算。我所期望的，是从提交网申的那个时间开始算，例如我申请 2012Fall ，提交网申的时间大概是在 2011 年 11 月左右，那么我只要在 2009 年 11 月之后考的 T 都应该是有效的。事实上大部分学校都是这样算的，然而有些学校则是按照入学时间来算的，2012 Fall 的入学时间通常是 2012 年 9 月，也就是说必须在 2010 年 9 月之后考的 T 才是有效的。比较悲剧的是我的 T 是在 2010 年 4 月考的，而我发现这个情况的时候已经非常晚了，而且即使早了我肯定也不想考第二次的吧！有些学校明确说了有效期的计算方法，有些学校说得模模糊糊，有些学校则完全没提，为了保险起见，我发邮件到所有我关注的学校去确认了一圈。这个应该是比所谓的最低分要求更加严格的限制，比如 Berkeley 明确说了如果超过了他们算法的有效期，那么即使 ETS 把分数送过来了他们也是不接受的。在我看过的学校里，有 Berkeley、Stanford、UIUC、WISC、USC 和 UMass 是悲剧了的。结果我后来强申了 Berkeley 和 Stanford ，然后被拒了，当然被拒的理由大概也不止因为 T 的有效期吧。录取过程中的各种未知因素，作为学生来说可就无从得知了。

当然像我这种考得太晚的情况估计算是比较反常的吧…… =.=bb 大部分人应该是会担心考得太晚的问题。这个我没有太多的经验，不过一般情况下是可以和小蜜沟通的，不要晚太多就好。另外 ETS 送分速度非常不稳定，两天到几个月都有可能，我都是在 deadline 前一个月送的，没有出什么问题。而且如果分数已经有了，只是 ETS 送得缓慢的话，大部分学校都可以先把成绩扫描版上传上去作为 unofficial 成绩供对方审材料的时候用。

Tags: Tip
留学申请注意事项：选校
 by pluskid, on 2012-03-23, in Life     11 comments
选校一般是在 GT 之后。我大致是在 2011 年暑假快结束的时候开始看学校的，一开始也比较悠哉，但是到后面就开始有些紧张了，最好做好计划，因为比如每天看一个学校的话，看 20 个学校也要花掉大半个月的。实际上选校这个事情的建议是越早越好，或者可以分成几个阶段来，因为很多步骤其实都会依赖于你要申请哪几个学校。



比如知道去哪里的话，考试也有针对性了，例如去欧洲的话一般要考雅思而不是托福，而加拿大有不少学校似乎是不要 GRE 的，另外 MIT 的 EECS 其实也是不需要 GRE 成绩的。

再比如在考 GT 的时候会有 4 所免费送分的学校，如果事先有看过学校的话（只要大致知道自己肯定会申的 4 个学校就好了），就很好填了，G 和 T 每个学校送一次分都要 100+ 米的，所以还是要好好利用的。我就比较悲剧，考 G 的时候随便填了几个，后来申请的时候搞晕了结果又把那几个重新送了一次；考 T 的时候以为可以后面申请的时候再填结果就留空了，然后后来发现留空了就相当于放弃了免费送分的名额……

还有就是办理成绩单的时候，因为这也是一件比较麻烦的事情——特别是在高峰期的时候。知道自己要申多少学校的话，就好一次办好了。不过到这个阶段就需要更仔细一些的选校了，一方面要把学校列表确定下来，另一方面还得看看各个学校关于成绩单的要求：有个别学校是要求寄两份成绩单的，还有更多的学校并不需要寄成绩单，只要上传扫描版就可以了，纸质版成绩单可以在拿到 offer 之后再寄过去。

» Continue reading 留学申请注意事项：选校

Tags: Tip, Tool
留学申请注意事项：文书
 by pluskid, on 2012-03-23, in Life     4 comments
申请过程中的文书一般就是指 PS (Personal Statement) （或者 SoP：Statement of Purpose）和 CV ，这里重点说一下 PS 吧。

PS 重不重要呢？我觉得是非常重要的。当然说他重要并不是说其他条件都很水仅靠一篇金光闪闪的 PS 就能帮你拿到牛校 offer ，而是说 PS 是申请的时候学生唯一一个比较灵活地表现自己能力的机会。举个不太恰当的例子，就好比在沙漠里一壶水之所以重要并不是说有了这壶水你就能活着走出去，而是因为这壶水是你生存下去唯一可以倚仗的东西。

除了 CV 之外，其他的材料（成绩单、GT 等等）每个人都是同一个“模样”的，但是 CV 要求简洁（一般建议不超过一页），所以可以传达的信息并不是很多，Statement 则一般可以写到两页纸的文字，是表现自己 uniqueness 的唯一机会，uniqueness 就是指你和其他的申请者所不同的地方，这么多申请者，别人为什么选择你？当然“我一顿饭能吃八两”、“我左手长了六个指头”之类的虽然也可称为“独特之处”，但是肯定就不用写上去了，阅读你 PS 的人想看的是什么，不妨换位思考一下，自己站在他们的位置上想一想就大致明白了。或者可以具体来实践一下，比如你想买个什么东西（比如出国装行李用的 28 寸拉杆箱），然后上淘宝去搜索一下，然后可能你会通过价格、销量、信誉、地域等条件筛选出一个候选店铺列表来，之后就点进去看这些店铺的宝贝介绍页面——这个页面的内容就相当于我们申请的时候的 PS 了！你在浏览这些页面的时候有没有发现某个店铺让你眼前一亮的感觉呢？或者你可能会觉得这些页面其实都大同小异——因为本来就是公开可见的，大家互相抄袭模仿咯。然而 PS 虽然并不是公开可见的，但是其实绝大部分人都是按照网上找得到的那些建议、模板来写或者由那些中介之类的来修改，最后一样的会造成这个效果。我觉得在浏览淘宝购物页面的时候这种心情和教授挑学生的时候的感觉应该是比较相似的——特别是通过 RA 的方式，要由教授出钱来“买”这个学生的时候，所以我们自己多体验一下这个过程，应该也会对我们准备自己的文书准备工作产生一些启发吧！

» Continue reading 留学申请注意事项：文书

Tags: Tip
留学申请注意事项：网申与推荐信
 by pluskid, on 2012-03-23, in Life     6 comments
网申付款和送 GRE 成绩的时候都需要一张双币信用卡，应该正常一点的双币卡都可以吧，比如建行的浙大龙卡就挺好用的，没有出任何问题。TOEFL 送分由于是国内的一个网站，好像只能工行（还是哪个行？）的网银付账。另外网申是一件非常麻烦和痛苦的事情，要填各种各样乱七八糟的东西，注意事项大概以下几点吧：

大部分学校的网申系统都并不是要求你一次填完提交的，可以填一半保持了以后再慢慢填，我大部分学校基本上都是前前后后磨蹭了大半个月才提交。
有些学校对于没有填完的 form 有差不多一个月的保存时间，要注意看，不要等拖太久了它给你删了你又得辛辛苦苦重新填。
有些学校（比如 CMU）号称是你付款提交之后才会去帮你去整理匹配你送过去的成绩单和 GT 成绩之类的，所以为了有时间能确认寄过去的东西有没有收到，以及各种奇怪的意外问题，最好不要拖到最后一天才提交吧。比如在比较后面我才突然发现 CMU 的 TOEFL 成绩我居然忘了寄了。
大部分系统在提交之后就不能修改了，所以请再三确认。不过有的学校（比如 Columbia、CMU、MIT）在提交之后还是可以修改信息的。还有一些学校只可以修改部分信息。不过如果万一真的有问题的话，也可以联系小蜜，一般也可以帮忙修改的，特别是在 deadline 还没有过的情况下。
申请的学校多的话，密码是一个问题，全都用同一个密码倒也可以，但是有时候有些系统对密码有特殊要求，比如必须要同时有字母和数字啊，或者必须要有符号啊，如果两个网站的要求不一样的话，就不好统一了。还有许多学校是用的同一个网申系统的。如果觉得乱的话，可以用个密码管理器什么的，比如 LastPass 。
有时候说不定会有惊喜，比如 UAlberta 的网申，我照例拖了很久之后有一天突然收到一封 Email 说我们可以给你把申请费给免了，你只要点第三方支付，然后找谁谁谁就可以了。虽然不知道是怎么回事，但是总之是好事哈！ 
如果申请的学校比较多的话，建议用 Excel （或者任何方便使用的工具）做一下详细的进度跟踪和记录，否则很容易混淆或者遗漏了。

» Continue reading 留学申请注意事项：网申与推荐信

Tags: Tip
留学申请注意事项：陶瓷
 by pluskid, on 2012-03-23, in Life     One comment
申请阶段最后一个话题就是陶瓷了。陶瓷有没有用这几乎是一个永恒的争论，对于这个问题我的答案简单来说是“我不知道”，这里我只陈述一下我的想法和经历，具体大家自行判断。一开始我的主要想法是比较负面的，特别是在看到有不少教授在自己主页上或客气或不客气地写明了“请不要发邮件给我询问申请录取的事”、“一切资料都可以在学校网站上找到”、“你需要按照标准流程来提交申请”、“决定是由 committee 做的，给我发邮件并不会增大你被录取的几率”之类的话之后。文字太多了，再插播一幅听起来好像挺切题的图吧：Sasha 的 pottery



除非是那些在主页上写明了正在招生欢迎发邮件的人，否则如果你真的要申请，走正常申请渠道就好了啊，如果对某个老师感兴趣，直接在 SoP 上提到他的名字，他应该就会看到了，而且如果他真的对你感兴趣的话，从系统里看就可以看到你的各种材料，相比你发的邮件来说要全面得多。这个观点实际上是我之前有一个机会同 UMich 的一位教授聊天的时候问起来这样的问题得到的答案。我个人是比较认同这样的观点的。当然有可能出现的情况是初选的时候被不小心刷掉了，根本没到你提到的教授手里？我不知道学校在录取的时候审材料到底是什么样一个认真仔细程度，以及误杀的比例会是多大。但是学校也想招好的学生，所以应该也不会太过于马虎吧？不过我也问过许多许多其他人的意见，大家对待这个问题也各有观点，大多也都比较慎重，不过大部分人都表示“即便没有好处的话，至少也没有坏处吧”。

» Continue reading 留学申请注意事项：陶瓷

Tags: Tip
留学申请注意事项：最终试炼
 by pluskid, on 2012-03-23, in Life     One comment
如果说读 PhD 是一场战争的话，那么等待 offer 的这段时间大概就要算上战场之前的最终试炼了吧。我感觉，这似乎是申请过程中最痛苦难熬的阶段。首先，在前面漫长的紧张忙碌之后突然闲下来了，无事可做了，难免会觉得突然失去了方向一样倍感空虚；与此同时心又是悬着的，在等待结果，却又无法做任何事情来加速这个进程，就有点像有时候喜欢一个人但是却什么都做不了只能等待着等待着那样的痛苦。当然最痛苦的阶段还是真正开始于别人都开始有 offer 了，你还什么都没有或者只有 reject 的时候。一般是很难淡定下来做事情的，还好这段时间一般是寒假过年阶段，在家的时候大可轻松一下，出去找同学亲戚什么的玩一下什么的，每天早上起来查一下邮件就可以了。



» Continue reading 留学申请注意事项：最终试炼

Tags: Tip
   Older Entries »
Comments
Jeffy: 学长，请问下，对于只有两类的Spectrum CLuster, 最小化目标函数 f’Lf也就是最小化RatioCut的值，可是为什么当f是L的第二个特征向量时(第一个特征值是0)，该目标函数就是最小的？
pluskid: OK 没问题
Lian: 前辈，可以转载你的这篇博文吗？
xiao_cao: 你好，请问一下pickle的这些初始数据是怎么生成的
pluskid: MSTC 千秋万代一桶浆糊！
Jinfeng: 学长的blog写的真棒，MSTCer过来帮学长打打气~~
pluskid: 你好！
Ling: 我是阳及的同学，今天通过阳及认识学长。膜拜一下！希望能和学长有深入的交流！
Meta
Log in
Entries RSS
Comments RSS
WordPress.org
License
Except where otherwise noted, content on this site is licensed under a Creative Commons Attribution 3.0 License.
Copyright © 2013 Free Mind - All Rights Reserved
Powered by WordPress & the Atahualpa Theme by BytesForAll. Discuss on our WP Forum
========== http://blog.csdn.net/abcjennifer/article/details/8170687 ==========
========== http://blog.yufeng.info/ ==========
捐赠：喜欢就请我喝一杯
系统技术非业余研究
系统技术深度探索和应用
Home 推荐工作机会 资料下载 留言板 关于我

捐赠：喜欢就请我喝一杯 招聘信息：猛点这里获得淘宝数据库引擎开发工作机会
服务器时间校正思考
August 30th, 2013Yu Feng2 comments
原创文章，转载请注明： 转载自系统技术非业余研究

本文链接地址: 服务器时间校正思考

大部分网络业务服务器都大量用到了时间，比如各种状态机，各种超时，各种取时间戳， 如果机器的挂钟时间发生突变，没有特殊处理的服务器大部分都得挂。好的服务器程序如erlang, nginx等都有time correction机制，我这里就不罗嗦了，直接摘抄erlang的time correction文档，写的很好：

2 Time and time correction in Erlang

Time is vital to an Erlang program and, more importantly, correct time is vital to an Erlang program. As Erlang is a language with soft real time properties and we have the possibility to express time in our programs, the Virtual Machine and the language has to be very careful about what is considered a correct point in time and in how time functions behave.

In the beginning, Erlang was constructed assuming that the wall clock time in the system showed a monotonic time moving forward at exactly the same pace as the definition of time. That more or less meant that an atomic clock (or better) was expected to be attached to your hardware and that the hardware was then expected to be locked away from any human (or unearthly) tinkering for all eternity. While this might be a compelling thought, it’s simply never the case.

A “normal” modern computer can not keep time. Not on itself and not unless you actually have a chip level atomic clock wired to it. Time, as perceived by your computer, will normally need to be corrected. Hence the NTP protocol that together with the ntpd process will do it’s best to keep your computers time in sync with the “real” time in the universe. Between NTP corrections, usually a less potent time-keeper than an atomic clock is used.

But NTP is not fail safe. The NTP server can be unavailable, the ntp.conf can be wrongly configured or your computer may from time to time be disconnected from the internet. Furthermore you can have a user (or even system administrator) on your system that thinks the right way to handle daylight saving time is to adjust the clock one hour two times a year (a tip, that is not the right way to do it…). To further complicate things, this user fetched your software from the internet and has never ever thought about what’s the correct time as perceived by a computer. The user simply does not care about keeping the wall clock in sync with the rest of the universe. The user expects your program to have omnipotent knowledge about the time.

Most programmers also expect time to be reliable, at least until they realize that the wall clock time on their workstation is of by a minute. Then they simply set it to the correct time, maybe or maybe not in a smooth way. Most probably not in a smooth way.

The amount of problems that arise when you expect the wall clock time on the system to always be correct may be immense. Therefore Erlang introduced the “corrected estimate of time”, or the “time correction” many years ago. The time correction relies on the fact that most operating systems have some kind of monotonic clock, either a real time extension or some built in “tick counter” that is independent of the wall clock settings. This counter may have microsecond resolution or much less, but generally it has a drift that is not to be ignored.

So we have this monotonic ticking and we have the wall clock time. Two unreliable times that together can give us an estimate of an actual wall clock time that does not jump around and that monotonically moves forward. If the tick counter has a high resolution, this is fairly easy to do, if the counter has a low resolution, it’s more expensive, but still doable down to frequencies of 50-60 Hz (of the tick counter).

So the corrected time is the nearest approximation of an atomic clock that is available on the computer. We want it to have the following properties:

Monotonic
The clock should not move backwards
Intervals should be near the truth
We want the actual time (as measured by an atomic clock or an astronomer) that passes between two time stamps, T1 and T2, to be as near to T2 – T1 as possible.
Tight coupling to the wall clock
We want a timer that is to be fired when the wall clock reaches a time in the future, to fire as near to that point in time as possible
To meet all the criteria, we have to utilize both times in such a way that Erlangs “corrected time” moves slightly slower or slightly faster than the wall clock to get in sync with it. The word “slightly” means a maximum of 1% difference to the wall clock time, meaning that a sudden change in the wall clock of one minute, takes 100 minutes to fix, by letting all “corrected time” move 1% slower or faster.

Needless to say, correcting for a faulty handling of daylight saving time may be disturbing to a user comparing wall clock time to for example calendar:now_to_local_time(erlang:now()). But calendar:now_to_local_time/1 is not supposed to be used for presenting wall clock time to the user.

Time correction is not perfect, but it saves you from the havoc of clocks jumping around, which would make timers in your program fire far to late or far to early and could bring your whole system to it’s knees (or worse) just because someone detected a small error in the wall clock time of the server where your program runs. So while it might be confusing, it is still a really good feature of Erlang and you should not throw it away using time functions which may give you higher benchmark results, not unless you really know what you’re doing.

2.1 What does time correction mean in my system?

Time correction means that Erlang estimates a time from current and previous settings of the wall clock, and it uses a fairly exact tick counter to detect when the wall clock time has jumped for some reason, slowly adjusting to the new value.

In practice, this means that the difference between two calls to time corrected functions, like erlang:now(), might differ up to one percent from the corresponding calls to non time corrected functions (like os:timestamp()). Furthermore, if comparing calendar:local_time/0 to calendar:now_to_local_time(erlang:now()), you might temporarily see a difference, depending on how well kept your system is.

It is important to understand that it is (to the program) always unknown if it is the wall clock time that moves in the wrong pace or the Erlang corrected time. The only way to determine that, is to have an external source of universally correct time. If some such source is available, the wall clock time can be kept nearly perfect at all times, and no significant difference will be detected between erlang:now/0′s pace and the wall clock’s.

Still, the time correction will mean that your system keeps it’s real time characteristics very well, even when the wall clock is unreliable.

2.2 Where does Erlang use corrected time?

For all functionality where real time characteristics are desirable, time correction is used. This basically means:

erlang:now/0
The infamous erlang:now/0 function uses time correction so that differences between two “now-timestamps” will correspond to other timeouts in the system. erlang:now/0 also holds other properties, discussed later.
receive … after
Timeouts on receive uses time correction to determine a stable timeout interval.
The timer module
As the timer module uses other built in functions which deliver corrected time, the timer module itself works with corrected time.
erlang:start_timer/3 and erlang:send_after/3
The timer BIF’s work with corrected time, so that they will not fire prematurely or too late due to changes in the wall clock time.
All other functionality in the system where erlang:now/0 or any other time corrected functionality is used, will of course automatically benefit from it, as long as it’s not “optimized” to use some other time stamp function (like os:timestamp/0).

Modules like calendar and functions like erlang:localtime/0 use the wall clock time as it is currently set on the system. They will not use corrected time. However, if you use a now-value and convert it to local time, you will get a corrected local time value, which may or may not be what you want. Typically older code tend to use erlang:now/0 as a wall clock time, which is usually correct (at least when testing), but might surprise you when compared to other times in the system.

2.3 What is erlang:now/0 really?

erlang:now/0 is a function designed to serve multiple purposes (or a multi-headed beast if you’re a VM designer). It is expected to hold the following properties:

Monotonic
erlang:now() never jumps backwards – it always moves forward
Interval correct
The interval between two erlang:now() calls is expected to correspond to the correct time in real life (as defined by an atomic clock, or better)
Absolute correctness
The erlang:now/0 value should be possible to convert to an absolute and correct date-time, corresponding to the real world date and time (the wall clock)
System correspondence
The erlang:now/0 value converted to a date-time is expected to correspond to times given by other programs on the system (or by functions like os:timestamp/0)
Unique
No two calls to erlang:now on one Erlang node should return the same value
All these requirements are possible to uphold at the same time if (and only if):

The wall clock time of the system is perfect
The system (Operating System) time needs to be perfectly in sync with the actual time as defined by an atomic clock or a better time source. A good installation using NTP, and that is up to date before Erlang starts, will have properties that for most users and programs will be near indistinguishable from the perfect time. Note that any larger corrections to the time done by hand, or after Erlang has started, will partly (or temporarily) invalidate some of the properties, as the time is no longer perfect.
Less than one call per microsecond to erlang:now/0 is done
This means that at any microsecond interval in time, there can be no more than one call to erlang:now/0 in the system. However, for the system not to loose it’s properties completely, it’s enough that it on average is no more than one call per microsecond (in one Erlang node).
The uniqueness property of erlang:now/0 is the most limiting property. It means that erlang:now() maintains a global state and that there is a hard-to-check property of the system that needs to be maintained. For most applications this is still not a problem, but a future system might very well manage to violate the frequency limit on the calls globally. The uniqueness property is also quite useless, as there are globally unique references that provide a much better unique value to programs. However the property will need to be maintained unless a really subtle backward compatibility issue is to be introduced.

2.4 Should I use erlang:now/0 or os:timestamp/0

The simple answer is to use erlang:now/0 for everything where you want to keep real time characteristics, but use os:timestamp for things like logs, user communication and debugging (typically timer:ts uses os:timestamp, as it is a test tool, not a real world application API). The benefit of using os:timestamp/0 is that it’s faster and does not involve any global state (unless the operating system has one). The downside is that it will be vulnerable to wall clock time changes.

2.5 Turning off time correction

If, for some reason, time correction causes trouble and you are absolutely confident that the wall clock on the system is nearly perfect, you can turn off time correction completely by giving the +c option to erl. The probability for this being a good idea, is very low.

祝玩得开心！

Post Footer automatically generated by wp-posturl plugin for wordpress.

Categories: Erlang探索Tags: time correction
application配置文件和热升级
August 29th, 2013Yu FengNo comments
原创文章，转载请注明： 转载自系统技术非业余研究

本文链接地址: application配置文件和热升级

前面我们一直说过erlang是以app为单位来组织程序，数据，配置等信息，让这些信息聚合在一起成为一个整体，设计上和unix系统一模一样。 那app的配置信息存在哪里呢？

配置信息有三种方式体现(其实是4种)：
1. .app文件里面的env字段, 通常是MyApplication.app， 具体参见这里
2. .config文件，通常是sys.config，具体参见这里
3. 命令行 erl -ApplName Par1 Val1 … ParN ValN 具体参见这里

我们摘抄重要的信息如下：
方式1：

7.8 Configuring an Application

An application can be configured using configuration parameters. These are a list of {Par, Val} tuples specified by a key env in the .app file.

{application, ch_app,
[{description, "Channel allocator"},
{vsn, "1"},
{modules, [ch_app, ch_sup, ch3]},
{registered, [ch3]},
{applications, [kernel, stdlib, sasl]},
{mod, {ch_app,[]}},
{env, [{file, "/usr/local/log"}]}
]}.
Par should be an atom, Val is any term. The application can retrieve the value of a configuration parameter by calling application:get_env(App, Par) or a number of similar functions, see application(3)

方式2：

A configuration file contains values for configuration parameters for the applications in the system. The erl command line argument -config Name tells the system to use data in the system configuration file Name.config.

Configuration parameter values in the configuration file will override the values in the application resource files (see app(4)). The values in the configuration file can be overridden by command line flags (see erl(1)).

The value of a configuration parameter is retrieved by calling application:get_env/1,2.

方式3：

The values in the .app file, as well as the values in a system configuration file, can be overridden directly from the command line:

% erl -ApplName Par1 Val1 … ParN ValN

这三种方式都可以很方便的来设置应用的配置信息，由于一个应用会依赖于其他很多应用，所以会有很多的配置信息，这里我比较推荐sys.config方式，这也是rebar组织配置文件的标准形式。
Read more…

Post Footer automatically generated by wp-posturl plugin for wordpress.

Categories: Erlang探索, 源码分析Tags: application, config_change, env
erlang和其他语言读文件性能大比拼
August 28th, 2013Yu Feng8 comments
原创文章，转载请注明： 转载自系统技术非业余研究

本文链接地址: erlang和其他语言读文件性能大比拼

百岁同学说：

今天公司技术比武，比赛题目是给一个1.1g的大文本，统计文本中词频最高的前十个词。花了两天用erlang写完了代码，但是放到公司16核的机器上这么一跑，结果不比不知道，一比吓一条。erlang写的代码执行时间花了55秒左右，同事们有的用java，有的用C，还有的用C++，用C最快一个老兄只花了2.6秒，用java的也只用了3.2秒。相比之下erlang的代码，真是一头大蜗牛，太慢了。

详细参见这篇文章：http://www.iteye.com/topic/1131748

读取文件并且分析这是很多脚本语言如perl, python,ruby经常会干的事情.这个同学的问题是很普遍的问题，不只一个人反映过慢的问题。
今天我们来重新来修正下这个看法， 我们用数据说话。

首先我们来准备下文件, 这个文件是完全的随机数，有1G大小：

$ dd if=/dev/urandom  of=test.dat count=1024 bs=1024K
1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB) copied, 188.474 s, 5.7 MB/s
$ time dd if=test.dat of=/dev/null
2097152+0 records in
2097152+0 records out
1073741824 bytes (1.1 GB) copied, 1.16021 s, 925 MB/s
 
real    0m1.162s
user    0m0.219s
sys     0m0.941s
$ time dd if=test.dat of=/dev/null bs=1024k
1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB) copied, 0.264298 s, 4.1 GB/s
 
real    0m0.266s
user    0m0.000s
sys     0m0.267s
我们准备了1G大小左右的文件，由于用的是buffered io, 数据在准备好了后，全部缓存在pagecache里面，只要内存足够，这个测试的性能和IO设备无关。 我们试着用dd读取这个文件，如果块大小是4K的话，读取这个文件花了1.16秒，而如果块大小是1M的话，0.26秒，带宽达到4.1GB每秒，远超过真实设备的速度。

那么我们用erlang来读取下这个文件来比较下，我们有三种读法：
1. 一下子读取整个1G文件。
2. 一个线程一次读取1块，比如1M大小，直到读完。
3. 多个线程读取，每个读取一大段，每次读取1M块大小。
然后比较下性能。

首先普及下背景：
1. erlang的文件IO操作由efile driver来提高，这个driver内部有个线程池，大小由+A 参数控制，所以IO是多线程完成的。
2. erlang的文件分二种模式： 1. raw模式 2. io模式 在raw模式下，数据直接由driver提供给调用进程， io模式下数据先经过file_server做格式化，然后再给调用进程。
3. 数据可以以binary和list方式返回，list方式下文件内容的byte就是一个整数，在64位机器上占用8个字节内存。
Read more…

Post Footer automatically generated by wp-posturl plugin for wordpress.

Categories: Erlang探索, Linux, 调优Tags: dd, file, read, thread_pool_size
erlang关键的环境变量
August 23rd, 2013Yu FengNo comments
原创文章，转载请注明： 转载自系统技术非业余研究

本文链接地址: erlang关键的环境变量

Erlang新增全面的系统信息收集器-system_information模块 这个模块列出来以下的环境变量，对系统运行非常关键，你都了解吗？

+%% get known useful erts environment
+
+os_getenv_erts_specific() ->
+ os_getenv_erts_specific([
+ "BINDIR",
+ "DIALYZER_EMULATOR",
+ "CERL_DETACHED_PROG",
+ "EMU",
+ "ERL_CONSOLE_MODE",
+ "ERL_CRASH_DUMP",
+ "ERL_CRASH_DUMP_NICE",
+ "ERL_CRASH_DUMP_SECONDS",
+ "ERL_EPMD_PORT",
+ "ERL_EMULATOR_DLL",
+ "ERL_FULLSWEEP_AFTER",
+ "ERL_LIBS",
+ "ERL_MALLOC_LIB",
+ "ERL_MAX_PORTS",
+ "ERL_MAX_ETS_TABLES",
+ "ERL_NO_VFORK",
+ "ERL_NO_KERNEL_POLL",
+ "ERL_THREAD_POOL_SIZE",
+ "ERLC_EMULATOR",
+ "ESCRIPT_EMULATOR",
+ "HOME",
+ "HOMEDRIVE",
+ "HOMEPATH",
+ "LANG",
+ "LC_ALL",
+ "LC_CTYPE",
+ "PATH",
+ "PROGNAME",
+ "RELDIR",
+ "ROOTDIR",
+ "TERM",
+ %"VALGRIND_LOG_XML",
+
+ %% heart
+ "COMSPEC",
+ "HEART_COMMAND",
+
+ %% run_erl
+ "RUN_ERL_LOG_ALIVE_MINUTES",
+ "RUN_ERL_LOG_ACTIVITY_MINUTES",
+ "RUN_ERL_LOG_ALIVE_FORMAT",
+ "RUN_ERL_LOG_ALIVE_IN_UTC",
+ "RUN_ERL_LOG_GENERATIONS",
+ "RUN_ERL_LOG_MAXSIZE",
+ "RUN_ERL_DISABLE_FLOWCNTRL",
+
+ %% driver getenv
+ "CALLER_DRV_USE_OUTPUTV",
+ "ERL_INET_GETHOST_DEBUG",
+ "ERL_EFILE_THREAD_SHORT_CIRCUIT",
+ "ERL_WINDOW_TITLE",
+ "ERL_ABORT_ON_FAILURE",
+ "TTYSL_DEBUG_LOG"
+ ]).

翻文档吧，都是很有意思的控制参数。

祝玩得开心！

Post Footer automatically generated by wp-posturl plugin for wordpress.

Categories: Erlang探索, 源码分析Tags: getenv
再谈crashdump产生注意事项
August 23rd, 2013Yu FengNo comments
原创文章，转载请注明： 转载自系统技术非业余研究

本文链接地址: 再谈crashdump产生注意事项

在前面的博文里面，我们提到了crashdump的作用, 以及看门狗heart的工作原理，我们可以在程序crash后，让heart看门狗重新帮我们拉起来。

这里有几个问题需要注意：
1. 看门狗检查失效的时间，默认是65秒。
2. erlang系统在crash的时候会记录crashdump, 操作系统会产生coredump, 这个时间到底是多长。

代码证明如下：

/* heart.c */
...
/*  Maybe interesting to change */
/* Times in seconds */
#define  HEART_BEAT_BOOT_DELAY       60  /* 1 minute */
#define  SELECT_TIMEOUT               5  /* Every 5 seconds we reset the                                                 
                                            watchdog timer */
 
/* heart_beat_timeout is the maximum gap in seconds between two                                                          
   consecutive heart beat messages from Erlang, and HEART_BEAT_BOOT_DELAY                                                
   is the the extra delay that wd_keeper allows for, to give heart a                                                     
   chance to reboot in the "normal" way before the hardware watchdog                                                     
   enters the scene. heart_beat_report_delay is the time allowed for reporting                                           
   before rebooting under VxWorks. */
 
int heart_beat_timeout = 60;
int heart_beat_report_delay = 30;
int heart_beat_boot_delay = HEART_BEAT_BOOT_DELAY;
...
这二个时间都会影响系统重新启动的间隔时间。
而crashdump的dump文件名、dump时间和优先级由下面几个变量来控制：

ERL_CRASH_DUMP
If the emulator needs to write a crash dump, the value of this variable will be the file name of the crash dump file. If the variable is not set, the name of the crash dump file will be erl_crash.dump in the current directory.

ERL_CRASH_DUMP_NICE
Unix systems: If the emulator needs to write a crash dump, it will use the value of this variable to set the nice value for the process, thus lowering its priority. The allowable range is 1 through 39 (higher values will be replaced with 39). The highest value, 39, will give the process the lowest priority.

ERL_CRASH_DUMP_SECONDS
Unix systems: This variable gives the number of seconds that the emulator will be allowed to spend writing a crash dump. When the given number of seconds have elapsed, the emulator will be terminated by a SIGALRM signal.

If the environment variable is not set or it is set to zero seconds, ERL_CRASH_DUMP_SECONDS=0, the runtime system will not even attempt to write the crash dump file. It will just terminate.

If the environment variable is set to negative valie, e.g. ERL_CRASH_DUMP_SECONDS=-1, the runtime system will wait indefinitely for the crash dump file to be written.

This environment variable is used in conjuction with heart if heart is running:

ERL_CRASH_DUMP_SECONDS=0
Suppresses the writing a crash dump file entirely, thus rebooting the runtime system immediately. This is the same as not setting the environment variable.

ERL_CRASH_DUMP_SECONDS=-1
Setting the environment variable to a negative value will cause the termination of the runtime system to wait until the crash dump file has been completly written.

ERL_CRASH_DUMP_SECONDS=S
Will wait for S seconds to complete the crash dump file and then terminate the runtime system.

如果我们不想产生coredump 可以透过 -env ERL_CRASH_DUMP_SECONDS 0 来关掉，避免产生dump时间过长的悲剧。同时每次crashdump产生的文件名相同，可以在启动通过 -env ERL_CRASH_DUMP erl_crash_date_time.dump 来修改，避免覆盖掉。

祝玩得开心！

Post Footer automatically generated by wp-posturl plugin for wordpress.

Categories: Erlang探索, 源码分析Tags: crashdump
Erlang heart – 高可靠性的最后防线
August 23rd, 2013Yu FengNo comments
原创文章，转载请注明： 转载自系统技术非业余研究

本文链接地址: Erlang heart – 高可靠性的最后防线

我们写的程序不可能都没有bug, 都存在crash的危险。很多时候我们需要个看门狗(watchdog)程序，在发现系统不正常的时候，就把系统重新启动。这类watchdog程序从内核到各种高可用程序都会设置有一个。erlang系统当然不能免俗，也会有几个heart.

我们来看下流程和效果：

$ export HEART_COMMAND="erl -heart"
$ erl -heart
heart_beat_kill_pid = 12640
Erlang R15B03 (erts-5.9.3.1) 1 [64-bit] [smp:16:16] [async-threads:0] [hipe] [kernel-poll:false]
 
Eshell V5.9.3.1  (abort with ^G)
1> os:getpid().
"12640"
2>
CTRL + Z 挂起erlang
$ pstree -p
…
+-beam.smp(12640)-+-heart(12670)
| | | |-{beam.smp}(12647)
| | | |-{beam.smp}(12648)
| | | |-{beam.smp}(12650)
| | | |-{beam.smp}(12653)
| | | |-{beam.smp}(12654)
| | | |-{beam.smp}(12655)
| | | |-{beam.smp}(12656)
| | | |-{beam.smp}(12657)
| | | |-{beam.smp}(12658)
| | | |-{beam.smp}(12659)
| | | |-{beam.smp}(12660)
| | | |-{beam.smp}(12661)
| | | |-{beam.smp}(12662)
| | | |-{beam.smp}(12663)
| | | |-{beam.smp}(12664)
| | | |-{beam.smp}(12665)
| | | |-{beam.smp}(12666)
| | | |-{beam.smp}(12667)
| | | |-{beam.smp}(12668)
| | | `-{beam.smp}(12669)
| | `-pstree(13702)
…

$ heart: Fri Aug 23 20:36:25 2013: heart-beat time-out, no activity for 65 seconds
heart_beat_kill_pid = 27920

我们看到erl重新被启动起来了。 现在简单的分析下原理：
heart由2部份组成：1. 外部程序: heart 2. erlang port模块: heart.erl

当开启heart的时候（erl – heart …) 外部程序heart被erlang模块heart.erl作为独立的进程启动起来，监视emulator的运作. heart.erl 每隔一定的时间向heart外部程序报告状态。当外部heart没有监测到心跳的时候就要采取行动, 重新运行$HEART_COMMAND所指定的命令。
Read more…

Post Footer automatically generated by wp-posturl plugin for wordpress.

Categories: Erlang探索, 源码分析Tags: heart
application之染色特性分析和应用
August 18th, 2013Yu FengNo comments
原创文章，转载请注明： 转载自系统技术非业余研究

本文链接地址: application之染色特性分析和应用

我们知道典型的erlang虚拟机里面会运行好多application，这些app互相依赖，相互协作，形成一个生态圈。典型场景见下图：



每个app里面都会有很多进程，这些进程为这个app负责，会有些共同特性。那么这些进程如何区分出来属于哪个app的呢？就像我们伟大的祖国，有56个民族一样，这些民族都有自己的文化、服饰，甚至相貌，一看就和其他族群不太一样。他们的基因里面就携带了某种东西，这些东西子子孙孙传下去，一直保持下去。那么同样的，每个app里面的进程就和我们人，一样也会生老病死，也会有生命周期。他们是靠什么来识别的呢？ 典型的application里面有很多层次的进程，通常成树状，和我们人类的组织差不多，见下图：



我们先来看下application的文档和关键的几个函数：

which_applications() -> [{Application, Description, Vsn}]
Returns a list with information about the applications which are currently running. Application is the application name. Description and Vsn are the values of its description and vsn application specification keys, respectively.

示例如下：

1> application:which_applications().
[{os_mon,"CPO CXC 138 46","2.2.9"},
{sasl,"SASL CXC 138 11","2.2.1"},
{stdlib,"ERTS CXC 138 10","1.18.3"},
{kernel,"ERTS CXC 138 10","2.15.3"}]

我们可以看到我们运行的几个app的名字，版本号，描述等基本信息，再细节的就没有了。那第一，二个图中的这些信息是哪里来的呢？

Read more…

Post Footer automatically generated by wp-posturl plugin for wordpress.

Categories: Erlang探索, 源码分析Tags: application, get_application, group_leader
Older Entries
RSS
Twitter
buy me a coffee.

广告时间
Erlang调优指南编写中, 请留下宝贵意见
淘宝核心系统数据库组招募高手！
工作机会
招聘信息：猛点这里获得工作机会
Recent Posts
服务器时间校正思考
application配置文件和热升级
erlang和其他语言读文件性能大比拼
erlang关键的环境变量
再谈crashdump产生注意事项
Recent Comments
Heaven on erlang和其他语言读文件性能大比拼
网络栈内存不足引发进程挂起问题 | 系统技术非业余研究 – 码农们的博客 on systemtap观察page_cache的使用情况
网络栈内存不足引发进程挂起问题 | 系统技术非业余研究 – 码农们的博客 on 用systemtap来修改下linux内核变量的值
Categories
Erlang探索
Linux
了解系列
体系结构
工具介绍
数据库
杂七杂八
源码分析
生活
网络编程
调优
Blogroll
book and man
Erlang中国
MySQL专家丁奇
一工(BohuTANG)博客
伯松的blog
剑川个人博客
叔度博客(nginx专家)
小天后的图像处理博客
庆亮的博客
彭爷MySQL研究博客
我的旧非业余研究
斯巴达第二季
日照分布式存储
李子非主流程序员
武藏个人博客
淘宝千石的博客
淘宝数据库组
淘宝核心系统博客
瀚海星空
皓庭Erlang开发博客
祁奚个人博客
老婆的交互式音乐
苏普的MySQL故事博客
运维和开发-hoterran
阿里巴巴技术协会
雕梁nginx和内核
项仲个人博客
Archives
August 2013
July 2013
June 2013
May 2013
April 2013
March 2013
February 2013
January 2013
December 2012
October 2012
September 2012
August 2012
July 2012
June 2012
May 2012
April 2012
March 2012
February 2012
January 2012
December 2011
November 2011
October 2011
September 2011
July 2011
June 2011
May 2011
April 2011
March 2011
February 2011
January 2011
December 2010
November 2010
October 2010
September 2010
August 2010
July 2010
June 2010
May 2010
April 2010
March 2010
February 2010
January 2010
November 2009
October 2009
September 2009
August 2009
Meta
Log in
TopWordPress
Copyright © 2009-2013 系统技术非业余研究
Theme by NeoEase. Valid XHTML 1.1 and CSS 3.
========== https://code.google.com/p/concurrentlinkedhashmap/wiki/Design ==========
My favorites ▼ | Sign in
 	
concurrentlinkedhashmap
A ConcurrentLinkedHashMap for Java
  
Project HomeDownloadsWikiIssuesSource
Search   for    
Design  
The algorithmic design of a concurrent linked hash map. 
Featured Updated Oct 20, 2012
Introduction
LinkedHashMap provides a convenient data structure that maintains the ordering of entries within the hash-table. This is accomplished by cross-cutting the hash-table with a doubly-linked list, so that entries can be removed or reordered in O(1) time. When operating in access-order an entry is retrieved, unlinked, and relinked at the tail of the list. The result is that the head element is the least recently used and the tail element is the most recently used. When bounded, this class becomes a convenient LRU cache.



The problem with this approach is that every access operation requires updating the list. To function in a concurrent setting the entire data structure must be synchronized. 

Lock Amortization
An alternative approach is to realize that the data structure can be split into two parts: a synchronous view and an asynchronous view. The hash-table must be synchronous from the perspective of the caller so that a read after a write returns the expected value. The list, however, does not have any visible external properties.

This observation allows the operations on the list to be applied lazily by buffering them. This allows threads to avoid needing to acquire the lock and the buffer can be drained in a non-blocking fashion. Instead of incurring lock contention, the penalty of draining the buffer is amortized across threads. This drain must be performed when either the buffer exceeds a threshold size or a write is performed.



Scalable Buffers
A single buffer provides FIFO semantics so that a drain applies each operation in the correct order. However, a single buffer can become a point of contention as the concurrency level increases.

The usage of multiple buffers improves concurrency at the cost of no longer maintaining order. This can be resolved by tagging each operation with an id and sorting the operations prior to applying them. To avoid the counter from causing contention, it can be racy to allow duplicate ids. The combination of counting sort and closed addressing reduces the runtime cost to an O(n) sort.



Out-of-Order Processing
To allow better concurrency characteristics, the operations may be processed out-of-order. However, doing so could result in a corrupted state such as by processing the removal prior to the addition of an entry. A simple state machine allows for resolving these race conditions so that a strict ordering is not required.

State	Description
Alive	 The entry is in both the hash-table and the page replacement policy
Retired	 The entry is not in the hash-table and is pending removal from the page replacement policy
Dead	 The entry is not in the hash-table and is not in the page replacement policy
Beyond LRU
The least recently used policy provides a good reference point. It does not suffer degradation scenarios as the cache size increases, it provides a reasonably good hit rate, and can be implemented with O(1) time complexity.

However, an LRU policy only utilizes the recency of an entry and does not take advantage of its frequency. The low inter-reference recency set replacement policy does, while also maintaining the same beneficial characteristics. This allows improving the hit rate at a very low cost.

An additional advantage of LIRS is that the strictness of draining the buffers can be loosened. By leveraging frequency to make up for a weakened recency constraint, the pending operations do not need to be drain in a sorted order. This allows for reducing the amortized penalty at a minimal impact to the hit rate.

Weighted Values
A cache may decide to allow the the capacity consumed by an entry to differ between them. For example, a cache that limits by memory usage may have entries that take up more space than others. This is called the weight of the entry.

If all entries are assigned a weight of 1 then the LIRS policy can be taken advantage of. Unfortunately, this policy does not work well with weighted entries due to constantly resizing its internal data structures.

If weights are specified then the cache can degrade to an LRU policy to maintain a satisfactory hit rate. Alternatively, the greedy dual size frequency policy can be used which takes into account the weight when determining which entry to evict.

Towards MapMaker
ConcurrentLinkedHashMap has been used to prove out these ideas in isolation, but our long-term goal is to bring them into Google's MapMaker. In our initial efforts towards that we began seeing other usages for lock amortization.

Expiration is a perfect fit. In a time-to-idle policy the entry's time window is reset on every access. This can be viewed as a an LRU policy where the constraint is a time bounding instead of the maximum size. If an access-ordered list is maintained then both constraints can be applied. Similarly a time-to-live policy can be cleaned up during the drain process.

The cleanup of entries that were invalidated due to soft and weak garbage collection can be amortized on user threads during the draining process. This allows making the background thread optional, which may be useful for eager cleanup during inactivity but not always allowed by the SecurityManager.

References
BP-Wrapper: A System Framework Making Any Replacement Algorithms (Almost) Lock Contention Free

Flat Combining and the Synchronization-Parallelism Tradeoff

Scalable Flat-Combining Based Synchronous Queues

LIRS: An Efﬁcient Low Inter-reference Recency Set Replacement Policy to Improve Buffer Cache Performance

The Performance Impact of Kernel Prefetching on Buffer Cache Replacement Algorithms

Improving WWW Proxies Performance with Greedy-Dual-Size-Frequency Caching Policy

Terms - Privacy - Project Hosting Help
Powered by Google Project Hosting
========== http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/collect/MapMaker.html ==========
OverviewPackageClassUseTreeDeprecatedIndexHelp Prev ClassNext ClassFramesNo FramesAll ClassesSummary: Nested | Field | Constr | MethodDetail: Field | Constr | Method
com.google.common.collect
Class MapMaker

java.lang.Object
com.google.common.collect.GenericMapMaker<Object,Object>
com.google.common.collect.MapMaker

@GwtCompatible(emulated=true)
public final class MapMaker
extends GenericMapMaker<Object,Object>
A builder of ConcurrentMap instances having any combination of the following features:

keys or values automatically wrapped in weak or soft references
notification of evicted (or otherwise removed) entries
on-demand computation of values for keys not already present
Usage example:

   ConcurrentMap<Request, Stopwatch> timers = new MapMaker()
       .concurrencyLevel(4)
       .weakKeys()
       .makeMap();
These features are all optional; new MapMaker().makeMap() returns a valid concurrent map that behaves similarly to a ConcurrentHashMap.

The returned map is implemented as a hash table with similar performance characteristics to ConcurrentHashMap. It supports all optional operations of the ConcurrentMap interface. It does not permit null keys or values.

Note: by default, the returned map uses equality comparisons (the equals method) to determine equality for keys or values. However, if weakKeys() was specified, the map uses identity (==) comparisons instead for keys. Likewise, if weakValues() or softValues() was specified, the map uses identity comparisons for values.

The view collections of the returned map have weakly consistent iterators. This means that they are safe for concurrent use, but if other threads modify the map after the iterator is created, it is undefined which of these changes, if any, are reflected in that iterator. These iterators never throw ConcurrentModificationException.

If weakKeys(), weakValues(), or softValues() are requested, it is possible for a key or value present in the map to be reclaimed by the garbage collector. Entries with reclaimed keys or values may be removed from the map on each map modification or on occasional map accesses; such entries may be counted by Map.size(), but will never be visible to read or write operations. A partially-reclaimed entry is never exposed to the user. Any Map.Entry instance retrieved from the map's entry set is a snapshot of that entry's state at the time of retrieval; such entries do, however, support Map.Entry.setValue(V), which simply calls Map.put(K, V) on the entry's key.

The maps produced by MapMaker are serializable, and the deserialized maps retain all the configuration properties of the original map. During deserialization, if the original map had used soft or weak references, the entries are reconstructed as they were, but it's not unlikely they'll be quickly garbage-collected before they are ever accessed.

new MapMaker().weakKeys().makeMap() is a recommended replacement for WeakHashMap, but note that it compares keys using object identity whereas WeakHashMap uses Object.equals(java.lang.Object).

Since:
2.0 (imported from Google Collections Library)
Author:
Bob Lee, Charles Fry, Kevin Bourrillion
Constructor Summary

Constructors 
Constructor and Description
MapMaker()
Constructs a new MapMaker instance with default settings, including strong keys, strong values, and no automatic eviction of any kind.
Method Summary

Methods 
Modifier and Type	Method and Description
MapMaker	concurrencyLevel(int concurrencyLevel)
Guides the allowed concurrency among update operations.
MapMaker	initialCapacity(int initialCapacity)
Sets the minimum total size for the internal hash tables.
<K,V> ConcurrentMap<K,V>	makeMap()
Builds a thread-safe map, without on-demand computation of values.
MapMaker	softValues()
Deprecated. 
Caching functionality in MapMaker has been moved to CacheBuilder, with softValues() being replaced by CacheBuilder.softValues(). Note that CacheBuilder is simply an enhanced API for an implementation which was branched from MapMaker. This method is scheduled for deletion in September 2014.
String	toString()
Returns a string representation for this MapMaker instance.
MapMaker	weakKeys()
Specifies that each key (not value) stored in the map should be wrapped in a WeakReference (by default, strong references are used).
MapMaker	weakValues()
Specifies that each value (not key) stored in the map should be wrapped in a WeakReference (by default, strong references are used).
Methods inherited from class java.lang.Object
clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait
Constructor Detail

MapMaker
public MapMaker()
Constructs a new MapMaker instance with default settings, including strong keys, strong values, and no automatic eviction of any kind.
Method Detail

initialCapacity
public MapMaker initialCapacity(int initialCapacity)
Sets the minimum total size for the internal hash tables. For example, if the initial capacity is 60, and the concurrency level is 8, then eight segments are created, each having a hash table of size eight. Providing a large enough estimate at construction time avoids the need for expensive resizing operations later, but setting this value unnecessarily high wastes memory.
Specified by:
initialCapacity in class GenericMapMaker<Object,Object>
Throws:
IllegalArgumentException - if initialCapacity is negative
IllegalStateException - if an initial capacity was already set
concurrencyLevel
public MapMaker concurrencyLevel(int concurrencyLevel)
Guides the allowed concurrency among update operations. Used as a hint for internal sizing. The table is internally partitioned to try to permit the indicated number of concurrent updates without contention. Because assignment of entries to these partitions is not necessarily uniform, the actual concurrency observed may vary. Ideally, you should choose a value to accommodate as many threads as will ever concurrently modify the table. Using a significantly higher value than you need can waste space and time, and a significantly lower value can lead to thread contention. But overestimates and underestimates within an order of magnitude do not usually have much noticeable impact. A value of one permits only one thread to modify the map at a time, but since read operations can proceed concurrently, this still yields higher concurrency than full synchronization. Defaults to 4.
Note: Prior to Guava release 9.0, the default was 16. It is possible the default will change again in the future. If you care about this value, you should always choose it explicitly.

Specified by:
concurrencyLevel in class GenericMapMaker<Object,Object>
Throws:
IllegalArgumentException - if concurrencyLevel is nonpositive
IllegalStateException - if a concurrency level was already set
weakKeys
@GwtIncompatible(value="java.lang.ref.WeakReference")
public MapMaker weakKeys()
Specifies that each key (not value) stored in the map should be wrapped in a WeakReference (by default, strong references are used).
Warning: when this method is used, the resulting map will use identity (==) comparison to determine equality of keys, which is a technical violation of the Map specification, and may not be what you expect.

Specified by:
weakKeys in class GenericMapMaker<Object,Object>
Throws:
IllegalStateException - if the key strength was already set
See Also:
WeakReference
weakValues
@GwtIncompatible(value="java.lang.ref.WeakReference")
public MapMaker weakValues()
Specifies that each value (not key) stored in the map should be wrapped in a WeakReference (by default, strong references are used).
Weak values will be garbage collected once they are weakly reachable. This makes them a poor candidate for caching; consider softValues() instead.

Warning: when this method is used, the resulting map will use identity (==) comparison to determine equality of values. This technically violates the specifications of the methods containsValue, remove(Object, Object) and replace(K, V, V), and may not be what you expect.

Specified by:
weakValues in class GenericMapMaker<Object,Object>
Throws:
IllegalStateException - if the value strength was already set
See Also:
WeakReference
softValues
@Deprecated
@GwtIncompatible(value="java.lang.ref.SoftReference")
public MapMaker softValues()
Deprecated. Caching functionality in MapMaker has been moved to CacheBuilder, with softValues() being replaced by CacheBuilder.softValues(). Note that CacheBuilder is simply an enhanced API for an implementation which was branched from MapMaker. This method is scheduled for deletion in September 2014.
Specifies that each value (not key) stored in the map should be wrapped in a SoftReference (by default, strong references are used). Softly-referenced objects will be garbage-collected in a globally least-recently-used manner, in response to memory demand.
Warning: in most circumstances it is better to set a per-cache maximum size instead of using soft references. You should only use this method if you are well familiar with the practical consequences of soft references.

Warning: when this method is used, the resulting map will use identity (==) comparison to determine equality of values. This technically violates the specifications of the methods containsValue, remove(Object, Object) and replace(K, V, V), and may not be what you expect.

Specified by:
softValues in class GenericMapMaker<Object,Object>
Throws:
IllegalStateException - if the value strength was already set
See Also:
SoftReference
makeMap
public <K,V> ConcurrentMap<K,V> makeMap()
Builds a thread-safe map, without on-demand computation of values. This method does not alter the state of this MapMaker instance, so it can be invoked again to create multiple independent maps.
The bulk operations putAll, equals, and clear are not guaranteed to be performed atomically on the returned map. Additionally, size and containsValue are implemented as bulk read operations, and thus may fail to observe concurrent writes.

Specified by:
makeMap in class GenericMapMaker<Object,Object>
Returns:
a serializable concurrent map having the requested features
toString
public String toString()
Returns a string representation for this MapMaker instance. The exact form of the returned string is not specificed.
Overrides:
toString in class Object
Returns:
a string representation of the object.
OverviewPackageClassUseTreeDeprecatedIndexHelp Prev ClassNext ClassFramesNo FramesAll ClassesSummary: Nested | Field | Constr | MethodDetail: Field | Constr | Method
Copyright © 2010-2013. All Rights Reserved.
========== http://www.ibm.com/developerworks/cn/java/java-lo-concurrenthashmap/index.html?ca=drs- ==========

登录 (或注册)
中文
IBM

技术主题
软件下载
社区
技术讲座
  
打印本页面用电子邮件发送本页面新浪微博人人网腾讯微博搜狐微博网易微博DiggFacebookTwitterDeliciousLinked In
developerWorks 中国技术主题Java technology文档库
探索 ConcurrentHashMap 高并发性的实现机制
ConcurrentHashMap 是 Java concurrent 包的重要成员。本文将结合 Java 内存模型，来分析 ConcurrentHashMap 的 JDK 源代码。通过本文，读者将了解到 ConcurrentHashMap 高并发性的具体实现机制。这对于我们在实际应用中更加高效的使用它是很有帮助的。
 评论：
程 晓明 (abccheng@hotmail.com), 软件工程师
2011 年 5 月 25 日

内容
简介
ConcurrentHashMap 是 util.concurrent 包的重要成员。本文将结合 Java 内存模型，分析 JDK 源代码，探索 ConcurrentHashMap 高并发的具体实现机制。
由于 ConcurrentHashMap 的源代码实现依赖于 Java 内存模型，所以阅读本文需要读者了解 Java 内存模型。同时，ConcurrentHashMap 的源代码会涉及到散列算法和链表数据结构，所以，读者需要对散列算法和基于链表的数据结构有所了解。
回页首
Java 内存模型
由于 ConcurrentHashMap 是建立在 Java 内存模型基础上的，为了更好的理解 ConcurrentHashMap，让我们首先来了解一下 Java 的内存模型。
Java 语言的内存模型由一些规则组成，这些规则确定线程对内存的访问如何排序以及何时可以确保它们对线程是可见的。下面我们将分别介绍 Java 内存模型的重排序，内存可见性和 happens-before 关系。
重排序
内存模型描述了程序的可能行为。具体的编译器实现可以产生任意它喜欢的代码 -- 只要所有执行这些代码产生的结果，能够和内存模型预测的结果保持一致。这为编译器实现者提供了很大的自由，包括操作的重排序。
编译器生成指令的次序，可以不同于源代码所暗示的“显然”版本。重排序后的指令，对于优化执行以及成熟的全局寄存器分配算法的使用，都是大有脾益的，它使得程序在计算性能上有了很大的提升。
重排序类型包括：
编译器生成指令的次序，可以不同于源代码所暗示的“显然”版本。
处理器可以乱序或者并行的执行指令。
缓存会改变写入提交到主内存的变量的次序。
内存可见性
由于现代可共享内存的多处理器架构可能导致一个线程无法马上（甚至永远）看到另一个线程操作产生的结果。所以 Java 内存模型规定了 JVM 的一种最小保证：什么时候写入一个变量对其他线程可见。
在现代可共享内存的多处理器体系结构中每个处理器都有自己的缓存，并周期性的与主内存协调一致。假设线程 A 写入一个变量值 V，随后另一个线程 B 读取变量 V 的值，在下列情况下，线程 B 读取的值可能不是线程 A 写入的最新值：
执行线程 A 的处理器把变量 V 缓存到寄存器中。
执行线程 A 的处理器把变量 V 缓存到自己的缓存中，但还没有同步刷新到主内存中去。
执行线程 B 的处理器的缓存中有变量 V 的旧值。
Happens-before 关系
happens-before 关系保证：如果线程 A 与线程 B 满足 happens-before 关系，则线程 A 执行动作的结果对于线程 B 是可见的。如果两个操作未按 happens-before 排序，JVM 将可以对他们任意重排序。
下面介绍几个与理解 ConcurrentHashMap 有关的 happens-before 关系法则：
程序次序法则：如果在程序中，所有动作 A 出现在动作 B 之前，则线程中的每动作 A 都 happens-before 于该线程中的每一个动作 B。
监视器锁法则：对一个监视器的解锁 happens-before 于每个后续对同一监视器的加锁。
Volatile 变量法则：对 Volatile 域的写入操作 happens-before 于每个后续对同一 Volatile 的读操作。
传递性：如果 A happens-before 于 B，且 B happens-before C，则 A happens-before C。
回页首
ConcurrentHashMap 的结构分析
为了更好的理解 ConcurrentHashMap 高并发的具体实现，让我们先探索它的结构模型。
ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。HashEntry 用来封装映射表的键 / 值对；Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。
HashEntry 类
HashEntry 用来封装散列映射表中的键值对。在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型。
清单 1.HashEntry 类的定义
 static final class HashEntry<K,V> { 
        final K key;                       // 声明 key 为 final 型
        final int hash;                   // 声明 hash 值为 final 型 
        volatile V value;                 // 声明 value 为 volatile 型
        final HashEntry<K,V> next;      // 声明 next 为 final 型 

        HashEntry(K key, int hash, HashEntry<K,V> next, V value) { 
            this.key = key; 
            this.hash = hash; 
            this.next = next; 
            this.value = value; 
        } 
 }
在 ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。 下图是在一个空桶中依次插入 A，B，C 三个 HashEntry 对象后的结构图：
图 1. 插入三个节点后桶的结构示意图：

注意：由于只能在表头插入，所以链表中节点的顺序和插入的顺序相反。
避免热点域
在 ConcurrentHashMap中，每一个 Segment 对象都有一个 count 对象来表示本 Segment 中包含的 HashEntry 对象的个数。这样当需要更新计数器时，不用锁定整个 ConcurrentHashMap。
Segment 类
Segment 类继承于 ReentrantLock 类，从而使得 Segment 对象能充当锁的角色。每个 Segment 对象用来守护其（成员对象 table 中）包含的若干个桶。
table 是一个由 HashEntry 对象组成的数组。table 数组的每一个数组成员就是散列映射表的一个桶。
count 变量是一个计数器，它表示每个 Segment 对象管理的 table 数组（若干个 HashEntry 组成的链表）包含的 HashEntry 对象的个数。每一个 Segment 对象都有一个 count 对象来表示本 Segment 中包含的 HashEntry 对象的总数。注意，之所以在每个 Segment 对象中包含一个计数器，而不是在 ConcurrentHashMap 中使用全局的计数器，是为了避免出现“热点域”而影响 ConcurrentHashMap 的并发性。
清单 2.Segment 类的定义
 static final class Segment<K,V> extends ReentrantLock implements Serializable { 
        /** 
         * 在本 segment 范围内，包含的 HashEntry 元素的个数
         * 该变量被声明为 volatile 型
         */ 
        transient volatile int count; 

        /** 
         * table 被更新的次数
         */ 
        transient int modCount; 

        /** 
         * 当 table 中包含的 HashEntry 元素的个数超过本变量值时，触发 table 的再散列
         */ 
        transient int threshold; 

        /** 
         * table 是由 HashEntry 对象组成的数组
         * 如果散列时发生碰撞，碰撞的 HashEntry 对象就以链表的形式链接成一个链表
         * table 数组的数组成员代表散列映射表的一个桶
         * 每个 table 守护整个 ConcurrentHashMap 包含桶总数的一部分
         * 如果并发级别为 16，table 则守护 ConcurrentHashMap 包含的桶总数的 1/16 
         */ 
        transient volatile HashEntry<K,V>[] table; 

        /** 
         * 装载因子
         */ 
        final float loadFactor; 

        Segment(int initialCapacity, float lf) { 
            loadFactor = lf; 
            setTable(HashEntry.<K,V>newArray(initialCapacity)); 
        } 

        /** 
         * 设置 table 引用到这个新生成的 HashEntry 数组
         * 只能在持有锁或构造函数中调用本方法
         */ 
        void setTable(HashEntry<K,V>[] newTable) { 
            // 计算临界阀值为新数组的长度与装载因子的乘积
            threshold = (int)(newTable.length * loadFactor); 
            table = newTable; 
        } 

        /** 
         * 根据 key 的散列值，找到 table 中对应的那个桶（table 数组的某个数组成员）
         */ 
        HashEntry<K,V> getFirst(int hash) { 
            HashEntry<K,V>[] tab = table; 
            // 把散列值与 table 数组长度减 1 的值相“与”，
 // 得到散列值对应的 table 数组的下标
            // 然后返回 table 数组中此下标对应的 HashEntry 元素
            return tab[hash & (tab.length - 1)]; 
        } 
 }
下图是依次插入 ABC 三个 HashEntry 节点后，Segment 的结构示意图。
图 2. 插入三个节点后 Segment 的结构示意图：

ConcurrentHashMap 类
ConcurrentHashMap 在默认并发级别会创建包含 16 个 Segment 对象的数组。每个 Segment 的成员对象 table 包含若干个散列表的桶。每个桶是由 HashEntry 链接起来的一个链表。如果键能均匀散列，每个 Segment 大约守护整个散列表中桶总数的 1/16。
清单 3.ConcurrentHashMap 类的定义
 public class ConcurrentHashMap<K, V> extends AbstractMap<K, V> 
        implements ConcurrentMap<K, V>, Serializable { 

    /** 
     * 散列映射表的默认初始容量为 16，即初始默认为 16 个桶
     * 在构造函数中没有指定这个参数时，使用本参数
     */ 
    static final 	 int DEFAULT_INITIAL_CAPACITY= 16; 

    /** 
     * 散列映射表的默认装载因子为 0.75，该值是 table 中包含的 HashEntry 元素的个数与
 * table 数组长度的比值
     * 当 table 中包含的 HashEntry 元素的个数超过了 table 数组的长度与装载因子的乘积时，
 * 将触发 再散列
     * 在构造函数中没有指定这个参数时，使用本参数
     */ 
    static final float DEFAULT_LOAD_FACTOR= 0.75f; 

    /** 
     * 散列表的默认并发级别为 16。该值表示当前更新线程的估计数
     * 在构造函数中没有指定这个参数时，使用本参数
     */ 
    static final int DEFAULT_CONCURRENCY_LEVEL= 16; 

    /** 
     * segments 的掩码值
     * key 的散列码的高位用来选择具体的 segment 
     */ 
    final int segmentMask; 

    /** 
     * 偏移量
     */ 
    final int segmentShift; 

    /** 
     * 由 Segment 对象组成的数组
     */ 
    final Segment<K,V>[] segments; 

    /** 
     * 创建一个带有指定初始容量、加载因子和并发级别的新的空映射。
     */ 
    public ConcurrentHashMap(int initialCapacity, 
                             float loadFactor, int concurrencyLevel) { 
        if(!(loadFactor > 0) || initialCapacity < 0 || 
 concurrencyLevel <= 0) 
            throw new IllegalArgumentException(); 

        if(concurrencyLevel > MAX_SEGMENTS) 
            concurrencyLevel = MAX_SEGMENTS; 

        // 寻找最佳匹配参数（不小于给定参数的最接近的 2 次幂） 
        int sshift = 0; 
        int ssize = 1; 
        while(ssize < concurrencyLevel) { 
            ++sshift; 
            ssize <<= 1; 
        } 
        segmentShift = 32 - sshift;       // 偏移量值
        segmentMask = ssize - 1;           // 掩码值 
        this.segments = Segment.newArray(ssize);   // 创建数组

        if (initialCapacity > MAXIMUM_CAPACITY) 
            initialCapacity = MAXIMUM_CAPACITY; 
        int c = initialCapacity / ssize; 
        if(c * ssize < initialCapacity) 
            ++c; 
        int cap = 1; 
        while(cap < c) 
            cap <<= 1; 

        // 依次遍历每个数组元素
        for(int i = 0; i < this.segments.length; ++i) 
            // 初始化每个数组元素引用的 Segment 对象
 this.segments[i] = new Segment<K,V>(cap, loadFactor); 
    } 

    /** 
     * 创建一个带有默认初始容量 (16)、默认加载因子 (0.75) 和 默认并发级别 (16) 
  * 的空散列映射表。
     */ 
    public ConcurrentHashMap() { 
        // 使用三个默认参数，调用上面重载的构造函数来创建空散列映射表
 this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); 
 }
}
下面是 ConcurrentHashMap 的结构示意图。
图 3.ConcurrentHashMap 的结构示意图：

回页首
用分离锁实现多个线程间的并发写操作
在 ConcurrentHashMap 中，线程对映射表做读操作时，一般情况下不需要加锁就可以完成，对容器做结构性修改的操作才需要加锁。下面以 put 操作为例说明对 ConcurrentHashMap 做结构性修改的过程。
首先，根据 key 计算出对应的 hash 值：
清单 4.Put 方法的实现
 public V put(K key, V value) { 
        if (value == null)          //ConcurrentHashMap 中不允许用 null 作为映射值
            throw new NullPointerException(); 
        int hash = hash(key.hashCode());        // 计算键对应的散列码
        // 根据散列码找到对应的 Segment 
        return segmentFor(hash).put(key, hash, value, false); 
 }
然后，根据 hash 值找到对应的Segment 对象：
清单 5.根据 hash 值找到对应的 Segment
 /** 
     * 使用 key 的散列码来得到 segments 数组中对应的 Segment 
     */ 
 final Segment<K,V> segmentFor(int hash) { 
    // 将散列值右移 segmentShift 个位，并在高位填充 0 
    // 然后把得到的值与 segmentMask 相“与”
 // 从而得到 hash 值对应的 segments 数组的下标值
 // 最后根据下标值返回散列码对应的 Segment 对象
        return segments[(hash >>> segmentShift) & segmentMask]; 
 }
最后，在这个 Segment 中执行具体的 put 操作：
清单 6.在 Segment 中执行具体的 put 操作
 V put(K key, int hash, V value, boolean onlyIfAbsent) { 
            lock();  // 加锁，这里是锁定某个 Segment 对象而非整个 ConcurrentHashMap 
            try { 
                int c = count; 

                if (c++ > threshold)     // 如果超过再散列的阈值
                    rehash();              // 执行再散列，table 数组的长度将扩充一倍

                HashEntry<K,V>[] tab = table; 
                // 把散列码值与 table 数组的长度减 1 的值相“与”
                // 得到该散列码对应的 table 数组的下标值
                int index = hash & (tab.length - 1); 
                // 找到散列码对应的具体的那个桶
                HashEntry<K,V> first = tab[index]; 

                HashEntry<K,V> e = first; 
                while (e != null && (e.hash != hash || !key.equals(e.key))) 
                    e = e.next; 

                V oldValue; 
                if (e != null) {            // 如果键 / 值对以经存在
                    oldValue = e.value; 
                    if (!onlyIfAbsent) 
                        e.value = value;    // 设置 value 值
                } 
                else {                        // 键 / 值对不存在 
                    oldValue = null; 
                    ++modCount;         // 要添加新节点到链表中，所以 modCont 要加 1  
                    // 创建新节点，并添加到链表的头部 
                    tab[index] = new HashEntry<K,V>(key, hash, first, value); 
                    count = c;               // 写 count 变量
                } 
                return oldValue; 
            } finally { 
                unlock();                     // 解锁
            } 
        }
注意：这里的加锁操作是针对（键的 hash 值对应的）某个具体的 Segment，锁定的是该 Segment 而不是整个 ConcurrentHashMap。因为插入键 / 值对操作只是在这个 Segment 包含的某个桶中完成，不需要锁定整个ConcurrentHashMap。此时，其他写线程对另外 15 个Segment 的加锁并不会因为当前线程对这个 Segment 的加锁而阻塞。同时，所有读线程几乎不会因本线程的加锁而阻塞（除非读线程刚好读到这个 Segment 中某个 HashEntry 的 value 域的值为 null，此时需要加锁后重新读取该值）。
相比较于 HashTable 和由同步包装器包装的 HashMap每次只能有一个线程执行读或写操作，ConcurrentHashMap 在并发访问性能上有了质的提高。在理想状态下，ConcurrentHashMap 可以支持 16 个线程执行并发写操作（如果并发级别设置为 16），及任意数量线程的读操作。
回页首
用 HashEntery 对象的不变性来降低读操作对加锁的需求
在代码清单“HashEntry 类的定义”中我们可以看到，HashEntry 中的 key，hash，next 都声明为 final 型。这意味着，不能把节点添加到链接的中间和尾部，也不能在链接的中间和尾部删除节点。这个特性可以保证：在访问某个节点时，这个节点之后的链接不会被改变。这个特性可以大大降低处理链表时的复杂性。
同时，HashEntry 类的 value 域被声明为 Volatile 型，Java 的内存模型可以保证：某个写线程对 value 域的写入马上可以被后续的某个读线程“看”到。在 ConcurrentHashMap 中，不允许用 unll 作为键和值，当读线程读到某个 HashEntry 的 value 域的值为 null 时，便知道产生了冲突——发生了重排序现象，需要加锁后重新读入这个 value 值。这些特性互相配合，使得读线程即使在不加锁状态下，也能正确访问 ConcurrentHashMap。
下面我们分别来分析线程写入的两种情形：对散列表做非结构性修改的操作和对散列表做结构性修改的操作。
非结构性修改操作只是更改某个 HashEntry 的 value 域的值。由于对 Volatile 变量的写入操作将与随后对这个变量的读操作进行同步。当一个写线程修改了某个 HashEntry 的 value 域后，另一个读线程读这个值域，Java 内存模型能够保证读线程读取的一定是更新后的值。所以，写线程对链表的非结构性修改能够被后续不加锁的读线程“看到”。
对 ConcurrentHashMap 做结构性修改，实质上是对某个桶指向的链表做结构性修改。如果能够确保：在读线程遍历一个链表期间，写线程对这个链表所做的结构性修改不影响读线程继续正常遍历这个链表。那么读 / 写线程之间就可以安全并发访问这个 ConcurrentHashMap。
结构性修改操作包括 put，remove，clear。下面我们分别分析这三个操作。
clear 操作只是把 ConcurrentHashMap 中所有的桶“置空”，每个桶之前引用的链表依然存在，只是桶不再引用到这些链表（所有链表的结构并没有被修改）。正在遍历某个链表的读线程依然可以正常执行对该链表的遍历。
从上面的代码清单“在 Segment 中执行具体的 put 操作”中，我们可以看出：put 操作如果需要插入一个新节点到链表中时 , 会在链表头部插入这个新节点。此时，链表中的原有节点的链接并没有被修改。也就是说：插入新健 / 值对到链表中的操作不会影响读线程正常遍历这个链表。
下面来分析 remove 操作，先让我们来看看 remove 操作的源代码实现。
清单 7.remove 操作
 V remove(Object key, int hash, Object value) { 
            lock();         // 加锁
            try{ 
                int c = count - 1; 
                HashEntry<K,V>[] tab = table; 
                // 根据散列码找到 table 的下标值
                int index = hash & (tab.length - 1); 
                // 找到散列码对应的那个桶
                HashEntry<K,V> first = tab[index]; 
                HashEntry<K,V> e = first; 
                while(e != null&& (e.hash != hash || !key.equals(e.key))) 
                    e = e.next; 

                V oldValue = null; 
                if(e != null) { 
                    V v = e.value; 
                    if(value == null|| value.equals(v)) { // 找到要删除的节点
                        oldValue = v; 
                        ++modCount; 
                        // 所有处于待删除节点之后的节点原样保留在链表中
                        // 所有处于待删除节点之前的节点被克隆到新链表中
                        HashEntry<K,V> newFirst = e.next;// 待删节点的后继结点
                        for(HashEntry<K,V> p = first; p != e; p = p.next) 
                            newFirst = new HashEntry<K,V>(p.key, p.hash, 
                                                          newFirst, p.value); 
                        // 把桶链接到新的头结点
                        // 新的头结点是原链表中，删除节点之前的那个节点
                        tab[index] = newFirst; 
                        count = c;      // 写 count 变量
                    } 
                } 
                return oldValue; 
            } finally{ 
                unlock();               // 解锁
            } 
        }
和 get 操作一样，首先根据散列码找到具体的链表；然后遍历这个链表找到要删除的节点；最后把待删除节点之后的所有节点原样保留在新链表中，把待删除节点之前的每个节点克隆到新链表中。下面通过图例来说明 remove 操作。假设写线程执行 remove 操作，要删除链表的 C 节点，另一个读线程同时正在遍历这个链表。
图 4. 执行删除之前的原链表：

图 5. 执行删除之后的新链表

从上图可以看出，删除节点 C 之后的所有节点原样保留到新链表中；删除节点 C 之前的每个节点被克隆到新链表中，注意：它们在新链表中的链接顺序被反转了。
在执行 remove 操作时，原始链表并没有被修改，也就是说：读线程不会受同时执行 remove 操作的并发写线程的干扰。
综合上面的分析我们可以看出，写线程对某个链表的结构性修改不会影响其他的并发读线程对这个链表的遍历访问。
回页首
用 Volatile 变量协调读写线程间的内存可见性
由于内存可见性问题，未正确同步的情况下，写线程写入的值可能并不为后续的读线程可见。
下面以写线程 M 和读线程 N 来说明 ConcurrentHashMap 如何协调读 / 写线程间的内存可见性问题。
图 6. 协调读 - 写线程间的内存可见性的示意图：

假设线程 M 在写入了 volatile 型变量 count 后，线程 N 读取了这个 volatile 型变量 count。
根据 happens-before 关系法则中的程序次序法则，A appens-before 于 B，C happens-before D。
根据 Volatile 变量法则，B happens-before C。
根据传递性，连接上面三个 happens-before 关系得到：A appens-before 于 B； B appens-before C；C happens-before D。也就是说：写线程 M 对链表做的结构性修改，在读线程 N 读取了同一个 volatile 变量后，对线程 N 也是可见的了。
虽然线程 N 是在未加锁的情况下访问链表。Java 的内存模型可以保证：只要之前对链表做结构性修改操作的写线程 M 在退出写方法前写 volatile 型变量 count，读线程 N 在读取这个 volatile 型变量 count 后，就一定能“看到”这些修改。
ConcurrentHashMap 中，每个 Segment 都有一个变量 count。它用来统计 Segment 中的 HashEntry 的个数。这个变量被声明为 volatile。
清单 8.Count 变量的声明
 transient volatile int count;
所有不加锁读方法，在进入读方法时，首先都会去读这个 count 变量。比如下面的 get 方法：
清单 9.get 操作
 V get(Object key, int hash) { 
            if(count != 0) {       // 首先读 count 变量
                HashEntry<K,V> e = getFirst(hash); 
                while(e != null) { 
                    if(e.hash == hash && key.equals(e.key)) { 
                        V v = e.value; 
                        if(v != null)            
                            return v; 
                        // 如果读到 value 域为 null，说明发生了重排序，加锁后重新读取
                        return readValueUnderLock(e); 
                    } 
                    e = e.next; 
                } 
            } 
            return null; 
        }
在 ConcurrentHashMap 中，所有执行写操作的方法（put, remove, clear），在对链表做结构性修改之后，在退出写方法前都会去写这个 count 变量。所有未加锁的读操作（get, contains, containsKey）在读方法中，都会首先去读取这个 count 变量。
根据 Java 内存模型，对 同一个 volatile 变量的写 / 读操作可以确保：写线程写入的值，能够被之后未加锁的读线程“看到”。
这个特性和前面介绍的 HashEntry 对象的不变性相结合，使得在 ConcurrentHashMap 中，读线程在读取散列表时，基本不需要加锁就能成功获得需要的值。这两个特性相配合，不仅减少了请求同一个锁的频率（读操作一般不需要加锁就能够成功获得值），也减少了持有同一个锁的时间（只有读到 value 域的值为 null 时 , 读线程才需要加锁后重读）。
回页首
ConcurrentHashMap 实现高并发的总结
基于通常情形而优化
在实际的应用中，散列表一般的应用场景是：除了少数插入操作和删除操作外，绝大多数都是读取操作，而且读操作在大多数时候都是成功的。正是基于这个前提，ConcurrentHashMap 针对读操作做了大量的优化。通过 HashEntry 对象的不变性和用 volatile 型变量协调线程间的内存可见性，使得 大多数时候，读操作不需要加锁就可以正确获得值。这个特性使得 ConcurrentHashMap 的并发性能在分离锁的基础上又有了近一步的提高。
总结
ConcurrentHashMap 是一个并发散列映射表的实现，它允许完全并发的读取，并且支持给定数量的并发更新。相比于 HashTable 和用同步包装器包装的 HashMap（Collections.synchronizedMap(new HashMap())），ConcurrentHashMap 拥有更高的并发性。在 HashTable 和由同步包装器包装的 HashMap 中，使用一个全局的锁来同步不同线程间的并发访问。同一时间点，只能有一个线程持有锁，也就是说在同一时间点，只能有一个线程能访问容器。这虽然保证多线程间的安全并发访问，但同时也导致对容器的访问变成串行化的了。
在使用锁来协调多线程间并发访问的模式下，减小对锁的竞争可以有效提高并发性。有两种方式可以减小对锁的竞争：
减小请求 同一个锁的 频率。
减少持有锁的 时间。
ConcurrentHashMap 的高并发性主要来自于三个方面：
用分离锁实现多个线程间的更深层次的共享访问。
用 HashEntery 对象的不变性来降低执行读操作的线程在遍历链表期间对加锁的需求。
通过对同一个 Volatile 变量的写 / 读访问，协调不同线程间读 / 写操作的内存可见性。
使用分离锁，减小了请求 同一个锁的频率。
通过 HashEntery 对象的不变性及对同一个 Volatile 变量的读 / 写来协调内存可见性，使得 读操作大多数时候不需要加锁就能成功获取到需要的值。由于散列映射表在实际应用中大多数操作都是成功的 读操作，所以 2 和 3 既可以减少请求同一个锁的频率，也可以有效减少持有锁的时间。
通过减小请求同一个锁的频率和尽量减少持有锁的时间 ，使得 ConcurrentHashMap 的并发性相对于 HashTable 和用同步包装器包装的 HashMap有了质的提高。
参考资料
学习
Java 语言规范（第 3 版）：Java 程序设计语言最权威的技术参考书。17.4 章探讨了 Java 内存模型。
Java 并发编程实践：本书作者系 Java 标准化组织 JSR 166 专家组的主要成员，本书是近年来 Java 并发编程图书中最值得一读的力作。5.2 章探讨了并发容器， 11.4 探讨了如何减少锁的竞争，11.5 比较了各种 Map 的性能，16 章探讨了 Java 内存模型。
Java 并发编程—设计原则与模式（第二版）：Java 并发编程领域的先驱 --Doug Lea 先生的经典著作。Doug Lea 先生是 JDK 中 util.concurrent 包的实现者。
多核系统的 Java 并发缺陷模式（bug patterns）：本文通过对 6 个鲜为人知的并发缺陷问题的讲解，阐述了威胁运行在多核系统上的 Java 应用程序线程安全和性能的原因，同时带领您研究并发缺陷模式（bug patterns），让您既能够提高对并发编程的理解，还能够了解如何发现无效或可能无效的编程方法。
Java 多线程与并发编程专题：本专题汇集了与 Java 多线程与并发编程相关的文章和教程，帮助读者理解 Java 并发编程的模式及其利弊，向读者展示了如何更精确地使用 Java 平台的线程模型。
developerWorks Java 技术专区：这里有数百篇关于 Java 编程各个方面的文章。
讨论
加入 developerWorks 中文社区。查看开发人员推动的博客、论坛、组和维基，并与其他 developerWorks 用户交流。
条评论
请 登录 或 注册 后发表评论。

添加评论:
注意：评论中不支持 HTML 语法

有新评论时提醒我剩余 1000 字符
 
good
由 fakeid 于 23 July 2012 报告滥用
很好的文章，最近对高并发的处理比较感兴趣，适合我的阶段
由 duanfa 于 28 April 2012 报告滥用

IBM PureSystems
IBM PureSystems™ 系列解决方案是一个专家集成系统

developerWorks 学习路线图
通过学习路线图系统掌握软件开发技能

软件下载资源中心
软件下载、试用版及云计算
回页首
帮助
联系编辑
提交内容
网站导航
订阅源
在线浏览每周时事通讯
新浪微博
报告滥用
使用条款
第三方提示
隐私条约
浏览辅助
IBM 教育学院教育培养计划
IBM 创业企业全球扶持计划
ISV 资源 (英语)
dW 中国每周时事通讯


========== http://space.itpub.net/8554499/viewspace-580300 ==========
Linc的Oracle生活
copyBookmark http://space.itpub.net/8554499
博客图片商品下载收藏影音好友论坛
空间管理 您的位置: ITPUB个人空间 » Linc的Oracle生活 » 日志
笑着面对，不去埋怨。悠然，随心，随性，随缘!
Linux命令----分析CPU的瓶颈

上一篇 / 下一篇  2009-03-27 00:45:46 / 个人分类：Linux
查看( 3265 ) / 评论( 8 ) / 评分( 30 / 0 )
衡量CPU性能的指标：

1，用户使用CPU的情况；
CPU运行常规用户进程
CPU运行niced process
CPU运行实时进程

2，系统使用CPU情况；
用于I/O管理：中断和驱动
用于内存管理：页面交换
用户进程管理：进程开始和上下文切换

3，WIO：用于进程等待磁盘I/O而使CPU处于空闲状态的比率。

4，CPU的空闲率，除了上面的WIO以外的空闲时间

5，CPU用于上下文交换的比率

6，nice

7，real-time

8，运行进程队列的长度

9，平均负载

Linux中常用的监控CPU整体性能的工具有：

 mpstat： mpstat 不但能查看所有CPU的平均信息，还能查看指定CPU的信息。

 vmstat：只能查看所有CPU的平均信息；查看cpu队列信息；

 iostat: 只能查看所有CPU的平均信息。

 sar： 与mpstat 一样，不但能查看CPU的平均信息，还能查看指定CPU的信息。

 top：显示的信息同ps接近，但是top可以了解到CPU消耗，可以根据用户指定的时间来更新显示。

下面一一介绍：

一，vmstat

[root@localhost ~]#vmstat -n 3       (每个3秒刷新一次）
procs-----------memory--------------------swap-- ----io---- --system---- ------cpu--------
r b   swpd   free       buff       cache       si   so    bi    bo   in      cs        us   sy   id  wa
10    144 186164 105252 2386848    0    0     18   166  83     2          48   21  31  0
20    144 189620 105252 2386848    0    0      0   177  1039 1210   34   10  56  0
00    144 214324 105252 2386848    0    0      0    10   1071   670    32   5    63  0
00    144 202212 105252 2386848    0    0      0   189   1035   558    20   3    77  0
20    144 158772 105252 2386848    0    0      0   203  1065 2832    70  14  15  0

红色内容标示CPU相关的参数

PROC(ESSES)
--r:如果在processes中运行的序列(process r)是连续的大于在系统中的CPU的个数表示系统现在运行比较慢,有多数的进程等待CPU.
如果r的输出数大于系统中可用CPU个数的4倍的话,则系统面临着CPU短缺的问题,或者是CPU的速率过低,系统中有多数的进程在等待CPU,造成系统中进程运行过慢.
SYSTEM
--in:每秒产生的中断次数
--cs:每秒产生的上下文切换次数
上面2个值越大，会看到由内核消耗的CPU时间会越大
 
CPU
-us:用户进程消耗的CPU时间百分
us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速（比如PHP/PERL）
-sy:内核进程消耗的CPU时间百分比（sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因）
-wa:IO等待消耗的CPU时间百分比
wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。
-id:CPU处于空闲状态时间百分比,如果空闲时间(cpu id)持续为0并且系统时间(cpu sy)是用户时间的两倍(cpu us) 系统则面临着CPU资源的短缺. 

 解决办法:
当发生以上问题的时候请先调整应用程序对CPU的占用情况.使得应用程序能够更有效的使用CPU.同时可以考虑增加更多的CPU.  关于CPU的使用情况还可以结合mpstat,  ps aux top  prstat –a等等一些相应的命令来综合考虑关于具体的CPU的使用情况,和那些进程在占用大量的CPU时间.一般情况下，应用程序的问题会比较大一些.比如一些SQL语句不合理等等都会造成这样的现象.
 
二，sar
sar [options] [-A] [-o file] t [n]

在命令行中，n 和t 两个参数组合起来定义采样间隔和次数，t为采样间隔，是必须有
的参数，n为采样次数，是可选的，默认值是1，-o file表示将命令结果以二进制格式
存放在文件中，file 在此处不是关键字，是文件名。options 为命令行选项，sar命令
的选项很多，下面只列出常用选项：

-A：所有报告的总和。
-u：CPU利用率
-v：进程、I节点、文件和锁表状态。
-d：硬盘使用报告。
-r：内存和交换空间的使用统计。
-g：串口I/O的情况。
-b：缓冲区使用情况。
-a：文件读写情况。
-c：系统调用情况。
-q：报告队列长度和系统平均负载
-R：进程的活动情况。
-y：终端设备活动情况。
-w：系统交换活动。
-x { pid | SELF | ALL }：报告指定进程ID的统计信息，SELF关键字是sar进程本身的统计，ALL关键字是所有系统进程的统计。

用sar进行CPU利用率的分析
#sar -u 2 10
Linux 2.6.18-53.el5PAE (localhost.localdomain)  03/28/2009
07:40:17 PM       CPU     %user     %nice   %system   %iowait    %steal     %idle
07:40:19 PM       all         12.44      0.00         6.97          1.74         0.00        78.86
07:40:21 PM       all         26.75      0.00        12.50         16.00       0.00        44.75
07:40:23 PM       all         16.96      0.00         7.98          0.00         0.00        75.06
07:40:25 PM       all         22.50      0.00         7.00          3.25         0.00        67.25
07:40:27 PM       all         7.25        0.00         2.75          2.50         0.00        87.50
07:40:29 PM       all         20.05      0.00         8.56          2.93         0.00        68.46
07:40:31 PM       all         13.97      0.00         6.23          3.49         0.00        76.31
07:40:33 PM       all         8.25        0.00         0.75          3.50         0.00        87.50
07:40:35 PM       all         13.25      0.00         5.75          4.00         0.00        77.00
07:40:37 PM       all         10.03      0.00         0.50          2.51         0.00        86.97
Average:             all         15.15      0.00         5.91          3.99         0.00        74.95
 
在显示内容包括：

　　%user：CPU处在用户模式下的时间百分比。
        %nice：CPU处在带NICE值的用户模式下的时间百分比。
　　%system：CPU处在系统模式下的时间百分比。
　　%iowait：CPU等待输入输出完成时间的百分比。
        %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。
　　%idle：CPU空闲时间百分比。
        在所有的显示中，我们应主要注意%iowait和%idle，%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。
 
用sar进行运行进程队列长度分析：
#sar -q 2 10
Linux 2.6.18-53.el5PAE (localhost.localdomain)  03/28/2009
07:58:14 PM   runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-15
07:58:16 PM         0         493          0.64        0.56        0.49
07:58:18 PM         1         491          0.64        0.56        0.49
07:58:20 PM         1         488          0.59        0.55        0.49
07:58:22 PM         0         487          0.59        0.55        0.49
07:58:24 PM         0         485          0.59        0.55        0.49
07:58:26 PM         1         483          0.78        0.59        0.50
07:58:28 PM         0         481          0.78        0.59        0.50
07:58:30 PM         1         480          0.72        0.58        0.50
07:58:32 PM         0         477          0.72        0.58        0.50
07:58:34 PM         0         474          0.72        0.58        0.50
Average:               0         484          0.68        0.57        0.49
 
runq-sz 准备运行的进程运行队列。
plist-sz  进程队列里的进程和线程的数量
ldavg-1  前一分钟的系统平均负载(load average)
ldavg-5  前五分钟的系统平均负载(load average)
ldavg-15  前15分钟的系统平均负载(load average)
 
顺便说一下load avarage的含义
load average可以理解为每秒钟CPU等待运行的进程个数.
在Linux系统中，sar -q、uptime、w、top等命令都会有系统平均负载load average的输出，那么什么是系统平均负载呢？
　　系统平均负载被定义为在特定时间间隔内运行队列中的平均任务数。如果一个进程满足以下条件则其就会位于运行队列中：
　　- 它没有在等待I/O操作的结果
　　- 它没有主动进入等待状态(也就是没有调用'wait')
　　- 没有被停止(例如：等待终止)
　　例如：
# uptime
　　20:55:40 up 24 days,  3:06,  1 user,  load average: 8.13, 5.90, 4.94
　　命令输出的最后内容表示在过去的1、5、15分钟内运行队列中的平均进程数量。
　　一般来说只要每个CPU的当前活动进程数不大于3那么系统的性能就是良好的，如果每个CPU的任务数大于5，那么就表示这台机器的性能有严重问题。对 于上面的例子来说，假设系统有两个CPU，那么其每个CPU的当前任务数为：8.13/2=4.065。这表示该系统的性能是可以接受的。
 
三，iostat
 
#iostat -c 2 10
Linux 2.6.18-53.el5PAE (localhost.localdomain)  03/28/2009
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
                    30.10    0.00          4.89         5.63    0.00   59.38
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
                    8.46       0.00          1.74         0.25    0.00   89.55
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
                    22.06     0.00          11.28       1.25    0.00   65.41
 
四，mpstat
mpstat是Multiprocessor Statistics的缩写，是实时系统监控工具。其报告与CPU的一些统计信息，这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。下面只介绍 mpstat与CPU相关的参数，mpstat的语法如下：
mpstat [-P {|ALL}] [internal [count]]

参数的含义如下：

参数 解释

-P {|ALL} 表示监控哪个CPU， cpu在[0,cpu个数-1]中取值

internal 相邻的两次采样的间隔时间

count 采样的次数，count只能和delay一起使用

当没有参数时，mpstat则显示系统启动以后所有信息的平均值。有interval时，第一行的信息自系统启动以来的平均信息。从第二行开始，输出为前一个interval时间段的平均信息。与CPU有关的输出的含义如下：

参数 解释 从/proc/stat获得数据

CPU 处理器ID

user 在internal时间段里，用户态的CPU时间（%） ，不包含 nice值为负 进程 usr/total*100

nice 在internal时间段里，nice值为负进程的CPU时间（%） nice/total*100

system 在internal时间段里，核心时间（%） system/total*100

iowait 在internal时间段里，硬盘IO等待时间（%） iowait/total*100

irq 在internal时间段里，软中断时间（%） irq/total*100

soft 在internal时间段里，软中断时间（%） softirq/total*100

idle 在internal时间段里，CPU除去等待磁盘IO操作外的因为任何原因而空闲的时间闲置时间 （%） idle/total*100

intr/s 在internal时间段里，每秒CPU接收的中断的次数 intr/total*100

CPU总的工作时间=total_cur=user+system+nice+idle+iowait+irq+softirq

total_pre=pre_user+ pre_system+ pre_nice+ pre_idle+ pre_iowait+ pre_irq+ pre_softirq

user=user_cur – user_pre

total=total_cur-total_pre

其中_cur 表示当前值，_pre表示interval时间前的值。上表中的所有值可取到两位小数点。

#mpstat -P ALL 2 10
Linux 2.6.18-53.el5PAE (localhost.localdomain)  03/28/2009
 
10:07:57 PM  CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal   %idle    intr/s
10:07:59 PM  all   20.75    0.00   10.50    1.50    0.25    0.25    0.00   66.75   1294.50
10:07:59 PM    0   16.00    0.00    9.00    1.50    0.00    0.00    0.00   73.50   1000.50
10:07:59 PM    1   25.76    0.00   12.12    1.52    0.00    0.51    0.00   60.10    294.00
 
五，top
该命令详见：
http://space.itpub.net/?uid-8554499-action-viewspace-itemid-580475
 

相关阅读:
Vmstat 命令详细介绍 (oracle_kai, 2008-1-31)
导入论坛 引用链接 收藏 分享给好友 推荐到圈子 管理 举报
TAG: iostat sar vmstat

引用删除 Guest   /   2013-05-17 14:20:01
评 5 分
引用删除 Guest   /   2012-07-25 22:10:52
评 5 分
引用删除 joejzvbjw   /   2012-01-11 01:40:14
eZLfXo  <a href="http://jzbvvexvtflb.com/">jzbvvexvtflb</a>
引用删除 evtmapxykm   /   2012-01-09 19:58:37
deveDc , [url=http://nbbwsjvtjjxg.com/]nbbwsjvtjjxg[/url], [link=http://exsccprhxwbc.com/]exsccprhxwbc[/link], http://vdjnydixmbkc.com/
引用删除 Denver   /   2012-01-08 13:02:06
If you're reading this, you're all set, pradner!
引用删除 刺猬   /   2011-11-01 00:10:02
very good
引用删除 Guest   /   2011-10-31 23:50:24
评 5 分
引用 删除 feilo4r   /   2010-07-21 23:00:00
评 5 分
查看全部评论

 
-5-3-1-+1+3+5
评分：0
我来说两句
显示全部
                   
内容 
昵称 
验证  
提交评论


zhanglincon
用户菜单
给我留言加入好友发短消息我的介绍论坛资料空间管理
我的栏目
Oracle
工作总结
JAVA
SQL
PL/SQL
Oracle Tools
Storage&Tuning
PGA/SGA
DataGuide
RAC
TCP/IP
Linux
Linc's Life
标题搜索
  
日历
«	2013-10-04	 
日	一	二	三	四	五	六
 	 	1	2	3	4	5
6	7	8	9	10	11	12
13	14	15	16	17	18	19
20	21	22	23	24	25	26
27	28	29	30	31	 	 
我的存档
2012年02月   2012年01月   
2011年12月   2011年11月   
2011年10月   2011年09月   
2011年08月   2011年07月   
2011年06月   2011年05月   
2011年04月   2011年03月   
2011年02月   2011年01月   
2010年12月   2010年11月   
2010年10月   2010年09月   
2010年08月   2010年07月   
2010年06月   2010年05月   
2010年04月   2010年03月   
2010年02月   2010年01月   
2009年12月   2009年11月   
2009年10月   2009年09月   
2009年08月   2009年07月   
2009年06月   2009年05月   
2009年04月   2009年03月   
查看所有存档
数据统计
访问量: 24964
日志数: 83
文件数: 1
建立时间: 2009-03-24
更新时间: 2012-02-01
RSS订阅

清空Cookie - 联系我们 - ITPUB个人空间 - 交流论坛 - 空间列表 - 站点存档 - 升级自己的空间
Powered by X-Space 3.0.2 © 2001-2007 Comsenz Inc. 
京ICP证:010037号网站统计 
Open Toolbar
========== http://luobeng.blogbus.com/logs/123290553.html ==========
========== http://cheney-mydream.iteye.com/blog/1867300 ==========
首页 资讯 精华 论坛 问答 博客 专栏 群组 更多 ▼ 您还未登录 ! 登录 注册
移动互联网
博客微博相册收藏留言关于我
  

 
#每周一算法#二叉查找树

博客分类： 算法
 
#每周一算法# 本周介绍一下二叉查找树，二叉查找树一般用的不是很多，但是它是平衡二叉树和红黑树的基础，所以还是要好好了解一下的。
首先说一下什么是二叉查找树：
二叉查找树是一种特殊的二叉树，特殊在哪呢？
1.对于树中的任意节点X，如果它的左子树不为空，则左子树中的所有节点的值均小于X的值。
2.对于树中的任意节点X，如果它的右子树不为空，则右子树中的所有节点的值均大于X的值。
3.二叉查找树的中序遍历是一个从小到大的有序序列。
如图这是一个二叉查找树：

 
下面这个不是二叉查找树，因为节点8是节点7的左子树，其值不能大于7：


 
 下面来看一下二叉查找树的一些基本操作：
1.插入操作：
  将新节点X插入到树T中，进行如下判断：
  1.如果T是空树，则X作为树T的根节点
  2.如果X的值小于根节点的值，则将X节点插入到左子树中，然后通过递归比较左子树的节点，直到插入到合适的位置
  3.如果X的值大于根节点的值，则将X节点插入到右子树中，然后通过递归比较右子树的节点，直到插入到合适的位置
 
   看下面的例子：


2.查找操作
  查找操作比较简单，如果该值等于根节点的值，则直接返回。如果该值大于根节点的值，则到右子树中进行递归查找，然后返回查询结果。如果该值小于根节点的值，则到左子树中进行递归查找，然后返回查询结果。
 
3.删除操作
 1.如果该节点是叶子节点，则直接将其删除
 2.如果该节点有一个子节点，则将该节点的父节点指向该节点的子节点，然后将该节点删除。
 3.如果该节点有两个子节点，一般的删除策略是用该节点的右子树中的最小节点值代替该节点的值，然后再递归的删除该最小节点，因为这是最小的节点，不可能再有左子树，所以删除的时候会简单一些（因为没有左子树所以该节点最多只有一个右子树，删除策略同2）。
 
 看下面的例子：


 概念介绍完了，现在用程序来实现一个简单的二叉查找树
 
Java代码  
package com.algorithm;  
  
/** 
 * 二叉查找树 
 * @author 马永华 
 * 
 */  
public class Bst {  
      
    //定义二叉树的数据结构  
    static class BinaryNode<T> {  
          
         private  T element;  
         private BinaryNode<T> left;  
         private BinaryNode<T> right;  
           
         //创建一个单节点  
         public BinaryNode(T element){  
             this(element,null,null);  
         }  
           
         //创建子节点  
         public BinaryNode(T element,BinaryNode<T> left,BinaryNode<T> right){  
             this.element = element;  
             this.left = left;  
             this.right = right;  
         }  
  
    }   
      
    //插入  
    public BinaryNode<Integer> insert(Integer i,BinaryNode<Integer> node){  
          
        if(node == null){  
            return new BinaryNode<Integer>(i);  
        }  
          
        //如果i 小于当前节点的值，则查找器左子树  
        if(i < node.element) {  
            node.left = insert(i,node.left);  
        }  
          
        //如果i 大于当前节点的值，则查找其右子树  
        if(i > node.element) {  
            node.right = insert(i,node.right);  
        }  
          
        return node;  
    }  
      
    //查找  
    public BinaryNode<Integer> find(int i,BinaryNode<Integer> node){  
        //如果树为空，则直接返回null  
        if(node == null)   
            return null;  
          
        if(node.element == i)  
            return node;  
          
        if(i < node.element)  
            return find(i,node.left);  
          
        if(i > node.element)   
            return find(i,node.right);  
          
        System.out.println("这里会执行吗");  
        return null;  
    }  
      
    //查询树的最大值  
    public BinaryNode<Integer> findMax(BinaryNode<Integer> node){  
        //如果树为空，则直接返回null  
        if(node == null)   
            return null;  
          
        if(node.right == null)  
            return node;  
        else   
            return findMax(node.right);  
    }  
      
    //查询树的最小值  
    public BinaryNode<Integer> findMin(BinaryNode<Integer> node){  
        //如果树为空，则直接返回null  
        if(node == null)   
            return null;  
          
        if(node.left == null)  
            return node;  
        else   
            return findMin(node.left);  
    }  
      
    //获得当前节点的父节点  
    public BinaryNode<Integer> findParent(int i,BinaryNode<Integer> node){  
          
        if(node == null)  
             return null;  
          
        //如果i的值小于  
        if(i<node.element){  
            if(node.left != null &&i == node.left.element)  
            return node;  
            else   
            return findParent(i,node.left);  
        }  
          
        //如果该值  
        if(i>node.element){  
            if(node.right != null && i == node.right.element)  
                return node;  
            else  
                return findParent(i,node.right);  
        }  
          
        return null;  
    }  
      
    //删除节点  
    public BinaryNode<Integer> delete(int i,BinaryNode<Integer> node){  
          
        if(node == null)  
            return null;  
          
        if(i<node.element){  
            //如果要删除的节点小于当前节点  
            node.left = delete(i,node.left);  
        }else if(i>node.element){  
            //如果要删除的节点大于当前节点  
            node.right = delete(i,node.right);  
        }else {  
            //要删除的节点等于当前节点  
            //如果该节点有两个子节点  
            if(node.left !=null && node.right !=null){  
                //找到该节点右子树中最小的节点，将它的值赋给当前节点  
                node.element = findMin(node.right).element;  
                //然后递归去删除这个最小的节点  
                node.right = delete(node.element,node.right);  
            }else {  
                //如果该节点有一个子节点或者没有子节点  
                return node = node.left != null ? node.left : node.right;  
            }  
              
        }  
            return node;  
    }  
      
    //对二叉查找树进行中序输出，输出的是一个从小到大的有序数列  
    public void sort(BinaryNode<Integer> node){  
          
        //先输出左子树  
        if(node.left != null){  
            sort(node.left);  
        }  
          
        //再输出中间  
        System.out.print(node.element+"->");  
          
        //最后输出右子树  
        if(node.right != null){  
            sort(node.right);  
        }  
          
          
    }  
      
    public static void main(String args[]){  
        Bst bst = new Bst();  
          
        //插入 6 2 8 1 5 3 4  
        BinaryNode<Integer> root = bst.insert(6, null);  
        bst.insert(2, root);  
        bst.insert(8, root);  
        bst.insert(1, root);  
        bst.insert(5, root);  
        bst.insert(3, root);  
        bst.insert(4, root);  
          
        //查询  
        BinaryNode<Integer> node2 =  bst.find(2, root);  
        BinaryNode<Integer> node0 =  bst.find(0, root);  
        BinaryNode<Integer> nodeMax =  bst.findMax(root);  
        BinaryNode<Integer> nodeMin =  bst.findMin(root);  
          
        //排序  
        bst.sort(root);  
          
        //删除  
//      BinaryNode<Integer> delete4 = bst.delete(4,root);  
//      BinaryNode<Integer> delete3 = bst.delete(3,root);  
//      BinaryNode<Integer> delete2 = bst.delete(2,root);  
    }  
}  
     
查看图片附件
10 
顶0 
踩 分享到：    
#每周一算法#逆波兰表达式求解
2013-05-11 22:03浏览 3810评论(1)分类:编程语言相关推荐
评论
1 楼 hailongshih 2013-05-14  
Good,好文
发表评论
  您还没有登录,请您登录后再发表评论

cheney_love
浏览: 93776 次
性别: 
来自: 济南

最近访客 更多访客>>
dylinshi126painarthurzwl12502我朝大明
文章分类
全部博客 (116)
webservice (11)
Spring (5)
hibernate (4)
随笔 (10)
加密 (2)
错误、异常 (5)
java (14)
Ext (1)
Js/Css (9)
正则表达式 (0)
jsp (2)
论坛 (3)
J2ME (2)
android (27)
iPhone (0)
算法 (3)
单片机 嵌入式 (0)
c/c++ (1)
生活 (2)
Linux (7)
JBPM (4)
MySQL (2)
Oracle (0)
VOA翻译 (2)
应用 (1)
英语 (1)
hadoop (0)
社区版块
我的资讯 (0)
我的论坛 (266)
我的问答 (59)
存档分类
2013-05 (2)
2013-04 (1)
2012-11 (1)
更多存档...
评论排行榜
Hadoop Eclipse 插件编译安装
#每周一算法#二叉查找树
最新评论
lionkingzw： lionkingzw 写道vigiles 写道你好！我用的是h ...
Hadoop Eclipse 插件编译安装
lionkingzw： vigiles 写道你好！我用的是hadoop-1.1.2，$ ...
Hadoop Eclipse 插件编译安装
xuxingfan000： 还在有另外一个BUG就是就是点击到上午0点——0点30分那个阶 ...
Jquery 仿 google 日历活动(图+源码)
elfasd： Myeclipse8.5成功 eclipse 3.3 始终失败 ...
axis webservice 笔记 安装eclipse axis2 插件 （links 方式）
vigiles： 我把自己的步骤详细写在这了：http://www.oschin ...
Hadoop Eclipse 插件编译安装
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]
  
========== http://wlh0706-163-com.iteye.com/blog/1867354 ==========
========== http://www.codingnow.com/2000/download/lua_manual.html ==========
Lua 5.1 参考手册

by Roberto Ierusalimschy, Luiz Henrique de Figueiredo, Waldemar Celes
云风 译 www.codingnow.com

Copyright © 2006 Lua.org, PUC-Rio. All rights reserved.

1 - 介绍

Lua 是一个扩展式程序设计语言，它被设计成支持通用的过程式编程，并有相关数据描述的设施。 Lua 也能对面向对象编程，函数式编程，数据驱动式编程提供很好的支持。 它可以作为一个强大、轻量的脚本语言，供任何需要的程序使用。 Lua 以一个用 clean C 写成的库形式提供。（所谓 Clean C ，指的 ANSI C 和 C++ 中共通的一个子集）

作为一个扩展式语言，Lua 没有 "main" 程序的概念：它只能 嵌入 一个宿主程序中工作，这个宿主程序被称作 embedding program 或简称为 host 。 宿主程序可以通过调用函数执行一小段 Lua 代码，可以读写 Lua 变量，可以注入 C 函数让 Lua 代码调用。 这些扩展的 C 函数，可以大大的扩展了 Lua 可以处理事务的领域，这样就可以订制出各种语言， 而它们共享一个统一的句法格式的框架。 Lua 的官方发布版就包含了一个叫做 lua 的简单的宿主程序，它用 Lua 库提供了一个保证独立的 Lua 解释器。

Lua 是一个自由软件，它的使用许可决定了对它的使用过程一般没有任何保证。 这份手册中描述的东西的实现，可以在 Lua 的官方网站 www.lua.org 找到，

跟其它的许多参考手册一样，这份文档有些地方比较枯燥。 关于 Lua 的设计想法的探讨，可以看看 Lua 网站上提供的技术论文。 有关用 Lua 编程的细节介绍，可以读一下 Roberto 的书，Programming in Lua (Second Edition) 。

2 - 语言

这一节从词法、语法、句法上描述 Lua 。 换句话说，这一节描述了哪些 token （符记）是有效的，它们如何被组合起来，这些组合方式有什么含义。

关于语言的构成概念将用常见的扩展 BNF 表达式写出。也就是这个样子： {a} 意思是 0 或多个 a ， [a] 意思是一个可选的 a 。 非最终的符号会保留原来的样子，关键字则看起来像这样 kword ， 其它最终的符号则写成 `=´ 。 完整的 Lua 语法可以在本手册最后找到。

2.1 - 词法约定

Lua 中用到的 名字（也称作 标识符）可以是任何非数字开头的字母、数字、下划线组成的字符串。 这符合几乎所有编程语言中关于名字的定义。 （字母的定义依赖于当前环境：系统环境中定义的字母表中的字母都可以被用于标识符。） 标识符用来命名变量，或作为表的域名。

下面的关键字是保留的，不能用作名字：

     and       break     do        else      elseif
     end       false     for       function  if
     in        local     nil       not       or
     repeat    return    then      true      until     while
Lua 是一个大小写敏感的语言： and 是一个保留字，但是 And 和 AND 则是两个不同的合法的名字。 一般约定，以下划线开头连接一串大写字母的名字（比如 _VERSION）被保留用于 Lua 内部全局变量。

下面这些是其它的 token ：

     +     -     *     /     %     ^     #
     ==    ~=    <=    >=    <     >     =
     (     )     {     }     [     ]
     ;     :     ,     .     ..    ...
字符串既可以用一对单引号引起，也可以是双引号，里面还可以包含类似 C 的转义符： '\a' （响铃）， '\b' （退格）， '\f' （表单）， '\n' （换行）， '\r' （回车）， '\t' （横向制表）， '\v' （纵向制表）， '\\' （反斜杠）， '\"' （双引号）， 以及 '\'' （单引号)。 而且，如果在一个反斜杠后跟了一个真正的换行符，其结果就是在字符串中产生一个换行符。 我们还可以用反斜杠加数字的形式 \ddd 来描述一个字符。这里， ddd 是一串最多三位的十进制数字。（注意，如果需要在这种描述方法后接一个是数字的字符， 那么反斜杠后必须写满三个数字。）Lua 中的字符串可以包含任何 8 位的值。包括用 '\0' 表示的零。

只有在你需要把不同的引号、换行、反斜杠、或是零结束符这些字符置入字符串时， 你才必须使用转义符。别的任何字符都可以直接写在文本里。（一些控制符可以会影响文件系统造成某些问题， 但是不会引起 Lua 的任何问题。）

字符串还可以用一种长括号括起来的方式定义。 我们把两个正的方括号间插入 n 个等号定义为第 n 级正长括号。 就是说，0 级正的长括号写作 [[ ， 一级正的长括号写作 [=[ ，如此等等。 反的长扩展也作类似定义； 举个例子，4 级反的长括号写作 ]====] 。 一个长字符串可以由任何一级的正的长括号开始，而由第一个碰到的同级反的长括号结束。 整个词法分析过程将不受分行限制，不处理任何转意符，并且忽略掉任何不同级别的长括号。 这种方式描述的字符串可以包含任何东西，当然特定级别的反长括号除外。

另一个约定是，当正的长括号后面立即跟了一个换行符， 这个换行符就不包含在这个字符串内。 举个例子，假设一个系统使用 ASCII 码 （这时，'a' 编码为 97 ，换行符编码为 10 ，'1' 编码为 49 ）， 下面五种方式描述了完全相同的字符串：

     a = 'alo\n123"'
     a = "alo\n123\""
     a = '\97lo\10\04923"'
     a = [[alo
     123"]]
     a = [==[
     alo
     123"]==]
数字常量可以分两部分写，十进制底数部分和十进制的指数部分。指数部分是可选的。 Lua 也支持十六进制整数常量，只需要在前面加上前缀 0x 。 下面是一些合法的数字常量的例子：

     3   3.0   3.1416   314.16e-2   0.31416E1   0xff   0x56
注释可以在除字符串内的任何地方是以两横 (--) 开始。 如果跟在两横后面的不是一个长括号，这就是一个短注释，它的作用范围直到行末； 否则就是一个长注释，其作用范围直到遇到反的长括号。 长注释通常被用来临时屏蔽代码块。

2.2 - 值与类型

Lua 是一种 动态类型语言。 这意味着变量没有类型，只有值才有类型。 语言中不存在类型定义。而所有的值本身携带它们自己的类型信息。

Lua 中的所有值都是一致 (first-class) 的。 这意味着所有的值都可以被放在变量里，当作参数传递到另一个函数中，并被函数作为结果返回。

Lua 中有八种基本类型： nil, boolean, number, string, function, userdata, thread, and table. Nil 类型只有一种值 nil ，它的主要用途用于标表识和别的任何值的差异； 通常，当需要描述一个无意义的值时会用到它。 Boolean 类型只有两种值：false 和 true。 nil 和 false 都能导致条件为假；而另外所有的值都被当作真。 Number 表示实数（双精度浮点数）。 （编译一个其它内部数字类型的 Lua 解释器是件很容易的事；比如把内部数字类型改作 单精度浮点数或长整型。参见文件 luaconf.h 。） String 表示一串字符的数组。 Lua 是 8-bit clean 的： 字符串可以包含任何 8 位字符， 包括零结束符 ('\0') （参见 §2.1）。

Lua 可以调用（和处理）用 Lua 写的函数以及用 C 写的函数（参见 §2.5.8）.

userdata 类型用来将任意 C 数据保存在 Lua 变量中。 这个类型相当于一块原生的内存，除了赋值和相同性判断，Lua 没有为之预定义任何操作。 然而，通过使用 metatable （元表） ，程序员可以为 userdata 自定义一组操作 （参见 §2.8）。 userdata 不能在 Lua 中创建出来，也不能在 Lua 中修改。这样的操作只能通过 C API。 这一点保证了宿主程序完全掌管其中的数据。

thread 类型用来区别独立的执行线程，它被用来实现 coroutine （协同例程）（参见 §2.11）。 不要把 Lua 线程跟操作系统的线程搞混。 Lua 可以在所有的系统上提供对 coroutine 的支持，即使系统并不支持线程。

table 类型实现了一个关联数组。也就是说， 数组可以用任何东西（除了nil）做索引，而不限于数字。 table 可以以不同类型的值构成；它可以包含所有的类型的值（除 nil 外）。 table 是 lua 中唯一的一种数据结构；它可以用来描述原始的数组、符号表、集合、 记录、图、树、等等。 用于表述记录时，lua 使用域名作为索引。 语言本身采用一种语法糖，支持以 a.name 的形式表示 a["name"]。 有很多形式用于在 lua 中创建一个 table （参见 §2.5.7）。

跟索引一样， table 每个域中的值也可以是任何类型（除 nil外）。 特别的，因为函数本身也是值，所以 table 的域中也可以放函数。 这样 table 中就可以有一些 methods 了 （参见see §2.5.9）。

table， function ，thread ，和 (full) userdata 这些类型的值是所谓的对象： 变量本身并不会真正的存放它们的值，而只是放了一个对对象的引用。 赋值，参数传递，函数返回，都是对这些对象的引用进行操作； 这些操作不会做暗地里做任何性质的拷贝。

库函数 type 可以返回一个描述给定值的类型的字符串。

2.2.1 - 强制转换

Lua 提供运行时字符串到数字的自动转换。 任何对字符串的数学运算操作都会尝试用一般的转换规则把这个字符串转换成一个数字。 相反，无论何时，一个数字需要作为字符串来使用时，数字都会以合理的格式转换为字符串。 需要完全控制数字怎样转换为字符串，可以使用字符串库中的 format 函数 （参见 string.format）。

2.3 - 变量

写上变量的地方意味着当以其保存的值来替代之。 Lua 中有三类变量：全局变量，局部变量，还有 table 的域。

一个单一的名字可以表示一个全局变量，也可以表示一个局部变量 （或者是一个函数的参数，这是一种特殊形式的局部变量）：

	var ::= Name
Name 就是 §2.1 中所定义的标识符。

任何变量都被假定为全局变量，除非显式的以 local 修饰定义 （参见 §2.4.7）。 局部变量有其作用范围： 局部变量可以被定义在它作用范围中的函数自由使用 （参见 §2.6）。

在变量的首次赋值之前，变量的值均为 nil。

方括号被用来对 table 作索引：

	var ::= prefixexp `[´ exp `]´
对全局变量以及 table 域之访问的含义可以通过 metatable 来改变。 以取一个变量下标指向的量 t[i] 等价于调用 gettable_event(t,i)。 （参见 §2.8 ，有一份完整的关于 gettable_event 函数的说明。 这个函数并没有在 lua 中定义出来，也不能在 lua 中调用。 这里我们把它列出来只是方便说明。）

var.Name 这种语法只是一个语法糖，用来表示 var["Name"]：

	var ::= prefixexp `.´ Name
所有的全局变量都是放在一个特定 lua table 的诸个域中，这个特定的 table 叫作 environment （环境）table 或者简称为 环境 （参见 §2.9）。 每个函数都有对一个环境的引用， 所以一个函数中可见的所有全局变量都放在这个函数所引用的环境表（environment table）中。 当一个函数被创建出来，它会从创建它的函数中继承其环境，你可以调用 getfenv 取得其环境。 如果想改变环境，可以调用 setfenv。 （对于 C 函数，你只能通过 debug 库来改变其环境； 参见 §5.9）。

对一个全局变量 x 的访问 等价于 _env.x，而这又可以等价于

     gettable_event(_env, "x")
这里，_env 是当前运行的函数的环境。 （函数 gettable_event 的完整说明参见 §2.8。 这个函数并没有在 lua 中定义出来，也不能调用。 当然，_env 这个变量也同样没有在 Lua 中定义出来。 我们在这里使用它们，仅仅只是方便解释而已。）

2.4 - 语句段（Statement）

Lua 支持惯例形式的语句段，它和 Pascal 或是 C 很相象。 这个集合包括赋值，控制结构，函数调用，还有变量声明。

2.4.1 - Chunk（语句组）

Lua 的一个执行单元被称作 chunk。 一个 chunk 就是一串语句段，它们会被循序的执行。 每个语句段可以以一个分号结束：

	chunk ::= {stat [`;´]}
这儿不允许有空的语句段，所以 ';;' 是非法的。

lua 把一个 chunk 当作一个拥有不定参数的匿名函数 （参见 §2.5.9）处理。 正是这样，chunk 内可以定义局部变量，接收参数，并且返回值。

chunk 可以被保存在一个文件中，也可以保存在宿主程序的一个字符串中。 当一个 chunk 被执行，首先它会被预编译成虚拟机中的指令序列， 然后被虚拟机解释运行这些指令。

chunk 也可以被预编译成二进制形式；细节参考程序 luac。 用源码形式提供的程序和被编译过的二进制形式的程序是可以相互替换的； Lua 会自动识别文件类型并做正确的处理。

2.4.2 - 语句块

语句块是一列语句段；从语法上来说，一个语句块跟一个 chunk 相同：

	block ::= chunk
一个语句块可以被显式的写成一个单独的语句段：

	stat ::= do block end
显式的语句块对于控制变量的作用范围很有用。 有时候，显式的语句块被用来在另一个语句块中插入 return 或是 break （参见 §2.4.4）。

2.4.3 - 赋值

Lua 允许多重赋值。 因此，赋值的语法定义是等号左边放一系列变量， 而等号右边放一系列的表达式。 两边的元素都用逗号间开：

	stat ::= varlist1 `=´ explist1
	varlist1 ::= var {`,´ var}
	explist1 ::= exp {`,´ exp}
表达式放在 §2.5 里讨论。

在作赋值操作之前， 那一系列的右值会被对齐到左边变量需要的个数。 如果右值比需要的更多的话，多余的值就被扔掉。 如果右值的数量不够需求， 将会按所需扩展若干个 nil。 如果表达式列表以一个函数调用结束， 这个函数所返回的所有值都会在对齐操作之前被置入右值序列中。 （除非这个函数调用被用括号括了起来；参见 §2.5）。

赋值段首先会做运算完所有的表达式，然后仅仅做赋值操作。 因此，下面这段代码

     i = 3
     i, a[i] = i+1, 20
会把 a[3] 设置为 20，而不会影响到 a[4] 。 这是因为 a[i] 中的 i 在被赋值为 4 之前就被拿出来了（那时是 3 ）。 简单说 ，这样一行

     x, y = y, x
可以用来交换 x 和 y 中的值。

对全局变量以及 table 中的域的赋值操作的含义可以通过 metatable 来改变。 对变量下标指向的赋值，即 t[i] = val 等价于 settable_event(t,i,val)。 （关于函数 settable_event 的详细说明，参见 §2.8。 这个函数并没有在 Lua 中定义出来，也不可以被调用。 这里我们列出来，仅仅出于方便解释的目的）

对于全局变量的赋值 x = val 等价于 _env.x = val，这个又可以等价于

     settable_event(_env, "x", val)
这里，_env 指的是正在运行中的函数的环境。 （变量 _env 并没有在 Lua 中定义出来。 我们仅仅出于解释的目的在这里写出来。）

2.4.4 - 控制结构

if、 while、以及 repeat 这些控制结构符合通常的意义，而且也有类似的语法：

	stat ::= while exp do block end
	stat ::= repeat block until exp
	stat ::= if exp then block {elseif exp then block} [else block] end
Lua 也有一个 for 语句，它有两种形式（参见 §2.4.5）。

控制结构中的条件表达式可以返回任何值。 false 和 nil 两者都被认为是假条件。 所有不同于 nil 和 false 的其它值都被认为是真 （特别需要注意的是，数字 0 和空字符串也被认为是真）。

在 repeat–until 循环中， 内部语句块的结束点不是在 until 这个关键字处， 它还包括了其后的条件表达式。 因此，条件表达式中可以使用循环内部语句块中的定义的局部变量。

return 被用于从函数或是 chunk（其实它就是一个函数）中 返回值。 函数和 chunk 可以返回不只一个值， 所以 return 的语法为

	stat ::= return [explist1]
break 被用来结束 while、 repeat、或 for 循环， 它将忽略掉循环中下面的语句段的运行：

	stat ::= break
break 跳出最内层的循环。

return 和 break 只能被写在一个语句块的最后一句。 如果你真的需要从语句块的中间 return 或是 break ， 你可以使用显式的声名一个内部语句块。 一般写作 do return end 或是 do break end， 可以这样写是因为现在 return 或 break 都成了一个语句块的最后一句了。

2.4.5 - For 语句

for 有两种形式：一种是数字形式，另一种是一般形式。

数字形式的 for 循环，通过一个数学运算不断的运行内部的代码块。 下面是它的语法：

	stat ::= for Name `=´ exp `,´ exp [`,´ exp] do block end
block 将把 name 作循环变量。从第一个 exp 开始起，直到第二个 exp 的值为止，其步长为 第三个 exp 。 更确切的说，一个 for 循环看起来是这个样子

     for v = e1, e2, e3 do block end
这等价于代码：

     do
       local var, limit, step = tonumber(e1), tonumber(e2), tonumber(e3)
       if not (var and limit and step) then error() end
       while (step > 0 and var <= limit) or (step <= 0 and var >= limit) do
         local v = var
         block
         var = var + step
       end
     end
注意下面这几点：

所有三个控制表达式都只被运算一次，表达式的计算在循环开始之前。 这些表达式的结果必须是数字。
var 、limit 、以及 step 都是一些不可见的变量。 这里给它们起的名字都仅仅用于解释方便。
如果第三个表达式（步长）没有给出，会把步长设为 1 。
你可以用 break 来退出 for 循环。
循环变量 v 是一个循环内部的局部变量； 当 for 循环结束后，你就不能在使用它。 如果你需要这个值，在退出循环前把它赋给另一个变量。
一般形式的 for 通过一个叫作迭代器（iterators）的函数工作。 每次迭代，迭代器函数都会被调用以产生一个新的值， 当这个值为 nil 时，循环停止。 一般形式的 for 循环的语法如下：

	stat ::= for namelist in explist1 do block end
	namelist ::= Name {`,´ Name}
for 语句好似这样

     for var_1, ···, var_n in explist do block end
它等价于这样一段代码：

     do
       local f, s, var = explist
       while true do
         local var_1, ···, var_n = f(s, var)
         var = var_1
         if var == nil then break end
         block
       end
     end
注意以下几点：

explist 只会被计算一次。 它返回三个值， 一个迭代器函数，一个状态，一个迭代器的初始值。
f、 s、 以及 var 都是不可见的变量。 这里给它们起的名字都只是为了解说方便。
你可以使用 break 来跳出 for 循环。
循环变量 var_i 对于循环来说是一个局部变量； 你不可以在 for 循环结束后继续使用。 如果你需要保留这些值，那么就在循环结束前赋值到别的变量里去。
2.4.6 - 把函数调用作为语句段

为了允许使用可能的副作用， 函数调用可以被作为一个语句段执行：

	stat ::= functioncall
在这种情况下，所有的返回值都被舍弃。 函数调用在 §2.5.8 中解释。

2.4.7 - 局部变量声名

局部变量可以在语句块中任何地方声名。 声名可以包含一个初始化赋值操作：

	stat ::= local namelist [`=´ explist1]
如果有的话，初始化赋值操作的行为等同于赋值操作（参见 §2.4.3）。 否则，所有的变量将被初始化为 nil。

一个 chunk 同时也是一个语句块（参见 §2.4.1）， 所以局部变量可以放在 chunk 中那些显式注明的语句块之外。 这些局部变量的作用范围从声明起一直延伸到 chunk 末尾。

局部变量的可见规则在 §2.6 中解释。

2.5 - 表达式

Lua 中有这些基本表达式：

	exp ::= prefixexp
	exp ::= nil | false | true
	exp ::= Number
	exp ::= String
	exp ::= function
	exp ::= tableconstructor
	exp ::= `...´
	exp ::= exp binop exp
	exp ::= unop exp
	prefixexp ::= var | functioncall | `(´ exp `)´
数字和字符串在 §2.1 中解释； 变量在 §2.3 中解释； 函数定义在 §2.5.9 中解释； 函数调用在 §2.5.8 中解释； table 的构造在 §2.5.7 中解释； 可变参数的表达式写作三个点 ('...') ，它只能被用在有可变参数的函数中； 这些在 §2.5.9 中解释。

二元操作符包含有数学运算操作符（参见 §2.5.1）， 比较操作符（参见 §2.5.2），逻辑操作符（参见 §2.5.3）， 以及连接操作符（参见 §2.5.4）。 一元操作符包括负号（参见see §2.5.1）， 取反 not（参见 §2.5.3）， 和取长度操作符（参见 §2.5.5）。

函数调用和可变参数表达式都可以放在多重返回值中。 如果表达式作为一个独立语句段出现（参见 §2.4.6） （这只能是一个函数调用）， 它们的返回列表将被对齐到零个元素，也就是忽略所有返回值。 如果表达式用于表达式列表的最后（或者是唯一）的元素， 就不会有任何的对齐操作（除非函数调用用括号括起来）。 在任何其它的情况下，Lua 将把表达式结果看成单一元素， 忽略除第一个之外的任何值。

这里有一些例子：

     f()                -- 调整到 0 个结果
     g(f(), x)          -- f() 被调整到一个结果
     g(x, f())          -- g 被传入 x 加上所有 f() 的返回值
     a,b,c = f(), x     -- f() 被调整到一个结果 （ c 在这里被赋为 nil ）
     a,b = ...          -- a 被赋值为可变参数中的第一个，
                        -- b 被赋值为第二个 （如果可变参数中并没有对应的值，
						-- 这里 a 和 b 都有可能被赋为 nil）
     
     a,b,c = x, f()     -- f() 被调整为两个结果
     a,b,c = f()        -- f() 被调整为三个结果
     return f()         -- 返回 f() 返回的所有结果
     return ...         -- 返回所有从可变参数中接收来的值
     return x,y,f()     -- 返回 x, y, 以及所有 f() 的返回值
     {f()}              -- 用 f() 的所有返回值创建一个列表
     {...}              -- 用可变参数中的所有值创建一个列表
     {f(), nil}         -- f() 被调整为一个结果
被括号括起来的表达式永远被当作一个值。所以， (f(x,y,z)) 即使 f 返回多个值，这个表达式永远是一个单一值。 （(f(x,y,z)) 的值是 f 返回的第一个值。如果 f 不返回值的话，那么它的值就是 nil 。）

2.5.1 - 数学运算操作符

Lua 支持常见的数学运算操作符： 二元操作 + （加法）， - （减法），* （乘法）， / （除法）， % （取模），以及 ^ （幂）； 和一元操作 - （取负）。 如果对数字操作，或是可以转换为数字的字符串（参见 §2.2.1）， 所有这些操作都依赖它通常的含义。 幂操作可以对任何幂值都正常工作。比如， x^(-0.5) 将计算出 x 平方根的倒数。 取模操作被定义为

     a % b == a - math.floor(a/b)*b
这就是说，其结果是商相对负无穷圆整后的余数。（译注：负数对正数取模的结果为正数）

2.5.2 - 比较操作符

Lua 中的比较操作符有

     ==    ~=    <     >     <=    >=
这些操作的结果不是 false 就是 true。

等于操作 (==) 首先比较操作数的类型。 如果类型不同，结果就是 false。 否则，继续比较值。 数字和字符串都用常规的方式比较。 对象 （table ，userdata ，thread ，以及函数）以引用的形式比较： 两个对象只有在它们指向同一个东西时才认为相等。 每次你创建一个新对象（一个 table 或是 userdata ，thread 函数）， 它们都各不相同，即不同于上次创建的东西。

你可以改变 Lua 比较 table 和 userdata 的方式，这需要使用 "eq" 这个原方法 （参见 §2.8）。

§2.2.1 中提及的转换规则并不作用于比较操作。 所以， "0"==0 等于 false， 而且 t[0] 和 t["0"] 描述的是 table 中不同的域。

操作符 ~= 完全等价于 (==) 操作的反值。

大小比较操作以以下方式进行。 如果参数都是数字，那么就直接做数字比较。 否则，如果参数都是字符串，就用字符串比较的方式进行。 再则，Lua 就试着调用 "lt" 或是 "le" 元方法 （参见 §2.8）。

2.5.3 - 逻辑操作符

Lua 中的逻辑操作符有 and, or, 以及 not。 和控制结构（参见 §2.4.4）一样， 所有的逻辑操作符把 false 和 nil 都作为假， 而其它的一切都当作真。

取反操作 not 总是返回 false 或 true 中的一个。 与操作符 and 在第一个参数为 false 或 nil 时 返回这第一个参数； 否则，and 返回第二个参数。 或操作符 or 在第一个参数不为 nil 也不为 false 时， 返回这第一个参数，否则返回第二个参数。 and 和 or 都遵循短路规则； 也就是说，第二个操作数只在需要的时候去求值。 这里有一些例子：

     10 or 20            --> 10
     10 or error()       --> 10
     nil or "a"          --> "a"
     nil and 10          --> nil
     false and error()   --> false
     false and nil       --> false
     false or nil        --> nil
     10 and 20           --> 20
（在这本手册中， --> 指前面表达式的结果。）

2.5.4 - 连接符

Lua 中字符串的连接操作符写作两个点 ('..')。 如果两个操作数都是字符串或都是数字，连接操作将以 §2.2.1 中提到的规则把其转换为字符串。 否则，会取调用元方法 "concat" （参见 §2.8）。

2.5.5 - 取长度操作符

取长度操作符写作一元操作 #。 字符串的长度是它的字节数（就是以一个字符一个字节计算的字符串长度）。

table t 的长度被定义成一个整数下标 n 。 它满足 t[n] 不是 nil 而 t[n+1] 为 nil； 此外，如果 t[1] 为 nil ，n 就可能是零。 对于常规的数组，里面从 1 到 n 放着一些非空的值的时候， 它的长度就精确的为 n，即最后一个值的下标。 如果数组有一个“空洞” （就是说，nil 值被夹在非空值之间）， 那么 #t 可能是指向任何一个是 nil 值的前一个位置的下标 （就是说，任何一个 nil 值都有可能被当成数组的结束）。

2.5.6 - 优先级

Lua 中操作符的优先级写在下表中，从低到高优先级排序：

     or
     and
     <     >     <=    >=    ~=    ==
     ..
     +     -
     *     /     %
     not   #     - (unary)
     ^
通常，你可以用括号来改变运算次序。 连接操作符 ('..') 和幂操作 ('^') 是从右至左的。 其它所有的操作都是从左至右。

2.5.7 - Table 构造

table 构造子是一个构造 table 的表达式。 每次构造子被执行，都会构造出一个新的 table 。 构造子可以被用来构造一个空的 table， 也可以用来构造一个 table 并初始化其中的一些域。 一般的构造子的语法如下

	tableconstructor ::= `{´ [fieldlist] `}´
	fieldlist ::= field {fieldsep field} [fieldsep]
	field ::= `[´ exp `]´ `=´ exp | Name `=´ exp | exp
	fieldsep ::= `,´ | `;´
每个形如 [exp1] = exp2 的域向 table 中增加新的一项， 其键值为 exp1 而值为 exp2。 形如 name = exp 的域等价于 ["name"] = exp。 最后，形如 exp 的域等价于 [i] = exp ， 这里的 i 是一个从 1 开始不断增长的数字。 这这个格式中的其它域不会破坏其记数。 举个例子：

     a = { [f(1)] = g; "x", "y"; x = 1, f(x), [30] = 23; 45 }
等价于

     do
       local t = {}
       t[f(1)] = g
       t[1] = "x"         -- 1st exp
       t[2] = "y"         -- 2nd exp
       t.x = 1            -- t["x"] = 1
       t[3] = f(x)        -- 3rd exp
       t[30] = 23
       t[4] = 45          -- 4th exp
       a = t
     end
如果表单中最后一个域的形式是 exp ， 而且其表达式是一个函数调用或者是一个可变参数， 那么这个表达式所有的返回值将连续的进入列表 （参见 §2.5.8）。 为了避免这一点，你可以用括号把函数调用（或是可变参数）括起来 （参见 §2.5）。

初始化域表可以在最后多一个分割符， 这样设计可以方便由机器生成代码。

2.5.8 - 函数调用

Lua 中的函数调用的语法如下：

	functioncall ::= prefixexp args
函数调用时，第一步，prefixexp 和 args 先被求值。 如果 prefixexp 的值的类型是 function， 那么这个函数就被用给出的参数调用。 否则 prefixexp 的元方法 "call" 就被调用， 第一个参数就是 prefixexp 的值，跟下来的是原来的调用参数 （参见 §2.8）。

这样的形式

	functioncall ::= prefixexp `:´ Name args
可以用来调用 "方法"。 这是 Lua 支持的一种语法糖。像 v:name(args) 这个样子，被解释成 v.name(v,args)， 这里 v 只会被求值一次。

参数的语法如下：

	args ::= `(´ [explist1] `)´
	args ::= tableconstructor
	args ::= String
所有参数的表达式求值都在函数调用之前。 这样的调用形式 f{fields} 是一种语法糖用于表示 f({fields})； 这里指参数列表是一个单一的新创建出来的列表。 而这样的形式 f'string' （或是 f"string" 亦或是 f[[string]]） 也是一种语法糖，用于表示 f('string')； 这里指参数列表是一个单独的字符串。

因为表达式语法在 Lua 中比较自由， 所以你不能在函数调用的 '(' 前换行。 这个限制可以避免语言中的一些歧义。 比如你这样写

     a = f
     (g).x(a)
Lua 将把它当作一个单一语句段， a = f(g).x(a) 。 因此，如果你真的想作为成两个语句段，你必须在它们之间写上一个分号。 如果你真的想调用 f， 你必须从 (g) 前移去换行。

这样一种调用形式：return functioncall 将触发一个尾调用。 Lua 实现了适当的尾部调用（或是适当的尾递归）： 在尾调用中， 被调用的函数重用调用它的函数的堆栈项。 因此，对于程序执行的嵌套尾调用的层数是没有限制的。 然而，尾调用将删除调用它的函数的任何调试信息。 注意，尾调用只发生在特定的语法下， 这时， return 只有单一函数调用作为参数； 这种语法使得调用函数的结果可以精确返回。 因此，下面这些例子都不是尾调用：

     return (f(x))        -- 返回值被调整为一个
     return 2 * f(x)
     return x, f(x)       -- 最加若干返回值
     f(x); return         -- 无返回值
     return x or f(x)     -- 返回值被调整为一个
2.5.9 - 函数定义

函数定义的语法如下：

	function ::= function funcbody
	funcbody ::= `(´ [parlist1] `)´ block end
另外定义了一些语法糖简化函数定义的写法：

	stat ::= function funcname funcbody
	stat ::= local function Name funcbody
	funcname ::= Name {`.´ Name} [`:´ Name]
这样的写法：

     function f () body end
被转换成

     f = function () body end
这样的写法：

     function t.a.b.c.f () body end
被转换成

     t.a.b.c.f = function () body end
这样的写法：

     local function f () body end
被转换成

     local f; f = function () body end
注意，并不是转换成

     local f = function () body end
（这个差别只在函数体内需要引用 f 时才有。）

一个函数定义是一个可执行的表达式， 执行结果是一个类型为 function 的值。 当 Lua 预编译一个 chunk 的时候， chunk 作为一个函数，整个函数体也就被预编译了。 那么，无论何时 Lua 执行了函数定义， 这个函数本身就被实例化了（或者说是关闭了）。 这个函数的实例（或者说是 closure（闭包）） 是表达式的最终值。 相同函数的不同实例有可能引用不同的外部局部变量， 也可能拥有不同的环境表。

形参（函数定义需要的参数）是一些由实参（实际传入参数）的值初始化的局部变量：

	parlist1 ::= namelist [`,´ `...´] | `...´
当一个函数被调用， 如果函数没有被定义为接收不定长参数，即在形参列表的末尾注明三个点 ('...')， 那么实参列表就会被调整到形参列表的长度， 变长参数函数不会调整实参列表； 取而代之的是，它将把所有额外的参数放在一起通过变长参数表达式传递给函数， 其写法依旧是三个点。 这个表达式的值是一串实参值的列表，看起来就跟一个可以返回多个结果的函数一样。 如果一个变长参数表达式放在另一个表达式中使用，或是放在另一串表达式的中间， 那么它的返回值就会被调整为单个值。 若这个表达式放在了一系列表达式的最后一个，就不会做调整了（除非用括号给括了起来）。

我们先做如下定义，然后再来看一个例子：

     function f(a, b) end
     function g(a, b, ...) end
     function r() return 1,2,3 end
下面看看实参到形参数以及可变长参数的映射关系：

     CALL            PARAMETERS
     
     f(3)             a=3, b=nil
     f(3, 4)          a=3, b=4
     f(3, 4, 5)       a=3, b=4
     f(r(), 10)       a=1, b=10
     f(r())           a=1, b=2
     
     g(3)             a=3, b=nil, ... -->  (nothing)
     g(3, 4)          a=3, b=4,   ... -->  (nothing)
     g(3, 4, 5, 8)    a=3, b=4,   ... -->  5  8
     g(5, r())        a=5, b=1,   ... -->  2  3
结果由 return 来返回（参见 §2.4.4）。 如果执行到函数末尾依旧没有遇到任何 return 语句， 函数就不会返回任何结果。

冒号语法可以用来定义方法， 就是说，函数可以有一个隐式的形参 self。 因此，如下写法：

     function t.a.b.c:f (params) body end
是这样一种写法的语法糖：

     t.a.b.c.f = function (self, params) body end
2.6 - 可视规则

Lua 是一个有词法作用范围的语言。 变量的作用范围开始于声明它们之后的第一个语句段， 结束于包含这个声明的最内层语句块的结束点。 看下面这些例子：

     x = 10                -- 全局变量
     do                    -- 新的语句块
       local x = x         -- 新的一个 'x', 它的值现在是 10
       print(x)            --> 10
       x = x+1
       do                  -- 另一个语句块
         local x = x+1     -- 又一个 'x'
         print(x)          --> 12
       end
       print(x)            --> 11
     end
     print(x)              --> 10  （取到的是全局的那一个）
注意这里，类似 local x = x 这样的声明， 新的 x 正在被声明，但是还没有进入它的作用范围， 所以第二个 x 指向的是外面一层的变量。

因为有这样一个词法作用范围的规则， 所以可以在函数内部自由的定义局部变量并使用它们。 当一个局部变量被更内层的函数中使用的时候， 它被内层函数称作 upvalue（上值），或是 外部局部变量。

注意，每次执行到一个 local 语句都会定义出一个新的局部变量。 看看这样一个例子：

     a = {}
     local x = 20
     for i=1,10 do
       local y = 0
       a[i] = function () y=y+1; return x+y end
     end
这个循环创建了十个 closure（这指十个匿名函数的实例）。 这些 closure 中的每一个都使用了不同的 y 变量， 而它们又共享了同一份 x。

2.7 - 错误处理

因为 Lua 是一个嵌入式的扩展语言， 所有的 Lua 动作都是从宿主程序的 C 代码调用 Lua 库 （参见 lua_pcall）中的一个函数开始的。 在 Lua 编译或运行的任何时候发生了错误，控制权都会交还给 C ， 而 C 可以来做一些恰当的措施（比如打印出一条错误信息）。

Lua 代码可以显式的调用 error 函数来产生一条错误。 如果你需要在 Lua 中捕获发生的错误， 你可以使用 pcall 函数。

2.8 - Metatable（元表）

Lua 中的每个值都可以用一个 metatable。 这个 metatable 就是一个原始的 Lua table ， 它用来定义原始值在特定操作下的行为。 你可以通过在 metatable 中的特定域设一些值来改变拥有这个 metatable 的值 的指定操作之行为。 举例来说，当一个非数字的值作加法操作的时候， Lua 会检查它的 metatable 中 "__add" 域中的是否有一个函数。 如果有这么一个函数的话，Lua 调用这个函数来执行一次加法。

我们叫 metatable 中的键名为 事件 (event) ，把其中的值叫作 元方法 (metamethod)。 在上个例子中，事件是 "add" 而元方法就是那个执行加法操作的函数。

你可以通过 getmetatable 函数来查询到任何一个值的 metatable。

你可以通过 setmetatable 函数来替换掉 table 的 metatable 。 你不能从 Lua 中改变其它任何类型的值的 metatable （使用 debug 库例外）； 要这样做的话必须使用 C API 。

每个 table 和 userdata 拥有独立的 metatable （当然多个 table 和 userdata 可以共享一个相同的表作它们的 metatable）； 其它所有类型的值，每种类型都分别共享唯一的一个 metatable。 因此，所有的数字一起只有一个 metatable ，所有的字符串也是，等等。

一个 metatable 可以控制一个对象做数学运算操作、比较操作、连接操作、取长度操作、取下标操作时的行为， metatable 中还可以定义一个函数，让 userdata 作垃圾收集时调用它。 对于这些操作，Lua 都将其关联上一个被称作事件的指定健。 当 Lua 需要对一个值发起这些操作中的一个时， 它会去检查值中 metatable 中是否有对应事件。 如果有的话，键名对应的值（元方法）将控制 Lua 怎样做这个操作。

metatable 可以控制的操作已在下面列出来。 每个操作都用相应的名字区分。 每个操作的键名都是用操作名字加上两个下划线 '__' 前缀的字符串； 举例来说，"add" 操作的键名就是字符串 "__add"。 这些操作的语义用一个 Lua 函数来描述解释器如何执行更为恰当。

这里展示的用 Lua 写的代码仅作解说用； 实际的行为已经硬编码在解释器中，其执行效率要远高于这些模拟代码。 这些用于描述的的代码中用到的函数 （ rawget ， tonumber ，等等。） 都可以在 §5.1 中找到。 特别注意，我们使用这样一个表达式来从给定对象中提取元方法

     metatable(obj)[event]
这个应该被解读作

     rawget(getmetatable(obj) or {}, event)
这就是说，访问一个元方法不再会触发任何的元方法， 而且访问一个没有 metatable 的对象也不会失败（而只是简单返回 nil）。

"add": + 操作。
下面这个 getbinhandler 函数定义了 Lua 怎样选择一个处理器来作二元操作。 首先，Lua 尝试第一个操作数。 如果这个东西的类型没有定义这个操作的处理器，然后 Lua 会尝试第二个操作数。

     function getbinhandler (op1, op2, event)
       return metatable(op1)[event] or metatable(op2)[event]
     end
通过这个函数， op1 + op2 的行为就是

     function add_event (op1, op2)
       local o1, o2 = tonumber(op1), tonumber(op2)
       if o1 and o2 then  -- 两个操作数都是数字？
         return o1 + o2   -- 这里的 '+' 是原生的 'add'
       else  -- 至少一个操作数不是数字时
         local h = getbinhandler(op1, op2, "__add")
         if h then
           -- 以两个操作数来调用处理器
           return h(op1, op2)
         else  -- 没有处理器：缺省行为
           error(···)
         end
       end
     end
"sub": - 操作。 其行为类似于 "add" 操作。
"mul": * 操作。 其行为类似于 "add" 操作。
"div": / 操作。 其行为类似于 "add" 操作。
"mod": % 操作。 其行为类似于 "add" 操作， 它的原生操作是这样的 o1 - floor(o1/o2)*o2
"pow": ^ （幂）操作。 其行为类似于 "add" 操作， 它的原生操作是调用 pow 函数（通过 C math 库）。
"unm": 一元 - 操作。
     function unm_event (op)
       local o = tonumber(op)
       if o then  -- 操作数是数字？
         return -o  -- 这里的 '-' 是一个原生的 'unm'
       else  -- 操作数不是数字。
         -- 尝试从操作数中得到处理器
         local h = metatable(op).__unm
         if h then
           -- 以操作数为参数调用处理器
           return h(op)
         else  -- 没有处理器：缺省行为
           error(···)
         end
       end
     end
"concat": .. （连接）操作，
     function concat_event (op1, op2)
       if (type(op1) == "string" or type(op1) == "number") and
          (type(op2) == "string" or type(op2) == "number") then
         return op1 .. op2  -- 原生字符串连接
       else
         local h = getbinhandler(op1, op2, "__concat")
         if h then
           return h(op1, op2)
         else
           error(···)
         end
       end
     end
"len": # 操作。
     function len_event (op)
       if type(op) == "string" then
         return strlen(op)         -- 原生的取字符串长度
       elseif type(op) == "table" then
         return #op                -- 原生的取 table 长度
       else
         local h = metatable(op).__len
         if h then
           -- 调用操作数的处理器
           return h(op)
         else  -- 没有处理器：缺省行为
           error(···)
         end
       end
     end
关于 table 的长度参见 §2.5.5 。

"eq": == 操作。 函数 getcomphandler 定义了 Lua 怎样选择一个处理器来作比较操作。 元方法仅仅在参于比较的两个对象类型相同且有对应操作相同的元方法时才起效。
     function getcomphandler (op1, op2, event)
       if type(op1) ~= type(op2) then return nil end
       local mm1 = metatable(op1)[event]
       local mm2 = metatable(op2)[event]
       if mm1 == mm2 then return mm1 else return nil end
     end
"eq" 事件按如下方式定义：

     function eq_event (op1, op2)
       if type(op1) ~= type(op2) then  -- 不同的类型？
         return false   -- 不同的对象
       end
       if op1 == op2 then   -- 原生的相等比较结果？
         return true   -- 对象相等
       end
       -- 尝试使用元方法
       local h = getcomphandler(op1, op2, "__eq")
       if h then
         return h(op1, op2)
       else
         return false
       end
     end
a ~= b 等价于 not (a == b) 。

"lt": < 操作。
     function lt_event (op1, op2)
       if type(op1) == "number" and type(op2) == "number" then
         return op1 < op2   -- 数字比较
       elseif type(op1) == "string" and type(op2) == "string" then
         return op1 < op2   -- 字符串按逐字符比较
       else
         local h = getcomphandler(op1, op2, "__lt")
         if h then
           return h(op1, op2)
         else
           error(···);
         end
       end
     end
a > b 等价于 b < a.

"le": <= 操作。
     function le_event (op1, op2)
       if type(op1) == "number" and type(op2) == "number" then
         return op1 <= op2   -- 数字比较
       elseif type(op1) == "string" and type(op2) == "string" then
         return op1 <= op2   -- 字符串按逐字符比较
       else
         local h = getcomphandler(op1, op2, "__le")
         if h then
           return h(op1, op2)
         else
           h = getcomphandler(op1, op2, "__lt")
           if h then
             return not h(op2, op1)
           else
             error(···);
           end
         end
       end
     end
a >= b 等价于 b <= a 。 注意，如果元方法 "le" 没有提供，Lua 就尝试 "lt" ， 它假定 a <= b 等价于 not (b < a) 。

"index": 取下标操作用于访问 table[key] 。
     function gettable_event (table, key)
       local h
       if type(table) == "table" then
         local v = rawget(table, key)
         if v ~= nil then return v end
         h = metatable(table).__index
         if h == nil then return nil end
       else
         h = metatable(table).__index
         if h == nil then
           error(···);
         end
       end
       if type(h) == "function" then
         return h(table, key)      -- 调用处理器
       else return h[key]          -- 或是重复上述操作
       end
     end
"newindex": 赋值给指定下标 table[key] = value 。
     function settable_event (table, key, value)
       local h
       if type(table) == "table" then
         local v = rawget(table, key)
         if v ~= nil then rawset(table, key, value); return end
         h = metatable(table).__newindex
         if h == nil then rawset(table, key, value); return end
       else
         h = metatable(table).__newindex
         if h == nil then
           error(···);
         end
       end
       if type(h) == "function" then
         return h(table, key,value)    -- 调用处理器
       else h[key] = value             -- 或是重复上述操作
       end
     end
"call": 当 Lua 调用一个值时调用。
     function function_event (func, ...)
       if type(func) == "function" then
         return func(...)   -- 原生的调用
       else
         local h = metatable(func).__call
         if h then
           return h(func, ...)
         else
           error(···)
         end
       end
     end
2.9 - 环境

类型为 thread ，function ，以及 userdata 的对象，除了 metatable 外还可以用另外一个与之关联的被称作 它们的环境的一个表， 像 metatable 一样，环境也是一个常规的 table ，多个对象可以共享 同一个环境。

userdata 的环境在 Lua 中没有意义。 这个东西只是为了在程序员想把一个表关联到一个 userdata 上时提供便利。

关联在线程上的环境被称作全局环境。 全局环境被用作它其中的线程以及线程创建的非嵌套函数 （通过 loadfile ， loadstring 或是 load ）的缺省环境。 而且它可以被 C 代码直接访问（参见 §3.3）。

关联在 C 函数上的环境可以直接被 C 代码访问（参见 §3.3）。 它们会作为这个 C 函数中创建的其它函数的缺省环境。

关联在 Lua 函数上的环境用来接管在函数内对全局变量（参见 §2.3）的所有访问。 它们也会作为这个函数内创建的其它函数的缺省环境。

你可以通过调用 setfenv 来改变一个 Lua 函数 或是正在运行中的线程的环境。 而想操控其它对象（userdata、C 函数、其它线程）的环境的话，就必须使用 C API 。

2.10 - 垃圾收集

Lua 提供了一个自动的内存管理。 这就是说你不需要关心创建新对象的分配内存操作，也不需要在这些对象不再需要时的主动释放内存。 Lua 通过运行一个垃圾收集器来自动管理内存，以此一遍又一遍的回收死掉的对象 （这是指 Lua 中不再访问的到的对象）占用的内存。 Lua 中所有对象都被自动管理，包括： table, userdata、 函数、线程、和字符串。

Lua 实现了一个增量标记清除的收集器。 它用两个数字来控制垃圾收集周期： garbage-collector pause 和 garbage-collector step multiplier 。

garbage-collector pause 控制了收集器在开始一个新的收集周期之前要等待多久。 随着数字的增大就导致收集器工作工作的不那么主动。 小于 1 的值意味着收集器在新的周期开始时不再等待。 当值为 2 的时候意味着在总使用内存数量达到原来的两倍时再开启新的周期。

step multiplier 控制了收集器相对内存分配的速度。 更大的数字将导致收集器工作的更主动的同时，也使每步收集的尺寸增加。 小于 1 的值会使收集器工作的非常慢，可能导致收集器永远都结束不了当前周期。 缺省值为 2 ，这意味着收集器将以内存分配器的两倍速运行。

你可以通过在 C 中调用 lua_gc 或是在 Lua 中调用 collectgarbage 来改变这些数字。 两者都接受百分比数值（因此传入参数 100 意味着实际值 1 ）。 通过这些函数，你也可以直接控制收集器（例如，停止或是重启）。

2.10.1 - 垃圾收集的元方法

使用 C API　， 你可以给 userdata （参见 §2.8）设置一个垃圾收集的元方法。 这个元方法也被称为结束子。 结束子允许你用额外的资源管理器和 Lua 的内存管理器协同工作 （比如关闭文件、网络连接、或是数据库连接，也可以说释放你自己的内存）。

一个 userdata 可被回收，若它的 metatable 中有 __gc 这个域　， 垃圾收集器就不立即收回它。 取而代之的是，Lua 把它们放到一个列表中。 最收集结束后，Lua 针对列表中的每个 userdata 执行了下面这个函数的等价操作：

     function gc_event (udata)
       local h = metatable(udata).__gc
       if h then
         h(udata)
       end
     end
在每个垃圾收集周期的结尾，每个在当前周期被收集起来的 userdata 的结束子会以 它们构造时的逆序依次调用。 也就是说，收集列表中，最后一个在程序中被创建的 userdata 的 结束子会被第一个调用。

2.10.2 - Weak Table（弱表）

weak table 是一个这样的 table，它其中的元素都被弱引用。 弱引用将被垃圾收集器忽略掉， 换句话说， 如果对一个对象的引用只有弱引用， 垃圾收集器将回收这个对象。

weak table 的键和值都可以是 weak 的。 如果一个 table 只有键是 weak 的，那么将运行收集器回收它们的键， 但是会阻止回收器回收对应的值。 而一个 table 的键和值都是 weak 时，就即允许收集器回收键又允许收回值。 任何情况下，如果键和值中任一个被回收了，整个键值对就会从 table 中拿掉。 table 的 weak 特性可以通过在它的 metatable 中设置 __mode 域来改变。 如果 __mode 域中是一个包含有字符 'k' 的字符串时， table 的键就是 weak 的。 如果 __mode 域中是一个包含有字符 'v' 的字符串时， table 的值就是 weak 的。

在你把一个 table 当作一个 metatable 使用之后， 就不能再修改 __mode 域的值。 否则，受这个 metatable 控制的 table 的 weak 行为就成了未定义的。

2.11 - Coroutine （协同例程）

Lua 支持 coroutine ，这个东西也被称为协同式多线程 (collaborative multithreading)　。 Lua 为每个 coroutine 提供一个独立的运行线路。 然而和多线程系统中的线程不同，coroutine 只在显式的调用了 yield 函数时才会挂起。

创建一个 coroutine 需要调用一次 coroutine.create 。 它只接收单个参数，这个参数是 coroutine 的主函数。 create 函数仅仅创建一个新的 coroutine 然后返回它的控制器 （一个类型为 thread 的对象）； 它并不会启动 coroutine 的运行。

当你第一次调用 coroutine.resume 时， 所需传入的第一个参数就是 coroutine.create 的返回值。 这时，coroutine 从主函数的第一行开始运行。 接下来传入 coroutine.resume 的参数将被传进 coroutine 的主函数。 在 coroutine 开始运行后，它讲运行到自身终止或是遇到一个 yields 。

coroutine 可以通过两种方式来终止运行： 一种是正常退出，指它的主函数返回（最后一条指令被运行后，无论有没有显式的返回指令）; 另一种是非正常退出，它发生在未保护的错误发生的时候。 第一种情况中， coroutine.resume 返回 true ， 接下来会跟着 coroutine 主函数的一系列返回值。 第二种发生错误的情况下， coroutine.resume 返回 false ， 紧接着是一条错误信息。

coroutine 中切换出去，可以调用 coroutine.yield。 当 coroutine 切出，与之配合的 coroutine.resume 就立即返回， 甚至在 yield 发生在内层的函数调用中也可以（就是说， 这不限于发生在主函数中，也可以是主函数直接或间接调用的某个函数里）。 在 yield 的情况下，coroutine.resume 也是返回 true， 紧跟着那些被传入 coroutine.yield 的参数。 等到下次你在继续同样的 coroutine ，将从调用 yield 的断点处运行下去。 断点处 yield 的返回值将是 coroutine.resume 传入的参数。

类似 coroutine.create ， coroutine.wrap 这个函数也将创建一个 coroutine ， 但是它并不返回 coroutine 本身，而是返回一个函数取而代之。一旦你调用这个返回函数，就会切入 coroutine 运行。 所有传入这个函数的参数等同于传入 coroutine.resume 的参数。 coroutine.wrap 会返回所有应该由除第一个（错误代码的那个布尔量） 之外的由 coroutine.resume 返回的值。 和 coroutine.resume 不同， coroutine.wrap 不捕获任何错误； 所有的错误都应该由调用者自己传递。

看下面这段代码展示的一个例子：

     function foo (a)
       print("foo", a)
       return coroutine.yield(2*a)
     end
     
     co = coroutine.create(function (a,b)
           print("co-body", a, b)
           local r = foo(a+1)
           print("co-body", r)
           local r, s = coroutine.yield(a+b, a-b)
           print("co-body", r, s)
           return b, "end"
     end)
            
     print("main", coroutine.resume(co, 1, 10))
     print("main", coroutine.resume(co, "r"))
     print("main", coroutine.resume(co, "x", "y"))
     print("main", coroutine.resume(co, "x", "y"))
当你运行它，将得到如下输出结果：

     co-body 1       10
     foo     2
     
     main    true    4
     co-body r
     main    true    11      -9
     co-body x       y
     main    true    10      end
     main    false   cannot resume dead coroutine
3 - 程序接口（API）

这个部分描述了 Lua 的 C API ， 也就是宿主程序跟 Lua 通讯用的一组 C 函数。 所有的 API 函数按相关的类型以及常量都声明在头文件 lua.h 中。

虽然我们说的是“函数”，但一部分简单的 API 是以宏的形式提供的。 所有的这些宏都只使用它们的参数一次 （除了第一个参数，也就是 lua 状态机）， 因此你不需担心这些宏的展开会引起一些副作用。

在所有的 C 库中，Lua API 函数都不去检查参数的有效性和坚固性。 然而，你可以在编译 Lua 时加上打开一个宏开关来 开启 luaconf.h 文件中的宏 luai_apicheck 以改变这个行为。

3.1 - 堆栈

Lua 使用一个虚拟栈来和 C 传递值。 栈上的的每个元素都是一个 Lua 值 （nil，数字，字符串，等等）。

无论何时 Lua 调用 C，被调用的函数都得到一个新的栈， 这个栈独立于 C 函数本身的堆栈，也独立于以前的栈。 （译注：在 C 函数里，用 Lua API 不能访问到 Lua 状态机中本次调用之外的堆栈中的数据） 它里面包含了 Lua 传递给 C 函数的所有参数， 而 C 函数则把要返回的结果也放入堆栈以返回给调用者 （参见 lua_CFunction）。

方便起见，所有针对栈的 API 查询操作都不严格遵循栈的操作规则。 而是可以用一个索引来指向栈上的任何元素： 正的索引指的是栈上的绝对位置（从一开始）； 负的索引则指从栈顶开始的偏移量。 更详细的说明一下，如果堆栈有 n 个元素， 那么索引 1 表示第一个元素（也就是最先被压入堆栈的元素） 而索引 n 则指最后一个元素； 索引 -1 也是指最后一个元素（即栈顶的元素）， 索引 -n 是指第一个元素。 如果索引在 1 到栈顶之间（也就是，1 ≤ abs(index) ≤ top） 我们就说这是个有效的索引。

3.2 - 堆栈尺寸

当你使用 Lua API 时，就有责任保证其坚固性。 特别需要注意的是，你有责任控制不要堆栈溢出。 你可以使用 lua_checkstack 这个函数来扩大可用堆栈的尺寸。

无论何时 Lua 调用 C ， 它都只保证 LUA_MINSTACK 这么多的堆栈空间可以使用。 LUA_MINSTACK 一般被定义为 20　， 因此，只要你不是不断的把数据压栈，通常你不用关心堆栈大小。

所有的查询函数都可以接收一个索引，只要这个索引是任何栈提供的空间中的值。 栈能提供的最大空间是通过 lua_checkstack 来设置的。 这些索引被称作可接受的索引，通常我们把它定义为：

     (index < 0 && abs(index) <= top) ||
     (index > 0 && index <= stackspace)
注意，0 永远都不是一个可接受的索引。（译注：下文中凡提到的索引，没有特别注明的话，都指可接受的索引。）

3.3 - 伪索引

除了特别声明外，任何一个函数都可以接受另一种有效的索引，它们被称作“伪索引”。 这个可以帮助 C 代码访问一些并不在栈上的 Lua 值。 伪索引被用来访问线程的环境，函数的环境，注册表，还有 C 函数的 upvalue （参见 §3.4）。

线程的环境（也就是全局变量放的地方）通常在伪索引 LUA_GLOBALSINDEX 处。 正在运行的 C 函数的环境则放在伪索引 LUA_ENVIRONINDEX 之处。

你可以用常规的 table 操作来访问和改变全局变量的值，只需要指定环境表的位置。 举例而言，要访问全局变量的值，这样做：

     lua_getfield(L, LUA_GLOBALSINDEX, varname);
3.4 - C Closure

当 C 函数被创建出来，我们有可能会把一些值关联在一起， 也就是创建一个 C closure ； 这些被关联起来的值被叫做 upvalue ， 它们可以在函数被调用的时候访问的到。 （参见 lua_pushcclosure）。

无论何时去调用 C 函数，函数的 upvalue 都被放在指定的伪索引处。 我们可以用 lua_upvalueindex 这个宏来生成这些伪索引。 第一个关联到函数的值放在 lua_upvalueindex(1) 位置处，依次类推。 任何情况下都可以用 lua_upvalueindex(n) 产生一个 upvalue 的索引， 即使　n 大于实际的 upvalue 数量也可以。它都可以产生一个可接受但不一定有效的索引。

3.5 - 注册表

Lua 提供了一个注册表，这是一个预定义出来的表，可以用来保存任何 C 代码想保存的 Lua 值。 这个表可以用伪索引 LUA_REGISTRYINDEX 来定位。 任何 C 库都可以在这张表里保存数据，为了防止冲突，你需要特别小心的选择键名。 一般的用法是，你可以用一个包含你的库名的字符串做为键名，或者可以取你自己 C 代码 中的一个地址，以 light userdata 的形式做键。

注册表里的整数健被用于补充库中实现的引用系统的工作，一般说来不要把它们用于别的用途。

3.6 - C 中的错误处理

在内部实现中，Lua 使用了 C 的 longjmp 机制来处理错误。 （如果你使用 C++ 的话，也可以选择换用异常；参见 luaconf.h 文件。） 当 Lua 碰到任何错误（比如内存分配错误、类型错误、语法错误、还有一些运行时错误） 它都会产生一个错误出去； 也就是调用一个 long jump 。 在保护环境下，Lua 使用 setjmp 来设置一个恢复点； 任何发生的错误都会激活最近的一个恢复点。

几乎所有的 API 函数都可能产生错误，例如内存分配错误。 但下面的一些函数运行在保护环境中（也就是说它们创建了一个保护环境再在其中运行）， 因此它们不会产生错误出来： lua_newstate, lua_close, lua_load, lua_pcall, and lua_cpcall。

在 C 函数里，你也可以通过调用 lua_error 产生一个错误。

3.7 - 函数和类型

在这里我们按字母次序列出了所有 C API 中的函数和类型。

lua_Alloc

typedef void * (*lua_Alloc) (void *ud,
                             void *ptr,
                             size_t osize,
                             size_t nsize);
Lua 状态机中使用的内存分配器函数的类型。 内存分配函数必须提供一个功能类似于 realloc 但又不完全相同的函数。 它的参数有 ud ，一个由 lua_newstate 传给它的指针； ptr ，一个指向已分配出来或是将被重新分配或是要释放的内存块指针； osize ，内存块原来的尺寸； nsize ，新内存块的尺寸。 如果且只有 osize 是零时，ptr 为 NULL 。 当 nsize 是零，分配器必须返回 NULL； 如果 osize 不是零，分配器应当释放掉 ptr 指向的内存块。 当 nsize 不是零，若分配器不能满足请求时，分配器返回 NULL 。 当 nsize 不是零而 osize 是零时，分配器应该和 malloc 有相同的行为。 当 nsize 和 osize 都不是零时，分配器则应和 realloc 保持一样的行为。 Lua 假设分配器在 osize >= nsize 时永远不会失败。

这里有一个简单的分配器函数的实现。 这个实现被放在补充库中，由 luaL_newstate 提供。

     static void *l_alloc (void *ud, void *ptr, size_t osize,
                                                size_t nsize) {
       (void)ud;  (void)osize;  /* not used */
       if (nsize == 0) {
         free(ptr);
         return NULL;
       }
       else
         return realloc(ptr, nsize);
     }
这段代码假设 free(NULL) 啥也不影响，而且 realloc(NULL, size) 等价于 malloc(size)。 这两点是 ANSI C 保证的行为。

lua_atpanic

lua_CFunction lua_atpanic (lua_State *L, lua_CFunction panicf);
设置一个新的 panic （恐慌） 函数，并返回前一个。

如果在保护环境之外发生了任何错误， Lua 就会调用一个 panic 函数，接着调用 exit(EXIT_FAILURE)， 这样就开始退出宿主程序。 你的 panic 函数可以永远不返回（例如作一次长跳转）来避免程序退出。

panic 函数可以从栈顶取到出错信息。

lua_call

void lua_call (lua_State *L, int nargs, int nresults);
调用一个函数。

要调用一个函数请遵循以下协议： 首先，要调用的函数应该被压入堆栈； 接着，把需要传递给这个函数的参数按正序压栈； 这是指第一个参数首先压栈。 最后调用一下 lua_call； nargs 是你压入堆栈的参数个数。 当函数调用完毕后，所有的参数以及函数本身都会出栈。 而函数的返回值这时则被压入堆栈。 返回值的个数将被调整为 nresults 个， 除非 nresults 被设置成 LUA_MULTRET。 在这种情况下，所有的返回值都被压入堆栈中。 Lua 会保证返回值都放入栈空间中。 函数返回值将按正序压栈（第一个返回值首先压栈）， 因此在调用结束后，最后一个返回值将被放在栈顶。

被调用函数内发生的错误将（通过 longjmp）一直上抛。

下面的例子中，这行 Lua 代码等价于在宿主程序用 C 代码做一些工作：

     a = f("how", t.x, 14)
这里是 C 里的代码：

     lua_getfield(L, LUA_GLOBALSINDEX, "f");          /* 将调用的函数 */
     lua_pushstring(L, "how");                          /* 第一个参数 */
     lua_getfield(L, LUA_GLOBALSINDEX, "t");          /* table 的索引 */
     lua_getfield(L, -1, "x");         /* 压入 t.x 的值（第 2 个参数）*/
     lua_remove(L, -2);                           /* 从堆栈中移去 't' */
     lua_pushinteger(L, 14);                           /* 第 3 个参数 */
     lua_call(L, 3, 1); /* 调用 'f'，传入 3 个参数，并索取 1 个返回值 */
     lua_setfield(L, LUA_GLOBALSINDEX, "a");      /* 设置全局变量 'a' */
注意上面这段代码是“平衡”的： 到了最后，堆栈恢复成原由的配置。 这是一种良好的编程习惯。

lua_CFunction

typedef int (*lua_CFunction) (lua_State *L);
C 函数的类型。

为了正确的和 Lua 通讯，C 函数必须使用下列 定义了参数以及返回值传递方法的协议： C 函数通过 Lua 中的堆栈来接受参数，参数以正序入栈（第一个参数首先入栈）。 因此，当函数开始的时候， lua_gettop(L) 可以返回函数收到的参数个数。 第一个参数（如果有的话）在索引 1 的地方，而最后一个参数在索引 lua_gettop(L) 处。 当需要向 Lua 返回值的时候，C 函数只需要把它们以正序压到堆栈上（第一个返回值最先压入）， 然后返回这些返回值的个数。 在这些返回值之下的，堆栈上的东西都会被 Lua 丢掉。 和 Lua 函数一样，从 Lua 中调用 C 函数也可以有很多返回值。

下面这个例子中的函数将接收若干数字参数，并返回它们的平均数与和：

     static int foo (lua_State *L) {
       int n = lua_gettop(L);    /* 参数的个数 */
       lua_Number sum = 0;
       int i;
       for (i = 1; i <= n; i++) {
         if (!lua_isnumber(L, i)) {
           lua_pushstring(L, "incorrect argument");
           lua_error(L);
         }
         sum += lua_tonumber(L, i);
       }
       lua_pushnumber(L, sum/n);   /* 第一个返回值 */
       lua_pushnumber(L, sum);     /* 第二个返回值 */
       return 2;                   /* 返回值的个数 */
     }
lua_checkstack

int lua_checkstack (lua_State *L, int extra);
确保堆栈上至少有 extra 个空位。 如果不能把堆栈扩展到相应的尺寸，函数返回 false 。 这个函数永远不会缩小堆栈； 如果堆栈已经比需要的大了，那么就放在那里不会产生变化。

lua_close

void lua_close (lua_State *L);
销毁指定 Lua 状态机中的所有对象（如果有垃圾收集相关的元方法的话，会调用它们）， 并且释放状态机中使用的所有动态内存。 在一些平台上，你可以不必调用这个函数， 因为当宿主程序结束的时候，所有的资源就自然被释放掉了。 另一方面，长期运行的程序，比如一个后台程序或是一个 web 服务器， 当不再需要它们的时候就应该释放掉相关状态机。这样可以避免状态机扩张的过大。

lua_concat

void lua_concat (lua_State *L, int n);
连接栈顶的 n 个值， 然后将这些值出栈，并把结果放在栈顶。 如果 n 为 1 ，结果就是一个字符串放在栈上（即，函数什么都不做）； 如果 n 为 0 ，结果是一个空串。 连接依照 Lua 中创建语义完成（参见 §2.5.4 ）。

lua_cpcall

int lua_cpcall (lua_State *L, lua_CFunction func, void *ud);
以保护模式调用 C 函数 func 。 func 只有能从堆栈上拿到一个参数，就是包含有 ud 的 light userdata。 当有错误时， lua_cpcall 返回和 lua_pcall 相同的错误代码， 并在栈顶留下错误对象； 否则它返回零，并不会修改堆栈。 所有从 func 内返回的值都会被扔掉。

lua_createtable

void lua_createtable (lua_State *L, int narr, int nrec);
创建一个新的空 table 压入堆栈。 这个新 table 将被预分配 narr 个元素的数组空间 以及 nrec 个元素的非数组空间。 当你明确知道表中需要多少个元素时，预分配就非常有用。 如果你不知道，可以使用函数 lua_newtable。

lua_dump

int lua_dump (lua_State *L, lua_Writer writer, void *data);
把函数 dump 成二进制 chunk 。 函数接收栈顶的 Lua 函数做参数，然后生成它的二进制 chunk 。 若被 dump 出来的东西被再次加载，加载的结果就相当于原来的函数。 当它在产生 chunk 的时候，lua_dump 通过调用函数 writer （参见 lua_Writer） 来写入数据，后面的 data 参数会被传入 writer 。

最后一次由写入器 (writer) 返回值将作为这个函数的返回值返回； 0 表示没有错误。

这个函数不会把 Lua 返回弹出堆栈。

lua_equal

int lua_equal (lua_State *L, int index1, int index2);
如果依照 Lua 中 == 操作符语义，索引 index1 和 index2 中的值相同的话，返回 1 。 否则返回 0 。 如果任何一个索引无效也会返回 0。

lua_error

int lua_error (lua_State *L);
产生一个 Lua 错误。 错误信息（实际上可以是任何类型的 Lua 值）必须被置入栈顶。 这个函数会做一次长跳转，因此它不会再返回。 （参见 luaL_error）。

lua_gc

int lua_gc (lua_State *L, int what, int data);
控制垃圾收集器。

这个函数根据其参数 what 发起几种不同的任务：

LUA_GCSTOP: 停止垃圾收集器。
LUA_GCRESTART: 重启垃圾收集器。
LUA_GCCOLLECT: 发起一次完整的垃圾收集循环。
LUA_GCCOUNT: 返回 Lua 使用的内存总量（以 K 字节为单位）。
LUA_GCCOUNTB: 返回当前内存使用量除以 1024 的余数。
LUA_GCSTEP: 发起一步增量垃圾收集。 步数由 data 控制（越大的值意味着越多步）， 而其具体含义（具体数字表示了多少）并未标准化。 如果你想控制这个步数，必须实验性的测试 data 的值。 如果这一步结束了一个垃圾收集周期，返回返回 1 。
LUA_GCSETPAUSE: 把 data/100 设置为 garbage-collector pause 的新值（参见 §2.10）。 函数返回以前的值。
LUA_GCSETSTEPMUL: 把 arg/100 设置成 step multiplier （参见 §2.10）。 函数返回以前的值。
lua_getallocf

lua_Alloc lua_getallocf (lua_State *L, void **ud);
返回给定状态机的内存分配器函数。 如果 ud 不是 NULL ，Lua 把调用 lua_newstate 时传入的那个指针放入 *ud 。

lua_getfenv

void lua_getfenv (lua_State *L, int index);
把索引处值的环境表压入堆栈。

lua_getfield

void lua_getfield (lua_State *L, int index, const char *k);
把 t[k] 值压入堆栈， 这里的 t 是指有效索引 index 指向的值。 在 Lua 中，这个函数可能触发对应 "index" 事件的元方法 （参见 §2.8）。

lua_getglobal

void lua_getglobal (lua_State *L, const char *name);
把全局变量 name 里的值压入堆栈。 这个是用一个宏定义出来的：

     #define lua_getglobal(L,s)  lua_getfield(L, LUA_GLOBALSINDEX, s)
lua_getmetatable

int lua_getmetatable (lua_State *L, int index);
把给定索引指向的值的元表压入堆栈。 如果索引无效，或是这个值没有元表， 函数将返回 0 并且不会向栈上压任何东西。

lua_gettable

void lua_gettable (lua_State *L, int index);
把 t[k] 值压入堆栈， 这里的 t 是指有效索引 index 指向的值， 而 k 则是栈顶放的值。

这个函数会弹出堆栈上的 key （把结果放在栈上相同位置）。 在 Lua 中，这个函数可能触发对应 "index" 事件的元方法 （参见 §2.8）。

lua_gettop

int lua_gettop (lua_State *L);
返回栈顶元素的索引。 因为索引是从 1 开始编号的， 所以这个结果等于堆栈上的元素个数（因此返回 0 表示堆栈为空）。

lua_insert

void lua_insert (lua_State *L, int index);
把栈顶元素插入指定的有效索引处， 并依次移动这个索引之上的元素。 不要用伪索引来调用这个函数， 因为伪索引不是真正指向堆栈上的位置。

lua_Integer

typedef ptrdiff_t lua_Integer;
这个类型被用于 Lua API 接收整数值。

缺省时这个被定义为 ptrdiff_t ， 这个东西通常是机器能处理的最大整数类型。

lua_isboolean

int lua_isboolean (lua_State *L, int index);
当给定索引的值类型为 boolean 时，返回 1 ，否则返回 0 。

lua_iscfunction

int lua_iscfunction (lua_State *L, int index);
当给定索引的值是一个 C 函数时，返回 1 ，否则返回 0 。

lua_isfunction

int lua_isfunction (lua_State *L, int index);
当给定索引的值是一个函数（ C 或 Lua 函数均可）时，返回 1 ，否则返回 0 。

lua_islightuserdata

int lua_islightuserdata (lua_State *L, int index);
当给定索引的值是一个 light userdata 时，返回 1 ，否则返回 0 。

lua_isnil

int lua_isnil (lua_State *L, int index);
当给定索引的值是 nil 时，返回 1 ，否则返回 0 。

lua_isnumber

int lua_isnumber (lua_State *L, int index);
当给定索引的值是一个数字，或是一个可转换为数字的字符串时，返回 1 ，否则返回 0 。

lua_isstring

int lua_isstring (lua_State *L, int index);
当给定索引的值是一个字符串或是一个数字（数字总能转换成字符串）时，返回 1 ，否则返回 0 。

lua_istable

int lua_istable (lua_State *L, int index);
当给定索引的值是一个 table 时，返回 1 ，否则返回 0 。

lua_isthread

int lua_isthread (lua_State *L, int index);
当给定索引的值是一个 thread 时，返回 1 ，否则返回 0 。

lua_isuserdata

int lua_isuserdata (lua_State *L, int index);
当给定索引的值是一个 userdata （无论是完整的 userdata 还是 light userdata ）时，返回 1 ，否则返回 0 。

lua_lessthan

int lua_lessthan (lua_State *L, int index1, int index2);
如果索引 index1 处的值小于 索引 index2 处的值时，返回 1 ； 否则返回 0 。 其语义遵循 Lua 中的 < 操作符（就是说，有可能调用元方法）。 如果任何一个索引无效，也会返回 0 。

lua_load

int lua_load (lua_State *L,
              lua_Reader reader,
              void *data,
              const char *chunkname);
加载一个 Lua chunk 。 如果没有错误， lua_load 把一个编译好的 chunk 作为一个 Lua 函数压入堆栈。 否则，压入出错信息。 lua_load 的返回值可以是：

0: 没有错误；
LUA_ERRSYNTAX: 在预编译时碰到语法错误；
LUA_ERRMEM: 内存分配错误。
这个函数仅仅加栽 chunk ；而不会去运行它。

lua_load 会自动检测 chunk 是文本的还是二进制的， 然后做对应的加载操作（参见程序 luac）。

lua_load 函数使用一个用户提供的 reader 函数来 读取 chunk （参见 lua_Reader）。 data 参数会被传入读取器函数。

chunkname 这个参数可以赋予 chunk 一个名字， 这个名字被用于出错信息和调试信息（参见 §3.8）。

lua_newstate

lua_State *lua_newstate (lua_Alloc f, void *ud);
创建的一个新的独立的状态机。 如果创建不了（因为内存问题）返回 NULL 。 参数 f 是一个分配器函数； Lua 将通过这个函数做状态机内所有的内存分配操作。 第二个参数 ud ，这个指针将在每次调用分配器时被直接传入。

lua_newtable

void lua_newtable (lua_State *L);
创建一个空 table ，并将之压入堆栈。 它等价于 lua_createtable(L, 0, 0) 。

lua_newthread

lua_State *lua_newthread (lua_State *L);
创建一个新线程，并将其压入堆栈， 并返回维护这个线程的 lua_State 指针。 这个函数返回的新状态机共享原有状态机中的所有对象（比如一些 table）， 但是它有独立的执行堆栈。

没有显式的函数可以用来关闭或销毁掉一个线程。 线程跟其它 Lua 对象一样是垃圾收集的条目之一。

lua_newuserdata

void *lua_newuserdata (lua_State *L, size_t size);
这个函数分配分配一块指定大小的内存块， 把内存块地址作为一个完整的 userdata 压入堆栈，并返回这个地址。

userdata 代表 Lua 中的 C 值。 完整的 userdata 代表一块内存。 它是一个对象（就像 table 那样的对象）： 你必须创建它，它有着自己的元表，而且它在被回收时，可以被监测到。 一个完整的 userdata 只和它自己相等（在等于的原生作用下）。

当 Lua 通过 gc 元方法回收一个完整的 userdata 时， Lua 调用这个元方法并把 userdata 标记为已终止。 等到这个 userdata 再次被收集的时候，Lua 会释放掉相关的内存。

lua_next

int lua_next (lua_State *L, int index);
从栈上弹出一个 key（键）， 然后把索引指定的表中 key-value（健值）对压入堆栈 （指定 key 后面的下一 (next) 对）。 如果表中以无更多元素， 那么 lua_next 将返回 0 （什么也不压入堆栈）。

典型的遍历方法是这样的：

     /* table 放在索引 't' 处 */
     lua_pushnil(L);  /* 第一个 key */
     while (lua_next(L, t) != 0) {
       /* 用一下 'key' （在索引 -2 处） 和 'value' （在索引 -1 处） */
       printf("%s - %s\n",
              lua_typename(L, lua_type(L, -2)),
              lua_typename(L, lua_type(L, -1)));
       /* 移除 'value' ；保留 'key' 做下一次迭代 */
       lua_pop(L, 1);
     }
在遍历一张表的时候， 不要直接对 key 调用 lua_tolstring ， 除非你知道这个 key 一定是一个字符串。 调用 lua_tolstring 有可能改变给定索引位置的值； 这会对下一次调用 lua_next 造成影响。

lua_Number

typedef double lua_Number;
Lua 中数字的类型。 确省是 double ，但是你可以在 luaconf.h 中修改它。

通过修改配置文件你可以改变 Lua 让它操作其它数字类型（例如：float 或是 long ）。

lua_objlen

size_t lua_objlen (lua_State *L, int index);
返回指定的索引处的值的长度。 对于 string ，那就是字符串的长度； 对于 table ，是取长度操作符 ('#') 的结果； 对于 userdata ，就是为其分配的内存块的尺寸； 对于其它值，为 0 。

lua_pcall

lua_pcall (lua_State *L, int nargs, int nresults, int errfunc);
以保护模式调用一个函数。

nargs 和 nresults 的含义与 lua_call 中的相同。 如果在调用过程中没有发生错误， lua_pcall 的行为和 lua_call 完全一致。 但是，如果有错误发生的话， lua_pcall 会捕获它， 然后把单一的值（错误信息）压入堆栈，然后返回错误码。 同 lua_call 一样， lua_pcall 总是把函数本身和它的参数从栈上移除。

如果 errfunc 是 0 ， 返回在栈顶的错误信息就和原始错误信息完全一致。 否则，errfunc 就被当成是错误处理函数在栈上的索引。 （在当前的实现里，这个索引不能是伪索引。） 在发生运行时错误时， 这个函数会被调用而参数就是错误信息。 错误处理函数的返回值将被 lua_pcall 作为出错信息返回在堆栈上。

典型的用法中，错误处理函数被用来在出错信息上加上更多的调试信息，比如栈跟踪信息 (stack traceback) 。 这些信息在 lua_pcall 返回后，因为栈已经展开 (unwound) ， 所以收集不到了。

lua_pcall 函数在调用成功时返回 0 ， 否则返回以下（定义在 lua.h 中的）错误代码中的一个：

LUA_ERRRUN: 运行时错误。
LUA_ERRMEM: 内存分配错误。 对于这种错，Lua 调用不了错误处理函数。
LUA_ERRERR: 在运行错误处理函数时发生的错误。
lua_pop

void lua_pop (lua_State *L, int n);
从堆栈中弹出 n 个元素。

lua_pushboolean

void lua_pushboolean (lua_State *L, int b);
把 b 作为一个 boolean 值压入堆栈。

lua_pushcclosure

void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n);
把一个新的 C closure 压入堆栈。

当创建了一个 C 函数后，你可以给它关联一些值，这样就是在创建一个 C closure （参见 §3.4）； 接下来无论函数何时被调用，这些值都可以被这个函数访问到。 为了将一些值关联到一个 C 函数上， 首先这些值需要先被压入堆栈（如果有多个值，第一个先压）。 接下来调用 lua_pushcclosure 来创建出 closure 并把这个 C 函数压到堆栈上。 参数 n 告之函数有多少个值需要关联到函数上。 lua_pushcclosure 也会把这些值从栈上弹出。

lua_pushcfunction

void lua_pushcfunction (lua_State *L, lua_CFunction f);
将一个 C 函数压入堆栈。 这个函数接收一个 C 函数指针，并将一个类型为 function 的 Lua 值 压入堆栈。当这个栈顶的值被调用时，将触发对应的 C 函数。

注册到 Lua 中的任何函数都必须遵循正确的协议来接收参数和返回值 （参见 lua_CFunction）。

lua_pushcfunction 是作为一个宏定义出现的：

     #define lua_pushcfunction(L,f)  lua_pushcclosure(L,f,0)
lua_pushfstring

const char *lua_pushfstring (lua_State *L, const char *fmt, ...);
把一个格式化过的字符串压入堆栈，然后返回这个字符串的指针。 它和 C 函数 sprintf 比较像，不过有一些重要的区别：

摸你需要为结果分配空间： 其结果是一个 Lua 字符串，由 Lua 来关心其内存分配 （同时通过垃圾收集来释放内存）。
这个转换非常的受限。 不支持 flag ，宽度，或是指定精度。 它只支持下面这些： '%%' （插入一个 '%'）， '%s' （插入一个带零终止符的字符串，没有长度限制）， '%f' （插入一个 lua_Number）， '%p' （插入一个指针或是一个十六进制数）， '%d' （插入一个 int)， '%c' （把一个 int 作为一个字符插入）。
lua_pushinteger

void lua_pushinteger (lua_State *L, lua_Integer n);
把 n 作为一个数字压栈。

lua_pushlightuserdata

void lua_pushlightuserdata (lua_State *L, void *p);
把一个 light userdata 压栈。

userdata 在 Lua 中表示一个 C 值。 light userdata 表示一个指针。 它是一个像数字一样的值： 你不需要专门创建它，它也没有独立的 metatable ， 而且也不会被收集（因为从来不需要创建）。 只要表示的 C 地址相同，两个 light userdata 就相等。

lua_pushlstring

void lua_pushlstring (lua_State *L, const char *s, size_t len);
把指针 s 指向的长度为 len 的字符串压栈。 Lua 对这个字符串做一次内存拷贝（或是复用一个拷贝）， 因此 s 处的内存在函数返回后，可以释放掉或是重用于其它用途。 字符串内可以保存有零字符。

lua_pushnil

void lua_pushnil (lua_State *L);
把一个 nil 压栈。

lua_pushnumber

void lua_pushnumber (lua_State *L, lua_Number n);
把一个数字 n 压栈。

lua_pushstring

void lua_pushstring (lua_State *L, const char *s);
把指针 s 指向的以零结尾的字符串压栈。 Lua 对这个字符串做一次内存拷贝（或是复用一个拷贝）， 因此 s 处的内存在函数返回后，可以释放掉或是重用于其它用途。 字符串中不能包含有零字符；第一个碰到的零字符会认为是字符串的结束。

lua_pushthread

int lua_pushthread (lua_State *L);
把 L 中提供的线程压栈。 如果这个线程是当前状态机的主线程的话，返回 1 。

lua_pushvalue

void lua_pushvalue (lua_State *L, int index);
把堆栈上给定有效处索引处的元素作一个拷贝压栈。

lua_pushvfstring

const char *lua_pushvfstring (lua_State *L,
                              const char *fmt,
                              va_list argp);
等价于 lua_pushfstring， 不过是用 va_list 接收参数，而不是用可变数量的实际参数。

lua_rawequal

int lua_rawequal (lua_State *L, int index1, int index2);
如果两个索引 index1 和 index2 处的值简单地相等 （不调用元方法）则返回 1 。 否则返回 0 。 如果任何一个索引无效也返回 0 。

lua_rawget

void lua_rawget (lua_State *L, int index);
类似于 lua_gettable， 但是作一次直接访问（不触发元方法）。

lua_rawgeti

void lua_rawgeti (lua_State *L, int index, int n);
把 t[n] 的值压栈， 这里的 t 是指给定索引 index 处的一个值。 这是一个直接访问；就是说，它不会触发元方法。

lua_rawset

void lua_rawset (lua_State *L, int index);
类似于 lua_settable， 但是是作一个直接赋值（不触发元方法）。

lua_rawseti

void lua_rawseti (lua_State *L, int index, int n);
等价于 t[n] = v， 这里的 t 是指给定索引 index 处的一个值， 而 v 是栈顶的值。

函数将把这个值弹出栈。 赋值操作是直接的；就是说，不会触发元方法。

lua_Reader

typedef const char * (*lua_Reader) (lua_State *L,
                                    void *data,
                                    size_t *size);
lua_load 用到的读取器函数， 每次它需要一块新的 chunk 的时候， lua_load 就调用读取器， 每次都会传入一个参数 data 。 读取器需要返回含有新的 chunk 的一块内存的指针， 并把 size 设为这块内存的大小。 内存块必须在下一次函数被调用之前一直存在。 读取器可以通过返回一个 NULL 来指示 chunk 结束。 读取器可能返回多个块，每个块可以有任意的大于零的尺寸。

lua_register

void lua_register (lua_State *L,
                   const char *name,
                   lua_CFunction f);
把 C 函数 f 设到全局变量 name 中。 它通过一个宏定义：

     #define lua_register(L,n,f) \
            (lua_pushcfunction(L, f), lua_setglobal(L, n))
lua_remove

void lua_remove (lua_State *L, int index);
从给定有效索引处移除一个元素， 把这个索引之上的所有元素移下来填补上这个空隙。 不能用伪索引来调用这个函数， 因为伪索引并不指向真实的栈上的位置。

lua_replace

void lua_replace (lua_State *L, int index);
把栈顶元素移动到给定位置（并且把这个栈顶元素弹出）， 不移动任何元素（因此在那个位置处的值被覆盖掉）。

lua_resume

int lua_resume (lua_State *L, int narg);
在给定线程中启动或继续一个 coroutine 。

要启动一个 coroutine 的话，首先你要创建一个新线程 （参见 lua_newthread ）； 然后把主函数和若干参数压到新线程的堆栈上； 最后调用 lua_resume ， 把 narg 设为参数的个数。 这次调用会在 coroutine 挂起时或是结束运行后返回。 当函数返回时，堆栈中会有传给 lua_yield 的所有值， 或是主函数的所有返回值。 如果 coroutine 切换时，lua_resume 返回 LUA_YIELD ， 而当 coroutine 结束运行且没有任何错误时，返回 0 。 如果有错则返回错误代码（参见 lua_pcall）。 在发生错误的情况下， 堆栈没有展开， 因此你可以使用 debug API 来处理它。 出错信息放在栈顶。 要继续运行一个 coroutine 的话，你把需要传给 yield 作结果的返回值压入堆栈，然后调用 lua_resume 。

lua_setallocf

void lua_setallocf (lua_State *L, lua_Alloc f, void *ud);
把指定状态机的分配器函数换成带上指针 ud 的 f 。

lua_setfenv

int lua_setfenv (lua_State *L, int index);
从堆栈上弹出一个 table 并把它设为指定索引处值的新环境。 如果指定索引处的值即不是函数又不是线程或是 userdata ， lua_setfenv 会返回 0 ， 否则返回 1 。

lua_setfield

void lua_setfield (lua_State *L, int index, const char *k);
做一个等价于 t[k] = v 的操作， 这里 t 是给出的有效索引 index 处的值， 而 v 是栈顶的那个值。

这个函数将把这个值弹出堆栈。 跟在 Lua 中一样，这个函数可能触发一个 "newindex" 事件的元方法 （参见 §2.8）。

lua_setglobal

void lua_setglobal (lua_State *L, const char *name);
从堆栈上弹出一个值，并将其设到全局变量 name 中。 它由一个宏定义出来：

     #define lua_setglobal(L,s)   lua_setfield(L, LUA_GLOBALSINDEX, s)
lua_setmetatable

int lua_setmetatable (lua_State *L, int index);
把一个 table 弹出堆栈，并将其设为给定索引处的值的 metatable 。

lua_settable

void lua_settable (lua_State *L, int index);
作一个等价于 t[k] = v 的操作， 这里 t 是一个给定有效索引 index 处的值， v 指栈顶的值， 而 k 是栈顶之下的那个值。

这个函数会把键和值都从堆栈中弹出。 和在 Lua 中一样，这个函数可能触发 "newindex" 事件的元方法 （参见 §2.8）。

lua_settop

void lua_settop (lua_State *L, int index);
参数允许传入任何可接受的索引以及 0 。 它将把堆栈的栈顶设为这个索引。 如果新的栈顶比原来的大，超出部分的新元素将被填为 nil 。 如果 index 为 0 ，把栈上所有元素移除。

lua_State

typedef struct lua_State lua_State;
一个不透明的结构，它保存了整个 Lua 解释器的状态。 Lua 库是完全可重入的： 它没有任何全局变量。 （译注：从 C 语法上来说，也不尽然。例如，在 table 的实现中 用了一个静态全局变量 dummynode_ ，但这在正确使用时并不影响可重入性。 只是万一你错误链接了 lua 库，不小心在同一进程空间中存在两份 lua 库实现的代码的话， 多份 dummynode_ 不同的地址会导致一些问题。） 所有的信息都保存在这个结构中。

这个状态机的指针必须作为第一个参数传递给每一个库函数。 lua_newstate 是一个例外， 这个函数会从头创建一个 Lua 状态机。

lua_status

int lua_status (lua_State *L);
返回线程 L 的状态。

正常的线程状态是 0 。 当线程执行完毕或发生一个错误时，状态值是错误码。 如果线程被挂起，状态为 LUA_YIELD 。

lua_toboolean

int lua_toboolean (lua_State *L, int index);
把指定的索引处的的 Lua 值转换为一个 C 中的 boolean 值（ 0 或是 1 ）。 和 Lua 中做的所有测试一样， lua_toboolean 会把任何 不同于 false 和 nil 的值当作 1 返回； 否则就返回 0 。 如果用一个无效索引去调用也会返回 0 。 （如果你想只接收真正的 boolean 值，就需要使用 lua_isboolean 来测试值的类型。）

lua_tocfunction

lua_CFunction lua_tocfunction (lua_State *L, int index);
把给定索引处的 Lua 值转换为一个 C 函数。 这个值必须是一个 C 函数；如果不是就返回 NULL 。

lua_tointeger

lua_Integer lua_tointeger (lua_State *L, int idx);
把给定索引处的 Lua 值转换为 lua_Integer 这样一个有符号整数类型。 这个 Lua 值必须是一个数字或是一个可以转换为数字的字符串 （参见 §2.2.1）； 否则，lua_tointeger 返回 0 。

如果数字不是一个整数， 截断小数部分的方式没有被明确定义。

lua_tolstring

const char *lua_tolstring (lua_State *L, int index, size_t *len);
把给定索引处的 Lua 值转换为一个 C 字符串。 如果 len 不为 NULL ， 它还把字符串长度设到 *len 中。 这个 Lua 值必须是一个字符串或是一个数字； 否则返回返回 NULL 。 如果值是一个数字，lua_tolstring 还会把堆栈中的那个值的实际类型转换为一个字符串。 （当遍历一个表的时候，把 lua_tolstring 作用在键上，这个转换有可能导致 lua_next 弄错。）

lua_tolstring 返回 Lua 状态机中 字符串的以对齐指针。 这个字符串总能保证 （ C 要求的）最后一个字符为零 ('\0') ， 而且它允许在字符串内包含多个这样的零。 因为 Lua 中可能发生垃圾收集， 所以不保证 lua_tolstring 返回的指针， 在对应的值从堆栈中移除后依然有效。

lua_tonumber

lua_Number lua_tonumber (lua_State *L, int index);
把给定索引处的 Lua 值转换为 lua_Number 这样一个 C 类型（参见 lua_Number ）。 这个 Lua 值必须是一个数字或是一个可转换为数字的字符串 （参见 §2.2.1 ）； 否则，lua_tonumber 返回 0 。

lua_topointer

const void *lua_topointer (lua_State *L, int index);
把给定索引处的值转换为一般的 C 指针 (void*) 。 这个值可以是一个 userdata ，table ，thread 或是一个 function ； 否则，lua_topointer 返回 NULL 。 不同的对象有不同的指针。 不存在把指针再转回原有类型的方法。

这个函数通常只为产生 debug 信息用。

lua_tostring

const char *lua_tostring (lua_State *L, int index);
等价于 lua_tolstring ，而参数 len 设为 NULL 。

lua_tothread

lua_State *lua_tothread (lua_State *L, int index);
把给定索引处的值转换为一个 Lua 线程（由 lua_State* 代表）。 这个值必须是一个线程；否则函数返回 NULL 。

lua_touserdata

void *lua_touserdata (lua_State *L, int index);
如果给定索引处的值是一个完整的 userdata ，函数返回内存块的地址。 如果值是一个 light userdata ，那么就返回它表示的指针。 否则，返回 NULL 。

lua_type

int lua_type (lua_State *L, int index);
返回给定索引处的值的类型， 当索引无效时则返回 LUA_TNONE （那是指一个指向堆栈上的空位置的索引）。 lua_type 返回的类型是一些个在 lua.h 中定义的常量： LUA_TNIL ， LUA_TNUMBER ， LUA_TBOOLEAN ， LUA_TSTRING ， LUA_TTABLE ， LUA_TFUNCTION ， LUA_TUSERDATA ， LUA_TTHREAD ， LUA_TLIGHTUSERDATA 。

lua_typename

const char *lua_typename  (lua_State *L, int tp);
返回 tp 表示的类型名， 这个 tp 必须是 lua_type 可能返回的值中之一。

lua_Writer

typedef int (*lua_Writer) (lua_State *L,
                           const void* p,
                           size_t sz,
                           void* ud);
由 lua_dump 用到的写入器函数。 每次 lua_dump 产生了一块新的 chunk ，它都会调用写入器。 传入要写入的缓存 (p) 和它的尺寸 (sz) ， 还有 lua_dump 的参数 data 。

写入器会返回一个错误码： 0 表示没有错误； 别的值均表示一个错误，并且会让 lua_dump 停止再次调用写入器。

lua_xmove

void lua_xmove (lua_State *from, lua_State *to, int n);
传递 同一个 全局状态机下不同线程中的值。

这个函数会从 from 的堆栈中弹出 n 个值， 然后把它们压入 to 的堆栈中。

lua_yield

int lua_yield  (lua_State *L, int nresults);
切出一个 coroutine 。

这个函数只能在一个 C 函数的返回表达式中调用。如下：

     return lua_yield (L, nresults);
当一个 C 函数这样调用 lua_yield ， 正在运行中的 coroutine 将从运行中挂起， 然后启动这个 coroutine 用的那次对 lua_resume 的调用就返回了。 参数 nresults 指的是堆栈中需要返回的结果个数，这些返回值将被传递给 lua_resume 。

3.8 - 调试接口

Lua 没有内建的调试设施。 取而代之的是提供了一些函数接口和钩子。 利用这些接口，可以做出一些不同类型的调试器， 性能分析器，或是其它一些需要从解释器中取到“内部信息”的工具。

lua_Debug

typedef struct lua_Debug {
  int event;
  const char *name;           /* (n) */
  const char *namewhat;       /* (n) */
  const char *what;           /* (S) */
  const char *source;         /* (S) */
  int currentline;            /* (l) */
  int nups;                   /* (u) upvalue 个数 */
  int linedefined;            /* (S) */
  int lastlinedefined;        /* (S) */
  char short_src[LUA_IDSIZE]; /* (S) */
  /* 私有部分 */
  其它域
} lua_Debug;
一个用来携带活动中函数的各种信息的结构。 lua_getstack 仅填写这个结构中的私有部分， 这些部分以后会用到。 调用 lua_getinfo 则可以填上 lua_Debug 中有用信息的那些域。

lua_Debug 中的各个域有下列含义：

source: 如果函数是定义在一个字符串中，source 就是这个字符串。 如果函数定义在一个文件中， source 是一个以 '@' 开头的文件名。
short_src: 一个“可打印版本”的 source，用于出错信息。
linedefined: 函数定义开始处的行号。
lastlinedefined: 函数定义结束处的行号。
what: 如果函数是一个 Lua 函数，则为一个字符串 "Lua" ； 如果是一个 C 函数，则为 "C"； 如果它是一个 chunk 的主体部分，则为 "main"； 如果是一个作了尾调用的函数，则为 "tail" 。 别的情况下，Lua 没有关于函数的别的信息。
currentline: 给定函数正在执行的那一行。 当提供不了行号信息的时候，currentline 被设为 -1 。
name: 给定函数的一个合理的名字。 因为 Lua 中的函数也是一个值， 所以它们没有固定的名字： 一些函数可能是全局复合变量的值， 另一些可能仅仅只是被保存在一个 table 中。 lua_getinfo 函数会检查函数是这样被调用的，以此来找到一个适合的名字。 如果它找不到名字，name 就被设置为 NULL 。
namewhat: 结实 name 域。 namewhat 的值可以是 "global", "local", "method", "field", "upvalue", 或是 "" （空串）。 这取决于函数怎样被调用。 （Lua 用空串表示其它选项都不符合）
nups: 函数的 upvalue 的个数。
lua_gethook

lua_Hook lua_gethook (lua_State *L);
返回当前的钩子函数。

lua_gethookcount

int lua_gethookcount (lua_State *L);
返回当前钩子记数。

lua_gethookmask

int lua_gethookmask (lua_State *L);
返回当前的钩子掩码 (mask) 。

lua_getinfo

int lua_getinfo (lua_State *L, const char *what, lua_Debug *ar);
返回一个指定的函数或函数调用的信息。

当用于取得一次函数调用的信息时， 参数 ar 必须是一个有效的活动的记录。 这条记录可以是前一次调用 lua_getstack 得到的， 或是一个钩子 （参见 lua_Hook）得到的参数。

用于获取一个函数的信息时，可以把这个函数压入堆栈， 然后把 what 字符串以字符 '>' 起头。 （这个情况下，lua_getinfo 从栈顶上弹出函数。） 例如，想知道函数 f 在哪一行定义的， 你可以下下列代码：

     lua_Debug ar;
     lua_getfield(L, LUA_GLOBALSINDEX, "f");  /* 取到全局变量 'f' */
     lua_getinfo(L, ">S", &ar);
     printf("%d\n", ar.linedefined);
what 字符串中的每个字符都筛选出结构 ar 结构中一些域用于填充，或是把一个值压入堆栈：

'n': 填充 name 及 namewhat 域；
'S': 填充 source， short_src， linedefined， lastlinedefined，以及 what 域；
'l': 填充 currentline 域；
'u': 填充 nups 域；
'f': 把正在运行中指定级别处函数压入堆栈； （译注：一般用于获取函数调用中的信息， 级别是由 ar 中的私有部分来提供。 如果用于获取静态函数，那么就直接把指定函数重新压回堆栈， 但这样做通常无甚意义。）
'L': 压一个 table 入栈，这个 table 中的整数索引用于描述函数中哪些行是有效行。 （有效行指有实际代码的行， 即你可以置入断点的行。 无效行包括空行和只有注释的行。）
这个函数出错会返回 0 （例如，what 中有一个无效选项）。

lua_getlocal

const char *lua_getlocal (lua_State *L, lua_Debug *ar, int n);
从给定活动记录中获取一个局部变量的信息。 参数 ar 必须是一个有效的活动的记录。 这条记录可以是前一次调用 lua_getstack 得到的， 或是一个钩子 （参见 lua_Hook）得到的参数。 索引 n 用于选择要检阅哪个局部变量 （ 1 表示第一个参数或是激活的第一个局部变量，以此类推，直到最后一个局部变量）。 lua_getlocal 把变量的值压入堆栈并返回它的名字。

以 '(' （正小括号）开始的变量指内部变量 （循环控制变量，临时变量，C 函数局部变量）。

当索引大于局部变量的个数时，返回 NULL （什么也不压入）。

lua_getstack

int lua_getstack (lua_State *L, int level, lua_Debug *ar);
获取解释器的运行时栈的信息。

这个函数用正在运行中的给定级别处的函数的活动记录来填写 lua_Debug 结构的一部分。 0 级表示当前运行的函数， 而 n+1 级处的函数就是调用第 n 级函数的那一个。 如果没有错误，lua_getstack 返回 1 ； 当调用传入的级别大于堆栈深度的时候，返回 0 。

lua_getupvalue

const char *lua_getupvalue (lua_State *L, int funcindex, int n);
获取一个 closure 的 upvalue 信息。 （对于 Lua 函数，upvalue 是函数需要使用的外部局部变量， 因此这些变量被包含在 closure 中。） lua_getupvalue 获取第 n 个 upvalue ， 把这个 upvalue 的值压入堆栈，并且返回它的名字。 funcindex 指向堆栈上 closure 的位置。 （ 因为 upvalue 在整个函数中都有效，所以它们没有特别的次序。 因此，它们以字母次序来编号。）

当索引号比 upvalue 数量大的时候，返回 NULL （而且不会压入任何东西） 对于 C 函数，这个函数用空串 "" 表示所有 upvalue 的名字。

lua_Hook

typedef void (*lua_Hook) (lua_State *L, lua_Debug *ar);
用于调试的钩子函数类型。

无论何时钩子被调用，它的参数 ar 中的 event 域 都被设为触发钩子的事件。 Lua 把这些事件定义为以下常量： LUA_HOOKCALL， LUA_HOOKRET, LUA_HOOKTAILRET， LUA_HOOKLINE， and LUA_HOOKCOUNT。 除此之外，对于 line 事件，currentline 域也被设置。 要想获得 ar 中的其他域， 钩子必须调用 lua_getinfo。 对于返回事件，event 的正常值可能是 LUA_HOOKRET， 或者是 LUA_HOOKTAILRET 。 对于后一种情况，Lua 会对一个函数做的尾调用也模拟出一个返回事件出来； 对于这个模拟的返回事件，调用 lua_getinfo 没有什么作用。

当 Lua 运行在一个钩子内部时，它将屏蔽掉其它对钩子的调用。 也就是说，如果一个钩子函数内再调回 Lua 来执行一个函数或是一个 chunk ， 这个执行操作不会触发任何的钩子。

lua_sethook

int lua_sethook (lua_State *L, lua_Hook f, int mask, int count);
设置一个调试用钩子函数。

参数 f 是钩子函数。 mask 指定在哪些事件时会调用： 它由下列一组位常量构成 LUA_MASKCALL， LUA_MASKRET， LUA_MASKLINE， 以及 LUA_MASKCOUNT。 参数 count 只在 mask 中包含有 LUA_MASKCOUNT 才有意义。 对于每个事件，钩子被调用的情况解释如下：

call hook: 在解释器调用一个函数时被调用。 钩子将于 Lua 进入一个新函数后，函数获取参数前被调用。
return hook: 在解释器从一个函数中返回时调用。 钩子将于 Lua 离开函数之前的那一刻被调用。 你无权访问被函数返回出去的那些值。 （译注：原文 (You have no access to the values to be returned by the function) 如此。 但“无权访问”一词值得商榷。 某些情况下你可以访问到一些被命名为 (*temporary) 的局部变量， 那些索引被排在最后的 (*temporary) 变量指的就是返回值。 但是由于 Lua 对特殊情况做了一些优化，比如直接返回一个被命名的局部变量， 那么就找不到对应的 (*temporary) 变量了。本质上，返回值一定存在于此刻的局部变量中， 并且可以访问它，只是无法确定是哪些罢了。至于这个时候函数体内的其它局部变量， 是不保证有效的。进入 return hook 的那一刻起，实际已经退出函数内部的运行环节， 返回值占用的局部变量空间以后的部分，都有可能因 hook 本身复用它们而改变。）
line hook: 在解释器准备开始执行新的一行代码时， 或是跳转到这行代码中时（即使在同一行内跳转）被调用。 （这个事件仅仅在 Lua 执行一个 Lua 函数时发生。）
count hook: 在解释器每执行 count 条指令后被调用。 （这个事件仅仅在 Lua 执行一个 Lua 函数时发生。）
钩子可以通过设置 mask 为零屏蔽。

lua_setlocal

const char *lua_setlocal (lua_State *L, lua_Debug *ar, int n);
设置给定活动记录中的局部变量的值。 参数 ar 与 n 和 lua_getlocal 中的一样 （参见 lua_getlocal）。 lua_setlocal 把栈顶的值赋给变量然后返回变量的名字。 它会将值从栈顶弹出。

当索引大于局部变量的个数时，返回 NULL （什么也不弹出）。

lua_setupvalue

const char *lua_setupvalue (lua_State *L, int funcindex, int n);
设置 closure 的 upvalue 的值。 它把栈顶的值弹出并赋于 upvalue 并返回 upvalue 的名字。 参数 funcindex 与 n 和 lua_getupvalue 中的一样 （参见 lua_getupvalue）。

当索引大于 upvalue 的个数时，返回 NULL （什么也不弹出）。

4 - The Auxiliary Library

The auxiliary library provides several convenient functions to interface C with Lua. While the basic API provides the primitive functions for all interactions between C and Lua, the auxiliary library provides higher-level functions for some common tasks.

All functions from the auxiliary library are defined in header file lauxlib.h and have a prefix luaL_.

All functions in the auxiliary library are built on top of the basic API, and so they provide nothing that cannot be done with this API.

Several functions in the auxiliary library are used to check C function arguments. Their names are always luaL_check* or luaL_opt*. All of these functions raise an error if the check is not satisfied. Because the error message is formatted for arguments (e.g., "bad argument #1"), you should not use these functions for other stack values.

4.1 - Functions and Types

Here we list all functions and types from the auxiliary library in alphabetical order.

luaL_addchar

void luaL_addchar (luaL_Buffer *B, char c);
Adds the character c to the buffer B (see luaL_Buffer).

luaL_addlstring

void luaL_addlstring (luaL_Buffer *B, const char *s, size_t l);
Adds the string pointed to by s with length l to the buffer B (see luaL_Buffer). The string may contain embedded zeros.

luaL_addsize

void luaL_addsize (luaL_Buffer *B, size_t n);
Adds to the buffer B (see luaL_Buffer) a string of length n previously copied to the buffer area (see luaL_prepbuffer).

luaL_addstring

void luaL_addstring (luaL_Buffer *B, const char *s);
Adds the zero-terminated string pointed to by s to the buffer B (see luaL_Buffer). The string may not contain embedded zeros.

luaL_addvalue

void luaL_addvalue (luaL_Buffer *B);
Adds the value at the top of the stack to the buffer B (see luaL_Buffer). Pops the value.

This is the only function on string buffers that can (and must) be called with an extra element on the stack, which is the value to be added to the buffer.

luaL_argcheck

void luaL_argcheck (lua_State *L,
                    int cond,
                    int narg,
                    const char *extramsg);
Checks whether cond is true. If not, raises an error with the following message, where func is retrieved from the call stack:

     bad argument #<narg> to <func> (<extramsg>)
luaL_argerror

int luaL_argerror (lua_State *L, int narg, const char *extramsg);
Raises an error with the following message, where func is retrieved from the call stack:

     bad argument #<narg> to <func> (<extramsg>)
This function never returns, but it is an idiom to use it in C functions as return luaL_argerror(args).

luaL_Buffer

typedef struct luaL_Buffer luaL_Buffer;
Type for a string buffer.

A string buffer allows C code to build Lua strings piecemeal. Its pattern of use is as follows:

First you declare a variable b of type luaL_Buffer.
Then you initialize it with a call luaL_buffinit(L, &b).
Then you add string pieces to the buffer calling any of the luaL_add* functions.
You finish by calling luaL_pushresult(&b). This call leaves the final string on the top of the stack.
During its normal operation, a string buffer uses a variable number of stack slots. So, while using a buffer, you cannot assume that you know where the top of the stack is. You can use the stack between successive calls to buffer operations as long as that use is balanced; that is, when you call a buffer operation, the stack is at the same level it was immediately after the previous buffer operation. (The only exception to this rule is luaL_addvalue.) After calling luaL_pushresult the stack is back to its level when the buffer was initialized, plus the final string on its top.

luaL_buffinit

void luaL_buffinit (lua_State *L, luaL_Buffer *B);
Initializes a buffer B. This function does not allocate any space; the buffer must be declared as a variable (see luaL_Buffer).

luaL_callmeta

int luaL_callmeta (lua_State *L, int obj, const char *e);
Calls a metamethod.

If the object at index obj has a metatable and this metatable has a field e, this function calls this field and passes the object as its only argument. In this case this function returns 1 and pushes onto the stack the value returned by the call. If there is no metatable or no metamethod, this function returns 0 (without pushing any value on the stack).

luaL_checkany

void luaL_checkany (lua_State *L, int narg);
Checks whether the function has an argument of any type (including nil) at position narg.

luaL_checkint

int luaL_checkint (lua_State *L, int narg);
Checks whether the function argument narg is a number and returns this number cast to an int.

luaL_checkinteger

lua_Integer luaL_checkinteger (lua_State *L, int narg);
Checks whether the function argument narg is a number and returns this number cast to a lua_Integer.

luaL_checklong

long luaL_checklong (lua_State *L, int narg);
Checks whether the function argument narg is a number and returns this number cast to a long.

luaL_checklstring

const char *luaL_checklstring (lua_State *L, int narg, size_t *l);
Checks whether the function argument narg is a string and returns this string; if l is not NULL fills *l with the string's length.

luaL_checknumber

lua_Number luaL_checknumber (lua_State *L, int narg);
Checks whether the function argument narg is a number and returns this number.

luaL_checkoption

int luaL_checkoption (lua_State *L,
                      int narg,
                      const char *def,
                      const char *const lst[]);
Checks whether the function argument narg is a string and searches for this string in the array lst (which must be NULL-terminated). Returns the index in the array where the string was found. Raises an error if the argument is not a string or if the string cannot be found.

If def is not NULL, the function uses def as a default value when there is no argument narg or if this argument is nil.

This is a useful function for mapping strings to C enums. (The usual convention in Lua libraries is to use strings instead of numbers to select options.)

luaL_checkstack

void luaL_checkstack (lua_State *L, int sz, const char *msg);
Grows the stack size to top + sz elements, raising an error if the stack cannot grow to that size. msg is an additional text to go into the error message.

luaL_checkstring

const char *luaL_checkstring (lua_State *L, int narg);
Checks whether the function argument narg is a string and returns this string.

luaL_checktype

void luaL_checktype (lua_State *L, int narg, int t);
Checks whether the function argument narg has type t.

luaL_checkudata

void *luaL_checkudata (lua_State *L, int narg, const char *tname);
Checks whether the function argument narg is a userdata of the type tname (see luaL_newmetatable).

luaL_dofile

int luaL_dofile (lua_State *L, const char *filename);
Loads and runs the given file. It is defined as the following macro:

     (luaL_loadfile(L, filename) || lua_pcall(L, 0, LUA_MULTRET, 0))
It returns 0 if there are no errors or 1 in case of errors.

luaL_dostring

int luaL_dostring (lua_State *L, const char *str);
Loads and runs the given string. It is defined as the following macro:

     (luaL_loadstring(L, str) || lua_pcall(L, 0, LUA_MULTRET, 0))
It returns 0 if there are no errors or 1 in case of errors.

luaL_error

int luaL_error (lua_State *L, const char *fmt, ...);
Raises an error. The error message format is given by fmt plus any extra arguments, following the same rules of lua_pushfstring. It also adds at the beginning of the message the file name and the line number where the error occurred, if this information is available.

This function never returns, but it is an idiom to use it in C functions as return luaL_error(args).

luaL_getmetafield

int luaL_getmetafield (lua_State *L, int obj, const char *e);
Pushes onto the stack the field e from the metatable of the object at index obj. If the object does not have a metatable, or if the metatable does not have this field, returns 0 and pushes nothing.

luaL_getmetatable

void luaL_getmetatable (lua_State *L, const char *tname);
Pushes onto the stack the metatable associated with name tname in the registry (see luaL_newmetatable).

luaL_gsub

const char *luaL_gsub (lua_State *L,
                       const char *s,
                       const char *p,
                       const char *r);
Creates a copy of string s by replacing any occurrence of the string p with the string r. Pushes the resulting string on the stack and returns it.

luaL_loadbuffer

int luaL_loadbuffer (lua_State *L,
                     const char *buff,
                     size_t sz,
                     const char *name);
Loads a buffer as a Lua chunk. This function uses lua_load to load the chunk in the buffer pointed to by buff with size sz.

This function returns the same results as lua_load. name is the chunk name, used for debug information and error messages.

luaL_loadfile

int luaL_loadfile (lua_State *L, const char *filename);
Loads a file as a Lua chunk. This function uses lua_load to load the chunk in the file named filename. If filename is NULL, then it loads from the standard input. The first line in the file is ignored if it starts with a #.

This function returns the same results as lua_load, but it has an extra error code LUA_ERRFILE if it cannot open/read the file.

As lua_load, this function only loads the chunk; it does not run it.

luaL_loadstring

int luaL_loadstring (lua_State *L, const char *s);
Loads a string as a Lua chunk. This function uses lua_load to load the chunk in the zero-terminated string s.

This function returns the same results as lua_load.

Also as lua_load, this function only loads the chunk; it does not run it.

luaL_newmetatable

int luaL_newmetatable (lua_State *L, const char *tname);
If the registry already has the key tname, returns 0. Otherwise, creates a new table to be used as a metatable for userdata, adds it to the registry with key tname, and returns 1.

In both cases pushes onto the stack the final value associated with tname in the registry.

luaL_newstate

lua_State *luaL_newstate (void);
Creates a new Lua state. It calls lua_newstate with an allocator based on the standard C realloc function and then sets a panic function (see lua_atpanic) that prints an error message to the standard error output in case of fatal errors.

Returns the new state, or NULL if there is a memory allocation error.

luaL_openlibs

void luaL_openlibs (lua_State *L);
Opens all standard Lua libraries into the given state.

luaL_optint

int luaL_optint (lua_State *L, int narg, int d);
If the function argument narg is a number, returns this number cast to an int. If this argument is absent or is nil, returns d. Otherwise, raises an error.

luaL_optinteger

lua_Integer luaL_optinteger (lua_State *L,
                             int narg,
                             lua_Integer d);
If the function argument narg is a number, returns this number cast to a lua_Integer. If this argument is absent or is nil, returns d. Otherwise, raises an error.

luaL_optlong

long luaL_optlong (lua_State *L, int narg, long d);
If the function argument narg is a number, returns this number cast to a long. If this argument is absent or is nil, returns d. Otherwise, raises an error.

luaL_optlstring

const char *luaL_optlstring (lua_State *L,
                             int narg,
                             const char *d,
                             size_t *l);
If the function argument narg is a string, returns this string. If this argument is absent or is nil, returns d. Otherwise, raises an error.

If l is not NULL, fills the position *l with the results's length.

luaL_optnumber

lua_Number luaL_optnumber (lua_State *L, int narg, lua_Number d);
If the function argument narg is a number, returns this number. If this argument is absent or is nil, returns d. Otherwise, raises an error.

luaL_optstring

const char *luaL_optstring (lua_State *L,
                            int narg,
                            const char *d);
If the function argument narg is a string, returns this string. If this argument is absent or is nil, returns d. Otherwise, raises an error.

luaL_prepbuffer

char *luaL_prepbuffer (luaL_Buffer *B);
Returns an address to a space of size LUAL_BUFFERSIZE where you can copy a string to be added to buffer B (see luaL_Buffer). After copying the string into this space you must call luaL_addsize with the size of the string to actually add it to the buffer.

luaL_pushresult

void luaL_pushresult (luaL_Buffer *B);
Finishes the use of buffer B leaving the final string on the top of the stack.

luaL_ref

int luaL_ref (lua_State *L, int t);
Creates and returns a reference, in the table at index t, for the object at the top of the stack (and pops the object).

A reference is a unique integer key. As long as you do not manually add integer keys into table t, luaL_ref ensures the uniqueness of the key it returns. You can retrieve an object referred by reference r by calling lua_rawgeti(L, t, r). Function luaL_unref frees a reference and its associated object.

If the object at the top of the stack is nil, luaL_ref returns the constant LUA_REFNIL. The constant LUA_NOREF is guaranteed to be different from any reference returned by luaL_ref.

luaL_Reg

typedef struct luaL_Reg {
  const char *name;
  lua_CFunction func;
} luaL_Reg;
Type for arrays of functions to be registered by luaL_register. name is the function name and func is a pointer to the function. Any array of luaL_Reg must end with an sentinel entry in which both name and func are NULL.

luaL_register

void luaL_register (lua_State *L,
                    const char *libname,
                    const luaL_Reg *l);
Opens a library.

When called with libname equal to NULL, it simply registers all functions in the list l (see luaL_Reg) into the table on the top of the stack.

When called with a non-null libname, luaL_register creates a new table t, sets it as the value of the global variable libname, sets it as the value of package.loaded[libname], and registers on it all functions in the list l. If there is a table in package.loaded[libname] or in variable libname, reuses this table instead of creating a new one.

In any case the function leaves the table on the top of the stack.

luaL_typename

const char *luaL_typename (lua_State *L, int idx);
Returns the name of the type of the value at index idx.

luaL_typerror

int luaL_typerror (lua_State *L, int narg, const char *tname);
Generates an error with a message like the following:

     location: bad argument narg to 'func' (tname expected, got rt)
where location is produced by luaL_where, func is the name of the current function, and rt is the type name of the actual argument.

luaL_unref

void luaL_unref (lua_State *L, int t, int ref);
Releases reference ref from the table at index t (see luaL_ref). The entry is removed from the table, so that the referred object can be collected. The reference ref is also freed to be used again.

If ref is LUA_NOREF or LUA_REFNIL, luaL_unref does nothing.

luaL_where

void luaL_where (lua_State *L, int lvl);
Pushes onto the stack a string identifying the current position of the control at level lvl in the call stack. Typically this string has the following format:

     chunkname:currentline:
Level 0 is the running function, level 1 is the function that called the running function, etc.

This function is used to build a prefix for error messages.

5 - Standard Libraries

The standard Lua libraries provide useful functions that are implemented directly through the C API. Some of these functions provide essential services to the language (e.g., type and getmetatable); others provide access to "outside" services (e.g., I/O); and others could be implemented in Lua itself, but are quite useful or have critical performance requirements that deserve an implementation in C (e.g., sort).

All libraries are implemented through the official C API and are provided as separate C modules. Currently, Lua has the following standard libraries:

basic library;
package library;
string manipulation;
table manipulation;
mathematical functions (sin, log, etc.);
input and output;
operating system facilities;
debug facilities.
Except for the basic and package libraries, each library provides all its functions as fields of a global table or as methods of its objects.

To have access to these libraries, the C host program should call the luaL_openlibs function, which opens all standard libraries. Alternatively, it can open them individually by calling luaopen_base (for the basic library), luaopen_package (for the package library), luaopen_string (for the string library), luaopen_table (for the table library), luaopen_math (for the mathematical library), luaopen_io (for the I/O and the Operating System libraries), and luaopen_debug (for the debug library). These functions are declared in lualib.h and should not be called directly: you must call them like any other Lua C function, e.g., by using lua_call.

5.1 - Basic Functions

The basic library provides some core functions to Lua. If you do not include this library in your application, you should check carefully whether you need to provide implementations for some of its facilities.

assert (v [, message])

Issues an error when the value of its argument v is false (i.e., nil or false); otherwise, returns all its arguments. message is an error message; when absent, it defaults to "assertion failed!"
collectgarbage (opt [, arg])

This function is a generic interface to the garbage collector. It performs different functions according to its first argument, opt:

"stop": stops the garbage collector.
"restart": restarts the garbage collector.
"collect": performs a full garbage-collection cycle.
"count": returns the total memory in use by Lua (in Kbytes).
"step": performs a garbage-collection step. The step "size" is controlled by arg (larger values mean more steps) in a non-specified way. If you want to control the step size you must experimentally tune the value of arg. Returns true if the step finished a collection cycle.
"setpause": sets arg/100 as the new value for the pause of the collector (see §2.10).
"setstepmul": sets arg/100 as the new value for the step multiplier of the collector (see §2.10).
dofile (filename)

Opens the named file and executes its contents as a Lua chunk. When called without arguments, dofile executes the contents of the standard input (stdin). Returns all values returned by the chunk. In case of errors, dofile propagates the error to its caller (that is, dofile does not run in protected mode).
error (message [, level])

Terminates the last protected function called and returns message as the error message. Function error never returns.
Usually, error adds some information about the error position at the beginning of the message. The level argument specifies how to get the error position. With level 1 (the default), the error position is where the error function was called. Level 2 points the error to where the function that called error was called; and so on. Passing a level 0 avoids the addition of error position information to the message.

_G

A global variable (not a function) that holds the global environment (that is, _G._G = _G). Lua itself does not use this variable; changing its value does not affect any environment, nor vice-versa. (Use setfenv to change environments.)
getfenv (f)

Returns the current environment in use by the function. f can be a Lua function or a number that specifies the function at that stack level: Level 1 is the function calling getfenv. If the given function is not a Lua function, or if f is 0, getfenv returns the global environment. The default for f is 1.
getmetatable (object)

If object does not have a metatable, returns nil. Otherwise, if the object's metatable has a "__metatable" field, returns the associated value. Otherwise, returns the metatable of the given object.

ipairs (t)

Returns three values: an iterator function, the table t, and 0, so that the construction

     for i,v in ipairs(t) do body end
will iterate over the pairs (1,t[1]), (2,t[2]), ···, up to the first integer key absent from the table.

load (func [, chunkname])

Loads a chunk using function func to get its pieces. Each call to func must return a string that concatenates with previous results. A return of nil (or no value) signals the end of the chunk.

If there are no errors, returns the compiled chunk as a function; otherwise, returns nil plus the error message. The environment of the returned function is the global environment.

chunkname is used as the chunk name for error messages and debug information.

loadfile ([filename])

Similar to load, but gets the chunk from file filename or from the standard input, if no file name is given.

loadstring (string [, chunkname])

Similar to load, but gets the chunk from the given string.

To load and run a given string, use the idiom

     assert(loadstring(s))()
next (table [, index])

Allows a program to traverse all fields of a table. Its first argument is a table and its second argument is an index in this table. next returns the next index of the table and its associated value. When called with nil as its second argument, next returns an initial index and its associated value. When called with the last index, or with nil in an empty table, next returns nil. If the second argument is absent, then it is interpreted as nil. In particular, you can use next(t) to check whether a table is empty.

The order in which the indices are enumerated is not specified, even for numeric indices. (To traverse a table in numeric order, use a numerical for or the ipairs function.)

The behavior of next is undefined if, during the traversal, you assign any value to a non-existent field in the table. You may however modify existing fields. In particular, you may clear existing fields.

pairs (t)

Returns three values: the next function, the table t, and nil, so that the construction

     for k,v in pairs(t) do body end
will iterate over all key–value pairs of table t.

See function next for the caveats of modifying the table during its traversal.

pcall (f, arg1, ···)

Calls function f with the given arguments in protected mode. This means that any error inside f is not propagated; instead, pcall catches the error and returns a status code. Its first result is the status code (a boolean), which is true if the call succeeds without errors. In such case, pcall also returns all results from the call, after this first result. In case of any error, pcall returns false plus the error message.

print (···)

Receives any number of arguments, and prints their values to stdout, using the tostring function to convert them to strings. print is not intended for formatted output, but only as a quick way to show a value, typically for debugging. For formatted output, use string.format.
rawequal (v1, v2)

Checks whether v1 is equal to v2, without invoking any metamethod. Returns a boolean.
rawget (table, index)

Gets the real value of table[index], without invoking any metamethod. table must be a table; index may be any value.
rawset (table, index, value)

Sets the real value of table[index] to value, without invoking any metamethod. table must be a table, index any value different from nil, and value any Lua value.
This function returns table.

select (index, ···)

If index is a number, returns all arguments after argument number index. Otherwise, index must be the string "#", and select returns the total number of extra arguments it received.

setfenv (f, table)

Sets the environment to be used by the given function. f can be a Lua function or a number that specifies the function at that stack level: Level 1 is the function calling setfenv. setfenv returns the given function.

As a special case, when f is 0 setfenv changes the environment of the running thread. In this case, setfenv returns no values.

setmetatable (table, metatable)

Sets the metatable for the given table. (You cannot change the metatable of other types from Lua, only from C.) If metatable is nil, removes the metatable of the given table. If the original metatable has a "__metatable" field, raises an error.

This function returns table.

tonumber (e [, base])

Tries to convert its argument to a number. If the argument is already a number or a string convertible to a number, then tonumber returns this number; otherwise, it returns nil.
An optional argument specifies the base to interpret the numeral. The base may be any integer between 2 and 36, inclusive. In bases above 10, the letter 'A' (in either upper or lower case) represents 10, 'B' represents 11, and so forth, with 'Z' representing 35. In base 10 (the default), the number may have a decimal part, as well as an optional exponent part (see §2.1). In other bases, only unsigned integers are accepted.

tostring (e)

Receives an argument of any type and converts it to a string in a reasonable format. For complete control of how numbers are converted, use string.format.
If the metatable of e has a "__tostring" field, then tostring calls the corresponding value with e as argument, and uses the result of the call as its result.

type (v)

Returns the type of its only argument, coded as a string. The possible results of this function are "nil" (a string, not the value nil), "number", "string", "boolean", "table", "function", "thread", and "userdata".
unpack (list [, i [, j]])

Returns the elements from the given table. This function is equivalent to
     return list[i], list[i+1], ···, list[j]
except that the above code can be written only for a fixed number of elements. By default, i is 1 and j is the length of the list, as defined by the length operator (see §2.5.5).

_VERSION

A global variable (not a function) that holds a string containing the current interpreter version. The current contents of this variable is "Lua 5.1".
xpcall (f, err)

This function is similar to pcall, except that you can set a new error handler.

xpcall calls function f in protected mode, using err as the error handler. Any error inside f is not propagated; instead, xpcall catches the error, calls the err function with the original error object, and returns a status code. Its first result is the status code (a boolean), which is true if the call succeeds without errors. In this case, xpcall also returns all results from the call, after this first result. In case of any error, xpcall returns false plus the result from err.

5.2 - Coroutine Manipulation

The operations related to coroutines comprise a sub-library of the basic library and come inside the table coroutine. See §2.11 for a general description of coroutines.

coroutine.create (f)

Creates a new coroutine, with body f. f must be a Lua function. Returns this new coroutine, an object with type "thread".

coroutine.resume (co [, val1, ···])

Starts or continues the execution of coroutine co. The first time you resume a coroutine, it starts running its body. The values val1, ··· are passed as the arguments to the body function. If the coroutine has yielded, resume restarts it; the values val1, ··· are passed as the results from the yield.

If the coroutine runs without any errors, resume returns true plus any values passed to yield (if the coroutine yields) or any values returned by the body function (if the coroutine terminates). If there is any error, resume returns false plus the error message.

coroutine.running ()

Returns the running coroutine, or nil when called by the main thread.

coroutine.status (co)

Returns the status of coroutine co, as a string: "running", if the coroutine is running (that is, it called status); "suspended", if the coroutine is suspended in a call to yield, or if it has not started running yet; "normal" if the coroutine is active but not running (that is, it has resumed another coroutine); and "dead" if the coroutine has finished its body function, or if it has stopped with an error.

coroutine.wrap (f)

Creates a new coroutine, with body f. f must be a Lua function. Returns a function that resumes the coroutine each time it is called. Any arguments passed to the function behave as the extra arguments to resume. Returns the same values returned by resume, except the first boolean. In case of error, propagates the error.

coroutine.yield (···)

Suspends the execution of the calling coroutine. The coroutine cannot be running a C function, a metamethod, or an iterator. Any arguments to yield are passed as extra results to resume.

5.3 - Modules

The package library provides basic facilities for loading and building modules in Lua. It exports two of its functions directly in the global environment: require and module. Everything else is exported in a table package.

module (name [, ···])

Creates a module. If there is a table in package.loaded[name], this table is the module. Otherwise, if there is a global table t with the given name, this table is the module. Otherwise creates a new table t and sets it as the value of the global name and the value of package.loaded[name]. This function also initializes t._NAME with the given name, t._M with the module (t itself), and t._PACKAGE with the package name (the full module name minus last component; see below). Finally, module sets t as the new environment of the current function and the new value of package.loaded[name], so that require returns t.

If name is a compound name (that is, one with components separated by dots), module creates (or reuses, if they already exist) tables for each component. For instance, if name is a.b.c, then module stores the module table in field c of field b of global a.

This function may receive optional options after the module name, where each option is a function to be applied over the module.

require (modname)

Loads the given module. The function starts by looking into the package.loaded table to determine whether modname is already loaded. If it is, then require returns the value stored at package.loaded[modname]. Otherwise, it tries to find a loader for the module.

To find a loader, first require queries package.preload[modname]. If it has a value, this value (which should be a function) is the loader. Otherwise require searches for a Lua loader using the path stored in package.path. If that also fails, it searches for a C loader using the path stored in package.cpath. If that also fails, it tries an all-in-one loader (see below).

When loading a C library, require first uses a dynamic link facility to link the application with the library. Then it tries to find a C function inside this library to be used as the loader. The name of this C function is the string "luaopen_" concatenated with a copy of the module name where each dot is replaced by an underscore. Moreover, if the module name has a hyphen, its prefix up to (and including) the first hyphen is removed. For instance, if the module name is a.v1-b.c, the function name will be luaopen_b_c.

If require finds neither a Lua library nor a C library for a module, it calls the all-in-one loader. This loader searches the C path for a library for the root name of the given module. For instance, when requiring a.b.c, it will search for a C library for a. If found, it looks into it for an open function for the submodule; in our example, that would be luaopen_a_b_c. With this facility, a package can pack several C submodules into one single library, with each submodule keeping its original open function.

Once a loader is found, require calls the loader with a single argument, modname. If the loader returns any value, require assigns the returned value to package.loaded[modname]. If the loader returns no value and has not assigned any value to package.loaded[modname], then require assigns true to this entry. In any case, require returns the final value of package.loaded[modname].

If there is any error loading or running the module, or if it cannot find any loader for the module, then require signals an error.

package.cpath

The path used by require to search for a C loader.

Lua initializes the C path package.cpath in the same way it initializes the Lua path package.path, using the environment variable LUA_CPATH (plus another default path defined in luaconf.h).

package.loaded

A table used by require to control which modules are already loaded. When you require a module modname and package.loaded[modname] is not false, require simply returns the value stored there.

package.loadlib (libname, funcname)

Dynamically links the host program with the C library libname. Inside this library, looks for a function funcname and returns this function as a C function. (So, funcname must follow the protocol (see lua_CFunction)).

This is a low-level function. It completely bypasses the package and module system. Unlike require, it does not perform any path searching and does not automatically adds extensions. libname must be the complete file name of the C library, including if necessary a path and extension. funcname must be the exact name exported by the C library (which may depend on the C compiler and linker used).

This function is not supported by ANSI C. As such, it is only available on some platforms (Windows, Linux, Mac OS X, Solaris, BSD, plus other Unix systems that support the dlfcn standard).

package.path

The path used by require to search for a Lua loader.

At start-up, Lua initializes this variable with the value of the environment variable LUA_PATH or with a default path defined in luaconf.h, if the environment variable is not defined. Any ";;" in the value of the environment variable is replaced by the default path.

A path is a sequence of templates separated by semicolons. For each template, require will change each interrogation mark in the template by filename, which is modname with each dot replaced by a "directory separator" (such as "/" in Unix); then it will try to load the resulting file name. So, for instance, if the Lua path is

     "./?.lua;./?.lc;/usr/local/?/init.lua"
the search for a Lua loader for module foo will try to load the files ./foo.lua, ./foo.lc, and /usr/local/foo/init.lua, in that order.

package.preload

A table to store loaders for specific modules (see require).

package.seeall (module)

Sets a metatable for module with its __index field referring to the global environment, so that this module inherits values from the global environment. To be used as an option to function module.

5.4 - String Manipulation

This library provides generic functions for string manipulation, such as finding and extracting substrings, and pattern matching. When indexing a string in Lua, the first character is at position 1 (not at 0, as in C). Indices are allowed to be negative and are interpreted as indexing backwards, from the end of the string. Thus, the last character is at position -1, and so on.

The string library provides all its functions inside the table string. It also sets a metatable for strings where the __index field points to the string table. Therefore, you can use the string functions in object-oriented style. For instance, string.byte(s, i) can be written as s:byte(i).

string.byte (s [, i [, j]])

Returns the internal numerical codes of the characters s[i], s[i+1], ···, s[j]. The default value for i is 1; the default value for j is i.
Note that numerical codes are not necessarily portable across platforms.

string.char (···)

Receives zero or more integers. Returns a string with length equal to the number of arguments, in which each character has the internal numerical code equal to its corresponding argument.
Note that numerical codes are not necessarily portable across platforms.

string.dump (function)

Returns a string containing a binary representation of the given function, so that a later loadstring on this string returns a copy of the function. function must be a Lua function without upvalues.

string.find (s, pattern [, init [, plain]])

Looks for the first match of pattern in the string s. If it finds a match, then find returns the indices of s where this occurrence starts and ends; otherwise, it returns nil. A third, optional numerical argument init specifies where to start the search; its default value is 1 and may be negative. A value of true as a fourth, optional argument plain turns off the pattern matching facilities, so the function does a plain "find substring" operation, with no characters in pattern being considered "magic". Note that if plain is given, then init must be given as well.
If the pattern has captures, then in a successful match the captured values are also returned, after the two indices.

string.format (formatstring, ···)

Returns a formatted version of its variable number of arguments following the description given in its first argument (which must be a string). The format string follows the same rules as the printf family of standard C functions. The only differences are that the options/modifiers *, l, L, n, p, and h are not supported and that there is an extra option, q. The q option formats a string in a form suitable to be safely read back by the Lua interpreter: the string is written between double quotes, and all double quotes, newlines, embedded zeros, and backslashes in the string are correctly escaped when written. For instance, the call
     string.format('%q', 'a string with "quotes" and \n new line')
will produce the string:

     "a string with \"quotes\" and \
      new line"
The options c, d, E, e, f, g, G, i, o, u, X, and x all expect a number as argument, whereas q and s expect a string.

This function does not accept string values containing embedded zeros.

string.gmatch (s, pattern)

Returns an iterator function that, each time it is called, returns the next captures from pattern over string s.
If pattern specifies no captures, then the whole match is produced in each call.

As an example, the following loop

     s = "hello world from Lua"
     for w in string.gmatch(s, "%a+") do
       print(w)
     end
will iterate over all the words from string s, printing one per line. The next example collects all pairs key=value from the given string into a table:

     t = {}
     s = "from=world, to=Lua"
     for k, v in string.gmatch(s, "(%w+)=(%w+)") do
       t[k] = v
     end
string.gsub (s, pattern, repl [, n])

Returns a copy of s in which all occurrences of the pattern have been replaced by a replacement string specified by repl, which may be a string, a table, or a function. gsub also returns, as its second value, the total number of substitutions made.
If repl is a string, then its value is used for replacement. The character % works as an escape character: any sequence in repl of the form %n, with n between 1 and 9, stands for the value of the n-th captured substring (see below). The sequence %0 stands for the whole match. The sequence %% stands for a single %.

If repl is a table, then the table is queried for every match, using the first capture as the key; if the pattern specifies no captures, then the whole match is used as the key.

If repl is a function, then this function is called every time a match occurs, with all captured substrings passed as arguments, in order; if the pattern specifies no captures, then the whole match is passed as a sole argument.

If the value returned by the table query or by the function call is a string or a number, then it is used as the replacement string; otherwise, if it is false or nil, then there is no replacement (that is, the original match is kept in the string).

The optional last parameter n limits the maximum number of substitutions to occur. For instance, when n is 1 only the first occurrence of pattern is replaced.

Here are some examples:

     x = string.gsub("hello world", "(%w+)", "%1 %1")
     --> x="hello hello world world"
     
     x = string.gsub("hello world", "%w+", "%0 %0", 1)
     --> x="hello hello world"
     
     x = string.gsub("hello world from Lua", "(%w+)%s*(%w+)", "%2 %1")
     --> x="world hello Lua from"
     
     x = string.gsub("home = $HOME, user = $USER", "%$(%w+)", os.getenv)
     --> x="home = /home/roberto, user = roberto"
     
     x = string.gsub("4+5 = $return 4+5$", "%$(.-)%$", function (s)
           return loadstring(s)()
         end)
     --> x="4+5 = 9"
     
     local t = {name="lua", version="5.1"}
     x = string.gsub("$name%-$version.tar.gz", "%$(%w+)", t)
     --> x="lua-5.1.tar.gz"
string.len (s)

Receives a string and returns its length. The empty string "" has length 0. Embedded zeros are counted, so "a\000bc\000" has length 5.
string.lower (s)

Receives a string and returns a copy of this string with all uppercase letters changed to lowercase. All other characters are left unchanged. The definition of what an uppercase letter is depends on the current locale.
string.match (s, pattern [, init])

Looks for the first match of pattern in the string s. If it finds one, then match returns the captures from the pattern; otherwise it returns nil. If pattern specifies no captures, then the whole match is returned. A third, optional numerical argument init specifies where to start the search; its default value is 1 and may be negative.
string.rep (s, n)

Returns a string that is the concatenation of n copies of the string s.
string.reverse (s)

Returns a string that is the string s reversed.
string.sub (s, i [, j])

Returns the substring of s that starts at i and continues until j; i and j may be negative. If j is absent, then it is assumed to be equal to -1 (which is the same as the string length). In particular, the call string.sub(s,1,j) returns a prefix of s with length j, and string.sub(s, -i) returns a suffix of s with length i.
string.upper (s)

Receives a string and returns a copy of this string with all lowercase letters changed to uppercase. All other characters are left unchanged. The definition of what a lowercase letter is depends on the current locale.
5.4.1 - Patterns

Character Class:

A character class is used to represent a set of characters. The following combinations are allowed in describing a character class:

x: (where x is not one of the magic characters ^$()%.[]*+-?) represents the character x itself.
.: (a dot) represents all characters.
%a: represents all letters.
%c: represents all control characters.
%d: represents all digits.
%l: represents all lowercase letters.
%p: represents all punctuation characters.
%s: represents all space characters.
%u: represents all uppercase letters.
%w: represents all alphanumeric characters.
%x: represents all hexadecimal digits.
%z: represents the character with representation 0.
%x: (where x is any non-alphanumeric character) represents the character x. This is the standard way to escape the magic characters. Any punctuation character (even the non magic) can be preceded by a '%' when used to represent itself in a pattern.
[set]: represents the class which is the union of all characters in set. A range of characters may be specified by separating the end characters of the range with a '-'. All classes %x described above may also be used as components in set. All other characters in set represent themselves. For example, [%w_] (or [_%w]) represents all alphanumeric characters plus the underscore, [0-7] represents the octal digits, and [0-7%l%-] represents the octal digits plus the lowercase letters plus the '-' character.
The interaction between ranges and classes is not defined. Therefore, patterns like [%a-z] or [a-%%] have no meaning.

[^set]: represents the complement of set, where set is interpreted as above.
For all classes represented by single letters (%a, %c, etc.), the corresponding uppercase letter represents the complement of the class. For instance, %S represents all non-space characters.

The definitions of letter, space, and other character groups depend on the current locale. In particular, the class [a-z] may not be equivalent to %l.

Pattern Item:

A pattern item may be

a single character class, which matches any single character in the class;
a single character class followed by '*', which matches 0 or more repetitions of characters in the class. These repetition items will always match the longest possible sequence;
a single character class followed by '+', which matches 1 or more repetitions of characters in the class. These repetition items will always match the longest possible sequence;
a single character class followed by '-', which also matches 0 or more repetitions of characters in the class. Unlike '*', these repetition items will always match the shortest possible sequence;
a single character class followed by '?', which matches 0 or 1 occurrence of a character in the class;
%n, for n between 1 and 9; such item matches a substring equal to the n-th captured string (see below);
%bxy, where x and y are two distinct characters; such item matches strings that start with x, end with y, and where the x and y are balanced. This means that, if one reads the string from left to right, counting +1 for an x and -1 for a y, the ending y is the first y where the count reaches 0. For instance, the item %b() matches expressions with balanced parentheses.
Pattern:

A pattern is a sequence of pattern items. A '^' at the beginning of a pattern anchors the match at the beginning of the subject string. A '$' at the end of a pattern anchors the match at the end of the subject string. At other positions, '^' and '$' have no special meaning and represent themselves.

Captures:

A pattern may contain sub-patterns enclosed in parentheses; they describe captures. When a match succeeds, the substrings of the subject string that match captures are stored (captured) for future use. Captures are numbered according to their left parentheses. For instance, in the pattern "(a*(.)%w(%s*))", the part of the string matching "a*(.)%w(%s*)" is stored as the first capture (and therefore has number 1); the character matching "." is captured with number 2, and the part matching "%s*" has number 3.

As a special case, the empty capture () captures the current string position (a number). For instance, if we apply the pattern "()aa()" on the string "flaaap", there will be two captures: 3 and 5.

A pattern cannot contain embedded zeros. Use %z instead.

5.5 - Table Manipulation

This library provides generic functions for table manipulation. It provides all its functions inside the table table.

Most functions in the table library assume that the table represents an array or a list. For these functions, when we talk about the "length" of a table we mean the result of the length operator.

table.concat (table [, sep [, i [, j]]])

Given an array where all elements are strings or numbers, returns table[i]..sep..table[i+1] ··· sep..table[j]. The default value for sep is the empty string, the default for i is 1, and the default for j is the length of the table. If i is greater than j, returns the empty string.
table.insert (table, [pos,] value)

Inserts element value at position pos in table, shifting up other elements to open space, if necessary. The default value for pos is n+1, where n is the length of the table (see §2.5.5), so that a call table.insert(t,x) inserts x at the end of table t.

table.maxn (table)

Returns the largest positive numerical index of the given table, or zero if the table has no positive numerical indices. (To do its job this function does a linear traversal of the whole table.)

table.remove (table [, pos])

Removes from table the element at position pos, shifting down other elements to close the space, if necessary. Returns the value of the removed element. The default value for pos is n, where n is the length of the table, so that a call table.remove(t) removes the last element of table t.

table.sort (table [, comp])

Sorts table elements in a given order, in-place, from table[1] to table[n], where n is the length of the table. If comp is given, then it must be a function that receives two table elements, and returns true when the first is less than the second (so that not comp(a[i+1],a[i]) will be true after the sort). If comp is not given, then the standard Lua operator < is used instead.
The sort algorithm is not stable; that is, elements considered equal by the given order may have their relative positions changed by the sort.

5.6 - Mathematical Functions

This library is an interface to the standard C math library. It provides all its functions inside the table math.

math.abs (x)

Returns the absolute value of x.

math.acos (x)

Returns the arc cosine of x (in radians).

math.asin (x)

Returns the arc sine of x (in radians).

math.atan (x)

Returns the arc tangent of x (in radians).

math.atan2 (x, y)

Returns the arc tangent of x/y (in radians), but uses the signs of both parameters to find the quadrant of the result. (It also handles correctly the case of y being zero.)

math.ceil (x)

Returns the smallest integer larger than or equal to x.

math.cos (x)

Returns the cosine of x (assumed to be in radians).

math.cosh (x)

Returns the hyperbolic cosine of x.

math.deg (x)

Returns the angle x (given in radians) in degrees.

math.exp (x)

Returns the the value ex.

math.floor (x)

Returns the largest integer smaller than or equal to x.

math.fmod (x, y)

Returns the remainder of the division of x by y.

math.frexp (x)

Returns m and e such that x = m2e, e is an integer and the absolute value of m is in the range [0.5, 1) (or zero when x is zero).

math.huge

The value HUGE_VAL, a value larger than or equal to any other numerical value.

math.ldexp (m, e)

Returns m2e (e should be an integer).

math.log (x)

Returns the natural logarithm of x.

math.log10 (x)

Returns the base-10 logarithm of x.

math.max (x, ···)

Returns the maximum value among its arguments.

math.min (x, ···)

Returns the minimum value among its arguments.

math.modf (x)

Returns two numbers, the integral part of x and the fractional part of x.

math.pi

The value of pi.

math.pow (x, y)

Returns xy. (You can also use the expression x^y to compute this value.)

math.rad (x)

Returns the angle x (given in degrees) in radians.

math.random ([m [, n]])

This function is an interface to the simple pseudo-random generator function rand provided by ANSI C. (No guarantees can be given for its statistical properties.)

When called without arguments, returns a pseudo-random real number in the range [0,1). When called with a number m, math.random returns a pseudo-random integer in the range [1, m]. When called with two numbers m and n, math.random returns a pseudo-random integer in the range [m, n].

math.randomseed (x)

Sets x as the "seed" for the pseudo-random generator: equal seeds produce equal sequences of numbers.

math.sin (x)

Returns the sine of x (assumed to be in radians).

math.sinh (x)

Returns the hyperbolic sine of x.

math.sqrt (x)

Returns the square root of x. (You can also use the expression x^0.5 to compute this value.)

math.tan (x)

Returns the tangent of x (assumed to be in radians).

math.tanh (x)

Returns the hyperbolic tangent of x.

5.7 - Input and Output Facilities

The I/O library provides two different styles for file manipulation. The first one uses implicit file descriptors; that is, there are operations to set a default input file and a default output file, and all input/output operations are over these default files. The second style uses explicit file descriptors.

When using implicit file descriptors, all operations are supplied by table io. When using explicit file descriptors, the operation io.open returns a file descriptor and then all operations are supplied as methods of the file descriptor.

The table io also provides three predefined file descriptors with their usual meanings from C: io.stdin, io.stdout, and io.stderr.

Unless otherwise stated, all I/O functions return nil on failure (plus an error message as a second result) and some value different from nil on success.

io.close ([file])

Equivalent to file:close(). Without a file, closes the default output file.

io.flush ()

Equivalent to file:flush over the default output file.

io.input ([file])

When called with a file name, it opens the named file (in text mode), and sets its handle as the default input file. When called with a file handle, it simply sets this file handle as the default input file. When called without parameters, it returns the current default input file.

In case of errors this function raises the error, instead of returning an error code.

io.lines ([filename])

Opens the given file name in read mode and returns an iterator function that, each time it is called, returns a new line from the file. Therefore, the construction

     for line in io.lines(filename) do body end
will iterate over all lines of the file. When the iterator function detects the end of file, it returns nil (to finish the loop) and automatically closes the file.

The call io.lines() (with no file name) is equivalent to io.input():lines(); that is, it iterates over the lines of the default input file. In this case it does not close the file when the loop ends.

io.open (filename [, mode])

This function opens a file, in the mode specified in the string mode. It returns a new file handle, or, in case of errors, nil plus an error message.

The mode string can be any of the following:

"r": read mode (the default);
"w": write mode;
"a": append mode;
"r+": update mode, all previous data is preserved;
"w+": update mode, all previous data is erased;
"a+": append update mode, previous data is preserved, writing is only allowed at the end of file.
The mode string may also have a 'b' at the end, which is needed in some systems to open the file in binary mode. This string is exactly what is used in the standard C function fopen.

io.output ([file])

Similar to io.input, but operates over the default output file.

io.popen (prog [, mode])

Starts program prog in a separated process and returns a file handle that you can use to read data from this program (if mode is "r", the default) or to write data to this program (if mode is "w").

This function is system dependent and is not available on all platforms.

io.read (···)

Equivalent to io.input():read.

io.tmpfile ()

Returns a handle for a temporary file. This file is opened in update mode and it is automatically removed when the program ends.

io.type (obj)

Checks whether obj is a valid file handle. Returns the string "file" if obj is an open file handle, "closed file" if obj is a closed file handle, or nil if obj is not a file handle.

io.write (···)

Equivalent to io.output():write.

file:close ()

Closes file. Note that files are automatically closed when their handles are garbage collected, but that takes an unpredictable amount of time to happen.

file:flush ()

Saves any written data to file.

file:lines ()

Returns an iterator function that, each time it is called, returns a new line from the file. Therefore, the construction

     for line in file:lines() do body end
will iterate over all lines of the file. (Unlike io.lines, this function does not close the file when the loop ends.)

file:read (···)

Reads the file file, according to the given formats, which specify what to read. For each format, the function returns a string (or a number) with the characters read, or nil if it cannot read data with the specified format. When called without formats, it uses a default format that reads the entire next line (see below).

The available formats are

"*n": reads a number; this is the only format that returns a number instead of a string.
"*a": reads the whole file, starting at the current position. On end of file, it returns the empty string.
"*l": reads the next line (skipping the end of line), returning nil on end of file. This is the default format.
number: reads a string with up to this number of characters, returning nil on end of file. If number is zero, it reads nothing and returns an empty string, or nil on end of file.
file:seek ([whence] [, offset])

Sets and gets the file position, measured from the beginning of the file, to the position given by offset plus a base specified by the string whence, as follows:

"set": base is position 0 (beginning of the file);
"cur": base is current position;
"end": base is end of file;
In case of success, function seek returns the final file position, measured in bytes from the beginning of the file. If this function fails, it returns nil, plus a string describing the error.

The default value for whence is "cur", and for offset is 0. Therefore, the call file:seek() returns the current file position, without changing it; the call file:seek("set") sets the position to the beginning of the file (and returns 0); and the call file:seek("end") sets the position to the end of the file, and returns its size.

file:setvbuf (mode [, size])

Sets the buffering mode for an output file. There are three available modes:

"no": no buffering; the result of any output operation appears immediately.
"full": full buffering; output operation is performed only when the buffer is full (or when you explicitly flush the file (see io.flush)).
"line": line buffering; output is buffered until a newline is output or there is any input from some special files (such as a terminal device).
For the last two cases, sizes specifies the size of the buffer, in bytes. The default is an appropriate size.

file:write (···)

Writes the value of each of its arguments to the file. The arguments must be strings or numbers. To write other values, use tostring or string.format before write.

5.8 - Operating System Facilities

This library is implemented through table os.

os.clock ()

Returns an approximation of the amount in seconds of CPU time used by the program.

os.date ([format [, time]])

Returns a string or a table containing date and time, formatted according to the given string format.

If the time argument is present, this is the time to be formatted (see the os.time function for a description of this value). Otherwise, date formats the current time.

If format starts with '!', then the date is formatted in Coordinated Universal Time. After this optional character, if format is the string "*t", then date returns a table with the following fields: year (four digits), month (1--12), day (1--31), hour (0--23), min (0--59), sec (0--61), wday (weekday, Sunday is 1), yday (day of the year), and isdst (daylight saving flag, a boolean).

If format is not "*t", then date returns the date as a string, formatted according to the same rules as the C function strftime.

When called without arguments, date returns a reasonable date and time representation that depends on the host system and on the current locale (that is, os.date() is equivalent to os.date("%c")).

os.difftime (t2, t1)

Returns the number of seconds from time t1 to time t2. In POSIX, Windows, and some other systems, this value is exactly t2-t1.

os.execute ([command])

This function is equivalent to the C function system. It passes command to be executed by an operating system shell. It returns a status code, which is system-dependent. If command is absent, then it returns nonzero if a shell is available and zero otherwise.

os.exit ([code])

Calls the C function exit, with an optional code, to terminate the host program. The default value for code is the success code.

os.getenv (varname)

Returns the value of the process environment variable varname, or nil if the variable is not defined.

os.remove (filename)

Deletes the file or directory with the given name. Directories must be empty to be removed. If this function fails, it returns nil, plus a string describing the error.

os.rename (oldname, newname)

Renames file or directory named oldname to newname. If this function fails, it returns nil, plus a string describing the error.

os.setlocale (locale [, category])

Sets the current locale of the program. locale is a string specifying a locale; category is an optional string describing which category to change: "all", "collate", "ctype", "monetary", "numeric", or "time"; the default category is "all". The function returns the name of the new locale, or nil if the request cannot be honored.

When called with nil as the first argument, this function only returns the name of the current locale for the given category.

os.time ([table])

Returns the current time when called without arguments, or a time representing the date and time specified by the given table. This table must have fields year, month, and day, and may have fields hour, min, sec, and isdst (for a description of these fields, see the os.date function).

The returned value is a number, whose meaning depends on your system. In POSIX, Windows, and some other systems, this number counts the number of seconds since some given start time (the "epoch"). In other systems, the meaning is not specified, and the number returned by time can be used only as an argument to date and difftime.

os.tmpname ()

Returns a string with a file name that can be used for a temporary file. The file must be explicitly opened before its use and explicitly removed when no longer needed.

5.9 - The Debug Library

This library provides the functionality of the debug interface to Lua programs. You should exert care when using this library. The functions provided here should be used exclusively for debugging and similar tasks, such as profiling. Please resist the temptation to use them as a usual programming tool: they can be very slow. Moreover, several of its functions violate some assumptions about Lua code (e.g., that variables local to a function cannot be accessed from outside or that userdata metatables cannot be changed by Lua code) and therefore can compromise otherwise secure code.

All functions in this library are provided inside the debug table. All functions that operate over a thread have an optional first argument which is the thread to operate over. The default is always the current thread.

debug.debug ()

Enters an interactive mode with the user, running each string that the user enters. Using simple commands and other debug facilities, the user can inspect global and local variables, change their values, evaluate expressions, and so on. A line containing only the word cont finishes this function, so that the caller continues its execution.

Note that commands for debug.debug are not lexically nested within any function, and so have no direct access to local variables.

debug.getfenv (o)

Returns the environment of object o.
debug.gethook ([thread])

Returns the current hook settings of the thread, as three values: the current hook function, the current hook mask, and the current hook count (as set by the debug.sethook function).

debug.getinfo ([thread,] function [, what])

Returns a table with information about a function. You can give the function directly, or you can give a number as the value of function, which means the function running at level function of the call stack of the given thread: level 0 is the current function (getinfo itself); level 1 is the function that called getinfo; and so on. If function is a number larger than the number of active functions, then getinfo returns nil.

The returned table may contain all the fields returned by lua_getinfo, with the string what describing which fields to fill in. The default for what is to get all information available, except the table of valid lines. If present, the option 'f' adds a field named func with the function itself. If present, the option 'L' adds a field named activelines with the table of valid lines.

For instance, the expression debug.getinfo(1,"n").name returns a name of the current function, if a reasonable name can be found, and the expression debug.getinfo(print) returns a table with all available information about the print function.

debug.getlocal ([thread,] level, local)

This function returns the name and the value of the local variable with index local of the function at level level of the stack. (The first parameter or local variable has index 1, and so on, until the last active local variable.) The function returns nil if there is no local variable with the given index, and raises an error when called with a level out of range. (You can call debug.getinfo to check whether the level is valid.)

Variable names starting with '(' (open parentheses) represent internal variables (loop control variables, temporaries, and C function locals).

debug.getmetatable (object)

Returns the metatable of the given object or nil if it does not have a metatable.

debug.getregistry ()

Returns the registry table (see §3.5).

debug.getupvalue (func, up)

This function returns the name and the value of the upvalue with index up of the function func. The function returns nil if there is no upvalue with the given index.

debug.setfenv (object, table)

Sets the environment of the given object to the given table. Returns object.

debug.sethook ([thread,] hook, mask [, count])

Sets the given function as a hook. The string mask and the number count describe when the hook will be called. The string mask may have the following characters, with the given meaning:

"c": The hook is called every time Lua calls a function;
"r": The hook is called every time Lua returns from a function;
"l": The hook is called every time Lua enters a new line of code.
With a count different from zero, the hook is called after every count instructions.

When called without arguments, debug.sethook turns off the hook.

When the hook is called, its first parameter is a string describing the event that has triggered its call: "call", "return" (or "tail return"), "line", and "count". For line events, the hook also gets the new line number as its second parameter. Inside a hook, you can call getinfo with level 2 to get more information about the running function (level 0 is the getinfo function, and level 1 is the hook function), unless the event is "tail return". In this case, Lua is only simulating the return, and a call to getinfo will return invalid data.

debug.setlocal ([thread,] level, local, value)

This function assigns the value value to the local variable with index local of the function at level level of the stack. The function returns nil if there is no local variable with the given index, and raises an error when called with a level out of range. (You can call getinfo to check whether the level is valid.) Otherwise, it returns the name of the local variable.

debug.setmetatable (object, table)

Sets the metatable for the given object to the given table (which can be nil).

debug.setupvalue (func, up, value)

This function assigns the value value to the upvalue with index up of the function func. The function returns nil if there is no upvalue with the given index. Otherwise, it returns the name of the upvalue.

debug.traceback ([thread,] [message] [, level])

Returns a string with a traceback of the call stack. An optional message string is appended at the beginning of the traceback. An optional level number tells at which level to start the traceback (default is 1, the function calling traceback).

6 - Lua Stand-alone

Although Lua has been designed as an extension language, to be embedded in a host C program, it is also frequently used as a stand-alone language. An interpreter for Lua as a stand-alone language, called simply lua, is provided with the standard distribution. The stand-alone interpreter includes all standard libraries, including the debug library. Its usage is:

     lua [options] [script [args]]
The options are:

-e stat: executes string stat;
-l mod: "requires" mod;
-i: enters interactive mode after running script;
-v: prints version information;
--: stops handling options;
-: executes stdin as a file and stops handling options.
After handling its options, lua runs the given script, passing to it the given args as string arguments. When called without arguments, lua behaves as lua -v -i when the standard input (stdin) is a terminal, and as lua - otherwise.

Before running any argument, the interpreter checks for an environment variable LUA_INIT. If its format is @filename, then lua executes the file. Otherwise, lua executes the string itself.

All options are handled in order, except -i. For instance, an invocation like

     $ lua -e'a=1' -e 'print(a)' script.lua
will first set a to 1, then print the value of a (which is '1'), and finally run the file script.lua with no arguments. (Here $ is the shell prompt. Your prompt may be different.)

Before starting to run the script, lua collects all arguments in the command line in a global table called arg. The script name is stored at index 0, the first argument after the script name goes to index 1, and so on. Any arguments before the script name (that is, the interpreter name plus the options) go to negative indices. For instance, in the call

     $ lua -la b.lua t1 t2
the interpreter first runs the file a.lua, then creates a table

     arg = { [-2] = "lua", [-1] = "-la",
             [0] = "b.lua",
             [1] = "t1", [2] = "t2" }
and finally runs the file b.lua. The script is called with arg[1], arg[2], ··· as arguments; it can also access these arguments with the vararg expression '...'.

In interactive mode, if you write an incomplete statement, the interpreter waits for its completion by issuing a different prompt.

If the global variable _PROMPT contains a string, then its value is used as the prompt. Similarly, if the global variable _PROMPT2 contains a string, its value is used as the secondary prompt (issued during incomplete statements). Therefore, both prompts can be changed directly on the command line. For instance,

     $ lua -e"_PROMPT='myprompt> '" -i
(the outer pair of quotes is for the shell, the inner pair is for Lua), or in any Lua programs by assigning to _PROMPT. Note the use of -i to enter interactive mode; otherwise, the program would just end silently right after the assignment to _PROMPT.

To allow the use of Lua as a script interpreter in Unix systems, the stand-alone interpreter skips the first line of a chunk if it starts with #. Therefore, Lua scripts can be made into executable programs by using chmod +x and the #! form, as in

     #!/usr/local/bin/lua
(Of course, the location of the Lua interpreter may be different in your machine. If lua is in your PATH, then

     #!/usr/bin/env lua
is a more portable solution.)

7 - Incompatibilities with the Previous Version

Here we list the incompatibilities that you may found when moving a program from Lua 5.0 to Lua 5.1. You can avoid most of the incompatibilities compiling Lua with appropriate options (see file luaconf.h). However, all these compatibility options will be removed in the next version of Lua.

7.1 - Changes in the Language

The vararg system changed from the pseudo-argument arg with a table with the extra arguments to the vararg expression. (See compile-time option LUA_COMPAT_VARARG in luaconf.h.)
There was a subtle change in the scope of the implicit variables of the for statement and for the repeat statement.
The long string/long comment syntax ([[string]]) does not allow nesting. You can use the new syntax ([=[string]=]) in these cases. (See compile-time option LUA_COMPAT_LSTR in luaconf.h.)
7.2 - Changes in the Libraries

Function string.gfind was renamed string.gmatch. (See compile-time option LUA_COMPAT_GFIND in luaconf.h.)
When string.gsub is called with a function as its third argument, whenever this function returns nil or false the replacement string is the whole match, instead of the empty string.
Function table.setn was deprecated. Function table.getn corresponds to the new length operator (#); use the operator instead of the function. (See compile-time option LUA_COMPAT_GETN in luaconf.h.)
Function loadlib was renamed package.loadlib. (See compile-time option LUA_COMPAT_LOADLIB in luaconf.h.)
Function math.mod was renamed math.fmod. (See compile-time option LUA_COMPAT_MOD in luaconf.h.)
Functions table.foreach and table.foreachi are deprecated. You can use a for loop with pairs or ipairs instead.
There were substantial changes in function require due to the new module system. However, the new behavior is mostly compatible with the old, but require gets the path from package.path instead of from LUA_PATH.
Function collectgarbage has different arguments. Function gcinfo is deprecated; use collectgarbage("count") instead.
7.3 - Changes in the API

The luaopen_* functions (to open libraries) cannot be called directly, like a regular C function. They must be called through Lua, like a Lua function.
Function lua_open was replaced by lua_newstate to allow the user to set a memory-allocation function. You can use luaL_newstate from the standard library to create a state with a standard allocation function (based on realloc).
Functions luaL_getn and luaL_setn (from the auxiliary library) are deprecated. Use lua_objlen instead of luaL_getn and nothing instead of luaL_setn.
Function luaL_openlib was replaced by luaL_register.
Function luaL_checkudata now throws an error when the given value is not a userdata of the expected type. (In Lua 5.0 it returned NULL.)
8 - The Complete Syntax of Lua

Here is the complete syntax of Lua in extended BNF. (It does not describe operator precedences.)


	chunk ::= {stat [`;´]} [laststat [`;´]]

	block ::= chunk

	stat ::=  varlist1 `=´ explist1 | 
		 functioncall | 
		 do block end | 
		 while exp do block end | 
		 repeat block until exp | 
		 if exp then block {elseif exp then block} [else block] end | 
		 for Name `=´ exp `,´ exp [`,´ exp] do block end | 
		 for namelist in explist1 do block end | 
		 function funcname funcbody | 
		 local function Name funcbody | 
		 local namelist [`=´ explist1] 

	laststat ::= return [explist1] | break

	funcname ::= Name {`.´ Name} [`:´ Name]

	varlist1 ::= var {`,´ var}

	var ::=  Name | prefixexp `[´ exp `]´ | prefixexp `.´ Name 

	namelist ::= Name {`,´ Name}

	explist1 ::= {exp `,´} exp

	exp ::=  nil | false | true | Number | String | `...´ | function | 
		 prefixexp | tableconstructor | exp binop exp | unop exp 

	prefixexp ::= var | functioncall | `(´ exp `)´

	functioncall ::=  prefixexp args | prefixexp `:´ Name args 

	args ::=  `(´ [explist1] `)´ | tableconstructor | String 

	function ::= function funcbody

	funcbody ::= `(´ [parlist1] `)´ block end

	parlist1 ::= namelist [`,´ `...´] | `...´

	tableconstructor ::= `{´ [fieldlist] `}´

	fieldlist ::= field {fieldsep field} [fieldsep]

	field ::= `[´ exp `]´ `=´ exp | Name `=´ exp | exp

	fieldsep ::= `,´ | `;´

	binop ::= `+´ | `-´ | `*´ | `/´ | `^´ | `%´ | `..´ | 
		 `<´ | `<=´ | `>´ | `>=´ | `==´ | `~=´ | 
		 and | or

	unop ::= `-´ | not | `#´

Last update: Tue Oct 3 21:27:28 BRT 2006 
译文最后更新：修改几处别字 2009年4月7日
========== http://stackoverflow.com/ ==========
========== http://ip.taobao.com/index.php ==========

登录
帮助
首页
IP查询/反馈
Rest API
IP统计
关于我们
最新新闻
常见问题
请输入要查询的IP：

 
查询
当前IP：113.233.13.199
关于淘宝IP地址库
我们目前提供的服务包括：
1. 根据用户提供的IP地址，快速查询出该IP地址所在的地理信息和地理相关的信息，包括国家、省、市和运营商。
2. 用户可以根据自己所在的位置和使用的IP地址更新我们的服务内容。
我们的优势：
1. 提供国家、省、市、县、运营商全方位信息，信息维度广，格式规范。
2. 提供完善的统计分析报表，省准确度超过99.8%，市准确度超过96.8%，数据质量有保障。
关于淘宝 合作伙伴 营销中心 服务中心 开放平台 诚征英才 联系我们 网站地图 版权说明
中国站 国际站 日文站| 淘宝网 天猫 一淘网| 支付宝 阿里云 中国雅虎 口碑网 阿里研究中心 阿里会展| 淘宝天下 快乐淘宝 淘花网
Copyright 2003-2012 Taobao.com 版权所有


========== http://www.akamai.cn/enzs/html/technology/dataviz1.html ==========
Failed!!
========== https://manage.host700.com/home.php ==========
VPS Control Panel
Virtual Private Server Management Made Easy...
Login
Username	
Password	

Forgot Password?
   
SolusVM © 2008-2012 Soluslabs Ltd. All Rights Reserved.


========== http://www.sayblog.me/wordpress-setting-up-after-installation.html ==========
========== https://www.dnspod.cn/Domain#all ==========
DNSPod登录
 


E-Mail
 
密码
 
 一个月内自动登录

还没有帐号？ 立即注册

» 忘记密码


© 2013 DNSPod, Inc. All rights reserved.
========== http://yuming.host700.com/ ==========
 您好! 登录/注册
0件商品购物车 结账
首页域名虚拟主机企业邮局SSL数字证书自助建站客户支持
注册域名
"快速注册只属于您的网络身份"
.asia
GO
免费的增值服务 - 每个域名都享有!
注册域名赠送2个域名邮箱批量管理工具DNS解析管理易于使用的管理后台whois隐私保护域名防盗保护域名转发无限邮件转发
最低价! ASIA
CNY 110.49
CNY 30.80
促销中RU
CNY 37.69
DE
CNY 59.79
ORG
CNY 79.29
CNY 40.70
促销中更多 »
域名
注册域名
查看域名价格
批量域名注册
批量域名转移
whois查询
域名建议工具
域名免费服务
查看促销
主机和产品
Linux主机
Windows主机
自助建站
邮局
SSL证书
基础架构
数据中心资料
主机安全
24 x 7 服务器监控
备份与恢复
客户支持
查看知识库
联系客服
举报
代理商
加入代理
选择语言 
Copyright © Host700. 版权所有
隐私政策 | 法律协议
========== https://www.google.com/analytics/web/?hl=zh-CN&pli=1#dashboard/default/a36670290w64933115p66678826/ ==========

========== http://who.is/whois/ ==========
========== http://0101.pro/test/chart/qpsArt.php ==========
PV & RT
PV
RT(s)
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
-10
0
10
20
30
40
50
60
Highcharts.com

========== https://orca.io/ ==========
========== http://www.host700.com/ ==========

========== https://twitter.com/ ==========
========== http://www.youtube.com/ ==========
========== http://www.facebook.com/ ==========
========== http://web.qq.com/ ==========
WebQQ
我们从未放弃成长 
WebQQ，比你想象更精彩...

SmartQQ

原 WebQQ
Copyright©2010 - 2013 Tencent. All Rights Reserved.
========== http://0101.pro/ ==========
plp_rapper The Cabin Of Pei Li Ping
跳至正文
首页
About Me
爬chrome的收藏夹网页
发表于 2013 年 10 月 3 日 由 peiliping
https://github.com/peiliping/nodejs/tree/master/phantomjs/favclaw

爬网页是通过phantomjs来实现的 singleclaw.js

shell进行整体的控制   main.sh

并提供一个search.sh 进行关键词和url的搜索

发表在 PhantomJs	 | 留下评论
Discuz论坛放垃圾注册的办法
发表于 2013 年 9 月 30 日 由 peiliping
之前搞了个discuz论坛玩玩，碰到大量的注册机，非常麻烦。

上网搜了很多办法(比如：修改注册页面的url路径、修改table的field的名字，邮箱注册等等)

尝试了一下 效果都不是非常理想。

不过看到某个blog给了我一个提示 ，就是discuz新用户只开放QQ登录和注册，这样依靠QQ的认证来过滤垃圾注册和发帖。

更改配置之后，看了一下效果非常理想，垃圾注册机都失败了。

 

发表在 Life	 | 留下评论
求职
发表于 2013 年 9 月 27 日 由 peiliping
离职已经有一段时间了，休息、放松、思考人生～～哈哈。

有一段时间不写代码了，有一些手痒了。

路过的朋友，如果你所在的公司需要小码农一枚，请gmail联系我，TKS。

个人简历请见 about me

发表在 Life	 | 2 条评论
awk getline的使用
发表于 2013 年 9 月 18 日 由 peiliping
getline 一直没机会用 做笔试题目碰到了

mark一下吧

 

https://github.com/peiliping/shell/blob/master/other/ltjx-test.sh

发表在 Linux	 | 一条评论
phantomjs引入jquery做处理
发表于 2013 年 9 月 1 日 由 peiliping
phantomjs可以用来做监控，做爬虫工具。

这里写一个简单的例子，利用phantomjs来提取v2ex的首页帖子标题。

https://github.com/peiliping/nodejs/blob/master/phantomjs/testjquery.js

代码非常简单。

发表在 PhantomJs	 | 留下评论
← 早期文章
  
链接表
v2ex论坛
VPS&域名服务
阿里外论坛
近期文章
爬chrome的收藏夹网页
Discuz论坛放垃圾注册的办法
求职
awk getline的使用
phantomjs引入jquery做处理
近期评论
peiliping 发表在《求职》
dagen 发表在《求职》
www.356688.com 发表在《awk getline的使用》
Nauru wycieczki 发表在《apache日志分割提取工具》
9527 发表在《About Me》
文章归档
2013 年十月
2013 年九月
2013 年八月
2013 年六月
2013 年五月
2013 年三月
2013 年二月
2013 年一月
2012 年十二月
2012 年十一月
2012 年十月
2012 年九月
2012 年八月
2012 年七月
2012 年六月
2012 年五月
2012 年四月
2012 年三月
2012 年二月
分类目录
Android
CSS
Hadoop
Hive
Idea
Java
JavaScript
Life
Linux
Mahout
MySQL
Net
PhantomJs
PHP
Service
性能优化
功能
登录
文章 RSS
评论 RSS
WordPress.org
plp_rapper 自豪地采用 WordPress。

========== https://github.com/peiliping ==========
Sign up Sign in
Explore
Features
Enterprise
Blog


Pei LiPing peiliping
TaoBao
peilipingplp@gmail.com
http://0101.pro
Joined on Jul 07, 2012
0
followers
 
1
starred
 
1
following
 Contributions   Repositories   Public Activity Follow
Popular repositories
shell 0 
java 0 
hivesql 0 
nodejs 0 
Public contributions
Oct
Nov
Dec
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
M
W
F
 Summary of Pull Requests, issues opened and commits. Learn more. Less      More
31 Total
Oct 04 2012 - Oct 04 2013
Year of Contributions
2 days
August 10 - August 11
Longest Streak
0 days
Rock - Hard Place
Current Streak
Contribution Activity Period: 1 Week
 3 Commits

Pushed 3 commits to peiliping/nodejs Oct 02 - Oct 04
Status API Training Shop Blog About © 2013 GitHub, Inc. Terms Privacy Security Contact
========== http://aliwai.net/forum.php ==========
设为首页收藏本站开启辅助访问切换到窄版

用户名
	自动登录	 找回密码
密码		登录	 立即注册

只需一步，快速开始
快捷导航
阿里外论坛
	
帖子
搜索	
热搜: 活动交友discuz
论坛宗旨(2013-7-12)
阿里外»阿里外论坛
今日: 0|昨日: 0|帖子: 87|会员: 31|欢迎新会员: plp-zhanning最新回复

阿里外
	
离职手续
离职过程中碰到的各种手续问题，比如户口迁移、养老保险、住房公积金等
16 / 20	
户口迁出手续找人代办
2013-8-25 15:14 admin
	
阿里爆料
1 / 1	
RSU行权价格再提高（22D） ...
2013-8-12 08:45 admin
	
放松心情
紧张的工作告一段落，先给自己放个假期吧。说说你去过的山水风光。
5 / 7	
温岭石塘
2013-7-28 08:21 admin
	
重新上路
想创业、想求职，说说你的想法。
7 / 14	
自由职业
2013-8-27 11:52 chuyi
	
互帮互助
相信这里的朋友值得你信任，会在你需要帮助的时候，伸出小手～
3 / 4	
Hi~大家好
2013-9-18 12:24 Lisa.cai
	
灌水专区
随便说说写写，发泄一下吧。
14 / 22	
郭德纲相声《扒马褂》
2013-8-10 21:37 admin
	
寻人启示
那些曾经的阿里同事，也许他（她）也在这里。
0 / 0	
从未
	
Music Show
15 / 16	
[pop]One For Da Money
2013-8-27 15:57 admin
	
论坛管理
3 / 3	
关于之前一段时间大量垃圾帐号问 ...
3 天前 admin

在线会员 - 5 人在线 - 0 会员(0 隐身), 5 位游客 - 最高记录是 133 于 2013-9-6.
 管理员        超级版主        版主        会员      
当前只有游客或隐身会员在线

官方论坛
提供最新 Discuz! 产品新闻、软件下载与技术交流
站长博客
GMT+8, 2013-10-4 19:01. This page is cached at 19:01:34 .
Powered by Discuz! X3
© 2001-2013 Comsenz Inc.

========== https://www.google.com.hk/ ==========
+你
搜索
图片
地图
Play
YouTube
新闻
Gmail
更多
登录

谷歌

 	


高级搜索
语言工具

Google.com.hk 使用下列语言： 中文（繁體） English

加入营销计划Google 大全Google.com
© 2013 - 隐私权和使用条款


========== http://0101.pro/test/taobao/s.php ==========


Í¬µê¹ºÂò
   
Ö»ËÑ¼¯ÊÐ
 
ËÑAµ«¹ýÂËµôB
  
========== http://www.meituan.com/deal/5514880.html ==========
手机美团猫眼电影美团，每天团购一次 登录 注册 我的美团  购物车0件 更多

沈阳
[切换城市]
团购商家

KTV火锅刘一锅烤肉蛋糕
全部分类
首页身边团购今日新单购物找商家品牌汇最近浏览
沈阳团购»酒店团购»经济型酒店»途179迷你酒店
【西四】途179迷你酒店
仅售148元！最高价值237元的途179迷你酒店一日房，房型4选1，享受生活。
¥ 148 门店价¥237 6.2折
抢购加入购物车
331 人已团购
剩余3天以上
 
支持随时退
 
支持过期退

QQ/MSN
新浪微博
腾讯微博
人人
豆瓣
QQ空间
分享到收藏本单
查看全部评价消费评分：4.4已有42人评价
商家位置
本单详情
商家介绍
消费评价(42)
 
亲爱的用户，本次团购有效期延长至2013年10月31日，其中不可用日期：2013年10月1日至10月6日，感谢您的支持，祝消费愉快~
商家位置
查看完整地图
本单详情
温馨入住
						
内容	单价	数量/规格	小计
以下房型4选1
大床房	237元	1间	237元
家庭房	237元	1间	237元
经济房	207元	1间	207元
双床房	227元	1间	227元
最高价值：237元
美团价：148元
床的规格：大床房和经济房床为1.5m×2m，1张床；家庭房和双床房床为1.1m×2m，2张床
其他设施：提供空调+24小时热水；使用酒店电话拨打内线免费、拨打外线收费；有无线网络需自备电脑；各房型有无窗户情况请咨询商家
客房入住时间为12:00至次日12:00，请您在次日12:00之前办理退房，超时将加收房费，18:00以前按原房费的半天收取，18:00以后收取原房费全天房费
本单不提供早餐
客人如需连续入住需提前告知前台，当天续住可能会没有房间
地铁四号线，西四站下车，A口出步行300米即到；公交13, 22, 38, 83, 88, 105, 204内夜, 204外夜, 409, 626, 690西四路口北下车
温馨提示：请不要携带宠物入住
购买须知
有效期：
2013.9.4 至 2013.10.31
不可用日期：
2013年10月1日至10月6日
使用时间：
全天24小时
预约提醒：
请至少提前24小时致电预约
使用规则：
凭美团券到店消费不可同时享受店内其他优惠
使用多张美团券可连续入住
每个房间家庭房最多3人，其余最多2人入住，1.2米（不含）以上儿童计入人数名额
入住时需交100元押金，并出示本人身份证（一人一证）
商家不提供加床服务
美团券密码一旦验证即代表消费成功，不可申请“随时退款”和“过期退款”，请您合理安排验证时间
途179迷你酒店
※以下为部分房间图，店内各房型略有差异，以商家实际安排为准。

列车将从北京出发，您下一站在哪里？途179，让梦旅行的地方！仅158元享最高原价257元【途179迷你酒店】西单店或西四店二店通用，商务大床/商务标间/普通房/家庭房入住一晚。以动车卧铺为原型，专门为背包客，旅行者准备的个性酒店，等您体验！（美团网摄影师：潘蕾）

消费评价我买过本单，我要评价
4.4分
已有42人评价
设施3.9分
服务4.3分
卫生4.2分
位置4.8分
5分24人
4分14人
3分2人
2分1人
1分1人
全部评价 有内容的评价默认按时间
¥148加入购物车抢购
门店价
¥237折扣
6.2折已购买
331人
热门专题


美团答疑

本单答疑 | 我要提问
有您的建议，美团才能更好»
您对美团的印象如何?请告诉美团，让美团更好的为您服务！
立即参与用户调查»
用户帮助

常见问题
往期沈阳团购
开放API
美团开放服务
邮箱白名单设置
反诈骗公告
获取更新

邮件订阅
iPhone/Android
美团QQ空间
美团新浪微博
美团腾讯微博
RSS订阅
商务合作

提供团购信息
美团商家营销平台
保证金缴纳说明
市场合作
美团联盟
廉正邮箱
moc.nautiem@gnehznail
公司信息

关于美团
美团承诺
媒体报道
加入我们
法律声明
用户协议
营业执照
客服电话(免长途费)
400-660-5335
周一到周日 9:00 - 22:00
©2013美团网团购 meituan.com 京ICP证070791号 京公网安备110105002099号 电子公告服务规则
备案信息
 
支付宝特约商家
 
财付通诚信商家
 
可信网站

========== http://www.neitui.me/ ==========
========== http://www.v2ex.com/ ==========
	
	首页   注册   登入
V2EX = way to explore
V2EX 是一个关于分享和探索的地方
现在注册
已注册用户请 登入

 
本日热议主题
		 想搭个独立博客，大家能帮我把关一下主机么？
		 吐槽：学校干嘛非得强制学Java
		 儿子还几天就出生了，求取名！
		 360多少还是有点用的
		 OSX Mavericks 10.9 GM版放出下载了
		 弱弱的发现，桌子上都是 iPhone
		 腾讯的《斗战神》有点意思
		 会写 Python 这个单词就觉得自己比 同学/老师 高级？优越感不是这么秀的
		 5个弱智 javascript 问题限时挑战 You can't JavaScript under pressure
		 我Godaddy帐号被黑，邮箱被改，谁拥有经验协助恢复，300元感谢！紧急
最热节点
问与答分享发现二手交易程序员酷工作Mac OS X水V2EX分享创造自言自语iPhonePython分享邀请码iDevProject Babel随想天黑以后AndroidMacBook ProLinux
  RSS
最近新增节点
WalnutRowland HeightsDiamond BarDogma淘宝纪录片SAPSalt StackDynPowerDNSIEZooKeeperBootstrapHyperloopDockerMapRiTransferBTSyncOculus VRBash
社区运行状况
注册会员	46337
主题	82913
回复	783782
› 财富排行榜
› 消费排行榜
技术创意好玩Apple酷工作交易城市问与答最热全部
程序员     Python     iDev     Linux     node.js     云计算
		分享个markdown的vim插件： vim-instant-markdown
Markdown  •  SevenJ  •  4 分钟前  •  最后回复来自 qq529633582	4
		(English) Google Cloud Developer Challenge
程序员  •  raincious  •  38 分钟前	
		5个弱智 javascript 问题限时挑战 You can't JavaScript under pressure
JavaScript  •  est  •  40 分钟前  •  最后回复来自 binux	15
		会写 Python 这个单词就觉得自己比 同学/老师 高级？优越感不是这么秀的
程序员  •  qiayue  •  45 分钟前  •  最后回复来自 TankyWoo	16
		吐槽：学校干嘛非得强制学Java
程序员  •  slimbloody  •  2 小时 0 分钟前  •  最后回复来自 sethverlo	59
		git 有没办法通过编程获取服务器上的 push 信息，用来做提醒。
程序员  •  justfly  •  2 小时 44 分钟前  •  最后回复来自 mengzhuo	11
		求问：如何将 iPod Touch 4G 改成一个电脑？
程序员  •  Hualin  •  7 小时 22 分钟前  •  最后回复来自 bleaker	15
		如何判断一份实习是否靠谱！或者怎么找到一份靠谱的实习！
程序员  •  iMouseWu  •  14 小时 31 分钟前  •  最后回复来自 nzomkxia	4
		推荐个 iOS 开发的每周精选
iDev  •  Mattsive  •  18 小时 48 分钟前  •  最后回复来自 6b79	8
		试了一把pycharm CE版
Python  •  rocxto  •  19 小时 3 分钟前  •  最后回复来自 cchange	5
		一个字符串 转化成 只带 连字符- , 字母 和 数字 的函数写法讨论
PHP  •  yeshang  •  20 小时 24 分钟前  •  最后回复来自 yangqi	2
		Linode VPS 购入计划 用途你懂的 求小伙伴补刀
shadowsocks  •  kawaiiushio  •  22 小时 18 分钟前  •  最后回复来自 Quaintjade	16
		Notepad++ 6.4.5
程序员  •  tanny  •  1 天前  •  最后回复来自 gdx50b7	20
		如何用 jQuery 触发 SVG animation 呢？
jQuery  •  P233  •  1 天前	
		网站分析的应用和价值
程序员  •  aleeke  •  1 天前  •  最后回复来自 lhx2008	1
		VPSWO 基于 Linode 合租 Blog Only 招人
Linode  •  Suming  •  1 天前  •  最后回复来自 vking	29
		你觉得你每天 coding 过程中最大的干扰是？
程序员  •  Livid  •  1 天前  •  最后回复来自 vivianalive	71
		javascript event 机制是不是有类似daemon进程支持？
程序员  •  barb  •  1 天前  •  最后回复来自 barb	2
		求java or android profiler tools 推荐
程序员  •  windylcx  •  1 天前  •  最后回复来自 crazybubble	1
		关于美国政府关门，理解有难度，有同学能详细地讲讲么？
程序员  •  Pascal  •  1 天前  •  最后回复来自 xiaolee	34
		“Eloquent JavaScript” 第二版出版需要你的帮助！
JavaScript  •  johnj  •  1 天前  •  最后回复来自 johnj	2
		我和一个朋友正在设计一款符合iOS7UI的报刊应用，各位程序员大大有人愿意投稿吗？
程序员  •  ethanzzz  •  1 天前  •  最后回复来自 mongodb	1
		linode想合租，有四个名额，想合租的速报名
Linode  •  Sherlockhlt  •  1 天前  •  最后回复来自 hzlzh	18
		谈谈你对 bootstrap3 看法？
程序员  •  darasion  •  1 天前  •  最后回复来自 Norma	19
		有没有什么公海、南极的虚拟主机，或者朝鲜也行？
VPS  •  520671  •  1 天前  •  最后回复来自 SharkIng	13
		想问一下各位，你们公司的线上Linux服务器都是无GUI环境的吗？
Linux  •  qingfeng  •  2 天前  •  最后回复来自 anheitongyi	66
		django-taggit怎么列出某篇文章的tag
Django  •  click  •  2 天前  •  最后回复来自 wangchen	8
		推荐《禅与摩托车维修艺术》
程序员  •  hustlzp  •  2 天前  •  最后回复来自 hustlzp	13
		用树莓派实现网络批量自动安装CentOS
Linux  •  ety001  •  2 天前  •  最后回复来自 garipan	7
		用DNSPOD遇到一个问题，A记录被改变到之前的记录。但查看后台，A记录没变
DNS  •  andyliu  •  2 天前  •  最后回复来自 SharkIng	4
		糟糕的網絡，安個軟件，還得出動VPN...
程序员  •  tanny  •  2 天前  •  最后回复来自 DreaMQ	1
		PyQt 里如何做到隐藏组件，但是位置留着？
Python  •  davepkxxx  •  2 天前  •  最后回复来自 PrideChung	4
		有没有做digitalocean代购的朋友?
VPS  •  echoHUST  •  2 天前  •  最后回复来自 orvice	20
		抓取全国的特价机票信息，有几种方法？
数据库  •  NFSwind  •  2 天前  •  最后回复来自 chendeshen	9
		当时我就震惊了……
DevOps  •  rrfeng  •  2 天前  •  最后回复来自 rrfeng	26
		shadowsocks-android 在 android 4.3 上无法正常工作
shadowsocks  •  yzhrain  •  3 天前  •  最后回复来自 bleaker	9
		新手求指导：关于本地端口
shadowsocks  •  kennedy32  •  3 天前  •  最后回复来自 jasontse	6
		有没有 npm 离线安装解决方案？
node.js  •  darasion  •  3 天前  •  最后回复来自 mantianyu	4
		web前端众多的框架是不是把我们变傻了！你如何看待他们？
程序员  •  kaifazhe  •  3 天前  •  最后回复来自 ximan	32
		Wayland 能用了吗？
Linux  •  tioover  •  3 天前  •  最后回复来自 farseerfc	5
  通过 Atom Feed 订阅→ 更多新主题
浏览全部节点V2EX / 节点导航
分享与探索	问与答    分享发现    分享创造    自言自语    分享邀请码    随想    奇思妙想    设计    Blog    Paper   
V2EX	V2EX    Project Babel    Google App Engine    DNS    反馈    Project Picky    使用指南    OLIVIDA   
iOS	iDev    iMarketing    iAd    iCode    iTransfer   
Geek	程序员    Python    Android    Linux    云计算    Bitcoin    PHP    服务器    硬件    设计师    Linode    Kindle    外包    MySQL    Tornado    宽带症候群    Ruby on Rails    字体排印    编程    Markdown    Java    MongoDB    Redis    Ruby    汽车    商业模式    Photoshop    LEGO    数学    SONY   
游戏	游戏    iGame    Battlefield 3    StarCraft 2    英雄联盟    PlayStation 3    Steam    World of Warcraft    EVE    Xbox 360    Wii    Gran Turismo   
Apple	Mac OS X    iPhone    MacBook Pro    iPad    MacBook Air    配件    iMac    iPod    Mac mini    MacBook    MobileMe    iWork    Mac Pro    iLife    GarageBand   
生活	二手交易    酷工作    天黑以后    音乐    电影    阅读    摄影    物物交换    剧集    美酒与美食    旅行    投资    乐活    信用卡    Baby    宠物    绿茵场    团购分享    骑行    咖啡    植物    蘑菇    日记    非诚勿扰    唐茶    行程控   
Internet	Google    Twitter    Facebook    Path    Wikipedia    reddit    foursquare   
城市	北京    上海    深圳    广州    杭州    成都    昆明    武汉    New York    天津    Los Angeles    San Francisco   
品牌	UNIQLO    Lamy    宜家    无印良品    Gap    Moleskine    G-Star    Nike    Adidas   

关于   ·   FAQ   ·   我们的愿景   ·   广告投放   ·   工作空间   ·   IP 查询   ·   博客   ·   上网首页   ·   216 人在线   最高记录 552
创意工作者们的社区
Lovingly made by OLIVIDA
VERSION: 3.0.0-dev · 210ms · UTC 11:16 · PVG 19:16 · LAX 04:16
♥ Do have faith in what you're doing.

========== http://douban.fm/ ==========
登录  马上注册  开启
豆瓣FM
我的私人兆赫
我的红心兆赫
试试这些

华语 MHz
欧美 MHz
新歌 MHz
民谣 MHz
小清新 MHz
品牌兆赫

MIIX 混得出色 MHz
新BMW 316i MHz
© 2013 douban 京ICP备11027288号 网络视听许可证0110418号 京公网安备110105012274 广告合作: adfm@douban.com | FM游乐场 | FM用户手册 |  豆瓣FM中心
分享这首歌  
全部兆赫
 

123456
华语MHz

每天发现一首好听的歌

热门歌曲：怎样 / 我的歌声里 / 如果来生还能遇见你
8407首歌曲 兆赫详情
欧美MHz

关于欧美流行音乐的一切，就在这里了

热门歌曲：The Show / Someone Like You / Free Loop
9224首歌曲 兆赫详情
新歌MHz

让你的耳朵吸收新鲜正能量

热门歌曲：致青春 / 我好想你 / 其实都没有
9522首歌曲 兆赫详情
民谣MHz

James Blunt、Bob Dylan 以及 Taylor Swift

热门歌曲：Valder Fields / New Soul / Gotta Have You
8827首歌曲 兆赫详情
小清新MHz

这里没有喧哗与吵闹，静下心来感受世界的美好

热门歌曲：我是不是还不够好 / 99滴眼泪 / 古德奈先生
2442首歌曲 兆赫详情
奥迪A1—嗨, partyMHz

热门歌曲：Payphone / Run (feat. RedFoo of LMFAO) / One 2.3 Four
100首歌曲 兆赫详情
摇滚古典爵士民谣/乡村流行电子原声配乐轻音乐说唱雷鬼拉丁世界音乐布鲁斯放克/灵歌/R&B
热门兆赫

上升最快

品牌兆赫

+ 申请制作兆赫
========== http://mp3cut.net/cn/ ==========
========== http://ele.me/place/-615746940927592074 ==========



手机客户端

我的饿单
礼品中心
反馈留言
登录 / 注册
创业大厦(文三路) [切换地址]
我的收藏 设置
推荐餐厅 营业中 抵价券
口味
全部
起送价

38分钟
第1佳鸡排（华..
中式 68点评	

  
罐中罐
休息中 太忙暂不接受新订单	

  
小D商务套餐
休息中 太忙暂不接受新订单	

26分钟
蓝白便当
休息中 太忙暂不接受新订单	

  
徐记外卖
休息中 太忙暂不接受新订单

  
家利饭店
休息中 太忙暂不接受新订单	

32分钟
众犇小炒(玉泉)
中式 71点评	

38分钟
家乐送
中式 428点评 	

  
雨村便当
休息中 太忙暂不接受新订单	

34分钟
味捷外卖
中式 598点评 

  
米宝宝便当
休息中 太忙暂不接受新订单	

  
东北私房蒸饺(..
休息中 太忙暂不接受新订单	

45+分钟
丰谷又一村
休息中 餐厅已休假	

33分钟
小d快餐
中式 265点评	

45+分钟
老饭桶外卖
中式 94点评

更多餐厅

  
宏瑞蠔干粥（..
休息中 餐厅已休假	

  
天下第一粉（..
休息中 太忙暂不接受新订单	

38分钟
吕妈妈骨头饭
中式 75点评	

  
老鸭粉丝馆
休息中 太忙暂不接受新订单	

45+分钟
大城小厨
中式 135点评 

  
（那家外卖）-..
休息中 餐厅已休假	

25分钟
迪克 - 汉堡（..
汉堡 72点评	

  
嵊州特色小吃
休息中 太忙暂不接受新订单	

  
粤之林
休息中 已打烊	

45+分钟
晓麒
奶茶 15点评

  
翠香怡餐厅
休息中 太忙暂不接受新订单	

  
珍食惠
休息中 太忙暂不接受新订单	

  
鲜目录外带寿司
休息中 太忙暂不接受新订单	

  
君再来
休息中 太忙暂不接受新订单	

  
茶桔便
休息中 太忙暂不接受新订单

  
瓦缸营养快餐
休息中 太忙暂不接受新订单	

  
好的餐馆(玉泉)
休息中 太忙暂不接受新订单	

  
山西面食
休息中 太忙暂不接受新订单	

  
福建美食(玉泉)
休息中 太忙暂不接受新订单	

  
沙县小吃
休息中 餐厅已休假

40分钟
食立方
休息中 太忙暂不接受新订单	

  
上品快餐
休息中 太忙暂不接受新订单	

  
哈尔滨特色菜
休息中 太忙暂不接受新订单	

  
王新建面馆
休息中 餐厅已休假	

  
家乐厨房
休息中 太忙暂不接受新订单

  
以马内利饭店
休息中 餐厅已休假	

  
辣的叫湘菜馆
中式	

  
衢龙小炒
休息中 太忙暂不接受新订单	

  
林记农家菜
休息中 太忙暂不接受新订单	

  
程鹏香辣馆
休息中 太忙暂不接受新订单

  
农夫小灶
休息中 太忙暂不接受新订单	

45+分钟
无饿不坐餐厅
46点评	

30分钟
八哥酸辣粉
中式 31点评	

35分钟
禾寿司-超级奶..
日式 20点评	

  
传家美膳
休息中 太忙暂不接受新订单

45+分钟
N多寿司（宋江..
休息中 太忙暂不接受新订单	

33分钟
蚁窝简餐
中式 36点评	

17分钟
美食人佳
中式 31点评	

30分钟
阿宝比萨玉泉店
中式, 西式 135点评	

  
美味寿司屋
韩式 9点评 
我要开店 联系我们 服务条款和协议 站点地图 加入我们
Copyright ©2008-2013 ele.me, All Rights Reserved.

沪ICP备
09007032 上海工商
行政管理


========== http://yyets.com/ ==========

用户名
 密码： 记住我       找回密码  注册新帐号  RSS订阅 《仙门》修仙网络游戏!
人人影视

热门搜索:吸血鬼日记 生活大爆炸 环太平洋 独行侠 绝命毒师 性爱大师
 
全部
首页我的收藏资讯影视列表今日更新字幕下载电影美女直播追新番动画观看美剧时间表加入我们内部区论坛

24小时热门榜
电影1独行侠
美剧2生活大爆炸
美剧3吸血鬼日记
电影4巨乳排球
电影5环太平洋
美剧6绿箭
美剧7神盾局特工
韩剧8主君的太阳
《将神3D》
今日新服开启，超炫目的3D特效网页游戏！
《天台爱情》
童年偶像周杰伦，最新高分电影！
《犯罪心理》第九季强势回归
世上有两件事是我们无法做好准备的
IT狂人
3年等待终得善终 今日之后再无狂人

人人影视推荐精品网页游戏，欢迎休闲游玩！

【小语种翻译招募】人人影视长期招募小语种翻译
【美剧翻译招募】长期招募美剧/英剧/纪录片/动画翻译同好
【公告】 人人影视各地域粉丝交流群公布
【长期招募】 招募rmvb,HR-HDTV,美剧，电影，日剧，韩剧压制成员
需要居住在欧美的同学录制CC字幕
可获得内部资源下载和补贴...
欢迎字幕组到本站发布资源
提供大带宽压片服务器支持...
百度影音在线点播
人人影视最新完成品在线看...
日剧翻译组长期招募
想加日剧组的赶快报名...

最新发布 (查看更多)

不沉的太阳
电影(日本)
剧情

斯万的爱情
电影(法国)
剧情

困在爱中
电影(美国)
剧情/喜剧

家园防线
电影(美国)
动作/惊悚

稻草之盾
电影(日本)
惊悚

段田凛～劳动基准监督官
日剧(日本)
剧情
最新资讯

《行尸走肉》第四季第一集剧照发布
《行尸走肉》（The Walking Dead）第四季首批剧照发布...
查看全文
《实习医生格蕾》第200集剧照华丽首发：舞会即将开始
除了救死扶伤，《实习医生格蕾》（Grey's Anatomy）显然也知道何...
Fox续订《断头谷》第二季
现在《断头谷》（Sleepy Hollow）该给男主角伊卡博德（Ichab...
《绝命毒师》男星工作不断，即将加盟《错位青春》
曾在《绝命毒师》（Breaking Bad）中饰演毒师之子弗林（Flynn）...
《吸血鬼日记》芭比专访
《吸血鬼日记》（The Vampire Diaries）的主角们要上大学啦。 ...
“督爷”评价自己票房哑火之作《冥界警局》
环球影业（Universal）于今年7月上映的大作《冥界警局》（R.I.P.D）...
近期全球影院热门影片
美国
《独行侠》
美国
《金刚狼2》
美国
《乔布斯传》
美国
《蓝精灵2》

8.5
类型：动作/冒险/西部
制作：Walt Disney Studios Motion Pictures
导演：戈尔·维宾斯基
编剧：特里·鲁西奥/泰德·埃里奥特/贾斯汀·海瑟
上映：2013-10-05(美国)
演员：詹姆斯·弗莱恩/汤姆·威尔金森/巴里·佩珀/威廉·菲德内尔/艾米·汉莫
《游侠传奇》最早是一出电台节目，诞生于30年代，之后被改编成电影、电视、漫画、小说等多种形式。《游侠传奇》的主人公是一名戴着面具的游侠（类似于佐罗），他原本是德州骑警，在追捕一伙不法之徒时险些送命，在印第安人Tonto（约翰尼·德普）的治疗和照顾下逐渐康复，并从此戴上面具、骑着白马和Tonto一...
立即购买此片电影票
-

最新更新更多>>

6分钟前【美剧】《福尔摩斯：演绎法》[悬疑/罪案] 8.2
[MP4]福尔摩斯：演绎法.Elementary.S02E02.中英字幕.HDTV.624x352.mp4(200.09MB)

10分钟前【电影】《家园防线》[动作/惊悚] 9.9
[预告片]家园防线.Homefront.Chi_Eng.720P-YYeTs人人影视预告片组.mkv

12分钟前【韩剧】《主君的太阳》[喜剧/恐怖] 9.2
[MP4][中韩双语][主君的太阳][E17.End.131003][HDTV-MP4][YYeTs_韩剧精灵].mp4(302.82MB)

1个小时前【美剧】《父亲的疯狂世界》[喜剧/生活] 9.0
[MP4]父亲的疯狂世界.Sean.Saves.the.World.S01E01.中英字幕.HDTVrip.720X400-YYeTs人人影视.mp4(122.66MB)

1个小时前【电影】《不沉的太阳》[剧情] 9.0
[720P]不沉的太阳.The.Unbroken.2009.720p.BluRay.x264-WiKi.mkv(9.99GB)

1个小时前【美剧】《疯狂广告人》[喜剧] 9.1
[HR-HDTV]疯狂广告人.The.Crazy.Ones.S01E02.中英字幕.HDTVrip.1024X576-YYeTs人人影视.mkv(231.64MB)
精彩评论

神都龙王，和龙有个毛线关系…
如果上一集我给打6分的话，这一集撑死最多5分。... ---- AX
犯罪心理第九季第1集——开篇 （BY 威廉思思 原创）
5哥 评 《犯罪心理》

大头仔仔 评 剧集 《巨乳排球》 7.3
那句“这是大家的奶子”真是把我笑喷了。友情提示，整个电影没有任何走光镜头哦。别跳着找了。

GTL225 评 剧集 《独行侠》 8.5
尼玛这个明天就上映了，你们现在放出来是作死的节奏吗？要考虑很多人已经买了首映票打算推荐与朋友一起去看的，现在好了，国庆长假都宅在家了。

七球成名 评 剧集 《巨乳排球》 7.3
是AV我就下了！

ricky5911 评 剧集 《独行侠》 8.5
哈哈，省掉电影票钱了，谢谢人人！！！

aaronnie 评 剧集 《始祖家族》 9.0
吸血鬼日记两个帅哥也比不上始祖的一个帅哥

jarry2009 评 剧集 《巨乳排球》 7.3
SDMS-949 岛国已经为大家考虑了，怎么可能没有同类型的片子呢？

szgg 评 剧集 《始祖家族》 9.0
傻吊剧也有9分评价

MikeNaNa 评 剧集 《主君的太阳》 9.2
真不知道说女主丑的是什么心态？嫌人家丑可以不看啊。其他女的是美，整出来的有意思吗？还不是假的。

vikyz 评 剧集 《独行侠》 8.5
德普票房惨败之片，德普自打演了加勒比海盗后，就再没演过正常人，一部比一部欠抽，现在看他的扮相都有作呕的感觉

wangfei207 评 剧集 《巨乳排球》 7.3
让你们别多想，你们就是不听，你们什么时候才能毕业啊？

灰灰是菇凉 评 剧集 《父亲的疯狂世界》 9.0
国庆比较缺人，双语听译中，莫急莫急，明天发布。

阿好 评 剧集 《疑犯追踪》 9.7
这剧好多有趣的角色，真心想念啊。——里昂、皮尔斯、老师……

owen8849 评 剧集 《美国之声》 9.5
episode 4怎么还没出啊，等了一晚上了

陈阿条 评 剧集 《独行侠》 8.5
说明：应版权方要求，本站不提供下载，只提供字幕文件 太好了 字幕呢？

kiswell 评 剧集 《极速前进》 9.5
hr严重的音画不同步

大头仔仔 评 剧集 《巨乳排球》 7.3
那句“这是大家的奶子”真是把我笑喷了。友情提示，整个电影没有任何走光镜头哦。别跳着找了。

GTL225 评 剧集 《独行侠》 8.5
尼玛这个明天就上映了，你们现在放出来是作死的节奏吗？要考虑很多人已经买了首映票打算推荐与朋友一起去看的，现在好了，国庆长假都宅在家了。

七球成名 评 剧集 《巨乳排球》 7.3
是AV我就下了！

ricky5911 评 剧集 《独行侠》 8.5
哈哈，省掉电影票钱了，谢谢人人！！！

aaronnie 评 剧集 《始祖家族》 9.0
吸血鬼日记两个帅哥也比不上始祖的一个帅哥

jarry2009 评 剧集 《巨乳排球》 7.3
SDMS-949 岛国已经为大家考虑了，怎么可能没有同类型的片子呢？

szgg 评 剧集 《始祖家族》 9.0
傻吊剧也有9分评价

MikeNaNa 评 剧集 《主君的太阳》 9.2
真不知道说女主丑的是什么心态？嫌人家丑可以不看啊。其他女的是美，整出来的有意思吗？还不是假的。

vikyz 评 剧集 《独行侠》 8.5
德普票房惨败之片，德普自打演了加勒比海盗后，就再没演过正常人，一部比一部欠抽，现在看他的扮相都有作呕的感觉

wangfei207 评 剧集 《巨乳排球》 7.3
让你们别多想，你们就是不听，你们什么时候才能毕业啊？

灰灰是菇凉 评 剧集 《父亲的疯狂世界》 9.0
国庆比较缺人，双语听译中，莫急莫急，明天发布。

阿好 评 剧集 《疑犯追踪》 9.7
这剧好多有趣的角色，真心想念啊。——里昂、皮尔斯、老师……

owen8849 评 剧集 《美国之声》 9.5
episode 4怎么还没出啊，等了一晚上了

陈阿条 评 剧集 《独行侠》 8.5
说明：应版权方要求，本站不提供下载，只提供字幕文件 太好了 字幕呢？

kiswell 评 剧集 《极速前进》 9.5
hr严重的音画不同步
北京影友交流区
北京地区影友交流论坛
上海影友交流区
上海地区影友交流论坛
广东影友交流区
广东地区影友交流论坛
江浙影友交流区
江苏、浙江地区影友交流论坛
海外影友交流区
欢迎海外影友一起交流讨论


飞享世界
获取最新资源软件


时间机器
字幕调整制作工具


外挂字幕字体
必备特效字体包


百度影音
全能播放器可点播本站影视


小红伞
德国免费杀毒软件


火狐浏览器
安全稳定的浏览器


旋风
极速下载,简单高速
合作伙伴
行知学园
在日华人升学辅导
芥末网
留学在线免费申请
前程日本
专注日本名校申请
每天美剧
高清影视剧磁力下载
宇宙点播网
免费影视在线观看站
Infinity无尽字幕组
最全德语双语影视
优酷人人影视专区
优酷正版在线观看
资源导航站
资源下载站大合集
丫丫下载站
影视资源下载站
宇宙影视网
影视下载站
迪幻字幕组
青少年题材美剧
最新电影
高清电影电视剧在线
百度影音点播
本站最新资源点播
OABT下载站
最新影视资源下载站
硕鼠FLVCD
下载视频站的视频工具
伦敦之心字幕组
日本综艺节目翻译
YYeTs新浪微博
人人影视官方微博
张晓雨博客
中国知名实力派漫画家
团IDC网
站长团购网
3E帝国
网盘资源下载站
追新番日剧站
人人影视日剧独立站
天涯小筑
美剧资讯站
光影资源联盟
光影资源联盟
非常恐怖影视
中国知名恐怖电影交流站
深影论坛
深影字幕组官方网站
幻浪网页游戏
精品网页游戏平台
在线漫画
最全的在线漫画网站
AllForBC-字幕组
AllForBC-字幕组微博
印坛字幕组
印度电影权威论坛
点游资讯
游戏资讯
百度绿箭侠吧
百度绿箭侠吧
摔角在线
全国最大的摔角网站
火影忍者漫画
火影忍者漫画
极影动漫BT
极影动漫BT
强皓运动联盟
淘宝运动专卖网店
洪翔高清店
硬盘与高清设备专卖
时尚男装专营
时尚男装专营淘宝店
极品动漫论坛
JBA字幕组
Jake吧字幕组
Jake吧字幕组网站
最新玄幻小说
最新玄幻小说下载
在线动画
最全的在线动画网站

 
本站所有资源信息均从互联网搜索而来，本站不对显示的内容承担责任
如您认为本站页面信息侵犯了您的权益，请附上版权证明邮件告知，在收到邮件后24小时内删除 我们的邮箱: YYeTs.net@gmail.com . 站长统计
本站服务器由 3A网络 提供
意见反馈 正版翻译洽谈 合作洽谈 加入人人影视 字幕组入驻 了解人人影视 客户端 手机版


========== http://www.text2mindmap.com/ ==========
========== http://weibo.com/2713424117/profile?topnav=1&wvr=3.6 ==========

请输入密码
忘记密码下次自动登录
登录
还没有微博？立即注册！
还没有新浪微博帐号？现在加入	 立即注册

iPhone/iPad Android Windows Phone 其他手机端
微博帮助| 意见反馈| 微博认证及合作| 开放平台| 微博招聘| 新浪网导航|  
Copyright © 1996-2013 SINA 北京微梦创科网络技术有限公司京网文[2011]0398-130号京ICP证号全国人大常委会关于加强网络信息保护的决定
========== http://www.shupeng.com/ ==========
m.shupeng.com上线啦！即刻用手机登录就送现金！收藏
新浪微博 腾讯微博

搜书键入书名、作者名开始搜索
横行天下逆印红色长筒袜天路逆天尘劫钻石女人极品男
首页
榜单家族
网络小说
精选书单





12345
书荒补给站：4-6月出版新书(39)书荒补给站：4-6月完结言情(101)香江四才子PK吴门四才子(42)凯撒沙拉(16)天降宝宝：我的漂亮小妈咪(22)书荒补给站：1-3月完结言情(77)
1234
大家都在看

拆掉思维里的墙（人生开窍手册：原来我还可以这样活）

正能量（坚持正向能量，人生无所畏惧！）

凶宅笔记（年度最火爆悬疑小说！南派三叔激赏推荐！）

木槿花西月锦绣（必读！曾经红透半边天的言情小说）

复贵盈门（重生回十三岁，她要改变她的命运）

傲风（女主腹黑强大，冷酷狂妄，男装行天下）

晨昏（一句话，像是一个魔咒，注定了三个人的宿命。）

盛夏晚晴天（热播都市商战悬爱剧原著小说）

致我们终将逝去的青春（2013年赵薇导演处女作原著小说）

跨过千年来爱你（超人气言情巨著，总点击超过2亿！）

君子之交（台湾网络大神级作家蓝淋最具影响力的作品）

原来你还在这里（爱让我们如履薄冰）

因为痛，所以叫青春（改变亚洲千万年轻人的疗愈经典）

白发皇妃（三千发丝白如雪，回眸一顾，倾断万人肠）

门第（婚恋话题情感剧《门第》原著，挑战门当户对铁则）

如愿（我们终究如愿以偿，但彼此都不是当初约好的模样）

谁的青春不迷茫（奋斗小青年刘同的十年逆袭人生）

养瘦（我不是天生的瘦子！蔡依林回首“减肥血泪史”）

我站在桥上看风景（重磅作家顾西爵温暖治愈系大作）

欢快斗地主（一个穿越女与众极品和恶地主斗智斗勇的故事）
新书入库


《读懂厚黑学的第一本书》

《时间心理学》2011年英国最佳科普图书

S.J.沃森 《别相信任何人》

《人性禁岛》

张小娴《永不永不说再见》
畅销书排行

当当图书
亚马逊图书
京东图书
百度小说
1
偷影子的人
马克·李维
《偷影子的人》内容简介：不知道姓氏的克蕾儿。这就是你...
2
新概念英语（2）
何其莘,亚历山大
本书分为4个单元，每个单元前各有一个摸底测验。每一单...
3
新概念英语（1）
亚历山大,何其莘
本版是《新概念英语》首次出版以来第一次推出的新版本。...
4
目送
龙应台
目送共由七十四篇散文组成，是为一本极具亲情、感人至深...
5
正能量
理查德·怀斯曼
坚持正向能量，人生无所畏惧！ 到底什么是正能量...
6
好妈妈胜过好老师
尹建莉
本书是近年来难得一见的优秀的家庭教育原创作品，是教育...
7
史玉柱自述
史玉柱 优米网
24年跌宕起伏，功成身退，史玉柱向您娓娓道来，历经时...
8
伊索寓言
伊索
伊索，公元前六世纪出生在爱琴海的萨摩斯岛，身为奴隶，...
9
百年孤独
[哥伦比亚]
《百年孤独》内容复杂，人物众多，情节离奇，手法新颖。...
10
谁的青春不迷茫
刘同
你觉得孤独就对了，那是让你认识自己的机会 你觉得不被...
网络文学排行

烟雨红尘
纵横中文网
铁血读书
起点中文网
17k小说网
凤鸣轩
1
情缠：官姐撩人
风语景言
被下放乡村做老师的乔进，无意中，认识美女单身县长裴若...
2
都市欲望：疯狂的缠绵
愤怒的莲藕
撞破未婚夫与亲妹妹的奸情，崩溃的苏唯选择了夜招牛郎来...
3
艳满杏花村
神妞
只要是他喜欢的女人统统都要收着。什么萝莉，熟女，少妇...
4
靠近美女上司：权色官途
转身回首泪倾城
无根无基的霍晓晨有幸成了县委书记的专职秘书，但随着县...
5
尼姑庵的男保安
记得爱情来过
退伍军人汪海洋因为妻子的不幸去世，从此一撅不振，身心...
6
出轨女人的自白
80后落扬
许静因为与自己的老公各种不和谐而长期备受煎熬，一次意...
7
走村：媳妇好美
风在先
父母过世后，石头跟小婶方桂枝生活在一起，方桂枝是个漂...
8
乡村禁忌：桂花嫂
儿女双全
与世隔绝的卧龙岭上美色如云，但有一个千年的禁忌，通奸...
9
我和极品女人的那些事
猎奇霸王兔子
极品女人，突出的就是极品。上了床是消魂蚀骨的女银魔，...
10
丁二狗的猎艳人生
钓人的鱼
丁二狗隐藏在黑暗里，从发现乡长和户籍女警在野外车震那...
更新小说列表

小说书名/小说章节更新时间作者
异界之苍穹领主079章 游击战术（下）10-04 18:30影舞双
画皮之劫后余生15 上天注定10-04 18:30七里未央
道之英雄第十二章 修炼小成10-04 18:30瓜小王
异世赖少第六章拼爹时代10-04 18:30痴恋红尘梦
龙帝伐天第十九章 抢回来当鼎炉（求包养）10-04 18:30渝小生
我们都输给了时光第五章10-04 18:30暖如炎夏
帝第008章 诡异阿婆10-04 18:30雷营
末世绘第10章 惊魂下水道10-04 18:30云图腾
王者强势归来06 不自量力10-04 18:30黯光养晦
随身带着吊坠葫芦第二十七章 四盒礼10-04 18:30司马预言
都市娱乐
都市生活 青春校园 异能 官场沉浮 商战风云 热血
女生
言情 现代 古代 穿越 都市 奇幻 宫廷 校园
管理经济
企业管理 经济管理 商业 市场营销 金融投资 股票
小说
武侠 科幻 原创 小说 青春 爱情 校园 台言
文学
文学 随笔 散文 杂文 名著 童话 诗歌 神话
历史军事
架空历史 战争幻想 穿越 军旅生活 抗战烽火 军事
人物军事
军事 二战 传记 名人
武侠仙侠
传统武侠 古典仙侠 修真
玄幻奇幻
东方玄幻 西方奇幻 魔法 异界大陆 远古神话 兽族
两性情感
现代都市 家庭婚姻 女性
励志职场
励志 成功 职场 口才
同人耽美
同人 动漫 武侠 小说 耽美 纯爱 影视 百合
恐怖悬疑
恐怖 悬疑 推理 侦探
科幻灵异
未来世界 恐怖惊悚 灵异 悬疑探险 星际战争 推理
游戏竞技
电子竞技 虚拟网游 足球
地区
中国 日本 台湾 美国
年代
民国 清朝 宋朝 唐朝 2012 2011 童年 80后
热门标签
人文其它 东方幻想乡 明朝 史诗大作 都市情感 技术 厚重 影视同人 童书 新颖 未来世界 魔王 死神 社会现实 玄幻魔法 绝对大作 思维 犯罪 公主 最新畅销 悲剧 感悟 坚持 游戏同人 大义凛然 遥远星空 苏联 革命 文革 武侠修真 投资理财 乔装改扮 重生 超能力 此书必火 修真武侠 头等好书 还珠 一女多男 社会
热门作者

窒息优雅 纯洁党 特色 草下金 无断 佗佗 雪娇儿 海菲子 范山己几 小燕子 么么 天蚕土豆 我吃西红柿 唐七公子 若水 方想 张小娴 猫腻 张爱玲 亦舒 严歌苓 席绢 王安忆 石章鱼
作者大全 | 关于我们 | 商务合作 | 友情链接 | 免责声明 | lab
京ICP证:11012693 ©Copyright shupeng.com 2010-2013, all rights reserved
========== http://www.taobao.com/ ==========
手机版亲，欢迎来淘宝！请登录免费注册 会员俱乐部
我要逛
我的淘宝
卖家中心
联系客服
购物车0件
收藏夹
网站导航



宝贝天猫店铺

搜 索高级搜索
使用帮助
短靴新品 卫衣 秋款连衣裙 长袖打底 针织开衫 打底裤 童装汇 男人装 更多
首页天猫聚划算电器城一淘网Hitao妆扮旅行云手机特色中国消费者保障
更多
淘宝服务
购物
司法拍卖 淘金币 天天特价 跳蚤街 全球购 试用 清仓
生活
彩票 淘书城 水电煤 保险 外卖 理财 电影 生活服务 
互动
随便逛逛 淘女郎 淘宝优站 新房装修 闺蜜淘货 值得买
工具
阿里旺旺 支付宝 浏览器
其它
品牌特卖 品牌街 品牌团购 天猫预售 设计品 特价名品
   12345
天猫俱乐部  天天限时抢 十元包邮 品牌特卖  大牌疯抢 1折起包邮

    
公告规则论坛安全中心公益
怎样做中国式文明妈妈马云夫妇捐助新基金会新一代好友互动“来往”最受赞赏公司阿里折桂
免费注册登录免费开店
便民服务
充话费游戏旅行保险电影
号码
面值
售价¥49-49.8
立即充值定期充值查看我的充值账单

主题市场：
店铺上新积分购物明星开店淘代购手机大全虾米音乐
特色购物：
中老年大码女装婚纱礼服买房租房创意站全球美食
所有类目
虚拟
网上营业厅合约机号码3G上网话费充值移动联通电信定期充彩票双色球大乐透快3竞彩足球游戏DNF魔兽天龙八部九阴点卡魔兽CF传奇QQ网页游戏机票酒店客栈旅游门票国际票 ◆◆
抢1000万国庆机票红包！
鞋包配饰
女鞋新品凉鞋拖鞋单鞋帆布鞋男鞋休闲潮鞋帆布鞋板鞋皮鞋配饰腰带帽子围巾手套搭配女包新品真皮大牌单肩钱包男包休闲单肩钱包手提真皮旅行箱包双肩旅行箱包登机 ◆◆
国庆好礼，抽奖不停！
珠宝手表
家电
母婴用品
美食特产
文化音像
玩乐爱好
服饰
女人新品女装连衣裙裤子开衫原创设计美搭牛仔蕾丝衬衫西装男人秋款T恤衬衫牛仔裤夹克男装把妹外套休闲裤针织衫时尚内衣文胸睡衣内裤袜子基础款童装童鞋套装裙子裤子T恤 ◆◆
国庆回馈，最爱腔调！
运动户外
运动鞋跑步板鞋篮球帆布运动馆运动服套装裤子POLO衫T恤卫衣纤体健身死飞泳衣跑步机舞蹈速干衣户外服饰钓鱼凉鞋照明速干衣包配单肩双肩军迷旅行腰包配品牌耐克阿迪特步李宁川崎 ◆◆
组队潜水去，好玩好礼遇！
数码
美容彩妆
家居建材
日用百货
汽车车品
本地生活

爱淘动态 条最新动态

我的淘宝生活
淘宝带你逛
热卖单品 秋装打底裙水晶灯针织衫客厅灯男衬衫香水文胸巧克力男内裤女T恤婚纱牛仔高腰裤男鞋男牛仔 更多
 

========== http://www.alimama.com/ ==========

首页产品介绍会员社区帮助中心关于我们营销推广平台
阿里妈妈会员我是淘宝会员

淘宝联盟
提供2亿淘宝商品库，频道/搜索/组件/活动等多种推广方式选择，灵活的API接口支持，与网站内容完美结合的推广方式。百万成功合作案例，30亿分成规模.
tanx SSP 橱窗推广
橱窗推广华丽升级，入驻tanx SSP平台，为媒体提供全方位的展示推广服务。通过实时竞价技术大幅优化媒体收益，支持媒体控制推广内容，同时提供推广资源管理和精准定向的功能，提高媒体推广资源售卖的效率.
无线联盟
面向无线开发者，提供APP端、无线WAP端的全方位流量变现解决方案，完善的推广投放系统，智能匹配推广模式，为开发者提供了高效、稳定的推广平台和效果监测.
营销推广平台：淘宝直通车 | 淘宝客 | tanx ADX | 网销宝 | 钻石展位
合作伙伴

公告
阿里妈妈邀您共建淘宝客开放体系
淘宝客无线API商品详情页调整
百万寻找“最骚”橙领
“我是橙领”—淘宝客孵化计划
联系客服 规则中心 法律声明 意见反馈 廉正邮箱
阿里巴巴集团 － 阿里巴巴网络： 中国站 国际站 日文站| 淘宝网| 支付宝| 中国雅虎| 口碑网| 阿里妈妈| 一淘网| 集团研究中心 | 淘宝天下
Copyright 2007-2013, 版权所有 alimama.com
    ICP证：浙B2-20070195  
alimm2.mm.cm3.tbsite.net
========== http://www.cmbchina.com/ ==========
简体中文		繁体中文	English		
手机一网通 | 分行网站 | 人才招聘 | 服务网点 | 在线客服 |
网站导航

 主 页
个人业务
公司业务
小企业
信用卡
i理财
商旅预订
今日招行 
热点频道： 金葵花理财 |私人银行 |个人贷款 |出国金融 |现金管理 |空中银行 |财智生活网 |VIP尊享 |投资者关系 |分行网站 |社区 |微博
特别推介
专业版优Key免费送
商旅中心出行易
在线申请生意贷
一卡通M+卡潮人专享
招行卡网购 一定优惠
千家万惠 全城热刷
信用卡免费微信服务
 1 2 3 4 5 6
重要公告 更多>>
·关于国庆期间暂停个人客户跨行转账...	 ·第三方存管银基通2013国庆休市...
·关于2013年国庆节期间上海黄金...	 ·关于上海黄金交易所系统升级的公告
网上银行
 
· 个人银行大众版
· 个人银行专业版
· i理财大众版
· 电子商务专业版
· 企业银行UBANK
· 安全提示
手机银行
 
· 手机一网通
· 个人手机银行
· 企业手机银行
Pad银行
 
· iPad银行
在线服务
 
· 网上支付申请
· 网上商户结账处理
· 信用卡申请
· i理财账户申请
· 在线申请生意贷  
实时金融信息
 
· 外汇实时汇率
· 黄金市场行情
· 国债柜台交易报价
· 理财产品净值
· 基金净值
· 存款利率
· 贷款利率
· 资费标准
 
便捷服务>>更多
 
 
· 网点地图
 
· 微博
 
· 理财经理
 
· 理财计算器
 
· 手机充值
 
· 积分兑换
 
· 酒店预订
 
· 机票预订
企业在线查询服务
 
· 企业年金查询
· 企业自助打印服务
· 公司业务申办渠道
 
分支机构
 
  
股票市场
 

优惠快讯
一卡通 
·招商银行石家庄分行发行“招银-教育爱心联名卡...
·[一定优惠]买电影票，就上招商银行手机银行格...
·[一定优惠]卡巴斯基携招行限时抢购
·[一定优惠]用招行手机支付，赢免费电影票，每...
·[一定优惠]黄金网购两小时，抽奖积分大派“兑...
信用卡 
·账单分期年终奖 3000积分邀您享
·一汽丰田指定车型分期0费率
·官方APP和官方微信用户专享
·欢迎开通每笔消费提醒功能，无论金额大小，确保...
·十年感恩0系你我
理财产品 基金 黄金 外汇 证券 保险 商城
证券市场要闻 
· 今日资金流向与热点板块前瞻(2013.09.30) · 盘后点评:文化传媒大涨 沪指涨0.68% · 韩国股市:收于两周低点 但本月涨幅为一年来最大 · 日本股市:收低2.1%创六周最大单日跌幅 因美国政府... · 台股跌0.69% 收报8173点 证券快捷通道
·国债柜台交易报价	·第三方存管
·财经时评	·金融市场
·国内财经要闻	·股市分析
·研究报告	·行业研究
·大势研判	·板块分析

个人业务
一卡通M+卡“一卡通”M+卡是招商银行发行的年轻人专属的银行卡，多款酷炫卡面设计，全国首创卡面二维码查优惠，高效、便携、实惠的金融服务，立享转账取款免费特权。 个人业务快捷通道
·自助缴费	·个人自助结售汇业务
·国际收入自助申报	·境内汇款
·生意一卡通	·境外汇款
·自助境外汇款业务	·个人贷款

公司业务
小贷通招商银行以通用融资产品加定制化贷款业务，标准流程，快速放贷，弹性还款，满足小企业短、小、频、急融资需求。 公司业务快捷通道
·现金管理	·投资银行
·国际业务	·企业年金
·资产托管	·离岸业务
·融资租赁	·同业金融

信用卡
小积分大乐趣·星巴克全国：799积分
·全家：25积分=1元
·DQ：20积分=1元
·麦当劳299积分起兑 信用卡业务快捷通道
·信用卡申请	·特惠快讯
·推荐亲友办卡	·分期付款购物
·非常E购信用卡商城	·优惠商户
·积分计划	·客户服务

			
今日招行
招行新闻
·招商银行“科技贷”助力科技型中小企业蓬勃发展
·招商银行开放商业平台 助力 “人人公益”新时代
·Hello，微信小招君！
·招商银行打造“供应链联盟”新商业模式
·招商银行：私人银行或成为银行转型突破口
·招行确定配股价格为9.29元
·田惠宇：以服务为主线深入推进二次转型
 招行公告
·2013年度H股配股发行结果及配股股份变...
·关于签署募集资金专户存储监管协议的公告
·关于田惠宇先生行长任职资格核准的公告
·2013年度A股配股股份变动及获配股票上...
·2013年度A股配股发行结果公告
·关于公司章程修订获中国银监会核准的公告
·2013年度A股配股发行提示性公告
 

 
安全说明|网站声明|隐私保密条款|网站地图|友情链接|加入收藏夹|人才招聘|手机一网通


手机一网通
m.cmbchina.com
 
服务热线：95555	 	招商银行客户投诉受理渠道：
境外服务热线：86-755-84391000	私人银行服务专线：40066-95555	电话渠道：95555转7     网络渠道：95555@cmbchina.com
信用卡服务热线：400-820-5555	钻石贵宾服务专线：40068-95555	信函渠道：深圳市福田区深南大道7088号招商银行大厦，
企业年金服务热线：800-830-8855	金葵花贵宾服务专线：40088-95555	          招商银行服务监督管理中心，邮政编码：518040
 		 	 	 招商银行一网通 创建于一九九七年 
© 2013 招商银行 版权所有
ICP许可证号 粤B2-20040497
========== http://www.guao.hk/ ==========
========== http://www.csdn.net/ ==========
您还未登录！|登录|注册|帮助



业界
云计算
移动
研发
程序员杂志
论坛
博客
下载
问答
ITeye
CODE
会议
招聘
培训
外包
EMS
iOS培训
3G培训
Java 培训
.NET培训
PHP培训
联想桌面
华为云计算
英特尔 软件
百度开放云
IBM大学
异构开发
CTO
CMDN
高校

定制你的个性CSDN内容快速入口

开放平台 大数据 移动游戏 视频集萃 开源 云先锋 HTML5 社区之星 推荐频道:ITHRClub 个性阅读 问答 社区大本营 博客导出 博客搬家 极客头条 网盘 推荐服务:腾讯云 联想开发者俱乐部 百度开放云 IBM 新兴技术大学 IBM dW 英特尔 软件 异构开发 PowerLinux技术社区 推荐专区:订阅服务 领袖套餐 团队套餐 MSDN Atlassian JIRA Confluence 企业服务:




订阅杂志iPad版程序员杂志

智慧无处不在——关于“硬件崛起”的思考
2013，智能手机的出货量第一次超过了功能手机，这是我们身边各种智能化设备的起点。过去功能设备仅实现着标准化的功能，而今天的硬件设备已更多融入了软件的基因。

行业热点


腾讯云公测火热开启
最弹性的计算服务，最优的网络质量，最丰富的海量服务运营经验与国内最大的公有云——腾讯云已面向广大开发者火热开启。

Informatica资源中心
我们诚邀您加入Potential at Work 社区。获取最新行业动态、市场发展趋势和 Informatica 产品信息。

联想开发者俱乐部
专注于为用户和开发者传递联想Table PC系列产品特性和理念，提供及时的技术支持和活动信息，打造轻松、高效的学习平台。
查看更多职位信息招聘宣言

亿阳信通
让我们齐心协力、群策群力、竭尽全力、至诚努力，以更大的智勇、更宽的思路、更多的办法、更热的...
蓝港在线
只有怀揣梦想和信仰的团队，才能成为一家受人尊敬的游戏公司。如果你是游戏高手，如果你希望在精...
微软亚太研发集团
当聪明、有创意又激情四射的人们聚集在一起时，结果可以令人震惊，同时可以创造无限机会。
查看更多题目信息编程挑战

子序列的个数
子序列的定义：对于一个序列a=a[1],a[2],......a[n]，则非空序列a'=a[p1],a[p2]......a[pm]为a的一个子序列，其中...
数组排序
本题来自caopengcs，只要你有兴趣，每个人都可以出题（出题入口在hero首页右侧边栏“贡献题目”内）...
字符串消除
给定一个字符串，仅由a,b,c 3种小写字母组成。当出现连续两个不同的字母时，你可以用另外一个字母...
如何发布我的活动活动日历

2013/10/08北京

开源力量公开课第33期：手把手教你用Coco2d-x开发跨平台移动应用
2013/10/10北京

CTO俱乐部晚宴：与视频名企CTO畅谈技术难点及行业发展趋势
2013/10/12杭州

2013中国科技与信息产业周
2013/10/18北京

2013中国互联网产品大会
2013/10/26杭州

PostgreSQL Conference China 2013
2013/10/29深圳

2013年安卓全球开发者大会
2013/11/02北京

2013中国开发者大会
2013/11/05湾仔

OpenStack Summit 香港2013
2013/11/05上海

IBM软件技术峰会
2013/11/19上海

TechCrunch 2013 创新峰会
2013/11/13北京

2013移动开发者大会.中国
2013/11/16上海

2013中华架构师大会
2013/11/23北京

Top100summit 2013全球软件案例研究峰会
2013/12/05北京

2013中国大数据技术大会

【CTO俱乐部】晚宴
与视频名企CTO畅谈技术难点及行业发展趋势

【高校俱乐部】2013年中国人民公安大学巡讲实录 
订阅技术邮件

【云计算】第32期：农民也玩数据挖掘
【移　动】第40期：手把手教学PhoneJS
【程序员速递】第3期：互联网系统架构的演进
【云计算】第31期：从攻到防，从白帽黑客到创业者
【移　动】第39期：分秒钟DIY一个移动网站
【云计算】第30期：高性能Web应用打造攻略
【CTO俱乐部】第5期：新任CTO如何避免决策失控
【移　动】第38期：小米的“高端大气国际化”修炼记
【云计算】第29期：15个步骤创立技术公司
【移　动】第37期：奶昔+海象+游泳池=开源
CSDN Share PPT下载

Ceph in UnitedStack
方兴：在微软公有云WindowsAzure上运用开源软件
基于轻量虚拟化的PaaS平台——RedHat OpenShift
社交与云计算时代：人才获取与招聘创新
罗旭平：DRM保护的现状与发展
王清：大数据中的大安全
放弃Bootstrap&Foundation，迎接Semantic UI？
Semantic UI—完全语义化的前端界面开发框架，跟Bootstrap和Foundation比起来，还是有些不同的，在功能特性上、布局设计上、用户体验上均存在很多差异。
PayPal前CTO 在美国改变世界的乌克兰犹太人
Mailbox：日支撑过亿信息数据库的性能调优及集群迁移
国博微信公众号，一天涨出一个“小道消息”
六年亲历，见证中国大数据技术与应用时代的到来
9月份浏览器份额：IE成最大赢家 Firefox和Chrome均下跌
Facebook与思科联手推免费Wi-Fi服务 搜集用户数据
Google发布Chrome 30：支持图片搜索及安卓端的一些新手势
操作系统市场份额：Windows占90.83%，Linux提升至1.64%
Google发布HTML5开发工具Google Web Designer
一图流：编程语言简史1843-2013
穿在脚上的苹果？苹果聘用Nike设计主管Ben Shaffer
更多

发布一条极客头条

微软研究项目：在纸上打印出来的计算机
lmctfy：Google的开源Linux容器
Intel发布Arduino兼容开源硬件平台Galieo
LOGO中的隐含信息
基于Web的开源开发环境PostgreSQL Studio发布
Pivotal以6500万美元收购加拿大移动开发公司Xtreme Labs
知名毒品网站站长在StackOverflow提问暴露身份而落网
Shumway：来自Mozilla的HTML5 Flash播放器
专题

2013中国互联网安全大会专题报道

SDCC 2013最受欢迎演讲TOP 10

博客推荐

【专栏】2014各大网络公司校招笔试题
【专栏】【cocos2d-x入门实战】微信飞机大战讲解
【贾志军】 Android病毒分析-“吸金幽灵”打劫银行
【杨华】理解Node.js的事件循环
【chenyu】网络库的设计与实现
程序人生

我这么离职是不是有些不讲究
女程序员悲催的感情
苦逼屌丝程序员的初恋
工作8年老IT人的纠结
因为我 公司的领导们闹僵了
吐槽一下今天的面试
嵌入式软件工程师30岁的困惑
恋爱后是不是就不愿意写代码了
谈我这几年的痛苦遭遇
37岁loser程序员现形记
最热下载

【数据库】SQL+Server+数据库基本SQL语句汇总
【开发技术】Windows应用高级编程 C#编程篇
【开发技术】C_C++资料文档解析大集合
【安全技术】189个常用修改注册表REG
【移动开发】android从程序员到架构师之路
要闻回顾

高薪技术排行：大数据居首，苹果相关次之，Java、C等相去甚远

少年才俊：看IT界8个不到20岁的科技公司创始人

或许很受用：苹果、谷歌和亚马逊等公司的14个怪异面试题

探秘Google新搜索引擎算法Hummingbird的16个疑惑

Oracle与Freescale展开深度合作，Java或将一统物联网？


滚动

如何在开发项目里进行自我激励！
针对网上出现的对于程序员工作的各种吐槽和不满，有经验的或是克服了工作中的挫折和疲惫不堪状况的前辈们给出了很好的解决办法。本文收集了各位出谋划策的主要内容，希望对正在工作当中苦恼的你有醍醐灌顶之功效。
一周消息树：Android比iOS 7好的十二个理由 谷歌15岁了

高薪技术排行：大数据居首，苹果相关次之，Java、C等相去甚远
在Hadoop、Big Data、NoSQL霸占了技术领域薪资最高3个岗位的同时，Apple等相关技术也紧随其后，而Java、C、C++等技术岗位的薪资并不占优。
新浪云平台（SAE）
新浪云平台为您提供了千兆多线机房，直接主干网络无需架构设计，无需运维管理，所付仅所用计费模...
GPU Saturday技术沙龙九月活动圆满结束！
GPU Saturday技术沙龙在北京·3WCoffee成功举办。本次活动邀请AMD资深技术人员及清华大学项目研究员就A...
或许很受用：苹果、谷歌和亚马逊等公司的14个怪异面试题
大多数人一生中都会换好几份工作，而待遇优厚的一般都是在那些大公司，而这些大公司在面试中通常都会问一两个怪异的问题，应付这些问题就需要多看多练，本文选取了14个开放式问题，一起来看看和练练吧。
一周热点：Top100高薪技术岗位、高端种菜模式、麻省理工TR35
本周内容精彩纷呈，有最高新的100个技术岗位、月事务过13亿的Salesforce架构、麻省理工TR35之IT界年轻有为创新者、谷歌7年210亿美元的基础设施建设及或将制霸物联网的Java。
BlackBerry Jam Asia 2013香港开幕 现场直击
BlackBerry Jam黑莓亚洲开发者大会于2013年9月26日在香港亚洲国际博览馆召开，业界专家、黑莓高层与黑莓平台的资深开发者共同展示了平台的新特性以及开发的经验和技巧。
谷歌开发网络跟踪新技术：AdID将取代第三方Cookie
日前，谷歌正在开发一种名为“AdID”的匿名跟踪技术，新技术可取代第三方Cookie，旨在帮助广告客户跟踪用户的上网活动，以及标准化追踪系统和跨界（在手机、平板等不同设备上）追踪用户行为。
网关虚拟化+智能化管控开创云数据中心边界防护新纪元
在棱镜门事件之后，企业对数据安全的敏感度已经大大超过以往，保护云数据中心也成为企业安全建设的重中之重。传统边界防护在云数据中心遭遇“困局”，天融信携手英特尔打造新一代云数据中心边界防护解决方案。
看IT界8个不到20岁的科技公司创始人
你在十八九岁的花季雨季在做什么事？在美国那边有这么一群年轻人，不到二十岁的他们辍学开创了属于自己的科技公司，拥有着特殊才华的他们在自己梦想的道路上执着的追求和奋斗，让我们来看看他们的创业点子和公司吧！
Oracle与Freescale展开深度合作，Java或将一统物联网？
随着无线技术愈加成熟，物联网也得到了进一步发展，然而众多的协议、过度的定制化却是让整个生态系统一盘散沙。继Eclipse基金会重拳出击之后，Oracle也与Freescale展开了深度合作，然而他们努力的方向却完全不同。
NDK 安卓* 应用移植方法
本指南用于帮助开发人员将现有的基于 ARM* 的 NDK 应用移植到 x86。
JIRA、Confluence，99元起,限购100套
最受欢迎的社交型企业协同软件Atlassian中文官网入驻CSDN，全中文购买环境，最火爆的项目跟踪工具，...
研发周报：Web前端优化最佳实践及工具集锦
国庆小长假悄然来临，是选择外出旅游还是选择在家给自己充电呢？对此，笔者精挑细选了研发频道的热门看点，供您在这个假期阅读欣赏，让你赚足眼球。
技术开发者如何看实时Web App开发框架？
由CSDN承办的百度Clouda开发者沙龙吸引了众多资深开发人员和JavaScript高手。CSDN在活动中采访了一些企业的技术领头人，他们认为未来Clouda及类似解决方案将成为一种趋势，开发商需要考虑的是如何打造出良好的生态系统。
IT界需求最旺的16项技能
对于刚踏入或者正准备踏入IT界的朋友，你知道市场上哪些技能是最缺乏的吗？你们不妨来看看本文提供的16项技能，选择其中一种最适合你的去钻研，或许某年某月的某一天，你就是该领域的大神。
Office将更强大：微软正开发Office Reader和Office Lens
微软正开发代号为Office Reader的Office，它具有Windows 8风格，整合了Bing和支持手写笔功能，能够跨格式使用，支持网页、Office文档、PDF、电子书和教科书。而为WP8开发的Office Lens，则支持拍照并自动转换内容。
AMD推 "Mantle" API 欲释放GPU全部潜能
AMD发布最新的 API（代号“Mantle”）积极扩展游戏开发者社区，推Mantle旨在方便与游戏开发商的合作优化。Mantel技术可以帮助游戏开发商利用GCN架构的PC和游戏主机之间的共性，使游戏共容于多个平台。
早Google一步，eBay数据中心率先搭载了火星上使用的技术
数据中心是毫无疑问的耗电大户，各大机构也在节能减排上煞费苦心。Google大力发展风电项目，Apple不断扩大燃料电池使用。然而近日的一则消息显示，eBay已早Google和Apple一步，使用燃料电池来驱动整个数据中心。
目标专利2000，技术研发人员占55%，斐讯的厚积薄发
斐讯作为一家以研发为导向的网络与通信设备解决方案的供应商，研发技术人员占比达到55%，专利申请达每月60项以上，产品线覆盖SOHO、ENT、MOBILE三大产品业务单元和ICT、CLOUD服务业务单元，在市场上初显峥嵘。
CTO如何避免决策失控（三）：从CEO角度看CTO的应对能力
对于刚刚从技术岗位走出来的许多CTO来说，往往会遇到一些决策方向的难题。Forbes记者Dan Woods走访了ideeli创始人、CTO Mark Uhrmacher，他在《CTO如何避免决策失控》系列文章中给新任CTO们提供了一些建议。
传福特CEO Alan Mulally目前最有希望执掌微软
据外媒报道，在微软遴选CEO中，目前，曾有过带领公司“起死回生”经历的福特CEO Alan Mulally在候选人中处于领先位置。虽然艾洛普依然是热门人选，但最近几周，Alan Mulally的势头越来越猛了。
PMC发布8系列RAID卡 找准互联网企业需求
PMC企业存储产品事业部产品营销总监Zaki Hassan在接受CSDN专访时表示，无论是对密度要求严苛的互联网企业还是对IOPS有着无尽需求的视频监控行业，Adaptec by PMC 8系列产品都能很好地满足他们的需求。
unity3d教程：利用UILabel和UIButton做一个计数器
阿里巴巴笔试题选解
Android病毒分析报告：新病毒UkyadPay
iOS 7如何为iPhone 5S编译64位应用
还原微信APK中的“发现”和“我”两个模块
iOS动画一点也不神秘
linux内核源码阅读之facebook硬盘加速flashcache之八
Android 匿名共享内存C接口分析
block一点也不神秘————如何利用block进行回调
HTML5 JavaScript实现图片文字识别与提取
查看更多全站动态
核心技术类目
全部主题 数据挖掘 SOA UML Teradata 开放平台 HTML5 创业 开源 移动开发 iOS Android 移动游戏 Windows Phone JavaScript CSS 游戏引擎 云计算 大数据 Hadoop OpenStack 云平台 PHP MongoDB JSON Xcode Node.js 前端开发 神经网络 黑客 安全 Java .NET MySQL textview BigTable web框架 SQL Redis GitHub CouchDB Oracle JavaEE Apple 微软 Google Windows Linux 可穿戴计算 NoSQL Ruby API GPL XAML 交互设计 ASP.NET 界面设计 .NET Java 前端开发 虚拟化 框架 机器学习 数据中心 IE10 敏捷 集群
感受CSDN丰富的服务
RSS活动邮件关注微博订阅微信程序员杂志iPadCSDN Share找工作发布项目
公司简介|招贤纳士|广告服务|银行汇款帐号|联系方式|版权声明|法律顾问|问题报告|合作伙伴
     
QQ客服 微博客服 论坛反馈 联系邮箱：webmaster@csdn.net 服务热线：400-600-2320
京ICP证070598号　京公网安备号：110105000969
电信业务审批[2007]字第380号　电信与信息服务业务经营许可证070598号
北京创新乐知信息技术有限公司 版权所有
世纪乐知(北京)网络技术有限公司 提供技术支持
江苏乐知网络技术有限公司 提供商务支持
Copyright © 1999-2012, CSDN.NET, All Rights Reserved
========== http://www.nashangban.com/candidate/chome ==========
 发布工作发布内推
注册
登录
 页面错误
没有找到你想要的内容

© 2013 哪上班・沪ICP备13033564号
关于我们
用户协议
加入我们
========== http://www.chromi.org/ ==========
502 Bad Gateway

nginx/0.8.54
========== http://map.sogou.com/ ==========
搜狗地图，出行专家，可靠帮手。
提供电子地图浏览、地点搜索、公交自驾路线查询、手机地图、手机导航、高清卫星图，城市仿真三维图等多项服务。
您使用的若是微博客户端。请点击“原网页”（在页面下方或上方），可正常浏览页面。
中国电子地图-高清卫星地图
新闻网页音乐图片视频知识地图更多
登录|注册
API | 意见箱 | Go2map|2013-09-23更新内容：
产品优化：
更丰富的停车场信息：
提供停车场的总车位数、收费标准、出入口
位置等信息供参考
修复其他bug
更多>>
搜 索公 交自 驾
请输入查询内容

更多>>热点推荐
地铁团购美食酒店加油站
景点电影院医院超市银行学校
手机买彩票巨方便，注册赠彩金！
国内最安全可靠的免费游戏平台
2013搜狐社区第二届摄影大赛
数十万款Android软件和游戏供您下载
沈阳论坛合作伙伴商户免费标注
搜狗地图
全国 > 辽宁 > 沈阳[更改]分享地图标记测距清空全屏
©2013 搜狗地图 - GS(2011)6004号 - 甲测资字11002014 - Data©NavInfo&Nav2&CenNavi2公里路况

========== http://qingting.fm/ ==========
========== http://xueqiu.com/4279213792 ==========

注册
登录

＋加关注@他发私信拉黑举报

plp_rapper
保密   辽宁沈阳   
股票3只  讨论4条  
能力圈：
兰亭集势，燕京啤酒，西藏旅游
全部
沪深
港股
美股
指数
股票	当前价	买入目标价	卖出目标价	备注	记录
燕京啤酒	6.43	-	-	-	1展开
西藏发展	11.8	-	-	-	1展开
西藏旅游	8.13	-	-	-	1展开
主贴(4)
收藏
关注(9)
粉丝
在￥6.43时关注股票$燕京啤酒(SZ000729)$。
09-30 09:27来自自选股转发分享收藏评论
在$12.02时关注股票$兰亭集势(LITB)$。
09-25 10:21来自自选股转发分享收藏评论
在￥12.45时关注股票$西藏发展(SZ000752)$。
09-12 12:09来自自选股转发分享收藏评论
在￥8.61时关注股票$西藏旅游(SH600749)$。
09-12 11:48来自自选股转发分享收藏评论

他最近常讨论的股票
兰亭集势(1条讨论)
燕京啤酒(1条讨论)
西藏发展(1条讨论)
西藏旅游(1条讨论)
提示：雪球里任何用户或者嘉宾的发言，都有其特定立场，投资决策需要建立在独立思考之上。
常见问题联系方式加入我们关于雪球© 2013 XUEQIU.COM京ICP证100666号
